id,file_dir,content
0,E:\DATN\dataframe\train_file\0.txt,"Trong Frontend, có 1 thứ gọi là State dùng để thể hiện trạng thái của các thành phần trong app."
1,E:\DATN\dataframe\train_file\0.txt,"Hiểu đơn giản là khi bạn gửi tin nhắn cho Crush thì tin nhắn đó sẽ có các trạng thái là đã gửi, đã nhận và đã xem (còn đã xem mà không trả lời là trạng thái mà bạn tự nhận ra được thì không phải là State sẽ được giải thích dưới đây)."
2,E:\DATN\dataframe\train_file\0.txt,"Các trạng thái trên là giá trị của state trong app, nó thể hiện ra để người dùng nhìn thấy."
3,E:\DATN\dataframe\train_file\0.txt,"Tuy nhiên, cũng có những State được sinh ra để xử lý ngầm trong app mà không thể hiện ra UI."
4,E:\DATN\dataframe\train_file\0.txt,"Ví dụ như khi bạn lướt Newsfeed Facebook, thực chất các nội dung sẽ được phân trang, mỗi lần bạn vuốt lên app sẽ tải nội dung của trang tiếp theo để hiển thị và số trang hiện tại chính là 1 State ngầm."
5,E:\DATN\dataframe\train_file\0.txt,"Một chiếc app sẽ có rất nhiều State, đôi khi chúng hoạt động độc lập, hoặc phụ thuộc cũng như là ràng buộc lẫn nhau nên chúng ta phải quản lý nó."
6,E:\DATN\dataframe\train_file\0.txt,Đó chính là State Management.
7,E:\DATN\dataframe\train_file\0.txt,"State Management chưa bao giờ là điều đơn giản, biết dùng State thì dễ, nhưng để tối ưu nó mới là điều khó"
8,E:\DATN\dataframe\train_file\1.txt,Sentence Vectors: Các phương pháp mô hình hóa câu văn lên không gian vector
9,E:\DATN\dataframe\train_file\1.txt,Bài đăng này đã không được cập nhật trong 3 năm
10,E:\DATN\dataframe\train_file\1.txt,"Trong một bài viết trước đây , mình đã giới thiệu về một số phương pháp biểu diễn vector cho dữ liệu dạng văn bản với đơn vị biểu diễn là từ."
11,E:\DATN\dataframe\train_file\1.txt,"Tuy nhiên, trong quá trình thực hiện các nhiệm vụ thực tế liên quan tới , dạng biễu diễn cho dữ liệu dạng text mà ta thường xuyên phải làm việc cùng lại không chỉ là từ mà còn là các câu văn, đoạn văn."
12,E:\DATN\dataframe\train_file\1.txt,Vậy câu hỏi đặt ra là:
13,E:\DATN\dataframe\train_file\1.txt,"Để có thể làm đầu vào cho các mô hình học máy, phương pháp nào giúp ta mô hình hóa các câu văn, đoạn văn thô đó thành biểu diễn vector?"
14,E:\DATN\dataframe\train_file\1.txt,Có thể sử dụng các phương pháp biểu diễn vector cho từ để biểu diễn vector cho câu hay không?
15,E:\DATN\dataframe\train_file\1.txt,"Trong bài viết này, chúng ta sẽ tìm hiểu điều đó, cùng mình điểm lại một số phương pháp phổ biến để mô hình hóa câu văn lên không gian vector hay còn gọi là ."
16,E:\DATN\dataframe\train_file\1.txt,Chúng ta bắt đầu từ phương pháp đơn giản nhất: Sử dụng word2vec để biểu diễn vector cho câu.
17,E:\DATN\dataframe\train_file\1.txt,Sử dụng word2vec để biểu diễn vector cho câu
18,E:\DATN\dataframe\train_file\1.txt,"Như một lẽ tự nhiên, các bạn sẽ thấy ngay một điều là các câu văn về cơ bản là tập hợp của các từ, khi ta đã có biểu diễn vector cho các từ cấu thành lên câu rồi thì liệu có cần thiết phải tìm một phương pháp khác để tìm biểu diễn vector cho câu không."
19,E:\DATN\dataframe\train_file\1.txt,"Đúng vậy, suy nghĩ của bạn hoàn toàn chính xác và hợp tự nhiên."
20,E:\DATN\dataframe\train_file\1.txt,Chúng ta hoàn toàn có thể lấy tổng hoặc lấy tổng trung bình vector các từ cấu thành lên câu để làm vector biểu diễn cho câu.
21,E:\DATN\dataframe\train_file\1.txt,Một ví dụ đơn giản cho bạn dễ thấy sự hợp tự nhiên mà mình nói tới ở đây.
22,E:\DATN\dataframe\train_file\1.txt,"Mình có 5 loại cocktail khác nhau, mỗi loại được được phân tích thành phần theo 300 loại phân tử phổ biến ngày này."
23,E:\DATN\dataframe\train_file\1.txt,"Và khi mình trộn 5 loại này với nhau mình sẽ được một loại cocktail mới, ly cocktail thứ 6 chứa đủ các thành phần của 5 loại cockltail kia cũng như có đủ vị của 5 loại (Điều này chỉ đúng khi các thành phần này không phản ứng hóa học với nhau)."
24,E:\DATN\dataframe\train_file\1.txt,"Tương tự, chúng ta biết Word2vec là phương pháp biểu diễn vector cho từ, mỗi từ cũng được chúng ta biểu diễn thành vector với trọng số của 100, 150 hay 300 chiều tương tự như các phân tử hóa học kia."
25,E:\DATN\dataframe\train_file\1.txt,"Việc tìm biểu diễn vector cho câu tương tự như khi ta trộn cocktail, ta kết hợp các thành phần vector của từ để làm biểu diễn cho câu."
26,E:\DATN\dataframe\train_file\1.txt,Vậy nếu các thành phần đó phản ứng với nhau như việc các phân tử có thể phản ứng hóa học với nhau thì sao?
27,E:\DATN\dataframe\train_file\1.txt,Chính xác điều đó sẽ xảy ra vì các từ cấu thành nên câu có thể xây dựng lên các câu với nghĩa khác nhau tùy thuộc vào cách sắp xếp của chúng.
28,E:\DATN\dataframe\train_file\1.txt,"Vì vậy, phương pháp này tồn tại những điểm hạn chế nghiêm trọng."
29,E:\DATN\dataframe\train_file\1.txt,Nó bỏ qua thứ tự của các từ trong câu
30,E:\DATN\dataframe\train_file\1.txt,"Nó hoàn toàn bỏ qua ngữ nghĩa, ngữ cảnh của câu"
31,E:\DATN\dataframe\train_file\1.txt,Ví dụ như 2 câu sau có cùng thành phần nhưng mang hai ý nghĩa hoàn toàn trái ngược:
32,E:\DATN\dataframe\train_file\1.txt,"Vì quá yêu bạn gái, chàng trai quyết định từ bỏ game."
33,E:\DATN\dataframe\train_file\1.txt,"Vì quá yêu game, chàng trai quyết định từ bỏ bạn gái."
34,E:\DATN\dataframe\train_file\1.txt,"Để ví dụ minh họa cho phương pháp này, mình sẽ giới thiệu một thư viện vô cùng quen thuộc trong xử lý ngôn ngữ tự nhiên đó là ."
35,E:\DATN\dataframe\train_file\1.txt,"Sử dụng Spacy, bạn có thể dễ dàng lấy ra vector đại diện của một từ có sẵn đã được huấn luyện trước đó."
36,E:\DATN\dataframe\train_file\1.txt,Spacy cũng cho phép lấy luôn ra vector đại diện cho câu theo phương pháp trung bình này.
37,E:\DATN\dataframe\train_file\1.txt,"Để cài Spacy, thực hiện lệnh:"
38,E:\DATN\dataframe\train_file\1.txt,pip install spacy
39,E:\DATN\dataframe\train_file\1.txt,python -m spacy download en_core_web_md
40,E:\DATN\dataframe\train_file\1.txt,import spacy
41,E:\DATN\dataframe\train_file\1.txt,nlp = spacy.load('en_core_web_md')
42,E:\DATN\dataframe\train_file\1.txt,"text = nlp(""I am Iron man"")"
43,E:\DATN\dataframe\train_file\1.txt,v1_vector = 0
44,E:\DATN\dataframe\train_file\1.txt,v2_vector = text.vector # Lấy vector của cả câu
45,E:\DATN\dataframe\train_file\1.txt,for t in text:
46,E:\DATN\dataframe\train_file\1.txt,    v1_vector += t.vector/len(text) # Lấy vector của cả từ chia trung bình
47,E:\DATN\dataframe\train_file\1.txt,print(v1_vector == v2_vector)
48,E:\DATN\dataframe\train_file\1.txt,"Kết quả là True, Spacy chính là đang sử dụng phương pháp này để lấy vector đại diện cho câu."
49,E:\DATN\dataframe\train_file\1.txt,"Các phương pháp tiếp cận dựa trên vector của từ khác như lấy trung bình có trọng số các vector từ hay kết hợp các từ theo thứ tự của cây phân tích ngữ pháp của câu đều rơi vào điểm hạn chế tương tự và không hiểu quả với các trường hợp câu khó phân tích như các câu thiếu, câu không hoàn chỉnh dẫn đến việc phân tích cây ngữ pháp bị sai."
50,E:\DATN\dataframe\train_file\1.txt,"Để khắc phục những điểm hạn chế kể trên, các phương pháp Sentence2vec mới đã được ra đời, sử dụng các tác vụ trung gian để tìm vector biểu diễn cho câu như classification, language modeling, autoencoder, encoder-decoder,... Trong phần tiếp theo, chúng ta cùng tiếp tục điểm qua một vài phương pháp nổi bật trong số đó."
51,E:\DATN\dataframe\train_file\1.txt,Sử dụng pre-trained từ các bài toán Classification
52,E:\DATN\dataframe\train_file\1.txt,"Trong thực tế, khi sử dụng các mô hình phân loại văn bản, các vector ở layer cận cuối cùng, trước khi đưa qua layer cuối cùng sử dụng hàm kích hoạt softmax để phân loại đã có đủ tính tổng quát để đại diện cho câu, đoạn văn bản đó."
53,E:\DATN\dataframe\train_file\1.txt,"Do vậy, ở phương pháp này, ta có thể sử dụng lại model đã được huấn luyện từ các tác vụ phân loại văn bản trước đó ví dụ như Sentiment analysis để sinh ra vector đại diện cho một câu văn mới."
54,E:\DATN\dataframe\train_file\1.txt,"Như trong bài báo , chúng ta ánh xạ các câu vào trong mạng bằng cách sử dụng một pre-trained word embbeding."
55,E:\DATN\dataframe\train_file\1.txt,Sau đó sử dụng một kiến trúc CNN để học ra các đặc trưng được sử dụng cho quá trình phân loại trước khi cho qua một fully connected layer.
56,E:\DATN\dataframe\train_file\1.txt,Vector cuối cùng thu được bởi kiến trúc chính là vector đại diện cho câu.
57,E:\DATN\dataframe\train_file\1.txt,Nhược điểm của phương pháp này là các biểu diễn thông qua các nhiệm vụ trung gian như vậy thường thu được các vector không tổng quát mà gắn chặt với nhiệm vụ trước đó.
58,E:\DATN\dataframe\train_file\1.txt,"Như vậy, các vector này có thể không sử dụng được cho các nhiệm vụ khác mà chỉ được sử dụng cho các nhiệm vụ tương tự hoặc ta phải là tìm vector biển diễn cho câu mà các vector thu được đủ tổng quát cho các nhiệm vụ khác."
59,E:\DATN\dataframe\train_file\1.txt,Paragraph Vectors: Doc2vec
60,E:\DATN\dataframe\train_file\1.txt,"Trong bài báo  của Quốc Lê và Tomas Mikolov năm 2015, các tác giả đã giới thiệu một phương pháp mới có khả năng tìm vector biểu diễn tốt hơn cho các câu văn/đoạn văn thông qua một mô hình tương tự như mô hình word2vec được giới thiệu trước đó cũng bởi Mikolov."
61,E:\DATN\dataframe\train_file\1.txt,Phương pháp được mô tả đơn giản như hình dưới đây.
62,E:\DATN\dataframe\train_file\1.txt,"Nhìn vào hình, bạn có thể thấy mô hình này chỉ khác mô hình word2vec 1 điểm duy nhất là ngoài input là các từ ngữ cảnh, chúng ta còn có thêm 1 giá trị mới là ID của các câu văn."
63,E:\DATN\dataframe\train_file\1.txt,"Về cơ bản, mỗi câu văn được ánh xạ tới một vector duy nhất và mô hình sử dụng các vector của câu văn này kết hợp với các vector từ cấu thành lên câu đó để dự đoán từ tiếp theo cho ngữ cảnh."
64,E:\DATN\dataframe\train_file\1.txt,"Thông qua quá trình đào tạo như vậy, các vector của câu sẽ có thể lưu trữ thông tin về ngữ cảnh, ý nghĩa của câu, những thông tin mà bản thân ý nghĩa của từng từ trong câu không thể thể hiện được."
65,E:\DATN\dataframe\train_file\1.txt,Nó hoạt động như một bộ nhớ lưu trữ của câu.
66,E:\DATN\dataframe\train_file\1.txt,"Cũng chính vì vậy, phương pháp này được gọi là Distributed Memory model (PV-DM)."
67,E:\DATN\dataframe\train_file\1.txt,"Để tìm được vector cho một câu mới, chúng ta sử dụng mô hình trên để dự đoán bằng cách khởi tạo một vector ngẫu nhiên cho câu văn đó."
68,E:\DATN\dataframe\train_file\1.txt,"Trọng số của tất cả các phần còn lại trong mạng được giữ nguyên, sau một vài epochs cho quá trình inference, ta thu được vector trọng số đại diện cho câu đầu vào mới."
69,E:\DATN\dataframe\train_file\1.txt,"Ngoài ra, tương tự như word2vec, chúng ta cũng có một mô hình khác, dự đoán các từ ngẫu nhiên trong ngữ cảnh và được gọi là Distributed BOW (PV-DBOW)."
70,E:\DATN\dataframe\train_file\1.txt,"Việc sử dụng và huấn luyện Doc2vec giờ đây đã khá đơn giản, việc duy nhất bạn phải làm đó là tìm hiểu về thư viên  và học cách sử dụng nó."
71,E:\DATN\dataframe\train_file\1.txt,"Việc sử dụng Gensim để huẩn luyện Doc2vec khá đơn giản, các bạn xem qua tại , mình sẽ không đi vào chi tiết."
72,E:\DATN\dataframe\train_file\1.txt,"Trong khi Doc2vec là một mô hình intra-sentence, tức là ta tìm ra vector đại diện của một câu chỉ dựa vào bản thân câu đấy mà không dựa vào các câu xung quanh thì Skip-thoughts lại là một mô hình inter-sentence."
73,E:\DATN\dataframe\train_file\1.txt,Phương pháp sử dụng tính liên tục của văn bản để dự đoán câu tiếp theo dựa vào câu đã cho.
74,E:\DATN\dataframe\train_file\1.txt,"Tư tưởng của điều này khá giống với thuật toán Skip-gram trong mô hình word2vec, sử dụng thông tin của câu hiện tại để dự đoán ngữ cảnh xung quanh nó, chỉ khác là word2vec sử dụng trừu tượng hóa ở mức từ thì ở skip-thoughts chúng ta trừu tượng hóa ở mức câu."
75,E:\DATN\dataframe\train_file\1.txt,Phương pháp được giới thiệu trong bài báo  của đại học Toronto đầu năm 2015.
76,E:\DATN\dataframe\train_file\1.txt,"Trong bài báo này, các tác giả đề xuất một mô hình encoder-decoder cho quá trình huấn luyện, sử dụng kiến trúc RNN cho cả phần encoding và decoding."
77,E:\DATN\dataframe\train_file\1.txt,"Ngoài sinh ra một vector đại diện cho câu, phương pháp này cũng sinh ra các vector cho các từ trong kho từ vựng."
78,E:\DATN\dataframe\train_file\1.txt,Hàm mục tiêu được tối ưu hóa như sau:
79,E:\DATN\dataframe\train_file\1.txt,"Trong đó, chỉ số"
80,E:\DATN\dataframe\train_file\1.txt,i+1 và
81,E:\DATN\dataframe\train_file\1.txt,i−1 tương ứng thể hiện là các câu tiếp theo và các câu trước đó của câu đầu vào.
82,E:\DATN\dataframe\train_file\1.txt,"Nhìn chung, hàm này đại diện cho tổng logarithm xác suất dự đoán đúng câu tiếp theo và câu trước đó của câu hiện tại."
83,E:\DATN\dataframe\train_file\1.txt,"Như trong ví dụ này, input là bộ 3 câu:"
84,E:\DATN\dataframe\train_file\1.txt,I got back home.
85,E:\DATN\dataframe\train_file\1.txt,I could see the cat on the steps.
86,E:\DATN\dataframe\train_file\1.txt,This was strange.
87,E:\DATN\dataframe\train_file\1.txt,Câu trước: I got back home
88,E:\DATN\dataframe\train_file\1.txt,Câu hiện tại: I could see the cat on the steps
89,E:\DATN\dataframe\train_file\1.txt,Câu sau: This was strange.
90,E:\DATN\dataframe\train_file\1.txt,"Encoder: Đầu vào là chuỗi các vector từ của các từ có trong câu hiện tại, sau đó được chuyển tiếp vào GRU hoặc LSTM."
91,E:\DATN\dataframe\train_file\1.txt,"Decoder: Kiến trúc tương tự như kiến trúc encoder nhưng thay vì chỉ có một, chúng ta có tới 2 decoder cho câu trước và câu sau."
92,E:\DATN\dataframe\train_file\1.txt,Chúng ta có thể tham khảo 1 số source code đã implement skip-thought sau:
93,E:\DATN\dataframe\train_file\1.txt,"Quick thought vector là phương pháp được phát triển dựa trên Skip-thoughts vectors, được giới thiệu trong bài báo  đầu năm 2018."
94,E:\DATN\dataframe\train_file\1.txt,"Tuy nhiên, thay vì sử dụng một lớp decoder để dự đoán các câu tiếp theo của câu hiện tại, Quick thought sử dụng một nhiệm vụ phân loại: Trong những câu được đưa ra, câu nào là câu kế tiếp của câu hiện tại."
95,E:\DATN\dataframe\train_file\1.txt,Sự thay đổi này tạo nên cho nó một lợi thế cạnh tranh mạnh mẽ so với Skip-thought đó là thời gian huấn luyện mô hình.
96,E:\DATN\dataframe\train_file\1.txt,Tốc độ huấn luyện giảm đáng kể khiến nó sử dụng tốt khi ra cần sử dụng với những bộ dữ liệu lớn và cực lớn.
97,E:\DATN\dataframe\train_file\1.txt,FastSent và Denoising autoencoders
98,E:\DATN\dataframe\train_file\1.txt,"FastSent được giới thiệu trong bài báo  vào đầu năm 2016 bởi nhóm tác giả Felix Hill, Kyunghyun Cho và Anna Korhonen."
99,E:\DATN\dataframe\train_file\1.txt,"Mô hình này được đề xuất là một kỹ thuật inter-sentence, về mặt tư tưởng khá giống với mô hình Skip-thoughts trước đó."
100,E:\DATN\dataframe\train_file\1.txt,"Điểm khác biệt duy nhất là nó sử dụng biểu diễn BOW(bag of word) của câu để dự đoán các câu xung quanh, điều này làm cho nó tính toán hiệu quả hơn so với Skip-thoughts, dẫn đến quá trình training được diễn ra nhanh hơn nhiều."
101,E:\DATN\dataframe\train_file\1.txt,"Giả thuyết đào tạo vẫn giữ nguyên, tức là ngữ nghĩa của câu có thể được suy ra từ nội dung của các câu liền kề."
102,E:\DATN\dataframe\train_file\1.txt,"Cũng trong bài báo này, một phiên bản khác của mô hình FastSent cũng được đề xuất được gọi là Denoising autoencoders."
103,E:\DATN\dataframe\train_file\1.txt,"Về cơ bản, nó là một phương pháp intra-sentence trong đó mục tiêu là tái tạo lại một câu từ một phiên bản lỗi/nhiễu của chính nó."
104,E:\DATN\dataframe\train_file\1.txt,"Trong phiên bản sửa đổi của một câu gốc, có 2 cách để tạo nhiễu để sinh ra nó:"
105,E:\DATN\dataframe\train_file\1.txt,"Đối với mỗi từ w trong câu S, xóa từ đó đi theo xác suất xóa là"
106,E:\DATN\dataframe\train_file\1.txt,"Đối với mỗi bigram không chồng chéo nhau, đổi chỗ các phần tử trong bigram với một xác suất là"
107,E:\DATN\dataframe\train_file\1.txt,Vì các chi tiết của mô hình khá giống với Skip-thought nên chúng ta sẽ không nói quá nhiều về nó nữa.
108,E:\DATN\dataframe\train_file\1.txt,Chi tiết bạn có thể xem tại bào báo gốc được giới thiệu phần bên trên.
109,E:\DATN\dataframe\train_file\1.txt,"Không giống như các phương pháp trên sử dụng hướng tiếp cận học máy không giám sát, InferSent sử dụng Stanford Natural Language Inference (SNLI) với 570k cặp câu với 3 nhãn: neutral, contradiction và entailment để huấn luyện một bộ phân loại."
110,E:\DATN\dataframe\train_file\1.txt,Cả hai câu đều được vector hóa bởi một kiến trúc encoder duy nhất.
111,E:\DATN\dataframe\train_file\1.txt,"Sau đó, các vector đại diện cho 2 câu được kết hợp theo 3 cách(Concatenation, Element-wise product, Absolute element-wise) và đưa qua một fully connected layers để thực hiện phân loại 3 lớp."
112,E:\DATN\dataframe\train_file\1.txt,Kiến trúc được mô tả chi tiết trong bài báo  của Facebook AI Research và được mô tả bằng hình vẽ dưới đây.
113,E:\DATN\dataframe\train_file\1.txt,"InferSent được Facebook viết bằng Pytorch, bạn có thể tham khảo và sử dụng tại ."
114,E:\DATN\dataframe\train_file\1.txt,Trên đây là những phương pháp mình cảm thấy phổ biến và thường hay được sử dụng nhất cho tới thời điểm hiện tại.
115,E:\DATN\dataframe\train_file\1.txt,"Ngoài ra, còn có rất nhiều biến thể và đề xuất khác được đưa ra, tuy nhiên, mình sẽ dựa vào mức độ phổ biến và hiệu quả của nó để quyết định bổ sung vào bài sau."
116,E:\DATN\dataframe\train_file\1.txt,Cảm ơn các bạn vì đã đọc bài. )
117,E:\DATN\dataframe\train_file\10.txt,"Khi lập trình dart và flutter chắc hẳn bạn đã gặp và sử dụng abstract class, interface(implements class) và mixin nhưng liệu bạn đã hiểu rõ sự khác nhau giữa chúng, hãy cùng mình đi so sánh để làm rõ điểm khác biệt nhé."
118,E:\DATN\dataframe\train_file\10.txt,Khi bạn extends thì bạn sẽ Chỉ có thể extends 1 class Phải override abstract fun hoặc C1 là abstract class Dùng lại normal fun.
119,E:\DATN\dataframe\train_file\10.txt,Khi bạn implements thì bạn sẽ Có thể implements nhiều class.
120,E:\DATN\dataframe\train_file\10.txt,"Phải override lại tất cả fun, cả normal fun chứ không dùng lại được, hoặc C2 là abstract class."
121,E:\DATN\dataframe\train_file\10.txt,"Mixin là một cách sử dụng lại code của dart, tận dụng ưu điểm và khắc phục nhược điểm của extends và implements."
122,E:\DATN\dataframe\train_file\10.txt,Khi bạn with mixin thì bạn sẽ.
123,E:\DATN\dataframe\train_file\10.txt,Dùng lại được code.
124,E:\DATN\dataframe\train_file\10.txt,Có thể with nhiều mixin.
125,E:\DATN\dataframe\train_file\10.txt,Có thể giới hạn class sử dụng mixin với on Class.
126,E:\DATN\dataframe\train_file\10.txt,Không thể extends mixin.
127,E:\DATN\dataframe\train_file\10.txt,"Nếu implements mixin thì phải override lại tất cả fun hoặc C3 là abstract class, chứ không dùng lại được code."
128,E:\DATN\dataframe\train_file\10.txt,"Trường hợp with nhiều mixin có chung fun, fun của mixin cuối cùng trong list mixin sẽ được thực thi Ở ví dụ trên thì parent class là abstract class, trường hợp parent class là normal class thì cũng tương tự, các bạn khám phá nhé."
129,E:\DATN\dataframe\train_file\11.txt,Tất tần tật về mô hình MVC
130,E:\DATN\dataframe\train_file\11.txt,Kiến thức nền tảng
131,E:\DATN\dataframe\train_file\11.txt,1.1 Tìm hiểu mô hình MVC là gì?
132,E:\DATN\dataframe\train_file\11.txt,MVC là viết tắt của cụm từ “Model-View-Controller“.
133,E:\DATN\dataframe\train_file\11.txt,Đây là mô hình thiết kế được sử dụng trong kỹ thuật phần mềm.
134,E:\DATN\dataframe\train_file\11.txt,MVC là một mẫu kiến trúc phần mềm để tạo lập giao diện người dùng trên máy tính.
135,E:\DATN\dataframe\train_file\11.txt,MVC chia thành ba phần được kết nối với nhau và mỗi thành phần đều có một nhiệm vụ riêng của nó và độc lập với các thành phần khác.
136,E:\DATN\dataframe\train_file\11.txt,"MVC cũng được sử dụng rộng rãi trong phát triển web, sự khác biệt được tùy chỉnh liên quan đến sự có mặt của server - client."
137,E:\DATN\dataframe\train_file\11.txt,1.2 Các thành phần trong MVC
138,E:\DATN\dataframe\train_file\11.txt,Có nhiệm vụ thao tác với Database
139,E:\DATN\dataframe\train_file\11.txt,"Nó chứa tất cả các hàm, các phương thức truy vấn trực tiếp với dữ liệu"
140,E:\DATN\dataframe\train_file\11.txt,"Controller sẽ thông qua các hàm, phương thức đó để lấy dữ liệu rồi gửi qua View"
141,E:\DATN\dataframe\train_file\11.txt,Là giao diện người dùng (User Interface)
142,E:\DATN\dataframe\train_file\11.txt,"Chứa các thành phần tương tác với người dùng như menu, button, image, text,..."
143,E:\DATN\dataframe\train_file\11.txt,Nơi nhận dữ liệu từ Controller và hiển thị
144,E:\DATN\dataframe\train_file\11.txt,Là thành phần trung gian giữa Model và View
145,E:\DATN\dataframe\train_file\11.txt,"Đảm nhận vai trò tiếp nhận yêu cầu từ người dùng, thông qua Model để lấy dữ liệu sau đó thông qua View để hiển thị cho người dùng"
146,E:\DATN\dataframe\train_file\11.txt,1.3 Luồng xử lý trong MVC
147,E:\DATN\dataframe\train_file\11.txt,"Luồng xử lý trong MVC rất đơn giản thôi, với web nó gồm các bước như sau:"
148,E:\DATN\dataframe\train_file\11.txt,Đầu tiên là Request từ người dùng được gửi từ client đến server ( nếu bạn chưa biết về Request)
149,E:\DATN\dataframe\train_file\11.txt,Sau đó Controller dựa vào yêu cầu của người dùng tiến hành giao tiếp với Model để lấy data từ database
150,E:\DATN\dataframe\train_file\11.txt,Cuối cùng Controller gửi dữ liệu vừa lấy được về View và hiển thị ra cho người dùng trên trình duyệt
151,E:\DATN\dataframe\train_file\11.txt,1.4 Tại sao nên sử dụng mô hình MVC
152,E:\DATN\dataframe\train_file\11.txt,Sự độc lập và phát triển song song
153,E:\DATN\dataframe\train_file\11.txt,"Vì mỗi thành phần trong MVC có nhiệm vụ riêng và độc lập với nhau, nên mỗi developer có thể đảm nhiệm một thành phần và không ảnh hưởng đến nhau khiến quá trình phát triển diễn ra nhanh chóng, dễ dàng"
154,E:\DATN\dataframe\train_file\11.txt,Hỗ trợ bất đồng bộ
155,E:\DATN\dataframe\train_file\11.txt,Kỹ thuật bất đồng bộ khiến các ứng dụng được load nhanh hơn đơn giản vì tiến hành chạy nhiều câu lệnh cùng lúc
156,E:\DATN\dataframe\train_file\11.txt,MVC thân thiện với SEO
157,E:\DATN\dataframe\train_file\11.txt,Nền tảng MVC hỗ trợ phát triển các trang web thân thiện với SEO.
158,E:\DATN\dataframe\train_file\11.txt,"Bằng nền tảng này, bạn có thể dễ dàng phát triển các URL thân thiện với SEO để tạo ra nhiều lượt truy cập hơn."
159,E:\DATN\dataframe\train_file\11.txt,1.5 Lịch sử mô hình MVC
160,E:\DATN\dataframe\train_file\11.txt,MVC được tiến sĩ Trygve Reenskaug đưa vào ngôn ngữ lập trình Smalltalk-76 khi ông đến trung tâm Nghiên cứu Xerox Palo Alto (PARC) vào giữa năm 1970.
161,E:\DATN\dataframe\train_file\11.txt,"Sau đó, việc triển khai trở nên phổ biến trong các phiên bản khác của Small- Talk."
162,E:\DATN\dataframe\train_file\11.txt,"Năm 1988, các bài báo “The Journal of Object Technology” – JOT mang lại bước tranh toàn cảnh về MVC mang liệu sự hiệu quả tốt nhất."
163,E:\DATN\dataframe\train_file\11.txt,Áp dụng MVC vào project thực tế
164,E:\DATN\dataframe\train_file\11.txt,"Nếu bạn đọc và hiểu những gì bên trên, thì bạn nắm được cơ bản về mô hình MVC rồi đấy, nhưng khi áp dụng nó vào project thì nó lại là chuyện khác."
165,E:\DATN\dataframe\train_file\11.txt,Ở đây tôi muốn chia sẻ cho bạn một nguồn mà tôi đã giúp tôi hiểu rõ hơn khi tìm hiểu về mô hình MVC.
166,E:\DATN\dataframe\train_file\11.txt,Đó là kênh youtube F8 Official của Sơn Đặng.
167,E:\DATN\dataframe\train_file\11.txt,Trong đó có rất nhiều khóa học hay về web nhưng nếu bạn chỉ muốn hiểu sâu hơn về cách áp dụng mô hình MVC trong project thực tế thì đây là  dành cho bạn.
168,E:\DATN\dataframe\train_file\11.txt,Hãy xem từ video 17: Mô hình MVC nhé!
169,E:\DATN\dataframe\train_file\11.txt,Chúc bạn thành công!!
170,E:\DATN\dataframe\train_file\12.txt,Các công cụ làm việc với JSON
171,E:\DATN\dataframe\train_file\12.txt,"Website những ngày đầu chỉ là những trang web tĩnh - static web (HTML/XHTML + CSS, có thể bao gồm cả Javascript), tĩnh có nghĩa là mỗi khi bạn request đến một đường link/site nào đấy thì nội dung trả về là không thay đổi."
172,E:\DATN\dataframe\train_file\12.txt,Với công nghệ hồi đó thì rất khó để thay đổi content của trang web trong thời gian thực như thế này nếu không có sự phát minh của những kĩ thuật tiên tiến khác.
173,E:\DATN\dataframe\train_file\12.txt,Đó là lý do mà kỹ thuật AJAX (Asynchronous JavaScript And XML) ra đời.
174,E:\DATN\dataframe\train_file\12.txt,Về cơ bản thì AJAX cho phép thay đổi nội dung của trang web mà không cần phải reload toàn bộ trang.
175,E:\DATN\dataframe\train_file\12.txt,"Ví dụ như khi anh Sơn Tùng MTP vừa đăng một bức hình lên FB, chưa có like nào cả, thì khi bạn bấm vào nút like, AJAX sẽ gọi lên server để lấy số like hiện tại và trả về để hiển thị."
176,E:\DATN\dataframe\train_file\12.txt,Do đó khi bạn like thì số like sẽ tự nhảy lên thành N likes chứ không phải là 1.
177,E:\DATN\dataframe\train_file\12.txt,"Trong khoảng thời gian tiếp theo làm việc với AJAX, một số cá nhân phát hiện ra sự bất tiện khi trao đổi dữ diệu giữa client và server bằng XML, nên một dạng data interchange format hiệu quả hơn có tên là JSON đã được sử dụng."
178,E:\DATN\dataframe\train_file\12.txt,Rồi dần dà khi dynamic website và AJAX chiếm lĩnh thị trường internet thì mô hình client-server trở nên vô cùng phổ biến khiến cho JSON theo đó cũng thở thành một tiêu chuẩn cho việc giao tiếp giữa client và server.
179,E:\DATN\dataframe\train_file\12.txt,"Ở thời điểm hiện tại, third party APIs như Google, Facebook....hay các dạng NoSQL database đều sử dụng JSON."
180,E:\DATN\dataframe\train_file\12.txt,"Nói chung là dữ liệu được tổ chức và lữu trữ bằng JSON vô cùng lớn, khả năng trong tương lại gần việc bạn phải làm việc với JSON data gần như là điều chắc chắn."
181,E:\DATN\dataframe\train_file\12.txt,Vì vậy trong bài viết này mình giới thiệu đến các bạn một số kỹ thuật giúp bạn làm việc với JSON nhanh và hiệu quả.
182,E:\DATN\dataframe\train_file\12.txt,Khi làm việc với JSON mình thường làm các tác vụ chủ yếu như sau:
183,E:\DATN\dataframe\train_file\12.txt,Resharping (transform)
184,E:\DATN\dataframe\train_file\12.txt,Edit (Manipulate)
185,E:\DATN\dataframe\train_file\12.txt,Convert to object (programming language)
186,E:\DATN\dataframe\train_file\12.txt,Format JSON
187,E:\DATN\dataframe\train_file\12.txt,Với những file JSON có dữ liệu vừa và nhỏ thì bạn có thể sử dụng một trong các công cụ sau để format/repair JSON:
188,E:\DATN\dataframe\train_file\12.txt,Hay thậm chí dùng Postman cũng được luôn =)) 😂😂
189,E:\DATN\dataframe\train_file\12.txt,Tuy nhiên nếu file JSON chứa một lượng lớn dữ diệu lên tới hàng triệu dòng (> 10MB) thì các tools ở trên thường gây ra tình trạng không phản hồi 🥲.
190,E:\DATN\dataframe\train_file\12.txt,Với trường hợp này thì mình hay dùng plugin Pretty JSON trong Sublime Text.
191,E:\DATN\dataframe\train_file\12.txt,Nếu bạn chưa biết thì cài đặt như sau:
192,E:\DATN\dataframe\train_file\12.txt,Nhấn tổ hợp phím Ctrl + Shift + P và gõ Install Package
193,E:\DATN\dataframe\train_file\12.txt,Click chọn Select Package Control: Install Package từ danh sách kết quả trả về.
194,E:\DATN\dataframe\train_file\12.txt,Click chọn Pretty JSON
195,E:\DATN\dataframe\train_file\12.txt,Reshape JSON
196,E:\DATN\dataframe\train_file\12.txt,Giả sử chúng ta có hai tập tin JSON như sau:
197,E:\DATN\dataframe\train_file\12.txt,"      ""id"": 1,"
198,E:\DATN\dataframe\train_file\12.txt,"          ""text"": ""A"""
199,E:\DATN\dataframe\train_file\12.txt,"      ""id"": 2,"
200,E:\DATN\dataframe\train_file\12.txt,"          ""text"": ""B"""
201,E:\DATN\dataframe\train_file\12.txt,"      ""id"": 1,"
202,E:\DATN\dataframe\train_file\12.txt,"      ""hashtags"": ""A"""
203,E:\DATN\dataframe\train_file\12.txt,"      ""id"": 1,"
204,E:\DATN\dataframe\train_file\12.txt,"      ""hashtags"": ""B"""
205,E:\DATN\dataframe\train_file\12.txt,Yêu cầu đặt ra là phải kiểm tra tất cả các cặpid và text trong tập tin raw-data.json có giống trong tập tin data.json thì bạn sẽ làm thế nào cho hiệu quả?
206,E:\DATN\dataframe\train_file\12.txt,"Bạn có thể làm thủ công, lấy từng id ra search rồi so sánh text, hay viết code chẳng hạn...nhưng về cơ bản là mình nghĩ là không quá nhanh."
207,E:\DATN\dataframe\train_file\12.txt,"Bằng cách sử dụng , công việc của bạn cần làm sẽ đơn giản hơn khá nhiều."
208,E:\DATN\dataframe\train_file\12.txt,Cũng có một cách khác đó là sử dụng JSON query của plugin Pretty JSON mà mình đề cập ở phần trước:
209,E:\DATN\dataframe\train_file\12.txt,Trên Ubuntu thì nhớ sudo apt install jq trước khi sử dụng bạn nhé 😇.
210,E:\DATN\dataframe\train_file\12.txt,"Nếu trong trường hợp gặp file JSON siêu to khổng lồ thì đừng dại gì mà sử dụng GUI, vì nếu không giật lag thì bạn cũng dễ gặp mấy cái lỗi như này =))"
211,E:\DATN\dataframe\train_file\12.txt,Cái thực sự mạnh thì không dễ dùng 🥰🥰.
212,E:\DATN\dataframe\train_file\12.txt,Xét về khoản performance thì command-line vẫn thể hiện sức mạnh áp đảo.
213,E:\DATN\dataframe\train_file\12.txt,Manipulate JSON
214,E:\DATN\dataframe\train_file\12.txt,"Đó là , một command-line utility chuyên để xử lý JSON rất mạnh."
215,E:\DATN\dataframe\train_file\12.txt,Tuy nhiên mình sẽ không đi vào chi tiết trong bài viết này.
216,E:\DATN\dataframe\train_file\12.txt,JSON to POJO
217,E:\DATN\dataframe\train_file\13.txt,"Git là một hệ thống quản lý phiên bản phân tán (Distributed Version Control System – DVCS), là một trong những hệ thống quản lý phiên bản phân tán phổ biến nhất hiện nay."
218,E:\DATN\dataframe\train_file\13.txt,Git cung cấp cho mỗi lập trình viên kho lưu trữ (repository) riêng chứa toàn bộ lịch sử thay đổi.
219,E:\DATN\dataframe\train_file\13.txt,Các dự án thực tế thường có nhiều lập trình viên làm việc song song.
220,E:\DATN\dataframe\train_file\13.txt,"Vì vậy, một hệ thống kiểm soát phiên bản như Git là cần thiết để đảm bảo không có xung đột code giữa các lập trình viên."
221,E:\DATN\dataframe\train_file\13.txt,"Ngoài ra, các yêu cầu trong các dự án như vậy thay đổi thường xuyên."
222,E:\DATN\dataframe\train_file\13.txt,"Vì vậy, một hệ thống kiểm soát phiên bản cho phép các nhà phát triển revert và quay lại phiên bản cũ hơn của code."
223,E:\DATN\dataframe\train_file\13.txt,"Có thể hiểu là 1 bản sao phiên bản của dự án, nơi chúng ta đang thao tác các thay đổi với dữ liệu tại local ."
224,E:\DATN\dataframe\train_file\13.txt,"Ở đây, ta thay đổi file nhưng chưa commit vào cơ sở dữ liệu."
225,E:\DATN\dataframe\train_file\13.txt,"Có thể hiểu chúng ta sẽ có các file data, nếu có bất kỳ thay đổi (thêm mới/chỉnh sửa/xóa bỏ) thì nó sẽ ở trạng thái ""Modified"""
226,E:\DATN\dataframe\train_file\14.txt,Imagen - Mô hình SOTA giải quyết bài toán Text-to-Image
227,E:\DATN\dataframe\train_file\14.txt,"Imagen - mô hình mới được công bố gần đây bởi Google với khả năng generate hình ảnh từ đoạn text mô tả bất kỳ, cho dù ảnh đó không có thật hoặc phi logic."
228,E:\DATN\dataframe\train_file\14.txt,"Phía trên là một ví dụ của ảnh được sinh ra bởi mô hình, rất ấn tượng phải không?"
229,E:\DATN\dataframe\train_file\14.txt,Bạn cũng có thể đọc bài viết tại đây:
230,E:\DATN\dataframe\train_file\14.txt,Tổng quan về các mô hình Generative
231,E:\DATN\dataframe\train_file\14.txt,4 họ model nổi bật trong tác vụ Generation:
232,E:\DATN\dataframe\train_file\14.txt,GAN: Huấn luyện dựa vào cơ chế học đối kháng với 2 thành phần: bộ sinh ảnh và bộ phân loại
233,E:\DATN\dataframe\train_file\14.txt,"VAE: Tìm cách học một mô hình có khả năng biểu diễn phân phối của training data, sau đó sample biến ẩn từ phân phối học được và đưa qua decoder để sinh ảnh"
234,E:\DATN\dataframe\train_file\14.txt,Flow-based model: Sử dụng một chuỗi các phép biến đổi khả nghịch (invertible transform) và sử dụng negative log-likelihood loss nhằm học phân phối dữ liệu một cách tường minh.
235,E:\DATN\dataframe\train_file\14.txt,"Diffusion Model: Từ từ phá hủy cấu trúc của ảnh bằng cách thêm dần nhiễu, mô hình được huấn luyện để học cách phục hồi nhiễu về ảnh ban đầu."
236,E:\DATN\dataframe\train_file\14.txt,"Nhờ sử dụng Diffusion Model làm cốt lõi và tận dụng sức mạnh của mô hình pretrained language lớn, đội ngũ của Google Research Team đã phát triển và tạo ra Imagen với khả năng Generation ảnh hết sức mạnh mẽ."
237,E:\DATN\dataframe\train_file\14.txt,"Nào, cùng tìm hiểu sâu hơn một chút về Diffusion model và điều gì đã khiến nó trở nên rất ""hot"" trong thời gian gần đây thôi."
238,E:\DATN\dataframe\train_file\14.txt,Let's go !
239,E:\DATN\dataframe\train_file\14.txt,Diffusion Model - a new approach for Generation Task
240,E:\DATN\dataframe\train_file\14.txt,2.1 Ý tưởng chung
241,E:\DATN\dataframe\train_file\14.txt,"Xuất phát từ paper năm 2015 bởi các sinh viên đại học Stanford, mô hình được lấy cảm hứng từ nguyên lý khuếch tán trong lĩnh vực nhiệt động lực học, các bạn có thể đọc thêm về paper ."
242,E:\DATN\dataframe\train_file\14.txt,"Ý tưởng chung là phá hủy một phân phối dữ liệu một cách từ từ và có kiểm soát thông qua một chuỗi cách khuếch tán thuận, việc của chúng ta lúc này là tìm cách học một mô hình có thể đảo ngược quá trình khuếch tán đó nhờ đó có thể phục hồi lại cấu trúc dữ liệu ban đầu."
243,E:\DATN\dataframe\train_file\14.txt,Mô hình sau khi học được cách đảo ngược quá trình đó có thể được sử dụng cho tác vụ generation một cách hiệu quả.
244,E:\DATN\dataframe\train_file\14.txt,Ảnh: Minh họa quá trình khuếch tán theo từng step
245,E:\DATN\dataframe\train_file\14.txt,"Cụ thể khi áp dụng với hình ảnh, quá trình khuếch tán thuận là một chuỗi các phép biến đổi bao gồm nhiều step, tại mỗi step ảnh nhiễu từ step trước lại được thêm Gaussion noise để gia tăng độ nhiễu, quá trình thêm nhiễu xảy ra dần dần và dừng lại khi ảnh hoàn toàn chỉ là nhiễu mà không còn đặc trưng thông tin ban đầu."
246,E:\DATN\dataframe\train_file\14.txt,"Từ nhiễu thu được ở cuối quá trình thuận,chúng ta tìm cách khử nhiễu ảnh dần dần theo từng step để thu được ảnh gốc ban đầu."
247,E:\DATN\dataframe\train_file\14.txt,Ảnh: Quá trình sinh ảnh từ trái sang phải bằng cách khử dần nhiễu
248,E:\DATN\dataframe\train_file\14.txt,Câu hỏi đặt ra là tại sao chúng ta phải thực hiện thêm nhiễu và khử nhiễu thông qua một chuỗi rất nhiều các step ?
249,E:\DATN\dataframe\train_file\14.txt,"Lý do khá đơn giản, thay vì trực tiếp giải bài toán khó chúng ta chia nhỏ vấn đề ra và giải quyết dần dần từng chút một, điều này giúp mô hình có thể ""tiêu hóa"" một cách dễ dàng."
250,E:\DATN\dataframe\train_file\14.txt,Vậy chúng ta khử nhiễu bằng cách nào ?
251,E:\DATN\dataframe\train_file\14.txt,"Bằng cách huấn luyện một mô hình nhận đầu vào là ảnh nhiễu và predict ra một phần nhiễu của ảnh đó, ảnh bớt nhiễu có được bằng việc lấy ảnh nhiễu ""trừ"" đi nhiễu đã predict được."
252,E:\DATN\dataframe\train_file\14.txt,"Khi phải học cách tái tạo lại một số lượng lớn các hình ảnh, mô hình sẽ ""vô tình"" nắm bắt được biểu diễn ẩn của phân phối dữ liệu được dùng từ đó sản sinh ra các hình ảnh tương tự."
253,E:\DATN\dataframe\train_file\14.txt,Nền tảng toán học đằng sau diffusion model mình sẽ trình bày ở phần phụ lục cuối bài viết.
254,E:\DATN\dataframe\train_file\14.txt,2.2 Kiến trúc của mạng
255,E:\DATN\dataframe\train_file\14.txt,Chúng ta cần xác định kiến trúc của model sử dụng trong quá trình ngược.
256,E:\DATN\dataframe\train_file\14.txt,"Có thể thấy, quá trình ngược ở trên yêu cầu ảnh input và ảnh ouput phải có cùng kích cỡ đồng thời chúng ta cũng phải thiết kế sao cho model có thể nắm được semantic của ảnh đầu vào ở mức độ pixel nhằm xác định noise."
257,E:\DATN\dataframe\train_file\14.txt,Tác giả của  đã quyết định sử dụng mạng U-Net do nó có thể đáp ứng đầy đủ các yêu cầu trên.
258,E:\DATN\dataframe\train_file\14.txt,Ảnh: Cấu trúc của mạng U-Net được sử dụng
259,E:\DATN\dataframe\train_file\14.txt,Text-to-Image Generative với Diffusion Model
260,E:\DATN\dataframe\train_file\14.txt,"Diffusion model đã được huấn luyện có thể thực hiện sinh ảnh mới tương tự với ảnh trong phân phối dùng để training từ một nhiễu trắng bất kì, tuy nhiên ảnh được sinh ra hoàn toàn ngẫu nhiên mà ta không thể kiểm soát được các đặc điểm cụ thể, hơn nữa ảnh được sinh ra thường có độ phân giải thấp."
261,E:\DATN\dataframe\train_file\14.txt,Để có thể áp dụng diffusion model cho tác vụ Text-to-image chúng ta cần bổ sung một vài cải tiến.
262,E:\DATN\dataframe\train_file\14.txt,Classifier Guidance
263,E:\DATN\dataframe\train_file\14.txt,Là phương pháp làm tăng tính trung thực cũng như chất lượng của hình ảnh với trade-off là giảm sự đa dạng của ảnh được sinh ra.
264,E:\DATN\dataframe\train_file\14.txt,"Nhằm bổ sung thêm thông tin về class của ảnh trong quá trình khuyếch tán , trong  các tác giả đến từ OpenAI có đề xuất bổ sung thêm gradient"
265,E:\DATN\dataframe\train_file\14.txt,c của một mô hình classifier đã được training riêng biệt qua đó hướng quá trình sinh ảnh tập trung vào class được target.
266,E:\DATN\dataframe\train_file\14.txt,"Ảnh: Bên trái là ảnh không được guidance, bên phải là ảnh được guidance (Text: ""Pembroke Welsh corgi"")"
267,E:\DATN\dataframe\train_file\14.txt,Classifier-Free Guidance
268,E:\DATN\dataframe\train_file\14.txt,"Với phương pháp Classifier Guidance bên trên, gradient được lấy từ một pre-trained model riêng biệt ."
269,E:\DATN\dataframe\train_file\14.txt,"Để tránh việc phụ thuộc vào thông tin từ một pre-trained model khác, phương pháp này huấn luyện một cách đồng thời một mô hình diffusion theo cả 2 mục tiêu là unconditional và conditional bằng cách ngẫu nhiên loại bỏ gradient"
270,E:\DATN\dataframe\train_file\14.txt,c trong quá trình training.
271,E:\DATN\dataframe\train_file\14.txt,"Cụ thể, predicted noise được định nghĩa:"
272,E:\DATN\dataframe\train_file\14.txt,"\tilde { \epsilon } _ { \theta } ( z _ { t } , c ) = w \epsilon _ { \theta } ( z _ { t } , c ) + ( 1 - w ) \epsilon _ { \theta } ( z _ { t } )"
273,E:\DATN\dataframe\train_file\14.txt,",c)+(1−w)ϵ"
274,E:\DATN\dataframe\train_file\14.txt,Trong đó
275,E:\DATN\dataframe\train_file\14.txt,"w được gọi là guidance weight,"
276,E:\DATN\dataframe\train_file\14.txt,w càng lớn tương ứng với việc tăng sức ảnh hưởng của gradient
277,E:\DATN\dataframe\train_file\14.txt,Note: Imagen đặc biệt chú trọng vào classifier-free guidance để generate ảnh có sự tương quan nhất với text.
278,E:\DATN\dataframe\train_file\14.txt,Cascaded diffusion models
279,E:\DATN\dataframe\train_file\14.txt,"Ảnh được sinh ra bởi mô hình diffusion thường sẽ cho độ phân giải thấp (VD: 32x32), lý do là bởi độ phân giải thấp thì mô hình sẽ tập trung vào việc generate ảnh với các chi tiết và đặc điểm một cách hợp lý nhất, điều này là khó khăn khi gen luôn ra ảnh với độ phân giải cao."
280,E:\DATN\dataframe\train_file\14.txt,"Do đó paper này đã đề xuất một cấu trúc nhằm tăng dần độ phân giải của ảnh đươc sinh ra bằng cách sử dụng mô hình thác nước với 3 diffusion model nối tiếp nhau, trong đó 2 model phía sau được sử dụng để tăng độ phân giải."
281,E:\DATN\dataframe\train_file\14.txt,Ảnh: Cấu trúc của cascaded diffusion model
282,E:\DATN\dataframe\train_file\14.txt,"Ảnh sau khi được sinh ra bởi mô hình đầu tiên sẽ làm input cho model diffusion thứ 2, tương tự đổi với diffusion model cuối cùng."
283,E:\DATN\dataframe\train_file\14.txt,"Ngoài ra để việc scale up ảnh đạt hiệu quả tốt nhất, các additional signal sử dụng trong conditional diffusion cũng được bổ sung vào input của từng model."
284,E:\DATN\dataframe\train_file\14.txt,Các bạn có thể tham khảo thêm về cascaded diffusion models .
285,E:\DATN\dataframe\train_file\14.txt,Text-to-Image Model
286,E:\DATN\dataframe\train_file\14.txt,"Sử dụng Text Encoder nhằm embedding text input thành vectơ và sử dụng vectơ này làm input cho mô hình Cascaded Diffusion, quá trình generate sẽ sử dụng thông tin từ vectơ text embedding để ảnh được sinh ra giống với mô tả của text."
287,E:\DATN\dataframe\train_file\14.txt,Ảnh: Flow của mô hình sinh ảnh Imagen
288,E:\DATN\dataframe\train_file\14.txt,Sau khi đi qua một vài khái niệm cơ bản giờ hãy phân tích về nhân vật chính của chúng ta.
289,E:\DATN\dataframe\train_file\14.txt,"Imagen được train với bộ dữ liệu xấp xỉ 860 triệu cặp image-text, trong đó gồm 400 triệu datapoint lấy từ bộ public Laion và 460 triệu còn lại lấy từ dữ liệu nội bộ của Google."
290,E:\DATN\dataframe\train_file\14.txt,Điểm khác biệt lớn khiến cho Imagen trở thành mô hình text-to-image mạnh nhất có thể kể đến đó là:
291,E:\DATN\dataframe\train_file\14.txt,Text Encoder sử dụng các mô hình pre-trained language lớn
292,E:\DATN\dataframe\train_file\14.txt,"DALL-E 2, GLIDE hay các mô hình text-to-image trước đó sử dụng Text Encoder được training với bimodal data - tức là data đi theo cặp (image, text caption), ưu điểm là dạng data này giúp mô hình có thể học được sự liên kết giữa ảnh và text tương ứng với nó, tuy nhiên lượng data là quá ít khi so sánh với lượng data thuần text hoặc image ."
293,E:\DATN\dataframe\train_file\14.txt,"Text Encoder được sử dụng trong Imagen là mô hình Encoder T5-XXL , T5 là pre-trained transformer language models mạnh mẽ và được sử dụng cho rất nhiều tác vụ NLP khác nhau."
294,E:\DATN\dataframe\train_file\14.txt,Mô hình T5 được train với lượng dữ liệu chỉ bao gồm text với lượng data là rất lớn khiến cho Encoder T5 có thể nắm bắt được ngữ nghĩa ẩn của câu text rất hiệu quả.
295,E:\DATN\dataframe\train_file\14.txt,"Một điểm đáng chú ý là phần Text Encoder này sẽ được ""frezze"" trong quá trình training."
296,E:\DATN\dataframe\train_file\14.txt,"Ảnh: Minh họa text embedding được ""chèn"" vào tại từng step để traning kết hợp với hình ảnh"
297,E:\DATN\dataframe\train_file\14.txt,Threshoding - khắc phục điểm yếu của classifier-free guidance
298,E:\DATN\dataframe\train_file\14.txt,Việc tăng guidance weight
299,E:\DATN\dataframe\train_file\14.txt,"w giúp mô hình có thể cải độ phù hợp giữa ảnh và text (image-text alignment), tuy nhiên khi"
300,E:\DATN\dataframe\train_file\14.txt,w quá lớn (VD:
301,E:\DATN\dataframe\train_file\14.txt,w>5 ) ảnh được generate sẽ thường trông không tự nhiên hay tệ hơn là ảnh bị bão hòa.
302,E:\DATN\dataframe\train_file\14.txt,Lí do là bởi khi
303,E:\DATN\dataframe\train_file\14.txt,"w lớn, ảnh được predict tại từng step có giá trị pixel vượt quá khoảng giá trị pixel của các ảnh trong training data (VD: khoảng [-1,1])."
304,E:\DATN\dataframe\train_file\14.txt,"Để giải quyết vấn đề này, tác giả Imagen đã nghiên cứu 2 giải pháp:"
305,E:\DATN\dataframe\train_file\14.txt,"Static Thresholding: Thực hiện clipped giá trị các pixel về khoảng [-1,1], cụ thể tất cả các giá trị pixel > 1 sẽ trở thành 1, các giá trị pixel < -1 sẽ trở thành -1."
306,E:\DATN\dataframe\train_file\14.txt,Dynamic Thresholding: Chọn một số lượng các pixel có giá trị dương (VD: 80% lượng pixel > 0) và threshhold trên giá trị
307,E:\DATN\dataframe\train_file\14.txt,s của các pixel đó.
308,E:\DATN\dataframe\train_file\14.txt,Khi giá trị
309,E:\DATN\dataframe\train_file\14.txt,s đó >1 thì clipped giá trị tất cả các pixel về khoảng
310,E:\DATN\dataframe\train_file\14.txt,"[−s,s], sau đó chia tất cả cho"
311,E:\DATN\dataframe\train_file\14.txt,"s để scale về khoảng [-1,1]."
312,E:\DATN\dataframe\train_file\14.txt,Ảnh: So sánh các phương pháp thresholding khi guidance weight tăng dần
313,E:\DATN\dataframe\train_file\14.txt,Phương pháp Dynamic Thresholding tỏ ra cực kỳ hiệu quả với guidance weight
314,E:\DATN\dataframe\train_file\14.txt,"w tăng cao, điều này cho phép Imagen tận dụng triệt để Classifier-free guidance để tối ưu image-text alignment, cho ra kết quả cực kỳ chính xác với text được mô tả mà ảnh vẫn trung thực và không bị bão hòa."
315,E:\DATN\dataframe\train_file\14.txt,Efficient U-Net
316,E:\DATN\dataframe\train_file\14.txt,"Với cascade diffusion model được trình bày ở trên, sau khi đưa qua 2 mạng supper-resolution ảnh thu được có độ phân giải 256x256 nhưng như vậy vẫn chưa đủ."
317,E:\DATN\dataframe\train_file\14.txt,Ảnh được sinh ra bởi Imagen có độ phân giải 1024x1024 và điều này khiến cho mạng U-net trở nên rất nặng với nhiều tham số.
318,E:\DATN\dataframe\train_file\14.txt,"Do đó các tác giả đã cải tiến U-Net để có thể tiết kiệm bộ nhớ, cải thiện thời gian training và inference, đó là Efficien U-Net."
319,E:\DATN\dataframe\train_file\14.txt,"Một số phương pháp được họ sử dụng: đảo thứ tự của các Downsampling (và Upsampling) với các lớp convolution nhằm giảm số lượng tham số, thêm các residual block khi ảnh ở độ phân giải thấp, scale các skip-connection bởi"
320,E:\DATN\dataframe\train_file\14.txt,1 / \sqrt { 2 }
321,E:\DATN\dataframe\train_file\14.txt,Có thể nói rằng generative model nói chung và bài toán text-to-image nói riêng đang là lĩnh vực đang được các ông lớn công nghệ cũng như giới khoa học đặc biệt quan tâm.
322,E:\DATN\dataframe\train_file\14.txt,"Các ứng dụng AI vẽ tranh, Deepfake,... sử dụng các mô hình generative đều thu hút được sự tò mò và phấn khích của người dùng."
323,E:\DATN\dataframe\train_file\14.txt,Mô hình mới đây của Google đã đặt một bước tiến mới trong việc cải thiện chất lượng của các mô hình sinh ảnh đồng thời mở ra nhiều hướng đi mới để tiếp tục cải thiện các mô hình này.
324,E:\DATN\dataframe\train_file\14.txt,Phụ lục: Nền tảng toán học đằng sau Diffusion model
325,E:\DATN\dataframe\train_file\14.txt,Khuếch tán thuận (Foward diffusion process)
326,E:\DATN\dataframe\train_file\14.txt,Một hình ảnh hay 1 datapoint
327,E:\DATN\dataframe\train_file\14.txt,x _ { 0 } \sim q ( x )
328,E:\DATN\dataframe\train_file\14.txt,∼q(x) với
329,E:\DATN\dataframe\train_file\14.txt,q(x) là phân phối của training data sẽ được thêm nhiễu (noise) lần lượt theo từng step.
330,E:\DATN\dataframe\train_file\14.txt,Ta định nghĩa một quá trình thuận
331,E:\DATN\dataframe\train_file\14.txt,q \left ( x _ { t } | x _ { t - 1 } \right )
332,E:\DATN\dataframe\train_file\14.txt,∣x
333,E:\DATN\dataframe\train_file\14.txt,t−1
334,E:\DATN\dataframe\train_file\14.txt,"t là tham số về mặt thời gian theo từng step,"
335,E:\DATN\dataframe\train_file\14.txt,t càng lớn tương ứng với bức ảnh càng nhiều nhiễu.
336,E:\DATN\dataframe\train_file\14.txt,Cụ thể quá trình thuận:
337,E:\DATN\dataframe\train_file\14.txt,"q ( x _ { t } | x _ { t - 1 } ) = N ( x _ { t } ; \sqrt { 1 - \beta _ { t } } x _ { t - 1 } , \beta _ { t } I)"
338,E:\DATN\dataframe\train_file\14.txt,∣x
339,E:\DATN\dataframe\train_file\14.txt,t−1
340,E:\DATN\dataframe\train_file\14.txt,1−β
341,E:\DATN\dataframe\train_file\14.txt,t−1
342,E:\DATN\dataframe\train_file\14.txt,Ở đây ảnh tại step t sẽ được thêm nhiễu Gaussion bằng cách sample ra
343,E:\DATN\dataframe\train_file\14.txt, theo phân phối Gauss với kỳ vọng
344,E:\DATN\dataframe\train_file\14.txt,\sqrt { 1 - \beta _ { t } } x _ { t - 1 }
345,E:\DATN\dataframe\train_file\14.txt,1−β
346,E:\DATN\dataframe\train_file\14.txt,t−1
347,E:\DATN\dataframe\train_file\14.txt, và phương sai
348,E:\DATN\dataframe\train_file\14.txt,\beta _ { t } I
349,E:\DATN\dataframe\train_file\14.txt,I. Lưu ý rằng
350,E:\DATN\dataframe\train_file\14.txt,β ở đây là siêu tham số được thay đổi theo thời gian và kiểm soát bởi variance schedule :
351,E:\DATN\dataframe\train_file\14.txt,"\{ \beta _ { t } \in ( 0 , 1 ) \} _ { t = 1 } ^ { T }"
352,E:\DATN\dataframe\train_file\14.txt,"∈(0,1)}"
353,E:\DATN\dataframe\train_file\14.txt,"Khi số step T đủ lớn, ảnh ban đầu sẽ chuyển thành một ảnh nhiễu trắng hoàn toàn (isotropic noise)."
354,E:\DATN\dataframe\train_file\14.txt,Khuếch tán ngược (Reverse diffusion process)
355,E:\DATN\dataframe\train_file\14.txt,Nếu chúng ta có thể đảo ngược quá trình bên trên thành
356,E:\DATN\dataframe\train_file\14.txt,q \left ( x _ { t -1} | x _ { t } \right )
357,E:\DATN\dataframe\train_file\14.txt,t−1
358,E:\DATN\dataframe\train_file\14.txt,∣x
359,E:\DATN\dataframe\train_file\14.txt,) thì từ một ảnh nhiễu trắng
360,E:\DATN\dataframe\train_file\14.txt,"x _ { T } \sim N ( 0 , I )"
361,E:\DATN\dataframe\train_file\14.txt,"∼N(0,I) chúng ta có thể tái tạo lại ảnh tương đương với mẫu được lấy trong phân phối"
362,E:\DATN\dataframe\train_file\14.txt,q(x) ban đầu.
363,E:\DATN\dataframe\train_file\14.txt,Nhưng thật không may rằng chúng ta không thể tính toán trực tiếp
364,E:\DATN\dataframe\train_file\14.txt,q \left ( x _ { t -1} | x _ { t } \right )
365,E:\DATN\dataframe\train_file\14.txt,t−1
366,E:\DATN\dataframe\train_file\14.txt,∣x
367,E:\DATN\dataframe\train_file\14.txt,) do đó chúng ta cần học một model
368,E:\DATN\dataframe\train_file\14.txt,p _ { \theta }
369,E:\DATN\dataframe\train_file\14.txt, có khả năng xấp xỉ quá trình đảo ngược bên trên.
370,E:\DATN\dataframe\train_file\14.txt,Ta định nghĩa một quá trình ngược:
371,E:\DATN\dataframe\train_file\14.txt,"p( x _ { t-1 } | x _ { t} )=N ( x _ { t -1} ; \mu _ { \theta } ( x _ { t } , t ),\Sigma _ { \theta } ( x _ { t } , t ) )"
372,E:\DATN\dataframe\train_file\14.txt,t−1
373,E:\DATN\dataframe\train_file\14.txt,∣x
374,E:\DATN\dataframe\train_file\14.txt,t−1
375,E:\DATN\dataframe\train_file\14.txt,trong đó
376,E:\DATN\dataframe\train_file\14.txt,\mu _ { \theta }
377,E:\DATN\dataframe\train_file\14.txt,\Sigma _ { \theta }
378,E:\DATN\dataframe\train_file\14.txt, chính là hai tham số mà mô hình của chúng ta cần xấp xỉ.
379,E:\DATN\dataframe\train_file\14.txt,Toàn bộ quá trình biến đổi ngược từ
380,E:\DATN\dataframe\train_file\14.txt,x _ { T }
381,E:\DATN\dataframe\train_file\14.txt,x _ { 0 }
382,E:\DATN\dataframe\train_file\14.txt, có thể được tính toán nhờ vào tính chất độc lập của chuỗi Markov:
383,E:\DATN\dataframe\train_file\14.txt,p _ { \theta } ( x _ { 0:T } ) = p ( x _ { T } ) \prod _ { t = 1 } ^ { T } p _ { \theta } ( x _ { t - 1 } | x _ { t } )
384,E:\DATN\dataframe\train_file\14.txt,t−1
385,E:\DATN\dataframe\train_file\14.txt,∣x
386,E:\DATN\dataframe\train_file\14.txt,Quá trình training
387,E:\DATN\dataframe\train_file\14.txt,Mục tiêu của ta lúc này là minimize hàm negative log-likelihood:
388,E:\DATN\dataframe\train_file\14.txt,- \log p _ { \theta } ( x _ { 0 } )
389,E:\DATN\dataframe\train_file\14.txt,−logp
390,E:\DATN\dataframe\train_file\14.txt,"), tuy nhiên hàm này cũng không trực tiếp tính toán được, do đó chúng ta cần sử dụng một kỹ thuật tương tự đã áp dụng với VAE đó là Variational lower bound:"
391,E:\DATN\dataframe\train_file\14.txt,- \log p _ { \theta } ( x _ { 0 } ) \leq - \log p _ { \theta } ( x _ { 0 } ) + D _ { K L } ( q ( x _ { 1:T } | x _ { 0 } ) \| p _ { \theta } ( x _ { 1:T } | x _ { 0 } ) )
392,E:\DATN\dataframe\train_file\14.txt,−logp
393,E:\DATN\dataframe\train_file\14.txt,)≤−logp
394,E:\DATN\dataframe\train_file\14.txt,∣x
395,E:\DATN\dataframe\train_file\14.txt,)∥p
396,E:\DATN\dataframe\train_file\14.txt,∣x
397,E:\DATN\dataframe\train_file\14.txt,Chúng ta sẽ gián tiếp minimize hàm
398,E:\DATN\dataframe\train_file\14.txt,- \log p _ { \theta } ( x _ { 0 } )
399,E:\DATN\dataframe\train_file\14.txt,−logp
400,E:\DATN\dataframe\train_file\14.txt,") bằng cách minimize đẳng thức phía bên phải.Tiếp tục sử dụng tính chất Bayes và bất đẳng thức Jensen chúng ta có được hàm mục tiêu cần minimize (phần biến đổi này khá dài và phức tạp nên mình không trình bày cụ thể, mình recommend các bạn nên đọc thêm ở link bên dưới để hiểu rõ):"
401,E:\DATN\dataframe\train_file\14.txt,"D _ { K L } ( q ( x _ { T } | x _ { 0 } ) \| p _ { \theta } ( x _ { T } ) ) +\sum_{t=2} ^ { T } D _{ K L } ( q ( x _{ t - 1 } | x _{ t } , x _{ 0 } ) \| p_{ \theta } ( x _{ t - 1 } | x _{ t } ) ) - \log p _{ \theta } ( x _{ 0 } | x _{ 1 } )"
402,E:\DATN\dataframe\train_file\14.txt,∣x
403,E:\DATN\dataframe\train_file\14.txt,)∥p
404,E:\DATN\dataframe\train_file\14.txt,t−1
405,E:\DATN\dataframe\train_file\14.txt,∣x
406,E:\DATN\dataframe\train_file\14.txt,)∥p
407,E:\DATN\dataframe\train_file\14.txt,t−1
408,E:\DATN\dataframe\train_file\14.txt,∣x
409,E:\DATN\dataframe\train_file\14.txt,))−logp
410,E:\DATN\dataframe\train_file\14.txt,∣x
411,E:\DATN\dataframe\train_file\14.txt,Thành phần KL Divergence đầu tiên có thể tính toán trực tiếp do
412,E:\DATN\dataframe\train_file\14.txt,"p _ { \theta } ( x _ { T }), x_{T}, x_{0}"
413,E:\DATN\dataframe\train_file\14.txt, và quá trình
414,E:\DATN\dataframe\train_file\14.txt,"q chúng ta đã biết, lúc này chúng ta chỉ cần minimize:"
415,E:\DATN\dataframe\train_file\14.txt,"\sum_{t=2} ^ { T } D_{ K L } ( q ( x_{ t - 1 } | x_{ t } , x_{ 0 } ) \| p_{ \theta } (x_{ t - 1 } | x_{ t } ) ) - \log p_{ \theta } ( x_{ 0 } | x_{ 1 } )"
416,E:\DATN\dataframe\train_file\14.txt,t−1
417,E:\DATN\dataframe\train_file\14.txt,∣x
418,E:\DATN\dataframe\train_file\14.txt,)∥p
419,E:\DATN\dataframe\train_file\14.txt,t−1
420,E:\DATN\dataframe\train_file\14.txt,∣x
421,E:\DATN\dataframe\train_file\14.txt,))−logp
422,E:\DATN\dataframe\train_file\14.txt,∣x
423,E:\DATN\dataframe\train_file\14.txt,Thành phần KL Divergence đầu tiên so sánh 2 phân phối Gauss
424,E:\DATN\dataframe\train_file\14.txt,"q ( x_{ t - 1 } | x_{ t } , x_{ 0 } )"
425,E:\DATN\dataframe\train_file\14.txt,t−1
426,E:\DATN\dataframe\train_file\14.txt,∣x
427,E:\DATN\dataframe\train_file\14.txt,p_{ \theta } (x_{ t - 1 } | x_{t})
428,E:\DATN\dataframe\train_file\14.txt,t−1
429,E:\DATN\dataframe\train_file\14.txt,∣x
430,E:\DATN\dataframe\train_file\14.txt,) do đó nó nó có thể tính toán ở dạng closed form.
431,E:\DATN\dataframe\train_file\14.txt,Ở trên ta có nói rằng
432,E:\DATN\dataframe\train_file\14.txt,q \left ( x _ { t -1} | x _ { t } \right )
433,E:\DATN\dataframe\train_file\14.txt,t−1
434,E:\DATN\dataframe\train_file\14.txt,∣x
435,E:\DATN\dataframe\train_file\14.txt,) không thể trực tiếp tính toán nhưng thật may là
436,E:\DATN\dataframe\train_file\14.txt,"q ( x_{ t - 1 } | x_{ t } , x_{ 0 } )"
437,E:\DATN\dataframe\train_file\14.txt,t−1
438,E:\DATN\dataframe\train_file\14.txt,∣x
439,E:\DATN\dataframe\train_file\14.txt,) thì lại có thể tính toán được ^^.
440,E:\DATN\dataframe\train_file\14.txt,"q ( x _ { t - 1 } | x _ { t } , x _ { 0 } ) = N ( x _ { t - 1 } ; \tilde { \mu } ( x _ { t } , x _ { 0 } ) , \tilde { \beta } _ { t } \Sigma \rangle"
441,E:\DATN\dataframe\train_file\14.txt,t−1
442,E:\DATN\dataframe\train_file\14.txt,∣x
443,E:\DATN\dataframe\train_file\14.txt,t−1
444,E:\DATN\dataframe\train_file\14.txt,Σ⟩
445,E:\DATN\dataframe\train_file\14.txt,\tilde { \mu }
446,E:\DATN\dataframe\train_file\14.txt,\tilde { \beta }
447,E:\DATN\dataframe\train_file\14.txt, có thể tính toán qua Bayes rule:
448,E:\DATN\dataframe\train_file\14.txt,\tilde { \beta } = \frac { 1 - \tilde { \alpha } _ { t - 1 } } { 1 - \tilde { \alpha } _ { t } } \cdot \beta _ { t } ; \tilde { \mu } = \frac { 1 } { \sqrt { \alpha _ { t } } } ( x _ { t } - \frac { 1 - \alpha _ { t } } { \sqrt { 1 - \tilde { \alpha } _ { t } } } \epsilon _ { t } )
449,E:\DATN\dataframe\train_file\14.txt,1−
450,E:\DATN\dataframe\train_file\14.txt,1−
451,E:\DATN\dataframe\train_file\14.txt,t−1
452,E:\DATN\dataframe\train_file\14.txt,⋅β
453,E:\DATN\dataframe\train_file\14.txt,1−
454,E:\DATN\dataframe\train_file\14.txt,1−α
455,E:\DATN\dataframe\train_file\14.txt,"Cần nhắc lại rằng, chúng ta đang tìm cách huấn luyện mô hình có thể xấp xỉ được xác suất có điều kiện của quá trình biến đổi ngược"
456,E:\DATN\dataframe\train_file\14.txt,"p _ { \theta } ( x _ { t - 1 } | x _ { t } ) = N ( x _ { t - 1 } ; \mu _ { \theta } ( x _ { t } , t ) , \Sigma _ { \theta } ( x _ { t } , t ) )"
457,E:\DATN\dataframe\train_file\14.txt,t−1
458,E:\DATN\dataframe\train_file\14.txt,∣x
459,E:\DATN\dataframe\train_file\14.txt,t−1
460,E:\DATN\dataframe\train_file\14.txt,Chúng ta mong muốn
461,E:\DATN\dataframe\train_file\14.txt,\mu _ { \theta }
462,E:\DATN\dataframe\train_file\14.txt, có thể dự đoán được
463,E:\DATN\dataframe\train_file\14.txt,\tilde { \mu } _ { t }
464,E:\DATN\dataframe\train_file\14.txt," , một phương pháp đơn giản được sử dụng để tính toán lỗi đó là MSE loss:"
465,E:\DATN\dataframe\train_file\14.txt,"L _ { t } = { \mathrm { E } } _ { x _ { 0 } , \epsilon } [ \frac { 1 } { 2 \| \Sigma _ { \theta } ( x _ { t } , t ) \| ^ { 2 } } \| \tilde { \mu } _ { t } ( x _ { t } , x _ { 0 } ) - \mu _ { \theta } ( x _ { t } , t ) \| ^ { 2 } ]"
466,E:\DATN\dataframe\train_file\14.txt,2∥Σ
467,E:\DATN\dataframe\train_file\14.txt,",t)∥"
468,E:\DATN\dataframe\train_file\14.txt,)−μ
469,E:\DATN\dataframe\train_file\14.txt,",t)∥"
470,E:\DATN\dataframe\train_file\14.txt,Và vì
471,E:\DATN\dataframe\train_file\14.txt,\tilde { \mu } _ { t }
472,E:\DATN\dataframe\train_file\14.txt,\mu _ { \theta }
473,E:\DATN\dataframe\train_file\14.txt, có thể tính toán thông qua noise
474,E:\DATN\dataframe\train_file\14.txt,"\epsilon _ { t }, \epsilon_{\theta}"
475,E:\DATN\dataframe\train_file\14.txt, và input
476,E:\DATN\dataframe\train_file\14.txt," theo từng step, cuối cùng mô hình chỉ cần predict ra noise đã được thêm vào:"
477,E:\DATN\dataframe\train_file\14.txt,"L _ { t } ^ { \operatorname { s i m p l e } } = E _ { t \sim [ l , T ] , x _ { 0 } , \epsilon _ { t } } [ \| \epsilon _ { t } - \epsilon _ { \theta } ( x _ { t } , t ) \| ^ { 2 } ]"
478,E:\DATN\dataframe\train_file\14.txt,"t∼[l,T],x"
479,E:\DATN\dataframe\train_file\14.txt,[∥ϵ
480,E:\DATN\dataframe\train_file\14.txt,−ϵ
481,E:\DATN\dataframe\train_file\14.txt,",t)∥"
482,E:\DATN\dataframe\train_file\14.txt,Chi tiết phần biến đổi toán học các bạn có thể tham khảo .
483,E:\DATN\dataframe\train_file\14.txt,"Khi đã xác định được noise đã được thêm vào trong quá trình thuận, tại từng step chúng ta có thể thu được ảnh bớt nhiễu bằng cách lấy ảnh nhiễu ""trừ"" đi noise."
484,E:\DATN\dataframe\train_file\15.txt,[Declarative Programming + Elm] Math & Type Variable
485,E:\DATN\dataframe\train_file\15.txt,Bây giờ chúng ta sẽ bắt đầu nói về các điểm cần lưu ý về các thao tác xử lý phổ biến đối với các kiểu dữ liệu đã được giới thiệu trong bài viết trước.
486,E:\DATN\dataframe\train_file\15.txt,"Tuy nhiên thì trước khi bắt đầu với các ví dụ chi tiết, mình vẫn muốn liệt kê lại danh sách tên các kiểu dữ liệu ở đây để chúng ta có thể tiện theo dõi mạch logic và liên hệ giữa các kiểu (nếu có) -"
487,E:\DATN\dataframe\train_file\15.txt,"Float, Int, number - các giá trị số học."
488,E:\DATN\dataframe\train_file\15.txt,"Ví dụ: 10.01, 10, ..."
489,E:\DATN\dataframe\train_file\15.txt,Bool - các giá trị nhận định logic True và False
490,E:\DATN\dataframe\train_file\15.txt,Char - các ký tự đơn.
491,E:\DATN\dataframe\train_file\15.txt,"Ví dụ: 'A', 'z', ..."
492,E:\DATN\dataframe\train_file\15.txt,String - các chuỗi văn bản.
493,E:\DATN\dataframe\train_file\15.txt,"Ví dụ: ""Elm Language"""
494,E:\DATN\dataframe\train_file\15.txt,List - lưu trữ các giá trị cùng kiểu theo dạng danh sách liệt kê
495,E:\DATN\dataframe\train_file\15.txt,Record - mô tả các bản ghi giống với C struct và JS Object
496,E:\DATN\dataframe\train_file\15.txt,Tuple - mô tả các bản ghi ngắn gọn không có tên trường dữ liệu
497,E:\DATN\dataframe\train_file\15.txt,Ok.. chúng ta bắt đầu thôi.
498,E:\DATN\dataframe\train_file\15.txt,Để tiết kiệm thời gian thì chúng ta sẽ tương tác với Elm REPL giống như bài viết trước.
499,E:\DATN\dataframe\train_file\15.txt,"Tuy nhiên, bạn có thể tạo các tệp module để lưu lại code ví dụ nếu muốn."
500,E:\DATN\dataframe\train_file\15.txt,cd Documents && cd learn-elm
501,E:\DATN\dataframe\train_file\15.txt,elm repl
502,E:\DATN\dataframe\train_file\15.txt,Các phép tính số học
503,E:\DATN\dataframe\train_file\15.txt,Không có gì khác biệt nhiều so với các ngôn ngữ Imperative như C hay JavaScript mà chúng ta đã biết.
504,E:\DATN\dataframe\train_file\15.txt,"Các phép tính +, -, *, / căn bản."
505,E:\DATN\dataframe\train_file\15.txt,1.0 + 2.0
506,E:\DATN\dataframe\train_file\15.txt,-- 3 : Float
507,E:\DATN\dataframe\train_file\15.txt,"Tuy nhiên, lưu ý đầu tiên là Elm không hỗ trợ tự động chuyển kiểu dữ liệu từ Int sang Float."
508,E:\DATN\dataframe\train_file\15.txt,"Giá trị trả về bởi round được định kiểu Int, và 1 : Int thì không thể cộng trực tiếp với 2.0 : Float -"
509,E:\DATN\dataframe\train_file\15.txt,(round 1.0) + 2.0
510,E:\DATN\dataframe\train_file\15.txt,-- thông báo lỗi
511,E:\DATN\dataframe\train_file\15.txt,Thế nhưng 1 : number và 2.0 : Float thì lại hợp lệ với phép tính + như vậy.
512,E:\DATN\dataframe\train_file\15.txt,Về lý do thì chúng ta sẽ để dành cho hạng mục cuối bài.
513,E:\DATN\dataframe\train_file\15.txt,1 + 2.0
514,E:\DATN\dataframe\train_file\15.txt,-- 3 : Float
515,E:\DATN\dataframe\train_file\15.txt,Có phép chia lấy phần nguyên với ký hiệu // thì mình chưa gặp bao giờ.
516,E:\DATN\dataframe\train_file\15.txt,9 // 2
517,E:\DATN\dataframe\train_file\15.txt,-- 4 : Int
518,E:\DATN\dataframe\train_file\15.txt,"Phép lũy thừa sử dụng ký hiệu ^, khác với ** của JS."
519,E:\DATN\dataframe\train_file\15.txt,2 ^ 10
520,E:\DATN\dataframe\train_file\15.txt,-- 1024 : number
521,E:\DATN\dataframe\train_file\15.txt,Ngoài ra thì các thao tác khác sẽ được xử lý bởi các sub-program.
522,E:\DATN\dataframe\train_file\15.txt,Ví dụ như phép chia lấy phần dư 9 % 2 trong JS -
523,E:\DATN\dataframe\train_file\15.txt,remainderBy 2 9
524,E:\DATN\dataframe\train_file\15.txt,-- 1 : Int
525,E:\DATN\dataframe\train_file\15.txt,Lấy giá trị nghịch đảo của một số trong Elm sẽ không sử dụng phép toán -.
526,E:\DATN\dataframe\train_file\15.txt,Lý do thì mình xin để dành sang hẳn Sub-Series tiếp theo.
527,E:\DATN\dataframe\train_file\15.txt,Ở đây chúng ta cứ xem như quy ước xử lý đặc biệt và sử dụng như vậy đi.
528,E:\DATN\dataframe\train_file\15.txt,negate -9
529,E:\DATN\dataframe\train_file\15.txt,-- 9 : number
530,E:\DATN\dataframe\train_file\15.txt,Giá trị tuyệt đối -
531,E:\DATN\dataframe\train_file\15.txt,abs 10.01
532,E:\DATN\dataframe\train_file\15.txt,-- 10.01 : Float
533,E:\DATN\dataframe\train_file\15.txt,abs -10.01
534,E:\DATN\dataframe\train_file\15.txt,-- 10.01 : Float
535,E:\DATN\dataframe\train_file\15.txt,Căn bậc 2 -
536,E:\DATN\dataframe\train_file\15.txt,sqrt 81
537,E:\DATN\dataframe\train_file\15.txt,-- 9 : Float
538,E:\DATN\dataframe\train_file\15.txt,Làm tròn giá trị tới biên gần -
539,E:\DATN\dataframe\train_file\15.txt,round 10.01
540,E:\DATN\dataframe\train_file\15.txt,-- 10 : Int
541,E:\DATN\dataframe\train_file\15.txt,round 1.9
542,E:\DATN\dataframe\train_file\15.txt,-- 2 : Int
543,E:\DATN\dataframe\train_file\15.txt,Làm tròn lên và xuống -
544,E:\DATN\dataframe\train_file\15.txt,ceiling 9.5
545,E:\DATN\dataframe\train_file\15.txt,-- 10 : Int
546,E:\DATN\dataframe\train_file\15.txt,floor 9.5
547,E:\DATN\dataframe\train_file\15.txt,-- 9 : Int
548,E:\DATN\dataframe\train_file\15.txt,Suy giảm về gốc 0 -
549,E:\DATN\dataframe\train_file\15.txt,truncate 9.8
550,E:\DATN\dataframe\train_file\15.txt,-- 9 : Int
551,E:\DATN\dataframe\train_file\15.txt,truncate -9.8
552,E:\DATN\dataframe\train_file\15.txt,-- -9 : Int
553,E:\DATN\dataframe\train_file\15.txt,Kiểm tra NaN của một giá trị thu được từ một phép thực thi trả về kiểu Float -
554,E:\DATN\dataframe\train_file\15.txt,isNaN (0/0)       -- True
555,E:\DATN\dataframe\train_file\15.txt,isNaN (sqrt -1)   -- True : Bool
556,E:\DATN\dataframe\train_file\15.txt,isNaN 1           -- False : Bool
557,E:\DATN\dataframe\train_file\15.txt,"Phép chia cho 0/0 và lấy căn bậc hai của -1 không thể cho kết quả có ý nghĩa số học, do đó nên chúng ta thu được giá trị NaN."
558,E:\DATN\dataframe\train_file\15.txt,Tuy nhiên trường hợp dưới dây thì kết quả là dương vô cùng Infinite vẫn thuộc kiểu Float.
559,E:\DATN\dataframe\train_file\15.txt,isNaN (1/0)
560,E:\DATN\dataframe\train_file\15.txt,-- False : Bool
561,E:\DATN\dataframe\train_file\15.txt,và để kiểm tra một giá trị trả về từ một thao tác định kiểu Float có phải là Infinite hay không -
562,E:\DATN\dataframe\train_file\15.txt,isInfinite (0/0)       -- False
563,E:\DATN\dataframe\train_file\15.txt,isInfinite (sqrt -1)   -- False
564,E:\DATN\dataframe\train_file\15.txt,isInfinite (1/0)       -- True
565,E:\DATN\dataframe\train_file\15.txt,isInfinite 1           -- False
566,E:\DATN\dataframe\train_file\15.txt,"NaN và Infinite về căn bản là khác nhau: NaN không có ý nghĩa số học, còn Infinite thì là một giá trị số học."
567,E:\DATN\dataframe\train_file\15.txt,Các phép tính logic
568,E:\DATN\dataframe\train_file\15.txt,Các ký hiệu && và || được Elm sử dụng với ý nghĩa tương tự như C và JS.
569,E:\DATN\dataframe\train_file\15.txt,"Tuy nhiên phép phủ định hay còn được gọi là lấy nghịch đảo một giá trị Bool được xử lý bằng chương trình not, thay vì ký hiệu !"
570,E:\DATN\dataframe\train_file\15.txt,như C và JS.
571,E:\DATN\dataframe\train_file\15.txt,not True
572,E:\DATN\dataframe\train_file\15.txt,-- False : Bool
573,E:\DATN\dataframe\train_file\15.txt,not False
574,E:\DATN\dataframe\train_file\15.txt,-- True : Bool
575,E:\DATN\dataframe\train_file\15.txt,"Các phép nhận định so sánh, hầu hết vẫn sử dụng các ký hiệu như chúng ta đã biết là ==, >, <, >=, <=."
576,E:\DATN\dataframe\train_file\15.txt,"Duy nhất có ký hiệu != trong C và JS để kiểm tra nhận định hai giá trị là khác nhau, được Elm thay thế bởi /=."
577,E:\DATN\dataframe\train_file\15.txt,1 /= 0.9
578,E:\DATN\dataframe\train_file\15.txt,-- True : Bool
579,E:\DATN\dataframe\train_file\15.txt,1 /= 1.0
580,E:\DATN\dataframe\train_file\15.txt,-- False : Bool
581,E:\DATN\dataframe\train_file\15.txt,Type Variable
582,E:\DATN\dataframe\train_file\15.txt,Các ngôn ngữ thuần Declarative hầu hết đều được xây dựng với một tinh thần chung - đó là khả năng định kiểu rất mạnh mẽ và nghiêm ngặt strong-typing.
583,E:\DATN\dataframe\train_file\15.txt,Và ở đây chúng ta có Elm là một trong số đó.
584,E:\DATN\dataframe\train_file\15.txt,Cụ thể là thông báo lỗi như ví dụ phép tính + giữa một giá trị Int và một giá trị Float mà chúng ta đã nhìn thấy ở phần đầu của bài viết.
585,E:\DATN\dataframe\train_file\15.txt,"Mặc dù trình biên dịch compiler của Elm đã có đủ thông tin về các giá trị nhận được trước khi thực hiện phép tính, tuy nhiên chỉ đơn giản là Elm không hỗ trợ tự động chuyển đổi kiểu ngầm định trong trường hợp này."
586,E:\DATN\dataframe\train_file\15.txt,Và chúng ta sẽ cần phải thực hiện việc chuyển kiểu dữ liệu trong code của mình -
587,E:\DATN\dataframe\train_file\15.txt,(toFloat (round 1.0)) + 2.0
588,E:\DATN\dataframe\train_file\15.txt,-- 3 : Float
589,E:\DATN\dataframe\train_file\15.txt,Ồ thế nhưng tại sao phép tính 1 + 2.0 lại không có thông báo lỗi ?
590,E:\DATN\dataframe\train_file\15.txt,Giá trị 1 trả về bởi  được định kiểu là Int.
591,E:\DATN\dataframe\train_file\15.txt,"Còn giá trị 1 mà chúng ta viết trực tiếp vào trong tệp code của chúng ta thì lại chưa được định kiểu cố định, do đó nên Elm sẽ xem là một giá trị thuộc kiểu biến thiên number."
592,E:\DATN\dataframe\train_file\15.txt,"Khái niệm kiểu biến thiên Type Variable, có thể hiểu đơn giản là một kiểu dữ liệu bất kỳ mà trình biên dịch compiler không tìm thấy thông tin định kiểu rõ ràng trong code."
593,E:\DATN\dataframe\train_file\15.txt,Và sẽ cố gắng tìm ra một logic xử lý thành công phù hợp nhất.
594,E:\DATN\dataframe\train_file\15.txt,Chính xác thì một kiểu biến thiên a được hiểu là một kiểu Union bao gồm tất cả các kiểu dữ liệu mà trình biên dịch thu thập được trong code định nghĩa của toàn bộ chương trình project.
595,E:\DATN\dataframe\train_file\15.txt,"Tuy nhiên, Elm cũng có tạo ra một vài Type Variable với khả năng hữu hạn hơn so với a. Đó là -"
596,E:\DATN\dataframe\train_file\15.txt,number - là một giá trị số học; Vì vậy nên có thể là Float hoặc Int.
597,E:\DATN\dataframe\train_file\15.txt,"comparable - là một giá trị có thể so sánh được bằng chương trình ; Bao gồm Int, Float, Char, String, và List/Tupple của các kiểu đó."
598,E:\DATN\dataframe\train_file\15.txt,appendable - là một giá trị có thể thực hiện các thao tác nối ghép nội dung; Vì vậy nên có thể là String hoặc List.
599,E:\DATN\dataframe\train_file\15.txt,compappend - là một giá trị vừa thuộc comparable và vừa thuộc appendable.
600,E:\DATN\dataframe\train_file\15.txt,Như vậy khi trình biên dịch đọc phép tính 1 + 2.0 thì giá trị 2.0 đã có đủ thông tin định kiểu rõ ràng là Float do có dấu phẩy thập phân .
601,E:\DATN\dataframe\train_file\15.txt,; Còn giá trị 1 thì chưa có thông tin định kiểu cụ thể nên sẽ là number.
602,E:\DATN\dataframe\train_file\15.txt,Logic thành công phù hợp nhất là Float + Float và chúng ta có logic được biên dịch là 1.0 + 2.0.
603,E:\DATN\dataframe\train_file\15.txt,Phép tính được thực hiện và không có thông báo lỗi.
604,E:\DATN\dataframe\train_file\15.txt,Nhân tiện sau khi giới thiệu xong khái niệm kiểu biến thiên Type Variable thì chúng ta đang có vài kiểu được định nghĩa sẵn như đã được liệt kê ở trên.
605,E:\DATN\dataframe\train_file\15.txt,"Cái number thì chúng ta đã vừa sử dụng để làm ví dụ minh họa ở trên rồi, và trong số mấy kiểu còn lại thì ở đây chúng ta đã có đủ kiến thức để nói về comparable."
606,E:\DATN\dataframe\train_file\15.txt,Một giá trị thuộc kiểu comparable sẽ có thể được sử dụng trong một thao tác so sánh bằng chương trình .
607,E:\DATN\dataframe\train_file\15.txt,Ở chỗ này chúng ta cần lưu ý một chút để tránh nhầm lẫn.
608,E:\DATN\dataframe\train_file\15.txt,"Các phép toán logic >, <, ==, /=, v.v... mà trả về các giá trị Bool thì được sử dụng để kiểm tra một nhận định so sánh."
609,E:\DATN\dataframe\train_file\15.txt,Hay nói cách khác là để kiểm tra một sự đánh giá.
610,E:\DATN\dataframe\train_file\15.txt,Và thao tác kiểm tra như vậy sẽ mang ý nghĩa có phần hơi khác một chút với thao tác so sánh bằng  mà chúng ta vừa nói ở trên.
611,E:\DATN\dataframe\train_file\15.txt,"Một phép kiểm tra a == b sẽ đưa ra kết quả trả lời cho câu hỏi: ""a có giá trị bằng b. Đúng hay Sai?"
612,E:\DATN\dataframe\train_file\15.txt,"Nếu đúng thì chọn True, còn nếu sai thì chọn False."
613,E:\DATN\dataframe\train_file\15.txt,"30 giây suy nghĩ bắt đầu !"""
614,E:\DATN\dataframe\train_file\15.txt,1 == 0.9
615,E:\DATN\dataframe\train_file\15.txt,-- False : Bool
616,E:\DATN\dataframe\train_file\15.txt,"Còn một phép so sánh compare a b, ở mặt khác, sẽ đưa ra kết quả trả lời cho câu hỏi: ""a so với b thì thế nào?"
617,E:\DATN\dataframe\train_file\15.txt,Bằng à EQ?
618,E:\DATN\dataframe\train_file\15.txt,Hay nhỏ hơn LT?
619,E:\DATN\dataframe\train_file\15.txt,Hay lớn hơn GT?
620,E:\DATN\dataframe\train_file\15.txt,"Trả lời ngay và luôn !"""
621,E:\DATN\dataframe\train_file\15.txt,compare 1 0.9
622,E:\DATN\dataframe\train_file\15.txt,-- GT : Order
623,E:\DATN\dataframe\train_file\15.txt,"Kết quả của một phép so sánh, sau đó, hiển nhiên cũng sẽ có thể được sử dụng để điều hướng logic hoạt động của code mà chúng ta xây dựng."
624,E:\DATN\dataframe\train_file\15.txt,"Và Elm cũng có một vài chương trình cơ bản, rất hữu ích, cần sử dụng tới các giá trị Order này."
625,E:\DATN\dataframe\train_file\15.txt,-- max : comparable -> comparable -> comparable
626,E:\DATN\dataframe\train_file\15.txt,max 1 0.9
627,E:\DATN\dataframe\train_file\15.txt,-- min : comparable -> comparable -> comparable
628,E:\DATN\dataframe\train_file\15.txt,"min ""abc"" ""xyz"""
629,E:\DATN\dataframe\train_file\16.txt,Xây dựng scan port với python và thư viện scapy
630,E:\DATN\dataframe\train_file\16.txt,"Chào mọi người, sau 2 bài viết về các phương pháp phát hiện live host và scan port bằng nmap, hôm nay mình sẽ hướng dẫn xây dựng 1 công cụ đơn giản có thể quét live host và scan port bằng cách tạo ra các gói tin, gửi chúng đi và chờ đợi phản hồi."
631,E:\DATN\dataframe\train_file\16.txt,"Từ các phản hồi, ta có thể phân tích và đưa ra các kết quả."
632,E:\DATN\dataframe\train_file\16.txt,"Để hiểu rõ cách hoạt động của các phương pháp scan, từ đó giúp xây dựng gói tin, các bạn nên đọc qua 2 bài viết trước của mình nằm trong series này."
633,E:\DATN\dataframe\train_file\16.txt,Link port scan:
634,E:\DATN\dataframe\train_file\16.txt,Link live host scan:
635,E:\DATN\dataframe\train_file\16.txt,Cài đặt module scapy (python3)
636,E:\DATN\dataframe\train_file\16.txt,"Như những module khác của python, các bạn cài đặt scapy với cú pháp như sau:pip install scapy"
637,E:\DATN\dataframe\train_file\16.txt,Xây dựng layer với scapy
638,E:\DATN\dataframe\train_file\16.txt,"Đầu tiên, ta import scapy from scapy.all import *"
639,E:\DATN\dataframe\train_file\16.txt,"Với scapy, nó hỗ trợ cho ta tất cả các layer, ví dụ như Ether(), ARP(), IP(), UDP(), TCP(),..."
640,E:\DATN\dataframe\train_file\16.txt,Một số function cơ bản cần phải nhớ
641,E:\DATN\dataframe\train_file\16.txt,sumary(): Show một cách tóm tắt gói tin
642,E:\DATN\dataframe\train_file\16.txt,show(): Show chi tiết gói tin
643,E:\DATN\dataframe\train_file\16.txt,srp(): Gửi và nhận gói tin đi ở layer 2
644,E:\DATN\dataframe\train_file\16.txt,sr(): Gửi và nhận gói tin đi ở layer 3
645,E:\DATN\dataframe\train_file\16.txt,sendp(): Gửi gói tin ở layer 2
646,E:\DATN\dataframe\train_file\16.txt,"send(): Gửi gói tin ở layer 3 Ví dụ dưới đây mình sẽ tạo ra 1 gói tin với layer IP, thực hiện 2 func show và sumary."
647,E:\DATN\dataframe\train_file\16.txt,"Sau khi sử dụng function show() để hiển thị các giá trị trong layer, ta có thể thực hiện sửa đổi giá trị trong layer, ví dụ mình thực hiện thay đổi src trong layer IP: pkt = IP(src=192.168.1.1)"
648,E:\DATN\dataframe\train_file\16.txt,Xây dựng các packet
649,E:\DATN\dataframe\train_file\16.txt,"Trong scapy, các packet được xây dựng từ các layer, để kết hợp các layer lại với nhau, ta sử dụng /, theo thứ tự từ layer thấp đến layer cao."
650,E:\DATN\dataframe\train_file\16.txt,Ví dụ: pkt = Ether()/ARP()/IP()
651,E:\DATN\dataframe\train_file\16.txt,3.1 Host discovery
652,E:\DATN\dataframe\train_file\16.txt,ARP: pkt = Ether(dst='ff:ff:ff:ff:ff:ff')/ARP(pdst=ipdest)
653,E:\DATN\dataframe\train_file\16.txt,"Trong đó, dst trong Ether layer là MAC address của địa chỉ đích, ở đây cần gửi cho tất cả các máy nên mình sẽ để địa chỉ là broadcast address, pdst là vùng địa chỉ ip đích cần quét, ví dụ 192.168.1."
654,E:\DATN\dataframe\train_file\16.txt,* Sau đó mình tiến hành gửi gói tin đi và nhận lại kết quả với hàm srp()
655,E:\DATN\dataframe\train_file\16.txt,ip = 'scanme.nmap.org'
656,E:\DATN\dataframe\train_file\16.txt,"ans, unans = srp(Ether(dst='ff:ff:ff:ff:ff:ff')/ARP(pdst=ip), timeout = 3)"
657,E:\DATN\dataframe\train_file\16.txt,"Nếu có kết quả trả về, tức là host live, điều này mình sẽ không giải thích nữa vì đã nói trong các bài trước.Tương tự như vậy, ta có thể xây dựng các gói tin để quét ICMP, SYN ping, ACK ping và UDP ping, hay port scan."
658,E:\DATN\dataframe\train_file\16.txt,"Mình sẽ gửi link github với code đã xây dựng xong của mình cho các bạn tham khảo, tuy nhiên mình nghĩ mng nên tự xây dựng và thử nghiệm, từ đó có thể hiểu chi tiết cách hoạt động của các phương pháp này."
659,E:\DATN\dataframe\train_file\17.txt,Cơ chế Attention (Attention mechanism) là một cơ chế vô cùng hay và nhận được rất nhiều sự phát triển gần đây.
660,E:\DATN\dataframe\train_file\17.txt,"Có những model được tạo thành lấy trọng tâm từ cơ chế này như: Transformer trong Attention is All You Need; VAN trong Visual Attention Network; ViT trong Vision Transformer,... Phương pháp mà tập trung sự chú ý (attention) đến các phần, vùng quan trọng trong ảnh và loại bỏ đi những vùng không quan trọng được gọi là cơ chế attention."
661,E:\DATN\dataframe\train_file\17.txt,"Trong Computer Vision (CV), cơ chế attention là quá trình lựa chọn một cách có chọn lọc thông qua việc đánh trọng số khác nhau cho features dựa trên độ quan trọng của input."
662,E:\DATN\dataframe\train_file\17.txt,Đại diện cho Channel Attention sẽ là SE Module từ Squeeze and Excitation Network (SENet).
663,E:\DATN\dataframe\train_file\17.txt,"Trong CNN, mỗi channel trong feature maps sẽ đại diện cho một thông tin."
664,E:\DATN\dataframe\train_file\17.txt,"Việc áp dụng Attention lên chiều channel tức là mỗi channel sẽ có một trọng số riêng, do đó sẽ ảnh hưởng khác nhau tới đầu ra thay vì có ảnh hưởng như nhau."
665,E:\DATN\dataframe\train_file\18.txt,Adapter pattern cho phép interface của một class đã có sẵn được dùng như là một interface khác.
666,E:\DATN\dataframe\train_file\18.txt,Nó sẽ giúp class đã tồn tại đó làm việc với những thằng khác mà không thay đổi source code.
667,E:\DATN\dataframe\train_file\18.txt,Nghe vẫn hơi trừu tượng đúng không nhỉ?
668,E:\DATN\dataframe\train_file\18.txt,Chúng ta sẽ từ từ đi bóc tách hết cái lớp vỏ ngoài khó hiểu này nhé.
669,E:\DATN\dataframe\train_file\18.txt,Tuy nhiên thì có 2 cách dùng adapter là Object Adapter và Class Adapter.
670,E:\DATN\dataframe\train_file\18.txt,Chúng ta sẽ cùng đi tìm hiểu chi tiết từng cách.
671,E:\DATN\dataframe\train_file\18.txt,Adapter là một design pattern khá quen thuộc với chúng ta.
672,E:\DATN\dataframe\train_file\18.txt,"Qua phần giải thích và một chút code mẫu, mong mọi người hiểu thêm về nó."
673,E:\DATN\dataframe\train_file\19.txt,Phương pháp phát triển phần mềm theo triết lý/mô hình Agile đang ngày càng trở nên phổ biến trên khắp thế giới.
674,E:\DATN\dataframe\train_file\19.txt,"Các công ty, doanh nghiệp và nhóm dự án vì thế cũng cần một cách thức kiểm thử phần mềm mới mới để phù hợp với mô hình làm việc theo Agile - vốn được biết đến là 1 triết lý hay một khung tư duy để nhanh chóng thích ứng và phản hồi với thay đổi."
675,E:\DATN\dataframe\train_file\19.txt,"Mặc dù kiểm thử tự động không được thiết kế để hỗ trợ các dự án Agile, nhưng nó giúp cho kiểm thử Agile - một thành phần quan trọng của các dự án Agile - có thể thực hiện được."
676,E:\DATN\dataframe\train_file\19.txt,Bài viết này sẽ giúp bạn hiểu được tầm quan trọng của Automation Testing – Kiểm thử tự động trong Agile và hướng dẫn các bước cần thiết để thiết để áp dụng kiểm thử tự động cho các nhóm dự án làm việc theo mô hình Agile.
677,E:\DATN\dataframe\train_file\19.txt,"Trước khi xuất hiện các khái niệm phát triển Agile, Mô hình Waterfall thường được sử dụng trong việc phát triển phần mềm."
678,E:\DATN\dataframe\train_file\19.txt,Có thể nói Waterfall thực sự là mô hình được sử dụng rộng rãi đầu tiên để phát triển phần mềm.
679,E:\DATN\dataframe\train_file\19.txt,"Giống như tên gọi, phương pháp luận Waterfall (thác nước) là một phương pháp quản lý dự án dựa trên quy trình thiết kế tuần tự và liên tiếp, giống như 1 thác nước chảy."
680,E:\DATN\dataframe\train_file\19.txt,Mỗi bước trong quá trình phát triển phải được hoàn thành trước khi chuyển sang bước tiếp theo.
681,E:\DATN\dataframe\train_file\19.txt,"Theo wikipedia, Agile là một phương thức thực hiện các dự án công nghệ phần mềm, phương thức này khuyến khích sự thay đổi khi phát triển dự án và đưa sản phẩm đến tay người dùng sao cho nhanh nhất."
682,E:\DATN\dataframe\train_file\19.txt,Mục tiêu của Agile là xuất bản phần mềm theo chức năng.
683,E:\DATN\dataframe\train_file\19.txt,"Để hoàn thành và xuất bản các ứng dụng theo chức năng, các lập trình viên và kiểm thử viên cần cộng tác theo nhóm."
684,E:\DATN\dataframe\train_file\19.txt,"Thay vì phát triển và triển khai toàn bộ ứng dụng cùng 1 lúc, giờ đây bạn chỉ cần hoàn thành từng phần của ứng dụng như cơ sở dữ liệu, nghiệp vụ logic và giao diện người dùng..v..v… Sự hợp tác để hoàn thành nhiệm vụ là 1 điều tất yếu trong mô hình Agile."
685,E:\DATN\dataframe\train_file\19.txt,"Giữa nhóm và các thành viên trong nhóm cần phải giao tiếp thường xuyên để mọi người đều ý thức được những gì team đang xây dựng và phát triển, cũng như trách nhiệm của mỗi cá nhân trong nhóm."
686,E:\DATN\dataframe\train_file\19.txt,Con người được đánh giá cao hơn các quy trình hoặc công cụ vì con người có thể đáp ứng nhu cầu kinh doanh và thúc đẩy quá trình phát triển.
687,E:\DATN\dataframe\train_file\19.txt,Nhóm sẽ kém thích nghi với sự thay đổi và ít có khả năng đáp ứng kỳ vọng của khách hàng nếu chỉ dựa quy trình hoặc công cụ để thúc đẩy sự phát triển.
688,E:\DATN\dataframe\train_file\19.txt,"Trong dự án Agile, mặc dù tài liệu được khuyến khích nhưng phần mềm hoạt động vẫn quan trọng hơn Trong dự án Agile tài liệu được đơn giản hoá và trình bày dễ hiểu để đội ngũ phát triển có thể hoàn thành yêu cầu mà mà không bị sa lầy vào chi tiết."
689,E:\DATN\dataframe\train_file\19.txt,"Agile tạo ra các câu chuyện của người dùng từ các yêu cầu, những yêu cầu đủ để lập trình viên bắt đầu làm một chức năng mới."
690,E:\DATN\dataframe\train_file\19.txt,Tuyên ngôn Agile xác định khách hàng là người tham gia và làm việc với đội ngũ phát triển trong các dự án.
691,E:\DATN\dataframe\train_file\19.txt,Việc phát triển sản phẩm thoả mãn nhu cầu của khách hàng vì thế cũng trở nên đơn giản hơn nhiều.
692,E:\DATN\dataframe\train_file\19.txt,"Trong 1 dự án Agile, khách hàng cũng có thể là người dùng cuối (end user) tham gia tất cả các cuộc họp, các buổi demo để đảm bảo rằng các chức năng đang phát triển đáp ứng/thoả mãn nhu cầu của khách hàng."
693,E:\DATN\dataframe\train_file\19.txt,"Đa phần các dự án đều có sự thay đổi điều chỉnh khi triển khai ví dụ như thay đổi về yêu cầu, thay đổi tech stack, thay đổi nhân sự, thay đổi deadline, thay đổi phương thức làm việc…v..v mặc dù kế hoạch đã được định ra rõ ràng từ đầu."
694,E:\DATN\dataframe\train_file\19.txt,"Mặc dù không khuyến khích sự thay đổi nhưng Agile khuyến chúng ta tập thích nghi, ứng phó với sự thay đổi."
695,E:\DATN\dataframe\train_file\19.txt,"Nhóm dự án agile thường xuyên làm việc trực tiếp với khách hàng, điều này giúp cho dự án nắm được độ ưu tiên giữa các yêu cầu đồng thời cập nhật các thay đổi từ phía khách hàng để kịp thời điều chỉnh."
696,E:\DATN\dataframe\train_file\19.txt,Nhờ đó các dự án agile thường giúp khách hàng tối ưu hóa được giá trị của dự án.
697,E:\DATN\dataframe\train_file\19.txt,Agile giúp dự án gia tăng đáng kể độ hài lòng của khách hàng.
698,E:\DATN\dataframe\train_file\2.txt,NODE CACHE - CHẶNG ĐƯỜNG ỨNG DỤNG LẦN ĐẦU CỦA MỘT NEWBIE
699,E:\DATN\dataframe\train_file\2.txt,"Chào các bạn, vậy là mình cũng đã lặn sâu được gần 10 tháng, hôm nay mình đã quay trở lại."
700,E:\DATN\dataframe\train_file\2.txt,Lần này là một nội dung “cũ mà mới”.
701,E:\DATN\dataframe\train_file\2.txt,"Cũ vì khi nhắc đến cache, gần như mọi người đã được nghe đến, đã được tiếp cận, đã làm việc hoặc đã được đọc những bài viết vô cùng chất lượng trên Viblo của các tác giả khác."
702,E:\DATN\dataframe\train_file\2.txt,Mới vì ở bài viết này:
703,E:\DATN\dataframe\train_file\2.txt,"Sẽ không đi sâu vào việc tích hợp Cache trong source code như thế nào mà tập trung vào quá trình phân tích, trải nghiệm của một Newbie (là mình cách đây hơn 1 năm) tập tành sử dụng Cache"
704,E:\DATN\dataframe\train_file\2.txt,"Bài viết sẽ không đi hết mọi thứ về Cache, mà nghiêng về sự trải nghiệm với những gì đã học, đã làm về Cache."
705,E:\DATN\dataframe\train_file\2.txt,"Mình phải nói trước như vậy để tránh các bạn quá kì vọng vào nội dung rồi không tìm thấy gì quá mới mẻ, nhất là các bạn đã có kinh nghiệm."
706,E:\DATN\dataframe\train_file\2.txt,"Còn nếu bạn cũng là newbie, muốn đồng hành cùng bài viết này thì cùng xem tiếp nhé"
707,E:\DATN\dataframe\train_file\2.txt,Nắm bắt tình hình
708,E:\DATN\dataframe\train_file\2.txt,"Quay trở lại hơn 1 năm về trước, khi 1 trong những dự án nhỏ của mình tham gia gặp vấn đề về “Performance”."
709,E:\DATN\dataframe\train_file\2.txt,API mất quá nhiều thời gian để có thể trả dữ liệu về phía Client.
710,E:\DATN\dataframe\train_file\2.txt,Đồng thời kéo theo CCU của ứng dụng là rất nhỏ.
711,E:\DATN\dataframe\train_file\2.txt,"Hãy lấy 1 ví dụ: Thông thường, 1 API xem chi tiết một bài Blog sẽ có endpoint như này /api/v1/posts/:post_id"
712,E:\DATN\dataframe\train_file\2.txt,"Và tin được không, khi chỉ cần khoảng 30 user truy cập vào 1 lúc là thứ mà bạn thấy trên màn hình là hiệu ứng “loading”."
713,E:\DATN\dataframe\train_file\2.txt,"Đo thời gian trung bình, API trên sẽ cần khoảng 4.25s để trả kết quả về client"
714,E:\DATN\dataframe\train_file\2.txt,"Được rồi, dù dự án có nhỏ đi chăng nữa thì không thể chấp nhận một con số như thế."
715,E:\DATN\dataframe\train_file\2.txt,Mình bắt đâu đi suy xét tình hình:
716,E:\DATN\dataframe\train_file\2.txt,Kiểm tra cấu hình server: 8GB RAM / 6 core / 100GB SSD.
717,E:\DATN\dataframe\train_file\2.txt,"Trông ổn, nhất là với ứng dụng nhỏ"
718,E:\DATN\dataframe\train_file\2.txt,Kiểm tra môi trường: BE của ứng dụng được viết bằng Typescript chạy trên Node.js runtime.
719,E:\DATN\dataframe\train_file\2.txt,Mà nhắc đến Node là nhắc đến Single Thread.
720,E:\DATN\dataframe\train_file\2.txt,"Vì vậy cần tận dụng những thứ như Promise, Cluster để tăng performance…."
721,E:\DATN\dataframe\train_file\2.txt,"Mình kiểm tra tất cả những thứ này, tất cả đã được implement đúng cách."
722,E:\DATN\dataframe\train_file\2.txt,Ngang đây sẽ có bạn thắc mắc rằng code Promise như nào là đúng cách và tốt cho hiệu suất?
723,E:\DATN\dataframe\train_file\2.txt,"Yên tâm, mình sẽ có 1 bài viết riêng biệt cho vấn đề này, còn bài này tập trung vào Cache nhé"
724,E:\DATN\dataframe\train_file\2.txt,Kiểm tra database (DB): DB được sử dụng là MongoDB.
725,E:\DATN\dataframe\train_file\2.txt,Thứ mà mình quan tâm đến là query đã được viết tốt chưa?
726,E:\DATN\dataframe\train_file\2.txt,Mình đánh giá qua 1 số tiêu chí như:
727,E:\DATN\dataframe\train_file\2.txt,Dữ liệu có thừa không (Chỉ lấy những gì cần thiết)?
728,E:\DATN\dataframe\train_file\2.txt,"Sử dụng aggregate, lookup, pagination đã đúng chưa?"
729,E:\DATN\dataframe\train_file\2.txt,Có thừa query hay không?
730,E:\DATN\dataframe\train_file\2.txt,- Phần này cũng sẽ có bài viết riêng nhé
731,E:\DATN\dataframe\train_file\2.txt,DB đã được đánh index chưa?
732,E:\DATN\dataframe\train_file\2.txt,"Xem qua thì có 1 số vấn đề, mình đã điều chỉnh lại."
733,E:\DATN\dataframe\train_file\2.txt,"Tuy nhiên tình hình dù có cải thiện, chủ yếu là giảm tải cho DB, giảm response data size, chứ chưa thực sự cải thiện nhiều về CCU."
734,E:\DATN\dataframe\train_file\2.txt,"Lúc này, mình lai tiếp tục tìm hiểu xem logic của API."
735,E:\DATN\dataframe\train_file\2.txt,Đầu tiên là xem API cần lấy những thông tin gì.
736,E:\DATN\dataframe\train_file\2.txt,"Dữ liệu về bài viết (Blog): Tất nhiên, nội dung chính mà."
737,E:\DATN\dataframe\train_file\2.txt,Phần này thì chỉ cần query theo post_id trong bảng Blogs là xong
738,E:\DATN\dataframe\train_file\2.txt,"Tác giả bài viết (User hay Author): Cần một số thông tin như: Tên, ảnh đại diện, thông tin thống kê (số bài viết, số lượt thích, đánh giá trung bình,…), giới thiệu,… lấy từ bảng Users"
739,E:\DATN\dataframe\train_file\2.txt,Danh mục (Category): Phần này cần lấy đầy đủ cây danh mục của ứng dụng để người dùng thay đổi.
740,E:\DATN\dataframe\train_file\2.txt,"Bài viết tương tự, bài viết gợi ý: Danh sách các bài viết tương tự dựa trên 1 số tiêu chí chung, phần này vẫn lấy từ bảng Blogs nhé."
741,E:\DATN\dataframe\train_file\2.txt,"Mỗi mục tương tự hay gợi ý lấy về khoảng 10 bài viết, mỗi bài viết chỉ hiển thị tiêu đề và thông tin cơ bản của tác giả tương ứng"
742,E:\DATN\dataframe\train_file\2.txt,Danh sách bình luận (Comment): Lấy từ bảng Comments
743,E:\DATN\dataframe\train_file\2.txt,Thông tin cần truy vấn ở đây là khá nhiều.
744,E:\DATN\dataframe\train_file\2.txt,"Lúc này, mình bắt đầu nghĩ đến cache"
745,E:\DATN\dataframe\train_file\2.txt,Tại sao lại nghĩ đến cache?
746,E:\DATN\dataframe\train_file\2.txt,Như các bạn thấy những thông tin cần trả về client ở màn hình xem bài viết là như trên.
747,E:\DATN\dataframe\train_file\2.txt,"Lúc này, căn cứ vào thiết kế hệ thống, mình chia thành 2 loại dữ liệu chính:"
748,E:\DATN\dataframe\train_file\2.txt,Static Data: Dữ liệu tĩnh.
749,E:\DATN\dataframe\train_file\2.txt,"Là dữ liệu không thay đổi, là cố định trên hệ thống."
750,E:\DATN\dataframe\train_file\2.txt,Chỉ tạo 1 lần và sử dụng mãi mãi thì có Danh mục (Category).
751,E:\DATN\dataframe\train_file\2.txt,Dynamic Data: Dữ liệu động.
752,E:\DATN\dataframe\train_file\2.txt,Là dữ liệu có khả năng thay đổi theo thời gian với nhiều mức độ khác nhau.
753,E:\DATN\dataframe\train_file\2.txt,Mình tiếp tục chia thành các mức độ sau:
754,E:\DATN\dataframe\train_file\2.txt,"Low: Dữ liệu ít bị thay đổi, tần suất thay đổi khoảng 1 ngày trở lên: Mình đưa phần thông tin user vào mức độ này"
755,E:\DATN\dataframe\train_file\2.txt,"Medium: Dữ liệu có sự thay đổi thường xuyên hơn, thường tính bằng giờ: Mình đưa phần thông tin bài viết chính, danh sách bài viết tương tự, bài viết gợi ý vào mức độ này, bởi ngoại trừ bài viết chính cần hiển thị đủ thông tin, dữ liệu còn lại như đã nói chỉ bao gồm tiêu đề và thông tin cơ bản tác giả."
756,E:\DATN\dataframe\train_file\2.txt,"Về tác giả thì đã được phân loại vào mức “low” ở trên, còn phần tiêu đề cũng hiếm khi bị thay đổi."
757,E:\DATN\dataframe\train_file\2.txt,"Thứ thay đổi nhiều hơn ở đây là điều kiện đánh giá tiêu chí bài viết tương tự, bài viết gợi ý"
758,E:\DATN\dataframe\train_file\2.txt,"High: Dữ liệu có sự thay đổi liên tục, thường tính bằng giây hoặc phút."
759,E:\DATN\dataframe\train_file\2.txt,Mình đưa phần comments vào mức độ này
760,E:\DATN\dataframe\train_file\2.txt,"Lưu ý: Mức độ thay đổi dữ liệu được mình tính dựa trên khả năng ""xấu nhất"", tức là mức độ thay đổi dữ liệu thường xuyên nhất của đối tượng và mang tính chất tương đối."
761,E:\DATN\dataframe\train_file\2.txt,"Việc phân chia như trên sẽ giúp chúng ta đánh giá được dữ liệu, từ đó đưa ra được phương pháp cache ""đúng hoặc gần đúng"""
762,E:\DATN\dataframe\train_file\2.txt,"Như vậy, ta nhận thấy rằng việc cache dữ liệu cho các thông tin trên là hoàn toàn khả thi để tăng hiệu năng hệ thống, nhất là với phần dữ liệu tĩnh."
763,E:\DATN\dataframe\train_file\2.txt,"Lan man thế đã đủ, giờ thì bắt tay vào ứng dụng thôi"
764,E:\DATN\dataframe\train_file\2.txt,Cache cho phần danh mục (Category)
765,E:\DATN\dataframe\train_file\2.txt,"Xời, cái này thì dễ quá rồi đúng không."
766,E:\DATN\dataframe\train_file\2.txt,"Đây là phần dữ liệu tĩnh, việc duy nhất của chúng ta là lưu dữ liệu lên cache 1 lần duy nhất, sau đó chỉ việc đọc nó mà thôi, mô hình đơn giản thì thế này:"
767,E:\DATN\dataframe\train_file\2.txt,"Tuy nhiên, nếu một ngày nào đó, anh cache nổi chứng ra sập, vậy thì ứng dụng chẳng phải sẽ không thể hiển thị được danh mục hay sao?"
768,E:\DATN\dataframe\train_file\2.txt,"🤔 Thế thôi thì, ta sẽ xây dựng lại mô hình để dự phòng cho trường hợp này nhé:"
769,E:\DATN\dataframe\train_file\2.txt,Triển khai ở code thì nó trông như này:
770,E:\DATN\dataframe\train_file\2.txt,const getOrSetCategory = async () => {
771,E:\DATN\dataframe\train_file\2.txt,    let categories = await getCategoryFromCache(key)
772,E:\DATN\dataframe\train_file\2.txt,        categories = await getCategoryFromDB()
773,E:\DATN\dataframe\train_file\2.txt,    return categories
774,E:\DATN\dataframe\train_file\2.txt,"Cache cho phần thông tin tác giả (Users) và danh sách bài viết tương tự, bài viết gợi ý (Blogs)"
775,E:\DATN\dataframe\train_file\2.txt,Về mặt đọc dữ liệu từ API sẽ không có gì khác so với logic ở trên.
776,E:\DATN\dataframe\train_file\2.txt,"Điều mà chúng ta quan tâm ở đây là: Khi dữ liệu thay đổi, ta sẽ cập nhật cache như thế nào?"
777,E:\DATN\dataframe\train_file\2.txt,"Như đã phân tích ở trên, dữ liệu hiển thị cho những đối tượng này có sự thay đổi ở mức độ ""Low or Medium""."
778,E:\DATN\dataframe\train_file\2.txt,"Do đó, mình chọn giải pháp là xây dựng 1 background job để chạy mỗi 6h/lần cho User và 1h/lần cho 2 danh sách bài viết gợi ý và bài viết tương tự."
779,E:\DATN\dataframe\train_file\2.txt,"Tại sao mình lại chọn con số 6h và 1h, và nó có ý nghĩa gì?"
780,E:\DATN\dataframe\train_file\2.txt,Đó chính là thời gian tối đa mà mình chấp nhận sự sai lệch dữ liệu giữa cache và DB.
781,E:\DATN\dataframe\train_file\2.txt,Việc chọn các con số này phụ thuộc vào mức độ realtime mà các bạn muốn áp dụng cho phần mà các bạn cache.
782,E:\DATN\dataframe\train_file\2.txt,"Ở đây, các dữ liệu hiển thị như tên tác giả, các thông số thống kê của tác giả hay tên bài viết là những dữ liệu ít dc thay đổi, do vậy, mình chọn 2 con số trên"
783,E:\DATN\dataframe\train_file\2.txt,"Bây giờ, mô hình của nó sẽ như thế này:"
784,E:\DATN\dataframe\train_file\2.txt,Điểm mới ở đây chính là mình xây dựng thêm 1 con Node hoạt động độc lập.
785,E:\DATN\dataframe\train_file\2.txt,"Chức năng của nó là xử lý các background job để phân tích, cập nhật dữ liệu lên cache."
786,E:\DATN\dataframe\train_file\2.txt,Nó sẽ lặp lại theo thời gian định sẵn để thực hiện các tác vụ mà mình cần.
787,E:\DATN\dataframe\train_file\2.txt,"Các bạn có thể sử dụng package ""node-cron"" nhé"
788,E:\DATN\dataframe\train_file\2.txt,Cache cho phần bình luận (Comments)
789,E:\DATN\dataframe\train_file\2.txt,"Sau một thời gian theo dõi, thống kê, mình nhận thấy rằng đây là phần có dữ liệu thường xuyên thay đổi nhất trên ứng dụng."
790,E:\DATN\dataframe\train_file\2.txt,Các bình luận được tạo mới / chỉnh sửa liên tục.
791,E:\DATN\dataframe\train_file\2.txt,"Nguyên do là hệ thống ở thời điểm đó chưa có chức năng Q&A riêng biệt, do đó, mỗi khi người dùng có thắc mắc hay điều cần trao đổi, họ đều sử dụng tính năng bình luận"
792,E:\DATN\dataframe\train_file\2.txt,"Một lần nữa, mô hình đọc dữ liệu sẽ không thay đổi."
793,E:\DATN\dataframe\train_file\2.txt,Vậy việc cập nhật cache thì sao?
794,E:\DATN\dataframe\train_file\2.txt,Có thể sử dụng background job như trên không?
795,E:\DATN\dataframe\train_file\2.txt,Câu trả lời là được.
796,E:\DATN\dataframe\train_file\2.txt,Chỉ cần giảm thời gian giữa các lần chạy xuống còn 10s/lần là cũng ổn đấy.
797,E:\DATN\dataframe\train_file\2.txt,"Nhưng, liệu nó có tốt, khi mà các job sẽ chồng chéo lên nhau, và liệu 10s có đủ để job hoàn thành việc đọc, phân tích và cập nhật dữ liệu?"
798,E:\DATN\dataframe\train_file\2.txt,"Chính vì vậy, mình chọn triển khai cache cho phần này theo một cách khác:"
799,E:\DATN\dataframe\train_file\2.txt,"Phần màu đỏ chính là phần mới của mô hình này, mỗi khi có 1 yêu cầu cập nhật dữ liệu, BE sẽ thực hiện việc cập nhật dữ liệu lên DB."
800,E:\DATN\dataframe\train_file\2.txt,"Nếu quá trình lưu thành công, dữ liệu sẽ đồng thời được cập nhật ngay lên cache."
801,E:\DATN\dataframe\train_file\2.txt,Code sẽ trông như thế này:
802,E:\DATN\dataframe\train_file\2.txt,const updateData = async (newData) => {
803,E:\DATN\dataframe\train_file\2.txt,"    const updatedData = await saveDataToDB(id, newData)"
804,E:\DATN\dataframe\train_file\2.txt,"    findAndUpdateCache(key, updatedData)"
805,E:\DATN\dataframe\train_file\2.txt,    return updatedData
806,E:\DATN\dataframe\train_file\2.txt,Cũng khá dễ hiểu đúng không nào?
807,E:\DATN\dataframe\train_file\2.txt,"Tuy nhiên, ta cần nghĩ đến 1 bài toán lớn hơn."
808,E:\DATN\dataframe\train_file\2.txt,"Trên thực tế, sẽ có nhiều API cùng thực hiện việc tạo mới / cập nhật một đối tượng."
809,E:\DATN\dataframe\train_file\2.txt,"Theo mô hình trên thì ta phải gọi hàm updateData ở tất cả các API đó Lúc này, mình áp dụng 1 số kĩ thuật tối ưu hơn như:"
810,E:\DATN\dataframe\train_file\2.txt,Redis Pub/Sub
811,E:\DATN\dataframe\train_file\2.txt,Mongo Change Stream (yêu cầu có Mongo Replica Set)
812,E:\DATN\dataframe\train_file\2.txt,Node EventEmitter
813,E:\DATN\dataframe\train_file\2.txt,Các kĩ thuật này sẽ giúp tự động hoá phần nào việc theo dõi sự thay đổi dữ liệu trên hệ thống và lưu vào cache.
814,E:\DATN\dataframe\train_file\2.txt,"Mình sẽ không đi sâu vào việc sử dụng các kĩ thuật này, vì đã có nhiều tác giả viết về những thứ này rồi"
815,E:\DATN\dataframe\train_file\2.txt,"Vậy là đã cache được hầu hết các dữ liệu trên API xem bài viết rồi, thành quả sau khi cache thì mình đo được:"
816,E:\DATN\dataframe\train_file\2.txt,Giảm thời gian phản hồi trung mình của API xuống <= 30ms
817,E:\DATN\dataframe\train_file\2.txt,"Tỉ lệ hit cache đạt <= 85%, giảm gánh nặng cho DB (Sẽ nhiều bạn thấy tỉ lệ cache này chưa cao, thì hãy đọc thêm bài  của tác giả Minhmonmen nhé, sẽ biết cách để tăng tỉ lệ nha, rất hay đấy)"
818,E:\DATN\dataframe\train_file\2.txt,"Tăng CCU lên ~ 8000 CCU (800 req/s) Thành quả này là nhỏ thôi, nhưng nó cũng là động lực cho 1 newbie về caching cách đây 1 năm"
819,E:\DATN\dataframe\train_file\2.txt,"Như các bạn thấy ngay từ phần ""Nắm bắt tình hình"" ở trên, mình đã kiểm tra qua khá nhiều thứ trước khi nghĩ đến cache, chứ không lạm dụng nó ngay."
820,E:\DATN\dataframe\train_file\2.txt,"Cache chỉ nên được sử dụng khi nó thật sự cần thiết và phải sau khi kiểm tra code, DB query."
821,E:\DATN\dataframe\train_file\2.txt,"Bởi nếu bản chất những thứ trên chưa tốt, mà lạm dụng cache khi chưa cần thiết, sẽ làm tăng tài nguyên hệ thống, khi đạt 1 giới hạn, sẽ làm tăng chi phí dự án, mà điều này gần như khách hàng của chúng ta không mong muốn, họ chỉ mong sao cho ""với chi phí nhỏ nhất có thể làm ra được 1 ứng dụng tốt nhất tương xứng"""
822,E:\DATN\dataframe\train_file\2.txt,Cách phân chi dữ liệu thành 2 dạng static data và dynamic data ở trên sẽ giúp chúng ta dễ dàng nhận biết cần cache những gì hơn.
823,E:\DATN\dataframe\train_file\2.txt,"Hiển nhiên, dữ liệu tĩnh được cache là điều nên làm."
824,E:\DATN\dataframe\train_file\2.txt,"Còn với dữ liệu động, nó nên tuỳ thuộc vào mức độ thay đổi dữ liệu để xác định có nên cache hay không?"
825,E:\DATN\dataframe\train_file\2.txt,"Nếu mức độ dữ liệu thay đổi thường xuyên, thì cần phải lựa chọn phương án cập nhật sao cho độ sai lệch dữ liệu là nhỏ nhất"
826,E:\DATN\dataframe\train_file\2.txt,"Một lưu ý ""nhỏ mà có võ"" nữa là: Các bạn chỉ nên lưu lên cache dữ liệu vừa đủ, không thừa cũng không thiếu."
827,E:\DATN\dataframe\train_file\2.txt,"Nếu dữ liệu quá nhiều ngoài việc tăng tốn kém tài nguyên, nó sẽ còn làm chậm quá trình đọc dũ liệu từ cache nữa đó nhé"
828,E:\DATN\dataframe\train_file\2.txt,"Sẽ vẫn còn nhiều điều thú vị về cache, về trải nghiệm của mình nữa, nhưng hôm nay tạm nghỉ ở đây thôi."
829,E:\DATN\dataframe\train_file\2.txt,"Nếu bài viết nãy hữu ích, đừng quên Upvote, đóng góp ý kiến và chờ bài viết sau nhé."
830,E:\DATN\dataframe\train_file\2.txt,Cám ơn các bạn thật nhiều và hẹn gặp lại 👋
831,E:\DATN\dataframe\train_file\20.txt,Golang Design Patterns - Abstract Factory.
832,E:\DATN\dataframe\train_file\20.txt,Hơn cả một Factory
833,E:\DATN\dataframe\train_file\20.txt,I. Abstract Factory - Creational Patterns
834,E:\DATN\dataframe\train_file\20.txt,"Nếu chúng ta đã biết được mẫu thiết kế  là như thế nào, thì hôm nay mình xin giới thiệu với các bạn design pattern bao quát hơn nữa, chính là Absract Factory."
835,E:\DATN\dataframe\train_file\20.txt,"Mục đích chính của mẫu thiết kế này là gom nhóm các Factory thành một Factory lớn, thứ có thể hoán đổi và mở rộng một cách dễ dàng hơn."
836,E:\DATN\dataframe\train_file\20.txt,"Thường trong giai đoạn đầu của việc plan, define về chức năng mà các Factory có thể có, việc chúng ta thao tác và chỉ quan tâm đến các factories và abstract factories sẽ là một hướng tiếp cận dễ dàng hơn so với việc đợi define đầy đủ chi tiết cho chúng."
837,E:\DATN\dataframe\train_file\20.txt,"Nhưng để triển khai pattern này, chúng ta cũng cần quan tâm những thứ mà mình sẽ nói trong bài viết sau nhé 😄"
838,E:\DATN\dataframe\train_file\20.txt,Abstract Factory mang lại cho developers những gì?
839,E:\DATN\dataframe\train_file\20.txt,"Pattern này giúp chúng ta gom nhóm các đối tượng liên quan khi số lượng đối tượng có thể tăng lên mà ta không thể kiểm soát trong giai đoạn phát triển, bằng cách tạo ra một unique point, nơi có thể tạo ra tất cả các đối tượng đó:"
840,E:\DATN\dataframe\train_file\20.txt,Tạo ra một lớp mới đóng gói các Factory Method và trả về một common interface cho toàn bộ fatories.
841,E:\DATN\dataframe\train_file\20.txt,"Gom nhóm các common factories vào một super Factory, hay còn được gọi là Factory của những Factories."
842,E:\DATN\dataframe\train_file\20.txt,Ví dụ thực tế
843,E:\DATN\dataframe\train_file\20.txt,"Chúng ta sẽ quay lại với ví dụ trong bài , nhưng có một vài yêu cầu đặc biệt hơn, chúng ta đến một cửa hàng bán xe để mua 1 chiếc xe máy và 1 chiếc xe đạp."
844,E:\DATN\dataframe\train_file\20.txt,Cửa hàng này có các loại xe sau:
845,E:\DATN\dataframe\train_file\20.txt,Xe đạp có 2 loại: xe đạp bình thường và xe đạp thể thao
846,E:\DATN\dataframe\train_file\20.txt,Xe máy có 2 loại: xe 125cc và 150cc
847,E:\DATN\dataframe\train_file\20.txt,"Để triển khai Abstract Factory dựa trên đối tượng Vehicle của mẫu Factory Method trước đó, chúng ta cần tuân thủ các nguyên tắc sau:"
848,E:\DATN\dataframe\train_file\20.txt,Chúng ta luôn tạo Vehicle bằng cách sử dụng factory được trả về từ abstract factory
849,E:\DATN\dataframe\train_file\20.txt,Một đối tượng xe luôn là 1 trong 2 đối tượng Bicycle (implement Vehicle + Bicycle) hoặc Motorbike (implement interface Vehicle + Motorbike)
850,E:\DATN\dataframe\train_file\20.txt,"Theo đề bài, chúng ta cần phải tạo những đối tượng như sau:"
851,E:\DATN\dataframe\train_file\20.txt,Vehicle: là một interface mà tất cả các đối tượng factory cần phải implement:
852,E:\DATN\dataframe\train_file\20.txt,Bicycle: Một interface bao gồm 2 loại xe đạp NormalBicycle - xe đạp thường và SportBicycle - xe đạp thể thao
853,E:\DATN\dataframe\train_file\20.txt,Motorbike: interface của xe máy gồm xe máy Motor125CC và Motor150CC
854,E:\DATN\dataframe\train_file\20.txt,VehicleFactory: là interface (abstract interface mà chúng ta đang quan tâm) để tạo ra các factories triển khai phương thức của nó:
855,E:\DATN\dataframe\train_file\20.txt,"BicycleFactory: là factory implement VehicleFactory interface và trả về đối tượng vehicle, đối tượng này bắt buộc phải implement các phương thức của interface Vehicle và Bicycle"
856,E:\DATN\dataframe\train_file\20.txt,"MotorbikeFactory: tương tự như trên, chỉ khác là các đối tượng vehicle này phải triển khai các phương thức từ interface Vehicle và Motorbike"
857,E:\DATN\dataframe\train_file\20.txt,Bắt đầu với Golang thôi nào ^^
858,E:\DATN\dataframe\train_file\20.txt,Chúng ta sẽ tạo các entity ở trên bằng những file riêng biệt.
859,E:\DATN\dataframe\train_file\20.txt,Đầu tiên là Vehicle interface trong file vehicle.go
860,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
861,E:\DATN\dataframe\train_file\20.txt,type Vehicle interface {
862,E:\DATN\dataframe\train_file\20.txt,	NumWheels() int
863,E:\DATN\dataframe\train_file\20.txt,	NumSeats() int
864,E:\DATN\dataframe\train_file\20.txt,"Bicycle interface và MotorBike interface sẽ được tạo trong file bicyle.go và motorbike.go, tương ứng như sau:"
865,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
866,E:\DATN\dataframe\train_file\20.txt,type Bicycle interface {
867,E:\DATN\dataframe\train_file\20.txt,	GetType() int
868,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
869,E:\DATN\dataframe\train_file\20.txt,type Motorbike interface {
870,E:\DATN\dataframe\train_file\20.txt,	GetCC() string
871,E:\DATN\dataframe\train_file\20.txt,"Chúng ta có một interface cuối cùng, nơi mà tất cả các factory đều phải triển khai đó là VehicleFactory trong file vehicle_factory.go, interface này cung cấp 1 method duy nhất (được xem như chức năng của cửa hàng bán xe là lấy xe giao cho khách 😄)"
872,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
873,E:\DATN\dataframe\train_file\20.txt,type VehicleFactory interface {
874,E:\DATN\dataframe\train_file\20.txt,"	NewVehicle(v int) (Vehicle, error)"
875,E:\DATN\dataframe\train_file\20.txt,"Bây giờ tới gian đoạn triển khai các đối tượng nhỏ hơn, ta bắt đầu với BicycleFactory và MotorbikeFactory nhé, vì đoạn này implement như mẫu Factory trong bài trước nên các bạn đọc qua sẽ hiểu, mình không nói chi tiết nữa."
876,E:\DATN\dataframe\train_file\20.txt,Với BicycleFactory:
877,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
878,E:\DATN\dataframe\train_file\20.txt,	NormalBicycleType = 1
879,E:\DATN\dataframe\train_file\20.txt,	SportBicycleType  = 2
880,E:\DATN\dataframe\train_file\20.txt,type BicycleFactory struct{}
881,E:\DATN\dataframe\train_file\20.txt,"func (c *BicycleFactory) NewVehicle(v int) (Vehicle, error) {"
882,E:\DATN\dataframe\train_file\20.txt,	switch v {
883,E:\DATN\dataframe\train_file\20.txt,	case NormalBicycleType:
884,E:\DATN\dataframe\train_file\20.txt,"		return new(NormalBicycle), nil"
885,E:\DATN\dataframe\train_file\20.txt,	case SportBicycleType:
886,E:\DATN\dataframe\train_file\20.txt,"		return new(SportBicycle), nil"
887,E:\DATN\dataframe\train_file\20.txt,"		err := fmt.Sprintf(""Vehicle of type %d not recognized\n"", v)"
888,E:\DATN\dataframe\train_file\20.txt,"		return nil, errors.New(err)"
889,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
890,E:\DATN\dataframe\train_file\20.txt,type NormalBicycle struct{}
891,E:\DATN\dataframe\train_file\20.txt,func (*NormalBicycle) GetType() string {
892,E:\DATN\dataframe\train_file\20.txt,"	return ""Normal Bicycle"""
893,E:\DATN\dataframe\train_file\20.txt,func (*NormalBicycle) NumWheels() int {
894,E:\DATN\dataframe\train_file\20.txt,	return 2
895,E:\DATN\dataframe\train_file\20.txt,func (*NormalBicycle) NumSeats() int {
896,E:\DATN\dataframe\train_file\20.txt,	return 1
897,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
898,E:\DATN\dataframe\train_file\20.txt,type SportBicycle struct{}
899,E:\DATN\dataframe\train_file\20.txt,func (*SportBicycle) GetType() string {
900,E:\DATN\dataframe\train_file\20.txt,"	return ""Sport Bicycle"""
901,E:\DATN\dataframe\train_file\20.txt,func (*SportBicycle) NumWheels() int {
902,E:\DATN\dataframe\train_file\20.txt,	return 1
903,E:\DATN\dataframe\train_file\20.txt,func (*SportBicycle) NumSeats() int {
904,E:\DATN\dataframe\train_file\20.txt,	return 1
905,E:\DATN\dataframe\train_file\20.txt,Và MotorbikeFactory:
906,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
907,E:\DATN\dataframe\train_file\20.txt,	Motorbike125CCType = 1
908,E:\DATN\dataframe\train_file\20.txt,	Motorbike150CCType = 2
909,E:\DATN\dataframe\train_file\20.txt,type MotorbikeFactory struct{}
910,E:\DATN\dataframe\train_file\20.txt,"func (c *MotorbikeFactory) NewVehicle(v int) (Vehicle, error) {"
911,E:\DATN\dataframe\train_file\20.txt,	switch v {
912,E:\DATN\dataframe\train_file\20.txt,	case Motorbike125CCType:
913,E:\DATN\dataframe\train_file\20.txt,"		return new(Motorbike125CC), nil"
914,E:\DATN\dataframe\train_file\20.txt,	case Motorbike150CCType:
915,E:\DATN\dataframe\train_file\20.txt,"		return new(Motorbike150CC), nil"
916,E:\DATN\dataframe\train_file\20.txt,"		err := fmt.Sprintf(""Vehicle of type %d not recognized\n"", v)"
917,E:\DATN\dataframe\train_file\20.txt,"		return nil, errors.New(err)"
918,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
919,E:\DATN\dataframe\train_file\20.txt,type Motorbike125CC struct{}
920,E:\DATN\dataframe\train_file\20.txt,func (*Motorbike125CC) GetCC() string {
921,E:\DATN\dataframe\train_file\20.txt,"	return ""125cc"""
922,E:\DATN\dataframe\train_file\20.txt,func (*Motorbike125CC) NumWheels() int {
923,E:\DATN\dataframe\train_file\20.txt,	return 2
924,E:\DATN\dataframe\train_file\20.txt,func (*Motorbike125CC) NumSeats() int {
925,E:\DATN\dataframe\train_file\20.txt,	return 2
926,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
927,E:\DATN\dataframe\train_file\20.txt,type Motorbike150CC struct{}
928,E:\DATN\dataframe\train_file\20.txt,func (*Motorbike150CC) GetCC() string {
929,E:\DATN\dataframe\train_file\20.txt,"	return ""150cc"""
930,E:\DATN\dataframe\train_file\20.txt,func (*Motorbike150CC) NumWheels() int {
931,E:\DATN\dataframe\train_file\20.txt,	return 2
932,E:\DATN\dataframe\train_file\20.txt,func (*Motorbike150CC) NumSeats() int {
933,E:\DATN\dataframe\train_file\20.txt,	return 2
934,E:\DATN\dataframe\train_file\20.txt,"Và cuối cùng, chúng ta cần abstract các factory trên, và tạo ra một unique point như đầu bài viết mình có nhắc đến, phục vụ cho việc tạo ra cách đối tượng vehicle."
935,E:\DATN\dataframe\train_file\20.txt,Chúng ta triển khai function này trong file vehicle_factory.go đã được tạo phía trên luôn nhé:
936,E:\DATN\dataframe\train_file\20.txt,package abstract_factory
937,E:\DATN\dataframe\train_file\20.txt,type VehicleFactory interface {
938,E:\DATN\dataframe\train_file\20.txt,"	NewVehicle(v int) (Vehicle, error)"
939,E:\DATN\dataframe\train_file\20.txt,	BicycleFactoryType   = 1
940,E:\DATN\dataframe\train_file\20.txt,	MotorbikeFactoryType = 2
941,E:\DATN\dataframe\train_file\20.txt,"func BuildFactory(f int) (VehicleFactory, error) {"
942,E:\DATN\dataframe\train_file\20.txt,	switch f {
943,E:\DATN\dataframe\train_file\20.txt,	case BicycleFactoryType:
944,E:\DATN\dataframe\train_file\20.txt,"		return new(BicycleFactory), nil"
945,E:\DATN\dataframe\train_file\20.txt,	case MotorbikeFactoryType:
946,E:\DATN\dataframe\train_file\20.txt,"		return new(MotorbikeFactory), nil"
947,E:\DATN\dataframe\train_file\20.txt,"		err := fmt.Sprintf(""Factory with id %d not recognized\n"", f)"
948,E:\DATN\dataframe\train_file\20.txt,"		return nil, errors.New(err)"
949,E:\DATN\dataframe\train_file\20.txt,"Có đầy đủ tất cả rồi, chúng ta chạy chương trình trong main.go:"
950,E:\DATN\dataframe\train_file\20.txt,func main() {
951,E:\DATN\dataframe\train_file\20.txt,		Example Abstract Factory
952,E:\DATN\dataframe\train_file\20.txt,"	fmt.Println(""*** Example Abstract Factory ***"")"
953,E:\DATN\dataframe\train_file\20.txt,"	bicycleFactory, err := abstract_factory.BuildFactory(abstract_factory.BicycleFactoryType)"
954,E:\DATN\dataframe\train_file\20.txt,	if err != nil {
955,E:\DATN\dataframe\train_file\20.txt,"		fmt.Println(""Error: "", err)"
956,E:\DATN\dataframe\train_file\20.txt,"	sportBicycle, err := bicycleFactory.NewVehicle(abstract_factory.SportBicycleType)"
957,E:\DATN\dataframe\train_file\20.txt,	if err != nil {
958,E:\DATN\dataframe\train_file\20.txt,"		fmt.Println(""Error: "", err)"
959,E:\DATN\dataframe\train_file\20.txt,"	fmt.Println(""Sport Bicycle:"")"
960,E:\DATN\dataframe\train_file\20.txt,"	fmt.Printf(""Vehicle has %d wheels, %d seats.\n"", sportBicycle.NumWheels(), sportBicycle.NumSeats())"
961,E:\DATN\dataframe\train_file\20.txt,"	fmt.Print(""*** End of Abstract Factory ***\n\n\n"")"
962,E:\DATN\dataframe\train_file\20.txt,V. Lời kết
963,E:\DATN\dataframe\train_file\20.txt,"Qua bài viết của mình, các bạn đã hiểu được cách tạo ra factory từ những factories rồi, mẫu thiết kế này thường được dùng nhiều trong các ứng dụng, thư viện đa nên tảng như GUI libraries."
964,E:\DATN\dataframe\train_file\20.txt,"Lấy ví dụ đơn giản nhất là button, một đối tượng rất chung, và một button factory giúp bạn tạo ra các factory trên các OS khác nhau như Microsoft Windows buttons hay Mac OS X buttons."
965,E:\DATN\dataframe\train_file\20.txt,"Chúng ta không cần quan tâm phần triển khai cụ thể trên từng platform, hệ điều hành,... Công việc của chúng ta chỉ cần định nghĩa một vài action đặc biệt phải có của một button mà thôi."
966,E:\DATN\dataframe\train_file\20.txt,"Việc tạo ra các đối tượng, có thể tiếp cận bằng nhiều phương pháp khác nhau."
967,E:\DATN\dataframe\train_file\20.txt,"Như ở bài viết Buider Design Pattern, mình tạo ra Bicycle và MotorBike từ 1 factory duy nhất, nhưng ở bài viết này, mình đã mở rộng nó ra, và chúng ta có thể thấy được việc customize những đối tượng mới thêm vào sẽ dễ dàng hơn rất nhiều."
968,E:\DATN\dataframe\train_file\20.txt,"Tuy nhiên, không có mẫu thiết kế nào là tối ưu hơn mẫu thiết kế nào cả, tất cả là phụ thuộc và business, vào chính bạn ^^"
969,E:\DATN\dataframe\train_file\20.txt,Cảm ơn các bạn đã xem bài viết.
970,E:\DATN\dataframe\train_file\21.txt,Debug ứng dụng Docker
971,E:\DATN\dataframe\train_file\21.txt,Hello các bạn lại là mình đâyyyyyyyyyy 👋👋👋
972,E:\DATN\dataframe\train_file\21.txt,"Nhân tiện đợt này có thời gian, nên lại ngồi xuống chia sẻ tiếp cùng với các bạn thêm những thứ mới, cùng nhau cải thiện skill kiếm job mới...... (đùa thế, chứ gắng mà đóng cho công ty hiện tại thật nhiều đã các bạn nhé)"
973,E:\DATN\dataframe\train_file\21.txt,"Từ khi series  của mình lên sóng 2 năm trước thì được rất nhiều bạn hưởng ứng và học theo, tự thẩm du tinh thần mình thấy khá sướng 🤣🤣, các bạn làm theo từng bài, comment rằng bạn đã làm được, nhưng cũng có rất nhiều bạn gặp lỗi trong quá trình thực hành, rồi các bạn comment hỏi mình hoặc nhắn tin trực tiếp cho mình."
974,E:\DATN\dataframe\train_file\21.txt,"Và mình nhận ra phần debug ứng dụng Docker của nhiều bạn chưa đc tốt, nhiều sự ""ngây thơ"" và học chưa sâu."
975,E:\DATN\dataframe\train_file\21.txt,"Cùng với đó khi đi làm, bản thân mình và đồng nghiệp làm cùng mình cũng thấy những lỗi tương tự, nên mới có bài này, mình sẽ liệt kê ra các lỗi mình thấy trong quá trình làm việc với Docker ta hay gặp phải và cách xử lý."
976,E:\DATN\dataframe\train_file\21.txt,Bài này có thể được cập nhật thêm nhiều lỗi phổ biến hơn theo thời gian (nếu có)
977,E:\DATN\dataframe\train_file\21.txt,Bắt đầu thôi nhé 🚀🚀🚀
978,E:\DATN\dataframe\train_file\21.txt,Các lỗi về Networking
979,E:\DATN\dataframe\train_file\21.txt,"Đây là các lỗi mà mình vô cùnggggggg hay gặp khi deploy app Docker, liên quan tới việc connect giữa các app với nhau không thành công, có thể là do sai sót, không biết hay mập mờ về cấu hình của từng app,..."
980,E:\DATN\dataframe\train_file\21.txt,"Cá nhân mình thấy khi làm việc với Docker (và sau này là Kubernetes) thì một khi đã hiểu về vấn đề này thì nó rấtttttttt là dễ dàng trong việc debug khi gặp lỗi, hứa luôn 🤪🤪🤪"
981,E:\DATN\dataframe\train_file\21.txt,Quên chưa map port
982,E:\DATN\dataframe\train_file\21.txt,Giả sử ta có file docker-compose.yml như sau:
983,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
984,E:\DATN\dataframe\train_file\21.txt,    image: vad1mo/hello-world-rest
985,E:\DATN\dataframe\train_file\21.txt,"Nhìn vào đây các bạn thấy ta có 1 service app, khi start lên sẽ tạo 1 container từ image vad1mo/hello-world-rest, thử start app lên nhé:"
986,E:\DATN\dataframe\train_file\21.txt,docker compose up -d
987,E:\DATN\dataframe\train_file\21.txt,"để ý bên trên ta dùng docker compose chứ không còn là docker-compose nữa nhé các bạn, ở các phiên bản mới thì compose đã được tích hợp vào docker luôn rồi 👏👏"
988,E:\DATN\dataframe\train_file\21.txt,Sau đó ta chui vào container:
989,E:\DATN\dataframe\train_file\21.txt,docker compose exec app sh
990,E:\DATN\dataframe\train_file\21.txt,apk update && apk add curl
991,E:\DATN\dataframe\train_file\21.txt,curl localhost:5050
992,E:\DATN\dataframe\train_file\21.txt,>>> Hello World!
993,E:\DATN\dataframe\train_file\21.txt,"Ở trên các bạn thấy rằng bên trong container ta có app chạy ở cổng 5050, curl vào thì thấy trả về message Hello World ngon lành cành đào rồi."
994,E:\DATN\dataframe\train_file\21.txt,"Thế nhưng nếu quay lại môi trường gốc thì hiện tại chưa có cách nào để ta có thể gọi được vào app kia, bởi vì app của chúng ta chưa có được ""mở"" cho thế giới bên ngoài gọi vào."
995,E:\DATN\dataframe\train_file\21.txt,"Cách fix thì rất đơn giản đó là ta chỉ việc map port, chọn 1 port từ môi trường ngoài và map (ánh xạ) vào port đang chạy trong container (5050), ta sửa lại docker-compose.yml như sau:"
996,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
997,E:\DATN\dataframe\train_file\21.txt,    image: vad1mo/hello-world-rest
998,E:\DATN\dataframe\train_file\21.txt,Sau đó restart lại project:
999,E:\DATN\dataframe\train_file\21.txt,docker compose down
1000,E:\DATN\dataframe\train_file\21.txt,docker compose up -d
1001,E:\DATN\dataframe\train_file\21.txt,Sau đó mở Chrome truy cập ở địa chỉ localhost:3000 là ta thấy app chạy oke rồi:
1002,E:\DATN\dataframe\train_file\21.txt,"Như các bạn thấy, đây là 1 vấn đề nhìn thì đơn giản, nhưng không hiểu sao rất nhiều bạn lại hay quên, nhắn tin hỏi mình thì câu đầu tiên mình trả lời luôn là ""bạn đã map port hay chưa?"
1003,E:\DATN\dataframe\train_file\21.txt,""", xong các bạn rép lại ""map port là gì ạ???!!!"
1004,E:\DATN\dataframe\train_file\21.txt,"""........Mình kiểu: 😵‍💫😵‍💫😵‍💫😵‍💫😵‍💫😵‍💫"
1005,E:\DATN\dataframe\train_file\21.txt,Không biết đâu ở trong đâu là ngoài container
1006,E:\DATN\dataframe\train_file\21.txt,"Hầu như trong lúc làm việc, để tiện thì mình thường chọn map port bên ngoài giống như trong container luôn, giả sử nếu là thực tế thì ví dụ bên trên mình sẽ viết là:"
1007,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
1008,E:\DATN\dataframe\train_file\21.txt,    image: vad1mo/hello-world-rest
1009,E:\DATN\dataframe\train_file\21.txt,      - 5050:5050 # ----> ở đây
1010,E:\DATN\dataframe\train_file\21.txt,Ở trên mình map luôn port 5050 bên ngoài vào port 5050 trong container.
1011,E:\DATN\dataframe\train_file\21.txt,"Xong nhiều bạn cũng làm theo như vậy, không biết 5050 của cái nào là bên ngoài, cái nào bên trong, thôi thì cứ giống nhau cho chắc cú 😂😂😂"
1012,E:\DATN\dataframe\train_file\21.txt,"Các bạn chú ý cho mình là Docker nó theo 1 pattern đó là khi map port hoặc mount volume thì vế trái của dấu hai chấm "":"" là môi trường ngoài, vế phải là bên trong container nhé."
1013,E:\DATN\dataframe\train_file\21.txt,"Do vậy khi viết blog, để làm rõ ràng nhất cho các bạn mình thường chọn map port trong ngoài khác nhau (thi thoảng quen tay vẫn chọn giống nhau 🤣🤣):"
1014,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
1015,E:\DATN\dataframe\train_file\21.txt,    image: vad1mo/hello-world-rest
1016,E:\DATN\dataframe\train_file\21.txt,      - 3000:5050 # ngoài 3000 : trong 5050
1017,E:\DATN\dataframe\train_file\21.txt,Không rõ là đang ở trong network nào
1018,E:\DATN\dataframe\train_file\21.txt,"Mình khuyến khích các bạn định nghĩa các network riêng biệt, sau đó cho các app(services) cần connect với nhau join chung 1 network, cái nào không cần thì tách biệt ra network khác."
1019,E:\DATN\dataframe\train_file\21.txt,"Nhưng chỉ dùng nếu thật sự các bạn hiểu được mình đang làm gì, còn không thì các bạn để mặc định Docker sẽ cho tất cả các services join chung vào 1 network luôn."
1020,E:\DATN\dataframe\train_file\21.txt,"Đôi khi các bạn toàn tự làm khó vấn đề lên, chưa xem kĩ bài  của mình đã phang luôn vào project thật, nên hỏi mình nhiều câu rất ối dồi ôi 🥲🥲🥲"
1021,E:\DATN\dataframe\train_file\21.txt,"Ta quay lại Gitlab ví dụ bài Docker Network (nhánh complete-tutorial), kết quả cuối cùng ta có :"
1022,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
1023,E:\DATN\dataframe\train_file\21.txt,    image: learning-docker/docker-node-mongo-redis:production
1024,E:\DATN\dataframe\train_file\21.txt,    environment: # phần này ta định nghĩa ở file .env nhé
1025,E:\DATN\dataframe\train_file\21.txt,"      - ""${PORT}:${PORT}"" # phần này ta định nghĩa ở file .env nhé"
1026,E:\DATN\dataframe\train_file\21.txt,    restart: unless-stopped
1027,E:\DATN\dataframe\train_file\21.txt,      test: wget --quiet --tries=1 --spider http://localhost:${PORT} || exit 1z
1028,E:\DATN\dataframe\train_file\21.txt,      interval: 30s
1029,E:\DATN\dataframe\train_file\21.txt,      timeout: 10s
1030,E:\DATN\dataframe\train_file\21.txt,      retries: 5
1031,E:\DATN\dataframe\train_file\21.txt,    image: mongo
1032,E:\DATN\dataframe\train_file\21.txt,    restart: unless-stopped
1033,E:\DATN\dataframe\train_file\21.txt,"      test: echo 'db.runCommand(""ping"").ok' | mongo db:27017/speech-api --quiet"
1034,E:\DATN\dataframe\train_file\21.txt,      interval: 30s
1035,E:\DATN\dataframe\train_file\21.txt,      timeout: 10s
1036,E:\DATN\dataframe\train_file\21.txt,      retries: 5
1037,E:\DATN\dataframe\train_file\21.txt,    image: redis:5-alpine
1038,E:\DATN\dataframe\train_file\21.txt,    restart: unless-stopped
1039,E:\DATN\dataframe\train_file\21.txt,"      test: [""CMD"", ""redis-cli"",""ping""]"
1040,E:\DATN\dataframe\train_file\21.txt,      interval: 30s
1041,E:\DATN\dataframe\train_file\21.txt,      timeout: 10s
1042,E:\DATN\dataframe\train_file\21.txt,      retries: 5
1043,E:\DATN\dataframe\train_file\21.txt,#Docker Networks
1044,E:\DATN\dataframe\train_file\21.txt,    driver: bridge
1045,E:\DATN\dataframe\train_file\21.txt,    driver: bridge
1046,E:\DATN\dataframe\train_file\21.txt,"Các bạn để ý, ở tận cùng file, mình định nghĩa 2 networks:"
1047,E:\DATN\dataframe\train_file\21.txt,db-network: cho các app cần connect tới database
1048,E:\DATN\dataframe\train_file\21.txt,redis-network: cho các thành phần cần connect tới redis
1049,E:\DATN\dataframe\train_file\21.txt,Mô tả cho network của chúng ta như hình dưới:
1050,E:\DATN\dataframe\train_file\21.txt,"Như các bạn thấy ở trên, service app ở trong cả 2 network nên nó có thể gọi vào cả redis và db, thế nhưng từ redis lại không gọi sang được db, và ngược lại."
1051,E:\DATN\dataframe\train_file\21.txt,Thử chạy app lên và debug ta thấy như sau:
1052,E:\DATN\dataframe\train_file\21.txt,docker build -t learning-docker/docker-node-mongo-redis:production .
1053,E:\DATN\dataframe\train_file\21.txt,docker compose up -d
1054,E:\DATN\dataframe\train_file\21.txt,Sau đó ta chui vào app:
1055,E:\DATN\dataframe\train_file\21.txt,docker compose exec app sh
1056,E:\DATN\dataframe\train_file\21.txt,apk update & apk add curl
1057,E:\DATN\dataframe\train_file\21.txt,curl db:27017
1058,E:\DATN\dataframe\train_file\21.txt,curl redis:6379
1059,E:\DATN\dataframe\train_file\21.txt,Ta được như sau:
1060,E:\DATN\dataframe\train_file\21.txt,"Như các bạn thấy, từ app khi curl sang db và redis ta đều nhận được response bình thường."
1061,E:\DATN\dataframe\train_file\21.txt,Giờ ta thử chui vào redis và curl sang db xem nhé:
1062,E:\DATN\dataframe\train_file\21.txt,docker compose exec redis sh
1063,E:\DATN\dataframe\train_file\21.txt,apk update & apk add curl
1064,E:\DATN\dataframe\train_file\21.txt,curl db:27017
1065,E:\DATN\dataframe\train_file\21.txt,"Ta thấy rằng câu lệnh bị treo 1 lúc sau đó bị timeout và lỗi in ra là không thể tìm thấy host db trong network hiện tại, bởi vì redis và db không có chung 1 network."
1066,E:\DATN\dataframe\train_file\21.txt,Điều tương tự xảy ra khi ta chui vào db:
1067,E:\DATN\dataframe\train_file\21.txt,docker compose exec db sh
1068,E:\DATN\dataframe\train_file\21.txt,apt update & apt -y install curl
1069,E:\DATN\dataframe\train_file\21.txt,curl redis:6379
1070,E:\DATN\dataframe\train_file\21.txt,"chú ý image mongodb ta dùng là bản Debian, và nó dùng apt thay vì apk như trên Alpine để quản lý system packages nhé"
1071,E:\DATN\dataframe\train_file\21.txt,"Như các bạn thấy, không khó lắm để ta xác định được rõ ràng service nào ở trong network nào, và liệu rằng 2 service A và B có trong cùng 1 network hay không."
1072,E:\DATN\dataframe\train_file\21.txt,"Luyện được kĩ năng này sẽ cựcccccccccccc kì hữu ích cho sau này, nó sẽ giúp các bạn tiết kiệm được rất nhiều thời gian, hiểu được flow traffic đi ra vào từng thành phần trong kiến trúc của mình như thế nào, và nâng trình lên rất nhiều , đặc biệt là khi ta làm vào dự án thật, khi mà các app nằm trên các network khác nhau, ví dụ thực tế là ở các VPC khác nhau (Virtual private cloud)"
1073,E:\DATN\dataframe\train_file\21.txt,"Phần này mình nghĩ là quan trọng nhất trong việc deploy thành công được 1 kiến trúc trong dự án thật, là skill ""ăn tiền"" , vì hầu hết các vấn đề mình gặp phải là liên quan tới vấn đề này"
1074,E:\DATN\dataframe\train_file\21.txt,Các lỗi về volume
1075,E:\DATN\dataframe\train_file\21.txt,Permission Denied
1076,E:\DATN\dataframe\train_file\21.txt,"Vâng, đúng rồi đó các bạn, lỗi kinh điển nhất trong mọi lỗi khi deploy app, kinh điển đến mức mình thấy phải cho nó vào sách giáo khoa 💁‍♂️💁‍♂️💁‍♂️ Một lỗi vô cùng phổ biến, xảy ra liên tục, hàng ngày."
1077,E:\DATN\dataframe\train_file\21.txt,Lỗi này xảy ra khi thực thể nào đó không có quyền đọc/ghi vào 1 file/đường dẫn nào đó.
1078,E:\DATN\dataframe\train_file\21.txt,"Vấn đề là việc xác định được cái ""thực thể"" kia nó là cái nào thì lại phụ thuộc vào bối cảnh app của các bạn đang được setup như thế nào."
1079,E:\DATN\dataframe\train_file\21.txt,Ta lấy ví dụ bài  nhé.
1080,E:\DATN\dataframe\train_file\21.txt,Ở trong Dockerfile ở bài đó:
1081,E:\DATN\dataframe\train_file\21.txt,ta có đoạn RUN chown -R www-data:www-data .
1082,E:\DATN\dataframe\train_file\21.txt,để đổi quyền folder hiện tại về của user/group www-data
1083,E:\DATN\dataframe\train_file\21.txt,"Ta không có chỉ định container chạy với user nào, nên mặc định nó được chạy bằng user root"
1084,E:\DATN\dataframe\train_file\21.txt,"Ở phần , ta có đoạn:"
1085,E:\DATN\dataframe\train_file\21.txt,command=php /var/www/html/artisan horizon;
1086,E:\DATN\dataframe\train_file\21.txt,"Ở trên ta có chỉ định là process horizon sẽ chạy với user www-data, do vậy nếu process đó trong lúc chạy có muốn đọc ghi vào phần source project thì nó sẽ có đủ quyền, vì ở trong Dockerfile mình đã set quyền cho folder về dưới user www-data rồi."
1087,E:\DATN\dataframe\train_file\21.txt,Vậy nên nếu ta chạy Horizon với user khác mà chẳng may nó cần ghi cái gì đó thì sẽ bị báo Permission Denied
1088,E:\DATN\dataframe\train_file\21.txt,"Tương tự, ở bài , mình rất khuyến khích các bạn chạy tất cả các container bằng non-root user (nếu có thể), mình cũng làm vậy ở các project thật."
1089,E:\DATN\dataframe\train_file\21.txt,"Thế nhưng nếu không hiểu rõ và sử dụng thì sẽ vô cùng đau đầu, và ta sẽ chỉ làm vấn đề thêm phức tạp."
1090,E:\DATN\dataframe\train_file\21.txt,Vậy nên khi gặp lỗi Permission Denied thì các bạn hãy tự đặt câu hỏi:
1091,E:\DATN\dataframe\train_file\21.txt,"Cái gì đang bị lỗi Permission Denied, thực thể đang cần đọc ghi là gì?"
1092,E:\DATN\dataframe\train_file\21.txt,"Nó đang được chạy bởi user nào: root, user1, user2, hay user3,.... user đó có quyền là gì?"
1093,E:\DATN\dataframe\train_file\21.txt,"(uid/gid là gì, xác định bằng cách chạy id -u và id -g)"
1094,E:\DATN\dataframe\train_file\21.txt,Lỗi đó đang bị ở file/folder nào?
1095,E:\DATN\dataframe\train_file\21.txt,file/folder đó hiện tại đang nằm dưới uid/gid là gì?
1096,E:\DATN\dataframe\train_file\21.txt,(chạy ls -la các bạn sẽ thấy)
1097,E:\DATN\dataframe\train_file\21.txt,"ở trên thì folder hiện tại của mình nằm dưới uid=ductrungmai, gid=staff"
1098,E:\DATN\dataframe\train_file\21.txt,Mất data do quên chưa mount volume
1099,E:\DATN\dataframe\train_file\21.txt,"Bị quả lỗi này thì thật sự là ối dồi ôi, thánh cứu 🤣🤣."
1100,E:\DATN\dataframe\train_file\21.txt,Phần này không có gì để mình trình bày nhiều.
1101,E:\DATN\dataframe\train_file\21.txt,"Các bạn luôn nhớ mount volume cho các service mà cần lưu lại data giữ các lần restart app nhé, ví dụ DB, Redis,..."
1102,E:\DATN\dataframe\train_file\21.txt,Mount volume không đúng format
1103,E:\DATN\dataframe\train_file\21.txt,"Các bạn chú ý rằng giống như khi map port, format của mount volume là: phía trái của dấu hai chấm "":"" là môi trường ngoài, phía tay phải là môi trường trong container"
1104,E:\DATN\dataframe\train_file\21.txt,"đường dẫn môi trường ngoài có thể là relative hoặc absolute, nhưng đường dần bên trong container phải là absolute"
1105,E:\DATN\dataframe\train_file\21.txt,"nếu khi mount volume mà folder ta đang mount không tồn tại thì nó sẽ được tự động tạo dưới quyền root, cái đó mình đã trình bày ở bài  rồi nhé"
1106,E:\DATN\dataframe\train_file\21.txt,"Docker support 2 kiểu đó là docker volume (volume được quản lý bởi Docker) và local volume (volume ta tự quản, ví dụ chạy mongo trên windows thì sẽ bị lỗi khi dùng local volume, khi đó ta đơn giản là chuyển qua dùng Docker volume, phần này các bạn nên thử các cách khác nhau trước khi ping hỏi mình nhé, cái nào được là mình đều thấy nó oke cả 🤣🤣:"
1107,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
1108,E:\DATN\dataframe\train_file\21.txt,    image: mongo
1109,E:\DATN\dataframe\train_file\21.txt,    restart: unless-stopped
1110,E:\DATN\dataframe\train_file\21.txt,"Xong có những bạn hỏi mình, ""anh ơi relative path à đường dẫn kiểu gì"", mình lại kiểu ""??????!!!!!"
1111,E:\DATN\dataframe\train_file\21.txt,"Thực tế là có nhiều bạn chưa rõ về cái đó, thì tiện đây mình giải thích:"
1112,E:\DATN\dataframe\train_file\21.txt,"relative path: đường dẫn tương đối, tương đối theo đường dẫn nơi bạn đang đứng, dạng ../../a/b/c -- > như ví dụ kia thì là: đi lên 2 cấp cha, sau đó tìm vào folder a -> trong đó tìm b -> trong b tìm c"
1113,E:\DATN\dataframe\train_file\21.txt,"absolute path: đường dẫn tuyệt đối, tức là dù ta đứng ở đâu thì đường dẫn này cũng trỏ về 1 file/folder."
1114,E:\DATN\dataframe\train_file\21.txt,Dạng /a/b/c (để ý dấu xoạc ở đầu)
1115,E:\DATN\dataframe\train_file\21.txt,Volume bị thay đổi theo cấu hình
1116,E:\DATN\dataframe\train_file\21.txt,"Với các service dạng stateful kiểu (mysql, mongodb,...), thì khi 1 số cấu hình thay đổi nó kèm theo volume có thể bị thay đổi và lỗi theo."
1117,E:\DATN\dataframe\train_file\21.txt,"Ví dụ mình setup mongodb ban đầu không có authentication, chạy lên ngon nghẻ, từ app gọi vào db bình thường, nhưng lát nữa mình shutdown các app đi, set password cho mongodb, sau đó lại chạy lên rồi từ app mình connect sang db, có password rồi, nhưng liên tục báo connect không thành công."
1118,E:\DATN\dataframe\train_file\21.txt,"Trong trường hợp đó thường mình phải xoá luôn cả volume đi chạy lại, nhưng nhớ lưu lại data của db trước khi xoá volume nhé  (dump db ra trước nhé)"
1119,E:\DATN\dataframe\train_file\21.txt,"Mount volume vào các đường dẫn ""nhạy cảm"""
1120,E:\DATN\dataframe\train_file\21.txt,"Trong container có rất nhiều đường dẫn của hệ điều hành (OS) trong đó mà ta không nên ghi đè hoặc mount volume vào, ví dụ /var, /etc,... Nếu hạn chế được thì các bạn né những nơi đó ra nhé vì nhiều process của OS dùng các đường dẫn đó, và hầu hết chúng nằm dưới user root, nên nếu các bạn mà chạy container với non-root user thì còn dễ bị dính lỗi hơn nữa"
1121,E:\DATN\dataframe\train_file\21.txt,Note cho app Javascript
1122,E:\DATN\dataframe\train_file\21.txt,Gỉa sử ta có app như sau:
1123,E:\DATN\dataframe\train_file\21.txt,FROM node:16-alpine
1124,E:\DATN\dataframe\train_file\21.txt,RUN npm install
1125,E:\DATN\dataframe\train_file\21.txt,    image: my-nodejs-image
1126,E:\DATN\dataframe\train_file\21.txt,"Trong Dockerfile ta cấu hình build image, và như thường lệ, ta sẽ chạy npm install để cài dependencies"
1127,E:\DATN\dataframe\train_file\21.txt,Trong file compose ta map toàn bộ code ở folder môi trường ngoài vào trong đường dẫn /app trong container
1128,E:\DATN\dataframe\train_file\21.txt,"Khi chạy app lên, nếu trước đó bên ngoài ta đã có folder node_modules thì folder node_modules bên ngoài sẽ ghi đè lên node_modules bên trong và ta sẽ gặp lỗi."
1129,E:\DATN\dataframe\train_file\21.txt,"Trường hợp này dễ dàng xảy ra khi trước đó bên ngoài ta đã chạy npm install trước rồi, sau đó ta mới Dockerize project"
1130,E:\DATN\dataframe\train_file\21.txt,Vậy nên để tránh điều này thì ta làm như sau:
1131,E:\DATN\dataframe\train_file\21.txt,    image: my-nodejs-image
1132,E:\DATN\dataframe\train_file\21.txt,      - /app/node_modules # -> thêm phần này vào
1133,E:\DATN\dataframe\train_file\21.txt,Các lỗi khác
1134,E:\DATN\dataframe\train_file\21.txt,Copy từ stage không tồn tại
1135,E:\DATN\dataframe\train_file\21.txt,"Khi build các app frontend (React, Vue, Angular,...) như các bài mình hướng dẫn thì ta nên chia quá trình build thành nhiều stages để có thể tối ưu image size, vậy nhưng khi implement thật thì nó lạ lắm 😅:"
1136,E:\DATN\dataframe\train_file\21.txt,FROM node:16-alpine
1137,E:\DATN\dataframe\train_file\21.txt,WORKDIR /app
1138,E:\DATN\dataframe\train_file\21.txt,COPY package.json yarn.lock ./
1139,E:\DATN\dataframe\train_file\21.txt,RUN yarn install --frozen-lockfile --ignore-scripts
1140,E:\DATN\dataframe\train_file\21.txt,FROM node:16-alpine as builder
1141,E:\DATN\dataframe\train_file\21.txt,WORKDIR /app
1142,E:\DATN\dataframe\train_file\21.txt,COPY --from=deps /app/node_modules ./node_modules
1143,E:\DATN\dataframe\train_file\21.txt,RUN yarn build && yarn install --production --ignore-scripts --prefer-offline
1144,E:\DATN\dataframe\train_file\21.txt,"Ở đoạn code bên trên, khi chạy tới bước COPY --from=deps /app/n... thì ta thấy Docker nó treo mãi và cuối cùng báo lỗi vì không tìm được deps."
1145,E:\DATN\dataframe\train_file\21.txt,"Vấn đề là ở dòng đầu tiên ta FROM, ta quên chưa set tên cho stage đó ""as"" cái gì, nên tới bước COPY --from=deps /app/n.... thì Docker nó sẽ tìm trên Dockerhub xem có image nào tên là deps hay không, và bởi vì không tìm được nên nó báo lỗi"
1146,E:\DATN\dataframe\train_file\21.txt,Do vậy luôn để ý tên của stage khi COPY làm sao cho đúng các bạn nhé
1147,E:\DATN\dataframe\train_file\21.txt,Chưa build image đã dùng
1148,E:\DATN\dataframe\train_file\21.txt,"Sau khi xem bài Docker nodejs, có bạn hỏi mình sao chạy docker compose up mà nó cứ báo không tìm thấy image, code và cấu hình docker-compose đúng hết rồi:"
1149,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
1150,E:\DATN\dataframe\train_file\21.txt,    image: learning-docker/docker-node-mongo-redis:production
1151,E:\DATN\dataframe\train_file\21.txt,"Mình bảo ""không tìm thấy image đơn giản vì image không tồn tại ở local và trên dockerhub, bạn đã build image chưa?"
1152,E:\DATN\dataframe\train_file\21.txt,""", các bạn ngây thơ ""phải build image mới dùng được à?????!!!!!!!""."
1153,E:\DATN\dataframe\train_file\21.txt,Hết nước chấm 🥲🥲🥲🥲
1154,E:\DATN\dataframe\train_file\21.txt,Map cả 1 dải port dài dẫn tới máy bị treo
1155,E:\DATN\dataframe\train_file\21.txt,"Các bạn nên cẩn thận khi map 1 dải nhiều port một lúc, vì Docker sẽ tạo ra 1 process để xử lý 1 port khi ta map, vậy nên map càng nhiều thì càng nhiều process và RAM sẽ bị ăn nhiều hơn"
1156,E:\DATN\dataframe\train_file\21.txt,"version: ""3.4"""
1157,E:\DATN\dataframe\train_file\21.txt,    image: learning-docker/docker-node-mongo-redis:production
1158,E:\DATN\dataframe\train_file\21.txt,"Lại hết 1 bài nữa rồi, 🥲🥲🥲"
1159,E:\DATN\dataframe\train_file\21.txt,"Hi vọng là qua bài này các bạn có thể hiểu hơn về một số lỗi hay gặp phải khi làm việc với Docker và cách xử lý chúng, từ đó nâng cao skill, và đặc biệt là hiểu được cách hệ thống của các bạn đang hoạt động như thế nào, các services kết nối với nhau ra sao."
1160,E:\DATN\dataframe\train_file\21.txt,"Việc cải thiện skill debug cũng sẽ giúp các bạn làm việc độc lập hơn nữa đó, ít phải search google hay ping hỏi đồng đội / leader mỗi khi có lỗi xảy ra"
1161,E:\DATN\dataframe\train_file\21.txt,"Thân ái và quyết thắng, hẹn gặp lại các bạn ở những bài sau"
1162,E:\DATN\dataframe\train_file\22.txt,GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.
1163,E:\DATN\dataframe\train_file\22.txt,"GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer tools."
1164,E:\DATN\dataframe\train_file\22.txt,QL viết tắt của từ query language nghĩa là ngôn ngữ truy vấn.
1165,E:\DATN\dataframe\train_file\22.txt,Có thể hiểu nó giống như một câu truy vấn SQL nhưng không phải trên Table mà là trên các API.
1166,E:\DATN\dataframe\train_file\22.txt,Nó không phải là một công nghệ thay thế REST API mà giống như một thư viện giúp khắc phục các vấn đề của REST.
1167,E:\DATN\dataframe\train_file\22.txt,"Có thể lấy chính xác dữ liệu mà Client cần thông qua câu truy vấn giúp nâng cao, cải thiện tốc độ truy vấn, tránh dư thừa dữ liệu không cần thiết."
1168,E:\DATN\dataframe\train_file\23.txt,Khởi tạo đối tượng Thread trong java
1169,E:\DATN\dataframe\train_file\23.txt,Khởi tạo Thread
1170,E:\DATN\dataframe\train_file\23.txt,"Class Thread, Object và interface Runnable đều có những phương thức hỗ trợ cho concurrency trong java."
1171,E:\DATN\dataframe\train_file\23.txt,"Thread có các phương thức như run(), start() và sleep() rất hữu ích cho các tác vụ đa luồng."
1172,E:\DATN\dataframe\train_file\23.txt,Object có các phương thức như wait() và notify() để hỗ trợ cho lập trình concurrency.
1173,E:\DATN\dataframe\train_file\23.txt,"Vì mọi class trong java đề kế thừa từ class Object, nên tất cả object đều có một số khả năng hỗ trợ đa luồng cơ bản."
1174,E:\DATN\dataframe\train_file\23.txt,"Ví dụ, ta có thể khóa bất kỳ object nào trong java (sử dụng từ khóa synchronized- sẽ được nhắc đến ở các bài viết sau)."
1175,E:\DATN\dataframe\train_file\23.txt,"Tuy nhiên, đối với việc khởi tạo thread thì các phương thức hỗ trợ của class Object không thực sự hữu dụng."
1176,E:\DATN\dataframe\train_file\23.txt,Để giải quyết vấn đề này ta có thể extend class java.lang.Thread hoặc implement interfacejava.lang.Runnable.
1177,E:\DATN\dataframe\train_file\23.txt,Cách đơn giản nhất để thực thi một thread là sử dụng class java.lang.Thread (viết tắt là Thread).
1178,E:\DATN\dataframe\train_file\23.txt,Thực thi một tác vụ với Thread là một quá trình gồm hai bước.
1179,E:\DATN\dataframe\train_file\23.txt,"Đầu tiên, xác định Thread với nhiệm vụ tương ứng sẽ được thực hiện."
1180,E:\DATN\dataframe\train_file\23.txt,"Sau đó, bắt đầu tác vụ bằng cách sử dụng phương thức start()."
1181,E:\DATN\dataframe\train_file\23.txt,Lưu ý: Java sẽ không đảm bảo về thứ tự mà một thread sẽ được xử lý sau khi nó được bắt đầu.
1182,E:\DATN\dataframe\train_file\23.txt,Nó có thể được thực hiện ngay lập tức hoặc bị trì hoãn trong một khoảng thời gian đáng kể.
1183,E:\DATN\dataframe\train_file\23.txt,Sau đây sẽ là cách để khởi tạo thread bằng Thread và Runnable
1184,E:\DATN\dataframe\train_file\23.txt,Khởi tạo bằng class Thread
1185,E:\DATN\dataframe\train_file\23.txt,Để khởi tạo một thread bằng cách kế thừa class Thread ta cần override phương thức run().
1186,E:\DATN\dataframe\train_file\23.txt,"Nếu không, phương thức run() mặc định của class Thread sẽ được sử dụng, nó sẽ không làm gì cả."
1187,E:\DATN\dataframe\train_file\23.txt,"Để override run(), ta cần đặt nó là hàm public, không có tham số đầu vào và kiểu trả về là void."
1188,E:\DATN\dataframe\train_file\23.txt,"Hay nói cách khác, sẽ là public void run()."
1189,E:\DATN\dataframe\train_file\23.txt,ta có thể thực thi một thread bằng cách gọi hàm start() từ một instance của class Thread.
1190,E:\DATN\dataframe\train_file\23.txt,"Khi JVM schedule thread, nó sẽ chuyển thread về trạng thái runnable và thực thi phương thức run()."
1191,E:\DATN\dataframe\train_file\23.txt,Khi run() được hoàn thành thì thread này sẽ bị terminate.
1192,E:\DATN\dataframe\train_file\23.txt,class MyThread extends Thread {
1193,E:\DATN\dataframe\train_file\23.txt,     public void run() {
1194,E:\DATN\dataframe\train_file\23.txt,         catch (InterruptedException ex) {
1195,E:\DATN\dataframe\train_file\23.txt,             // ignore the InterruptedException - this is perhaps the one of the
1196,E:\DATN\dataframe\train_file\23.txt,             // very few of the exceptions in Java which is acceptable to ignore
1197,E:\DATN\dataframe\train_file\23.txt,"         System.out.println(""In run(); thread name is: "" + getName());"
1198,E:\DATN\dataframe\train_file\23.txt,     public static void main(String args[]) {
1199,E:\DATN\dataframe\train_file\23.txt,         Thread myThread = new MyThread();
1200,E:\DATN\dataframe\train_file\23.txt,"         System.out.println(""In main(); thread name: "" +"
1201,E:\DATN\dataframe\train_file\23.txt,Chương trình trên sẽ có kết quả như sau:
1202,E:\DATN\dataframe\train_file\23.txt,In main(); thread name is: main
1203,E:\DATN\dataframe\train_file\23.txt,In run(); thread name is: Thread-0
1204,E:\DATN\dataframe\train_file\23.txt,"Trong ví dụ trên, class MyThread đã kế thừa class Thread."
1205,E:\DATN\dataframe\train_file\23.txt,"Phương thức run() đã được override, nó sẽ được gọi đến khi mà thread chạy."
1206,E:\DATN\dataframe\train_file\23.txt,"Tại hàm main(), ta khởi tạo một thread mới và bắt đầu nó bằng cách sử dụng phương thức start()."
1207,E:\DATN\dataframe\train_file\23.txt,"Một điều quan trọng là, không được gọi trực tiếp đến phương thức run()."
1208,E:\DATN\dataframe\train_file\23.txt,"Thay vào đó, khi bắt đầu thread bằng cách gọi hàm start(), phương thức run() sẽ tự động được thực hiện bởi JVM."
1209,E:\DATN\dataframe\train_file\23.txt,"Để lấy ra tên của thread, có thể sử dụng phương thức getName (), nó trả về một String."
1210,E:\DATN\dataframe\train_file\23.txt,Vì main() là một phương thức tĩnh nên không có quyền truy cập vào tham chiếu này.
1211,E:\DATN\dataframe\train_file\23.txt,"Vì vậy, phải lấy tên của thread hiện tại bằng cách sử dụng phương thức tĩnh currentThread() trong class Thread (trả về một đối tượng Thread)."
1212,E:\DATN\dataframe\train_file\23.txt,"Bây giờ, ta có thể gọi getName() trên đối tượng được trả về đó."
1213,E:\DATN\dataframe\train_file\23.txt,Khởi tạo bằng interface Runnable
1214,E:\DATN\dataframe\train_file\23.txt,Runnable interface là một functional interface có một phương thức duy nhất là run() và không yêu cầu tham số đầu vào cũng như return bất kỳ giá trị nào.
1215,E:\DATN\dataframe\train_file\23.txt,"Nó thường được sử dụng để xác định các công việc mà một thread sẽ thực thi, tách biệt với main thread của ứng dụng."
1216,E:\DATN\dataframe\train_file\23.txt,@FunctionalInterface public interface Runnable {
1217,E:\DATN\dataframe\train_file\23.txt,     void run();
1218,E:\DATN\dataframe\train_file\23.txt,Một cách khác để tạo một thread là implement interface Runnable (class Thread đã tự implement interface Runnable).
1219,E:\DATN\dataframe\train_file\23.txt,"Interface Runnable khai báo một phương thức duy nhất, run()."
1220,E:\DATN\dataframe\train_file\23.txt,"Do đó, khi implement, cần phải định nghĩa rõ ràng phương thức run()."
1221,E:\DATN\dataframe\train_file\23.txt,Một điều quan trọng là interface Runnable không khai báo phương thức start().
1222,E:\DATN\dataframe\train_file\23.txt,"Vì vậy, làm thế nào để tạo một thread bằng cách này?"
1223,E:\DATN\dataframe\train_file\23.txt,"Câu trả lời là, Thread có một overloaded constructor, nó sẽ nhận một đối tượng Runnable làm tham số đầu vào."
1224,E:\DATN\dataframe\train_file\23.txt,Cụ thể sẽ như sau:
1225,E:\DATN\dataframe\train_file\23.txt,class RunnableImpl implements Runnable {
1226,E:\DATN\dataframe\train_file\23.txt,    public void run() {
1227,E:\DATN\dataframe\train_file\23.txt,"        System.out.println(""In run(); thread name is: "" +"
1228,E:\DATN\dataframe\train_file\23.txt,    public static void main(String args[]) throws Exception {
1229,E:\DATN\dataframe\train_file\23.txt,        Thread myThread = new Thread(new RunnableImpl());
1230,E:\DATN\dataframe\train_file\23.txt,"        System.out.println(""In main(); thread name is: "" +"
1231,E:\DATN\dataframe\train_file\23.txt,Chương trình trên sẽ có kết quả như sau:
1232,E:\DATN\dataframe\train_file\23.txt,In main(); thread name is: main
1233,E:\DATN\dataframe\train_file\23.txt,In run(); thread name is: Thread-0
1234,E:\DATN\dataframe\train_file\23.txt,"Ở ví dụ trên, ta đã implement phương thức run()."
1235,E:\DATN\dataframe\train_file\23.txt,"Tuy nhiên, để lấy tên của thread, vẫn phải lấy thông qua Thread.currentThread().GetName()."
1236,E:\DATN\dataframe\train_file\23.txt,"Trong phương thức main(), để tạo một thread, ta đã truyền một object là một instance của class RunnableImpl cho phương thức khởi tạo của class Thread."
1237,E:\DATN\dataframe\train_file\23.txt,Phương thức start() bắt đầu thread và sau đó JVM gọi phương thức run().
1238,E:\DATN\dataframe\train_file\23.txt,Thread vs Runnable
1239,E:\DATN\dataframe\train_file\23.txt,Trong trường hợp muốn biết được khi nào thì sử dụng Thread khi nào thì sử dụng Runnable để khởi tạo một đối tượng thread thì dưới đây là một số lý do để lựa chọn phương pháp này hay phương pháp kia.
1240,E:\DATN\dataframe\train_file\23.txt,"Nếu cần định nghĩa Thread một cách chi tiết , ví dụ như mức độ ưu tiên của thread thì việc extend class Thread sẽ phù hợp hơn."
1241,E:\DATN\dataframe\train_file\23.txt,"Vì Java không hỗ trợ đa kế thừa, nên việc extend class Thread sẽ không cho phép chúng ta extend thêm bất kì class nào khác nữa."
1242,E:\DATN\dataframe\train_file\23.txt,Trong trường hợp này việc implement interfaceRunnable sẽ cho phép chúng ta extend thêm một class khác.
1243,E:\DATN\dataframe\train_file\23.txt,Implement interfaceRunnable thường sẽ là một phương án đáp ứng được thiết kế OOP tốt hơn.
1244,E:\DATN\dataframe\train_file\23.txt,Vì nó tách tác vụ đang được thực hiện ra khỏi đối tượng Thread đang thực hiện nó.
1245,E:\DATN\dataframe\train_file\23.txt,Implement interfaceRunnable cho phép class có thể được sử dụng bởi nhiều class concurrency API
1246,E:\DATN\dataframe\train_file\23.txt,"Tuy nhiên, ngoài việc extend class Thread và implement interface Runnable thì ta có thể sử dụng ExecutorService như một cách tiện lợi hơn để có thể thực hiện các tác vụ liên quan đến thread mà không cần phải trực tiếp tạo các đối tượng thread"
1247,E:\DATN\dataframe\train_file\23.txt,Polling với Sleep()
1248,E:\DATN\dataframe\train_file\23.txt,"Đôi khi, chúng ta cần một thread kiểm tra (poll) dữ liệu, trạng thái,.. tại một số thời điểm nhất định để tiến hành một số thao tác."
1249,E:\DATN\dataframe\train_file\23.txt,Polling là một process kiểm tra dữ liệu không liên tục tại một số khoảng thời gian cố định.
1250,E:\DATN\dataframe\train_file\23.txt,Ví dụ: giả sử ta có một thread cập nhật giá trị của một biến static counter được chia sẻ giữa các thread với nhau.
1251,E:\DATN\dataframe\train_file\23.txt,Trong khi đó main thread sẽ đợi counter đạt giá trị 100.
1252,E:\DATN\dataframe\train_file\23.txt,Được mô tả như sau:
1253,E:\DATN\dataframe\train_file\23.txt,public class CheckResults {
1254,E:\DATN\dataframe\train_file\23.txt,    private static int counter = 0;
1255,E:\DATN\dataframe\train_file\23.txt,    public static void main(String[] args) {
1256,E:\DATN\dataframe\train_file\23.txt,        new Thread(() -> {
1257,E:\DATN\dataframe\train_file\23.txt,            for(int i=0; i<500; i++) {
1258,E:\DATN\dataframe\train_file\23.txt,"            System.out.println(""Not reached yet"");"
1259,E:\DATN\dataframe\train_file\23.txt,Câu hỏi đặt ra là vòng lặp while() trong đoạn code trên sẽ thực hiện bao nhiêu lần và kết quả trả về sẽ in ra bao nhiêu dòng Not reached yet ?
1260,E:\DATN\dataframe\train_file\23.txt,"Câu trả lời là, không thể xác định được."
1261,E:\DATN\dataframe\train_file\23.txt,"Kết quả có thể là không có lần nào, 10 lần hay cả nghìn lần."
1262,E:\DATN\dataframe\train_file\23.txt,"Thậm chí, nếu như có một thread scheduler không tốt, nó có thể sẽ chạy đến vô hạn lần."
1263,E:\DATN\dataframe\train_file\23.txt,Sử dụng vòng lặp while() trong trường hợp này để kiểm tra dữ liệu mà không có một số kiểu độ trễ được áp dụng vào là một phương án code rất tệ vì nó khiến cho CPU resources bị chiếm dụng mà không có lý do gì cả.
1264,E:\DATN\dataframe\train_file\23.txt,Chúng ta có thể tránh được việc này bằng cách sử dụng phương thức Thread.sleep() để triển khai polling.
1265,E:\DATN\dataframe\train_file\23.txt,Phương thức Thread.sleep() yêu cầu luồng hiện tại sẽ phải dừng lại trong một khoảng mili giây được chỉ định.
1266,E:\DATN\dataframe\train_file\23.txt,"Khi được sử dụng trong hàm main(), thread được dùng để thực thi hàm main() sẽ tạm dừng, trong khi các luồng khác sẽ tiếp tục chạy."
1267,E:\DATN\dataframe\train_file\23.txt,Cụ thể như sau:
1268,E:\DATN\dataframe\train_file\23.txt,public class CheckResults {
1269,E:\DATN\dataframe\train_file\23.txt,    private static int counter = 0;
1270,E:\DATN\dataframe\train_file\23.txt,    public static void main(String[] args) throws InterruptedException{
1271,E:\DATN\dataframe\train_file\23.txt,        new Thread(() -> {
1272,E:\DATN\dataframe\train_file\23.txt,            for(int i=0; i<500; i++) {
1273,E:\DATN\dataframe\train_file\23.txt,"            System.out.println(""Not reached yet"");"
1274,E:\DATN\dataframe\train_file\23.txt,            Thread.sleep(1000); // 1 SECOND
1275,E:\DATN\dataframe\train_file\23.txt,"Ở ví dụ này, tạm thời bỏ qua việc phải throwInterruptedException thì ta đã delay 1000 mili giây ở cuối mỗi vòng lặp."
1276,E:\DATN\dataframe\train_file\23.txt,"Mặc dù thay đổi này là rất nhỏ, nhưng hiện ta ta đã có thể ngăn việc tạo ra một vòng lặp vô hạn và nguy cơ ứng dụng bị lock."
1277,E:\DATN\dataframe\train_file\23.txt,"Quay lại câu hỏi ban đầu, vòng lặp while() trong đoạn code trên sẽ thực hiện bao nhiêu lần và kết quả trả về sẽ in ra bao nhiêu dòng Not reached yet ?"
1278,E:\DATN\dataframe\train_file\23.txt,Câu trả lời vẫn sẽ là không thể xác định được.
1279,E:\DATN\dataframe\train_file\23.txt,"Mặc dù việc polling ngăn cho CPU không bị quá tải bởi một vòng lặp vô hạn có khả năng xảy ra, nhưng nó không chắc chắn được khi nào thì vòng lặp sẽ kết thúc.Ví dụ: thread tăng biến counter sẽ có thể sử dụng CPU một process có độ ưu tiên cao hơn, dẫn đến nhiều lần thực thi vòng lặp while() trước khi nó kết thúc."
1280,E:\DATN\dataframe\train_file\23.txt,Một vấn đề khác cần quan tâm là biến counter được chia sẻ giữa các thread.
1281,E:\DATN\dataframe\train_file\23.txt,Điều gì sẽ xảy ra nếu một thread đang đọc nó trong khi một thread khác đang cập nhật lại nó?
1282,E:\DATN\dataframe\train_file\23.txt,thread đọc sẽ có thể nhận được một giá trị không hợp lệ hoặc không chính xác.
1283,E:\DATN\dataframe\train_file\23.txt,Đây chính là vấn đề về việc đồng bộ hóa (synchronization) sẽ được đề cập đến sau.
1284,E:\DATN\dataframe\train_file\23.txt,Tài liệu tham khảo
1285,E:\DATN\dataframe\train_file\23.txt,"Jeanne Boyarsky, Scott Selikoff."
1286,E:\DATN\dataframe\train_file\23.txt,OCP Oracle Certified Professional Java SE 8 Programmer II Study Guide Exam
1287,E:\DATN\dataframe\train_file\24.txt,Hướng dẫn cấu hình Basic Authentication trên Nginx
1288,E:\DATN\dataframe\train_file\24.txt,"Trong quá trình phát triển web, có những lúc chúng ta sẽ cần phải giới hạn người dùng truy cập đến website của mình và để giới hạn chúng ta có thể yêu cầu người dùng xác thực qua tài khoản và mật khẩu."
1289,E:\DATN\dataframe\train_file\24.txt,Bài viết này sẽ hướng dẫn cho bạn các bước để cấu hình  bảo vệ server  chạy trên môi trường .
1290,E:\DATN\dataframe\train_file\24.txt,Chuẩn bị 1 VPS
1291,E:\DATN\dataframe\train_file\24.txt,Cài đặt  là web server
1292,E:\DATN\dataframe\train_file\24.txt,sudo apt-get update
1293,E:\DATN\dataframe\train_file\24.txt,sudo apt-get install nginx
1294,E:\DATN\dataframe\train_file\24.txt,Tạo file lưu mật khẩu
1295,E:\DATN\dataframe\train_file\24.txt,"Để tạo mật khẩu, chúng ta có thể sử dụng ."
1296,E:\DATN\dataframe\train_file\24.txt,"Nếu server đã có  thì có thể chuyển qua bước tiếp theo, còn chưa có thì chúng ta cần cài đặt  trước thông qua lệnh:"
1297,E:\DATN\dataframe\train_file\24.txt,sudo apt install libssl-dev
1298,E:\DATN\dataframe\train_file\24.txt,sudo apt install openssl
1299,E:\DATN\dataframe\train_file\24.txt,Tạo một file .htpasswd để lưu tài khoản và mật khẩu bên trong thư mục /etc/nginx/basic-auth.
1300,E:\DATN\dataframe\train_file\24.txt,"Nếu có nhiều web cùng chạy trên server này thì có thể tạo các file riêng cho từng web, ví dụ .htpasswd-web, .htpasswd-another-web."
1301,E:\DATN\dataframe\train_file\24.txt,Đầu tiên chúng ta sẽ thêm tên đăng nhập vào file .htpasswd.
1302,E:\DATN\dataframe\train_file\24.txt,Ví dụ chúng ta sử dụng tên đăng nhập là username thì chạy lệnh:
1303,E:\DATN\dataframe\train_file\24.txt,"sudo sh -c ""echo -n 'username:' >> /etc/nginx/basic-auth/.htpasswd"""
1304,E:\DATN\dataframe\train_file\24.txt,Tiếp theo chúng ta cần thêm mật khẩu đã mã hóa cho tên đăng nhập username bằng lệnh:
1305,E:\DATN\dataframe\train_file\24.txt,"sudo sh -c ""openssl passwd -apr1 >> /etc/nginx/basic-auth/.htpasswd"""
1306,E:\DATN\dataframe\train_file\24.txt,"Sau khi chạy lệnh trên, nhập mật khẩu mong muốn và xác nhận mật khẩu rồi nhấn Enter."
1307,E:\DATN\dataframe\train_file\24.txt,"Xem nội dung file .htpasswd vừa tạo, chạy lệnh:"
1308,E:\DATN\dataframe\train_file\24.txt,cat /etc/nginx/basic-auth/.htpasswd
1309,E:\DATN\dataframe\train_file\24.txt,Nội dung có dạng như bên dưới nghĩa là chúng ta đã tạo thành công tài khoản và mật khẩu:
1310,E:\DATN\dataframe\train_file\24.txt,Cấu hình xác thực mật khẩu cho Nginx
1311,E:\DATN\dataframe\train_file\24.txt,"Cập nhật file config nginx, trong ví dụ này mình sử dụng file default của nginx, ngoài ra mọi người có thể cập nhật vào file config tương ứng với web trên server cửa mình."
1312,E:\DATN\dataframe\train_file\24.txt,sudo nano /etc/nginx/sites-enabled/default
1313,E:\DATN\dataframe\train_file\24.txt,Ban đầu file /etc/nginx/sites-enabled/default có dạng như sau:
1314,E:\DATN\dataframe\train_file\24.txt,    listen 80 default_server;
1315,E:\DATN\dataframe\train_file\24.txt,    listen [::]:80 default_server ipv6only=on;
1316,E:\DATN\dataframe\train_file\24.txt,    root /usr/share/nginx/html;
1317,E:\DATN\dataframe\train_file\24.txt,    index index.html index.htm;
1318,E:\DATN\dataframe\train_file\24.txt,    server_name localhost;
1319,E:\DATN\dataframe\train_file\24.txt,        try_files $uri $uri/ =404;
1320,E:\DATN\dataframe\train_file\24.txt,Chúng ta thêm auth_basic và auth_basic_user_file trỏ đến file tên đăng nhập và mật khẩu bạn vừa mới tạo ở trên.
1321,E:\DATN\dataframe\train_file\24.txt,    listen 80 default_server;
1322,E:\DATN\dataframe\train_file\24.txt,    listen [::]:80 default_server ipv6only=on;
1323,E:\DATN\dataframe\train_file\24.txt,    root /usr/share/nginx/html;
1324,E:\DATN\dataframe\train_file\24.txt,    index index.html index.htm;
1325,E:\DATN\dataframe\train_file\24.txt,    server_name localhost;
1326,E:\DATN\dataframe\train_file\24.txt,        try_files $uri $uri/ =404;
1327,E:\DATN\dataframe\train_file\24.txt,"        auth_basic ""Restricted Content"";"
1328,E:\DATN\dataframe\train_file\24.txt,        auth_basic_user_file /etc/nginx/basic-auth/.htpasswd;
1329,E:\DATN\dataframe\train_file\24.txt,Lưu file config lại và restart lại server.
1330,E:\DATN\dataframe\train_file\24.txt,sudo systemctl restart nginx
1331,E:\DATN\dataframe\train_file\24.txt,"Sau khi khởi động lại server, truy cập vào trang web của mình, chúng ta sẽ thấy có 1 cửa sổ bật ra yêu cầu nhập tên đăng nhập và mật khẩu (giống như hình ảnh ở đầu bài viết)."
1332,E:\DATN\dataframe\train_file\24.txt,Nếu chúng ta điền đúng tài khoản thì sẽ được phép truy cập vào bên trong trang web.
1333,E:\DATN\dataframe\train_file\24.txt,Ngược lại nếu điền sai hoặc chọn cancel thì trang web sẽ tự chuyển hướng đến trang thông báo lỗi 401 Authorization Required.
1334,E:\DATN\dataframe\train_file\25.txt,Flutter - Continuous delivery android cho Flutter App
1335,E:\DATN\dataframe\train_file\25.txt,"Chào các bạn, để tiết kiệm thời gian build app rồi phải deploy thủ công thì hôm nay mình sẽ viết 1 bài về Continuous delivery (from local machine) android phục vụ cho deploy Flutter app."
1336,E:\DATN\dataframe\train_file\25.txt,Vì là bài viết đầu tay nên có gì thiếu sót mọi người thông cảm và góp ý để nâng cao chất lượng bài viết sau này nhé.
1337,E:\DATN\dataframe\train_file\25.txt,Các cách để setup Continuous delivery cho Flutter app
1338,E:\DATN\dataframe\train_file\25.txt,"Chúng ta có thể dễ dàng tìm được những giải pháp hỗ trợ cho việc deploy Flutter dễ dàng trên Docs của Flutter, về cơ bản có 2 giải pháp chính:"
1339,E:\DATN\dataframe\train_file\25.txt,"Sử dụng dịch vụ bên thứ 3 như: Codemagic, Bitrise, Appcircle."
1340,E:\DATN\dataframe\train_file\25.txt,"(mình có dùng qua Codemagic, khá tiện lợi)."
1341,E:\DATN\dataframe\train_file\25.txt,Cấu hình thủ công bằng fastlane (trong bài viết này mình sẽ tập trung vào giải pháp này).
1342,E:\DATN\dataframe\train_file\25.txt,Điều kiện tiên quyết
1343,E:\DATN\dataframe\train_file\25.txt,Cần có tài khoản Google Play Console Developer.
1344,E:\DATN\dataframe\train_file\25.txt,Đã cài đặt môi trường cần thiết để phát triển Flutter App.
1345,E:\DATN\dataframe\train_file\25.txt,Cài đặt môi trường phát triển và build file .aab (android app bundle).
1346,E:\DATN\dataframe\train_file\25.txt,Cài đặt và cấu hình fastlane.
1347,E:\DATN\dataframe\train_file\25.txt,brew install fastlane
1348,E:\DATN\dataframe\train_file\25.txt,flutter create —org com.example projectname
1349,E:\DATN\dataframe\train_file\25.txt,cd android
1350,E:\DATN\dataframe\train_file\25.txt,fastlane init
1351,E:\DATN\dataframe\train_file\25.txt,Sau khi chạy lệnh “fastlane init” terminal sẽ yêu cầu cung cấp 1 số thông tin:
1352,E:\DATN\dataframe\train_file\25.txt,Cung cấp package name của app (ví dụ: ).
1353,E:\DATN\dataframe\train_file\25.txt,Cung cấp json secret file: nhấn “n” (bước này mình sẽ thiết lập sau).
1354,E:\DATN\dataframe\train_file\25.txt,Nhấn 'n' khi được hỏi “liệu bạn có định tải thông tin lên Google Play qua fastlane hay không?” (mình sẽ thiết lập sau).
1355,E:\DATN\dataframe\train_file\25.txt,Sau khi hoàn tất “thủ tục” fastlane init fastlane sẽ khởi tạo 2 file Appfile (cấu hình thông tin cho app) và Fastfile (cấu hình các lệnh deploy) trong thư mục android/fastlane.
1356,E:\DATN\dataframe\train_file\25.txt,Cấu hình trên Google Play Console và Google Cloud Platform để lấy “Json secret file” đã đề cập trước đó.
1357,E:\DATN\dataframe\train_file\25.txt,Các bước sẽ như sau:
1358,E:\DATN\dataframe\train_file\25.txt,Mở Google Play Console
1359,E:\DATN\dataframe\train_file\25.txt,"Ở Sidebar bên trái, click vào Account Details, chú ý Developer Account ID."
1360,E:\DATN\dataframe\train_file\25.txt,Click vào Setup ⇒ API access
1361,E:\DATN\dataframe\train_file\25.txt,Chuyển tới Google Cloud Platform
1362,E:\DATN\dataframe\train_file\25.txt,Click vào nút Create new service account.
1363,E:\DATN\dataframe\train_file\25.txt,để chuyển tới Google Cloud Platform.
1364,E:\DATN\dataframe\train_file\25.txt,Click nút CREATE SERVICE ACCOUNT ở đầu trang Google Cloud Platform Console.
1365,E:\DATN\dataframe\train_file\25.txt,Xác minh dùng đúng Developer Account ID trong IAM & Admin → Service Account.
1366,E:\DATN\dataframe\train_file\25.txt,Cung cấp Service account name và click Create.
1367,E:\DATN\dataframe\train_file\25.txt,"Click Select a role, chọn Service Account User và nhấn tiếp tục → Nhấp DONE."
1368,E:\DATN\dataframe\train_file\25.txt,Click  Actions ở icon 3 chấm của service account vừa tạo → Chọn Manage keys.
1369,E:\DATN\dataframe\train_file\25.txt,Click ADD KEY  → Create New Key
1370,E:\DATN\dataframe\train_file\25.txt,Chọn kiểu JSON → nhấp CREATE.
1371,E:\DATN\dataframe\train_file\25.txt,Download file và lưu trữ nơi cần thiết trên máy tính.
1372,E:\DATN\dataframe\train_file\25.txt,Quay về Google Play Store click nút DONE để đóng popup
1373,E:\DATN\dataframe\train_file\25.txt,Click nút Grant Access  → Refresh service accounts để cập nhật những thay đổi từ bước 4.
1374,E:\DATN\dataframe\train_file\25.txt,Cấp quyền cho tài khoản này.
1375,E:\DATN\dataframe\train_file\25.txt,Gợi ý Admin (all permissions).
1376,E:\DATN\dataframe\train_file\25.txt,Click Invite user để hoàn tất.
1377,E:\DATN\dataframe\train_file\25.txt,Run những lệnh fastlane đầu tiên.
1378,E:\DATN\dataframe\train_file\25.txt,"Sau khi đã cấu hình những thứ cần thiết, chúng ta sẽ viết những lệnh phục vụ cho deploy."
1379,E:\DATN\dataframe\train_file\25.txt,"Đầu tiên kiểm tra xem thử đã kết nối với Google Play Store thành công chưa, chạy lệnh:"
1380,E:\DATN\dataframe\train_file\25.txt,fastlane run validate_play_store_json_key json_key:/path/to/your/downloaded/file.json
1381,E:\DATN\dataframe\train_file\25.txt,Khi mọi thứ đã ok hết thì mở file android/fastlane/Appfile để thêm đường dẫn file json secret.
1382,E:\DATN\dataframe\train_file\25.txt,Chạy lệnh sau để bắt đầu cấu hình.
1383,E:\DATN\dataframe\train_file\25.txt,fastlane supply init
1384,E:\DATN\dataframe\train_file\25.txt,Lưu ý: Google Play Store yêu cầu phải có 1 bản build đầu tiên (version code: 1) đã upload lên Google Play Store trước mới có thể deploy những bản build sau này.
1385,E:\DATN\dataframe\train_file\25.txt,Cấu hình build android app
1386,E:\DATN\dataframe\train_file\25.txt,"Để tránh bài viết dài dòng, các bạn có thể làm theo hướng dẫn của Flutter để build bản android app đầu tiên: ."
1387,E:\DATN\dataframe\train_file\25.txt,Thay đổi 1 số config để tránh việc chạy lệnh fastlane deploy bị lỗi.
1388,E:\DATN\dataframe\train_file\25.txt,Thêm lintOptions: android/app/build.gradle.
1389,E:\DATN\dataframe\train_file\25.txt,        checkReleaseBuilds false
1390,E:\DATN\dataframe\train_file\25.txt,"		// Đổi versionName, versionCode để phục vụ cho việc tăng version build bằng plugin"
1391,E:\DATN\dataframe\train_file\25.txt,        // TODO: Specify your own unique Application ID (https://developer.android.com/studio/build/application-id.html).
1392,E:\DATN\dataframe\train_file\25.txt,"        applicationId ""my.package.name"""
1393,E:\DATN\dataframe\train_file\25.txt,        minSdkVersion flutter.minSdkVersion
1394,E:\DATN\dataframe\train_file\25.txt,        targetSdkVersion flutter.targetSdkVersion
1395,E:\DATN\dataframe\train_file\25.txt,        // versionCode flutterVersionCode.toInteger()
1396,E:\DATN\dataframe\train_file\25.txt,        // versionName flutterVersionName
1397,E:\DATN\dataframe\train_file\25.txt,        versionCode 2 // Đổi về dạng tiêu chuẩn để khi chạy lệnh increment_version_code không bị lỗi
1398,E:\DATN\dataframe\train_file\25.txt,        versionName 1.0.0
1399,E:\DATN\dataframe\train_file\25.txt,Ở file android/gradle.properties thêm dòng lệnh sau:
1400,E:\DATN\dataframe\train_file\25.txt,org.gradle.jvmargs=-Xmx1536M --add-exports=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-exports=jdk.unsupported/sun.misc=ALL-UNNAMED
1401,E:\DATN\dataframe\train_file\25.txt,Ở file android/gradle/wrapper cài đặt project chạy trên gradle 7.5 thay vì 6.7 như hiện tại.
1402,E:\DATN\dataframe\train_file\25.txt,#Fri Jun 23 08:50:38 CEST 2017
1403,E:\DATN\dataframe\train_file\25.txt,Chạy lệnh sau để cập nhật gradle 7.5
1404,E:\DATN\dataframe\train_file\25.txt,cd android
1405,E:\DATN\dataframe\train_file\25.txt,./gradlew --refresh-dependencies
1406,E:\DATN\dataframe\train_file\25.txt,Viết các lệnh cần thiết cho việc Deploy
1407,E:\DATN\dataframe\train_file\25.txt,Sau khi đã hoàn tất các bước trên.
1408,E:\DATN\dataframe\train_file\25.txt,Mở file android/fastlane/Appfile.
1409,E:\DATN\dataframe\train_file\25.txt,# Increment version code - Lệnh này để tăng version code trước mỗi lần build
1410,E:\DATN\dataframe\train_file\25.txt,"  desc ""Increment version code"""
1411,E:\DATN\dataframe\train_file\25.txt,  lane :increment_vc do
1412,E:\DATN\dataframe\train_file\25.txt,"    gradle_file_path: ""./app/build.gradle"","
1413,E:\DATN\dataframe\train_file\25.txt,    version_code: 2 // Thay đổi version code ở đây 2 -> 3 -> 4 -> ... cho mỗi lần deploy mới.
1414,E:\DATN\dataframe\train_file\25.txt,Cấu hình việc build & deploy
1415,E:\DATN\dataframe\train_file\25.txt,"desc ""Deploy a new version to the Internal Google Play"""
1416,E:\DATN\dataframe\train_file\25.txt,  lane :deploy do // lane deploy
1417,E:\DATN\dataframe\train_file\25.txt,"    gradle(task: ""clean bundleRelease"") // Lệnh này để clean bundleRelease (làm sạch project trước mỗi lần build mới)."
1418,E:\DATN\dataframe\train_file\25.txt,"      task: 'bundle',"
1419,E:\DATN\dataframe\train_file\25.txt,      build_type: 'Release'
1420,E:\DATN\dataframe\train_file\25.txt,    ) // Lệnh này để build file .aab
1421,E:\DATN\dataframe\train_file\25.txt,"      track: 'internal', // Chúng ta thử nghiệm trên Internal tester."
1422,E:\DATN\dataframe\train_file\25.txt,"Thay đổi track cho những bản build production, beta, alpha, internal,..."
1423,E:\DATN\dataframe\train_file\25.txt,"      release_status: 'draft',"
1424,E:\DATN\dataframe\train_file\25.txt,"      skip_upload_changelogs: true,"
1425,E:\DATN\dataframe\train_file\25.txt,"      aab: '../build/app/outputs/bundle/release/app-release.aab', // Lệnh này để trỏ đường dẫn bản build file .aab (dùng file .aab này để upload lên Google Play Console)."
1426,E:\DATN\dataframe\train_file\25.txt,Hoàn tất các lệnh cần thiết.
1427,E:\DATN\dataframe\train_file\25.txt,Bắt đầu deploy thôi nào!
1428,E:\DATN\dataframe\train_file\25.txt,cd android
1429,E:\DATN\dataframe\train_file\25.txt,fastlane increment_vc // Chạy lệnh tăng version code trước mỗi lần deploy
1430,E:\DATN\dataframe\train_file\25.txt,fastlane deploy // Chạy lệnh để build & deploy trên lane :deploy
1431,E:\DATN\dataframe\train_file\25.txt,Tận hưởng thành quả.
1432,E:\DATN\dataframe\train_file\25.txt,Sau khi đã hoàn tất các bước trên thì ta đã hoàn thành việc Continuous delivery (local machine) cho android app.
1433,E:\DATN\dataframe\train_file\25.txt,"Các bản build sau chỉ cần nâng version code và chạy lệnh sau là đã upload file lên Internal Tester (tương tự cho các trường hợp beta, production,...)"
1434,E:\DATN\dataframe\train_file\25.txt,Tài liệu tham khảo
1435,E:\DATN\dataframe\train_file\26.txt,Gửi thông báo qua Telegram sử dụng Python kết hợp Markdown
1436,E:\DATN\dataframe\train_file\26.txt,"Ứng dụng Telegram là ứng dụng nhắn tin gọi điện miễn phí phổ biến các năm gần đây, hôm nay mình sẽ hướng dẫn mọi người cách gửi thông báo giám sát qua Telegram với ngôn ngữ Python."
1437,E:\DATN\dataframe\train_file\26.txt,Tạo Telegram bot
1438,E:\DATN\dataframe\train_file\26.txt,"Tìm BotFather trên Telegram, nhấn Start nhập /newbot để tạo một bot mới đóng vai trò người gửi thông báo (notification)."
1439,E:\DATN\dataframe\train_file\26.txt,Sau khi nhập /newbot bạn sẽ được yêu cầu nhập name của bot.
1440,E:\DATN\dataframe\train_file\26.txt,BotFather sẽ thông báo cho bạn đã tạo bot thành công với thông tin về API token.
1441,E:\DATN\dataframe\train_file\26.txt,Tạo Telegram group
1442,E:\DATN\dataframe\train_file\26.txt,Bạn tạo một new group với member cần nhận thông báo và member bot vừa tạo.
1443,E:\DATN\dataframe\train_file\26.txt,"Khi ở trong group này, bạn sẽ thấy group ID ở trong địa chỉ trình duyệt, như vậy bạn đã có 2 thông tin:"
1444,E:\DATN\dataframe\train_file\26.txt,API Token: ***************** Chat ID: 766239967
1445,E:\DATN\dataframe\train_file\26.txt,Bạn thực hành test thử như sau
1446,E:\DATN\dataframe\train_file\26.txt,"curl -s -X POST [API Token]/sendMessage -d chat_id=-766239967 -d text=""Hello World"""
1447,E:\DATN\dataframe\train_file\26.txt,Sử dụng Markdown
1448,E:\DATN\dataframe\train_file\26.txt,Tại sao phải sử dụng Markdown.
1449,E:\DATN\dataframe\train_file\26.txt,"Markdown được sử dụng để định dạng văn bản khiến nó trở nên bắt mắt và dễ nhìn hơn, mình thường xuyên sử dụng tính năng in đậm để report nhìn sinh động hơn."
1450,E:\DATN\dataframe\train_file\26.txt,Dưới đây là một đoạn code python để gửi thông báo qua Telegram
1451,E:\DATN\dataframe\train_file\26.txt,import requests
1452,E:\DATN\dataframe\train_file\26.txt,headers = {'Content-Type': 'application/xml'} # set what your server accepts
1453,E:\DATN\dataframe\train_file\26.txt,sum_price = XYZ
1454,E:\DATN\dataframe\train_file\26.txt,"body=""📤 Tổng giá trị đơn hàng tạm tính theo ngày: ""+""*""+sum_price+""*"""
1455,E:\DATN\dataframe\train_file\26.txt,"r = requests.post(""https://api.telegram.org/bot68292XXXX:AAE5jvi0g1UlRammHViXH9A2vNwn0wLXXXX/sendMessage?text="" + body + ""&chat_id=-100154747XXXX""+""&parse_mode=Markdown"", headers=headers)"
1456,E:\DATN\dataframe\train_file\26.txt,Kết quả mình nhận được thông báo như hình dưới.
1457,E:\DATN\dataframe\train_file\27.txt,Hàm `super()` trong Python và một số vấn đề liên quan
1458,E:\DATN\dataframe\train_file\27.txt,"Khi lập trình hướng đối tượng với Python, ta thường bắt gặp các câu lệnh như super().__init__() hoặc super().method() nhất là khi đọc doc của các thư viện có các lớp kế thừa nhiều lần."
1459,E:\DATN\dataframe\train_file\27.txt,Bài viết hôm nay của mình sẽ hướng đến việc giới thiệu hàm super() và các trường hợp sử dụng nó.
1460,E:\DATN\dataframe\train_file\27.txt,Kế thừa trong Python
1461,E:\DATN\dataframe\train_file\27.txt,Để hiểu rõ hơn về vai trò của super().
1462,E:\DATN\dataframe\train_file\27.txt,Mình sẽ bắt đầu với trường hợp không sử dụng super() trong kế thừa trước.
1463,E:\DATN\dataframe\train_file\27.txt,"Cho lớp cha Parent và được kế thừa bởi lớp con Children(Parent), khi đó lớp Children có thể gọi các phương thức hoặc thuộc tính từ lớp cha."
1464,E:\DATN\dataframe\train_file\27.txt,class Parent:
1465,E:\DATN\dataframe\train_file\27.txt,    def self_intro(self):
1466,E:\DATN\dataframe\train_file\27.txt,"        print(""This is parent class"")"
1467,E:\DATN\dataframe\train_file\27.txt,    def parent_method(self):
1468,E:\DATN\dataframe\train_file\27.txt,"        print(""This is parent method"")"
1469,E:\DATN\dataframe\train_file\27.txt,class Children(Parent):
1470,E:\DATN\dataframe\train_file\27.txt,    def self_intro(self):
1471,E:\DATN\dataframe\train_file\27.txt,"        print(""This is children class"")"
1472,E:\DATN\dataframe\train_file\27.txt,c = Children()
1473,E:\DATN\dataframe\train_file\27.txt,# >>> This is parent method
1474,E:\DATN\dataframe\train_file\27.txt,"Tuy nhiên, sẽ xảy ra trường hợp Children và Parent có phương thức trùng tên với nhau là self_intro và ta cần gọi phương thức self_intro của Parent bên trong phương thức family_intro của Children."
1475,E:\DATN\dataframe\train_file\27.txt,Trường hợp này vẫn có thể được giải quyết mà không cần dùng đến super() bằng cách gọi trực tiếp Parent.self_intro(self) bên trong family_intro()
1476,E:\DATN\dataframe\train_file\27.txt,class Parent:
1477,E:\DATN\dataframe\train_file\27.txt,    def self_intro(self):
1478,E:\DATN\dataframe\train_file\27.txt,"        print(""This is parent class"")"
1479,E:\DATN\dataframe\train_file\27.txt,    def parent_method(self):
1480,E:\DATN\dataframe\train_file\27.txt,"        print(""This is parent method"")"
1481,E:\DATN\dataframe\train_file\27.txt,class Children(Parent):
1482,E:\DATN\dataframe\train_file\27.txt,    def self_intro(self):
1483,E:\DATN\dataframe\train_file\27.txt,"        print(""This is children class"")"
1484,E:\DATN\dataframe\train_file\27.txt,    def family_intro(self):
1485,E:\DATN\dataframe\train_file\27.txt,        self.self_intro() # Same as Children.self_intro(self)
1486,E:\DATN\dataframe\train_file\27.txt,c = Children()
1487,E:\DATN\dataframe\train_file\27.txt,# >>> This is children class
1488,E:\DATN\dataframe\train_file\27.txt,# >>> This is parent class
1489,E:\DATN\dataframe\train_file\27.txt,"Nhiều bạn đã biết về bound method, unbound method có thể sẽ thắc mắc tại sao lại sử dụng tham số self cho phương thức self_intro dù hàm này không sử dụng thuộc tính hay phương thức của self."
1490,E:\DATN\dataframe\train_file\27.txt,Vì mình muốn tập trung vào việc giới thiệu phương pháp kế thừa nên đã viết đơn giản hơn thay vì thêm các decorator và thay đổi cách gọi hàm.
1491,E:\DATN\dataframe\train_file\27.txt,"Bạn nào có nhu cầu biết thêm về bound method, unbound method có thể tham khảo tại"
1492,E:\DATN\dataframe\train_file\27.txt,Chúng ta cũng có thể giải quyết trường hợp này bằng super() thay vì gọi trực tiếp
1493,E:\DATN\dataframe\train_file\27.txt,class Children(Parent):
1494,E:\DATN\dataframe\train_file\27.txt,    def self_intro(self):
1495,E:\DATN\dataframe\train_file\27.txt,"        print(""This is children class"")"
1496,E:\DATN\dataframe\train_file\27.txt,    def family_intro(self):
1497,E:\DATN\dataframe\train_file\27.txt,        self.self_intro() # Same as Children.self_intro(self)
1498,E:\DATN\dataframe\train_file\27.txt,c = Children()
1499,E:\DATN\dataframe\train_file\27.txt,# >>> This is children class
1500,E:\DATN\dataframe\train_file\27.txt,# >>> This is parent class
1501,E:\DATN\dataframe\train_file\27.txt,Hàm super() lúc này sẽ trả về một đối tượng thuộc lớp kế thừa từ Children lúc này là Parent và gọi self_intro().
1502,E:\DATN\dataframe\train_file\27.txt,"Khác với cách gọi trực tiếp, super() không cần viết lại tên lớp Parent khi gọi hàm, việc này sẽ giúp tránh bị các lỗi chính tả hoặc bạn có nhu cầu đổi tên lớp cha hoặc kế thừa từ lớp khác."
1503,E:\DATN\dataframe\train_file\27.txt,Nhưng đấy vẫn chưa phải là tất cả điểm mạnh của super().
1504,E:\DATN\dataframe\train_file\27.txt,super() được sử dụng linh hoạt trong các trường hợp đa kế thừa đặc biệt là  mà mình sẽ giới thiệu sau đây.
1505,E:\DATN\dataframe\train_file\27.txt,Trước tiên chúng ta cần phải hiểu rõ một vài khái niệm và các tham số của super()
1506,E:\DATN\dataframe\train_file\27.txt,Method resolution order (MRO)
1507,E:\DATN\dataframe\train_file\27.txt, MRO có thể hiểu đơn giản là trình tự kế thừa của lớp.
1508,E:\DATN\dataframe\train_file\27.txt,MRO của một lớp có thể được truy xuất bằng phương thức
1509,E:\DATN\dataframe\train_file\27.txt,MRO sẽ được tạo để đảm bảo các lớp chỉ được liệt kê một lần và các lớp con phải được gọi trước lớp cha.
1510,E:\DATN\dataframe\train_file\27.txt,Nếu bạn muốn tìm hiểu thêm về thuật toán tạo MRO của Python thì tham khảo
1511,E:\DATN\dataframe\train_file\27.txt,class Parent:
1512,E:\DATN\dataframe\train_file\27.txt,class Children(Parent):
1513,E:\DATN\dataframe\train_file\27.txt,"# >>> [__main__.Children, __main__.Parent, object]"
1514,E:\DATN\dataframe\train_file\27.txt,"Khi sử dụng một phương thức với đối tượng thuộc lớp Children, chương trình sẽ tìm kiếm phương thức dựa trên thứ tự MRO như trên, tức là bắt đầu từ Children, nếu không có thì sẽ tìm đến Parent và sau cùng là  (base class mặc định cho mọi loại dữ liệu Python)"
1515,E:\DATN\dataframe\train_file\27.txt,Tham số của hàm super()
1516,E:\DATN\dataframe\train_file\27.txt,"Hàm super(type, object) sẽ nhận vào hai tham số type và object:"
1517,E:\DATN\dataframe\train_file\27.txt,"type sẽ nhận giá trị kiểu lớp để khi tìm kiếm phương thức hoặc thuộc tính, chương trình sẽ tìm các lớp cha sau type trong MRO của lớp."
1518,E:\DATN\dataframe\train_file\27.txt,Dựa vào type ta có thể quyết định phương thức cần gọi được cài đặt trong lớp cha hoặc lớp ông nội.
1519,E:\DATN\dataframe\train_file\27.txt,object sẽ nhận vào một đối tượng để ràng buộc (bound) với phương thức hoặc thuộc tính được gọi bởi super().
1520,E:\DATN\dataframe\train_file\27.txt,"Để dễ hình dung, super(type, object).method() có thể hiểu là object.method() với phương thức method được cài đặt trong lớp cha của type."
1521,E:\DATN\dataframe\train_file\27.txt,"Xét ví dụ trên, hàm super() được gọi trong lớp Children sẽ có giá trị tham số mặc định là super(Children, self)."
1522,E:\DATN\dataframe\train_file\27.txt,class Grandparent:
1523,E:\DATN\dataframe\train_file\27.txt,    def call_method(self):
1524,E:\DATN\dataframe\train_file\27.txt,"        print(""This is Grandparent method"")"
1525,E:\DATN\dataframe\train_file\27.txt,class Parent(Grandparent):
1526,E:\DATN\dataframe\train_file\27.txt,    def call_method(self):
1527,E:\DATN\dataframe\train_file\27.txt,"        print(""This is Parent method"")"
1528,E:\DATN\dataframe\train_file\27.txt,class Children(Parent):
1529,E:\DATN\dataframe\train_file\27.txt,    def call_method(self):
1530,E:\DATN\dataframe\train_file\27.txt,        # call call_method of GrandParent
1531,E:\DATN\dataframe\train_file\27.txt,        # class instead of Parent class
1532,E:\DATN\dataframe\train_file\27.txt,"        super(Parent, self).call_method()"
1533,E:\DATN\dataframe\train_file\27.txt,c = Children()
1534,E:\DATN\dataframe\train_file\27.txt,# >>> This is Grandparent method
1535,E:\DATN\dataframe\train_file\27.txt,Ngoài ra type và object còn có một số ràng buộc để chương trình chạy không bị lỗi mà bạn có thể tham khảo tại  của super()
1536,E:\DATN\dataframe\train_file\27.txt,Lưu ý: Nếu trong call_method() của lớp Grandparent gọi tiếp super().call_method().
1537,E:\DATN\dataframe\train_file\27.txt,Hàm sẽ tìm call_method() của các lớp phía sau lớp Grandparent trong MRO.
1538,E:\DATN\dataframe\train_file\27.txt,"Ở đây MRO sẽ là [__main__.Children, __main__.Parent, __main__.Grandparent, object], vì object không được cài đặt call_method() nên sẽ trả về lỗi AttributeError: 'super' object has no attribute 'call_method'."
1539,E:\DATN\dataframe\train_file\27.txt,Giải quyết Diamond Problem bằng super()
1540,E:\DATN\dataframe\train_file\27.txt,Diamond Problem xuất hiện khi ta thực hiện đa kế thừa trên hai lớp cha cùng kế thừa từ một lớp ông nội.
1541,E:\DATN\dataframe\train_file\27.txt,Xét trường hợp ta có các lớp sau:
1542,E:\DATN\dataframe\train_file\27.txt,Lớp Grandparent
1543,E:\DATN\dataframe\train_file\27.txt,Lớp ParentA(Grandparent) và ParentB(Grandparent) cùng kế thừa từ lớp GrandParent
1544,E:\DATN\dataframe\train_file\27.txt,"Lớp Children(ParentA, ParentB) đa kế thừa từ hai lớp ParentA và ParentB"
1545,E:\DATN\dataframe\train_file\27.txt,Khi đó chúng ta sẽ gặp các vấn đề phát sinh sau:
1546,E:\DATN\dataframe\train_file\27.txt,ParentA và ParentB có phương thức trùng tên nhau
1547,E:\DATN\dataframe\train_file\27.txt,"Nếu bạn gọi phương thức bằng super(), phương thức của lớp có thứ tự nhỏ hơn trong MRO sẽ được gọi trước."
1548,E:\DATN\dataframe\train_file\27.txt,"Trong trường hợp này, thứ tự lớp cha trong MRO sẽ là thứ tự liệt kê lớp cha trong lúc khai báo lớp Children."
1549,E:\DATN\dataframe\train_file\27.txt,class Grandparent:
1550,E:\DATN\dataframe\train_file\27.txt,    def call_method(self):
1551,E:\DATN\dataframe\train_file\27.txt,"        print(""This is Grandparent method"")"
1552,E:\DATN\dataframe\train_file\27.txt,class ParentA(Grandparent):
1553,E:\DATN\dataframe\train_file\27.txt,    def call_method(self):
1554,E:\DATN\dataframe\train_file\27.txt,"        print(""This is ParentA method"")"
1555,E:\DATN\dataframe\train_file\27.txt,class ParentB(Grandparent):
1556,E:\DATN\dataframe\train_file\27.txt,    def call_method(self):
1557,E:\DATN\dataframe\train_file\27.txt,"        print(""This is ParentB method"")"
1558,E:\DATN\dataframe\train_file\27.txt,"class Children(ParentA, ParentB):"
1559,E:\DATN\dataframe\train_file\27.txt,    def say_name(self):
1560,E:\DATN\dataframe\train_file\27.txt,c = Children()
1561,E:\DATN\dataframe\train_file\27.txt,"# >>> [<class '__main__.Children'>, <class '__main__.ParentA'>,"
1562,E:\DATN\dataframe\train_file\27.txt,"#      <class '__main__.ParentB'>, <class '__main__.Grandparent'>, <class 'object'>]"
1563,E:\DATN\dataframe\train_file\27.txt,# >>> This is ParentA method
1564,E:\DATN\dataframe\train_file\27.txt,Nếu muốn gọi call_method() của ParentB ta có thể làm như sau:
1565,E:\DATN\dataframe\train_file\27.txt,"Đổi thứ tự khai báo class Children(ParentB, ParentA)"
1566,E:\DATN\dataframe\train_file\27.txt,Gọi trực tiếp ParentB.say_name(self)
1567,E:\DATN\dataframe\train_file\27.txt,Phương thức của lớp Grandparent được gọi lại hai lần
1568,E:\DATN\dataframe\train_file\27.txt,"Vấn đề này gặp khi chúng ta muốn gọi phương thức khởi tạo của ParentA và ParentB trực tiếp bên trong Children, nhưng phương thức khởi tạo của ParentA và ParentB lại gọi phương thức khởi tạo của GrandParent."
1569,E:\DATN\dataframe\train_file\27.txt,Khi đó sẽ xảy ra việc phương thức khởi tạo của GrandParent bị gọi 2 lần.
1570,E:\DATN\dataframe\train_file\27.txt,class Grandparent:
1571,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1572,E:\DATN\dataframe\train_file\27.txt,"        print(""Grandparent Init"")"
1573,E:\DATN\dataframe\train_file\27.txt,class ParentA(Grandparent):
1574,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1575,E:\DATN\dataframe\train_file\27.txt,"        print(""ParentA Init"")"
1576,E:\DATN\dataframe\train_file\27.txt,class ParentB(Grandparent):
1577,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1578,E:\DATN\dataframe\train_file\27.txt,"        print(""ParentB Init"")"
1579,E:\DATN\dataframe\train_file\27.txt,"class Children(ParentA, ParentB):"
1580,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1581,E:\DATN\dataframe\train_file\27.txt,"        print(""Children Init"")"
1582,E:\DATN\dataframe\train_file\27.txt,# >>> Children Init
1583,E:\DATN\dataframe\train_file\27.txt,# >>> ParentA Init
1584,E:\DATN\dataframe\train_file\27.txt,# >>> Grandparent Init
1585,E:\DATN\dataframe\train_file\27.txt,# >>> ParentB Init
1586,E:\DATN\dataframe\train_file\27.txt,# >>> Grandparent Init
1587,E:\DATN\dataframe\train_file\27.txt,Cách giải quyết: sử dụng hàm super() thay vì gọi trực tiếp.
1588,E:\DATN\dataframe\train_file\27.txt,Như đã lưu ý ở mục 3. hàm super() sẽ tìm các phương thức khởi tạo dựa trên MRO và lớp hiện tại.
1589,E:\DATN\dataframe\train_file\27.txt,"Vì các lớp chỉ xuất hiện trong MRO duy nhất một lần nên khi gọi super().__init__() sẽ tránh được việc gọi nhiều lần, giảm thiểu thời gian chạy và tránh bị ghi đè không cần thiết."
1590,E:\DATN\dataframe\train_file\27.txt,class Grandparent:
1591,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1592,E:\DATN\dataframe\train_file\27.txt,"        print(""Grandparent Init"")"
1593,E:\DATN\dataframe\train_file\27.txt,class ParentA(Grandparent):
1594,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1595,E:\DATN\dataframe\train_file\27.txt,"        print(""ParentA Init"")"
1596,E:\DATN\dataframe\train_file\27.txt,class ParentB(Grandparent):
1597,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1598,E:\DATN\dataframe\train_file\27.txt,"        print(""ParentB Init"")"
1599,E:\DATN\dataframe\train_file\27.txt,"class Children(ParentA, ParentB):"
1600,E:\DATN\dataframe\train_file\27.txt,    def __init__(self):
1601,E:\DATN\dataframe\train_file\27.txt,"        print(""Children Init"")"
1602,E:\DATN\dataframe\train_file\27.txt,# >>> Children Init
1603,E:\DATN\dataframe\train_file\27.txt,# >>> ParentA Init
1604,E:\DATN\dataframe\train_file\27.txt,# >>> ParentB Init
1605,E:\DATN\dataframe\train_file\27.txt,# >>> Grandparent Init
1606,E:\DATN\dataframe\train_file\27.txt,Tuy nhiên cách này lại dẫn đến vấn đề sau
1607,E:\DATN\dataframe\train_file\27.txt,Phương thức khởi tạo của ParentA và ParentB cần các tham số khác nhau
1608,E:\DATN\dataframe\train_file\27.txt,"Giả sử ta cần lưu số tuổi của mỗi lớp thông qua các biến gp_age, pb_age, pa_age và c_age"
1609,E:\DATN\dataframe\train_file\27.txt,Xét đoạn code sau đây:
1610,E:\DATN\dataframe\train_file\27.txt,class Grandparent:
1611,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, gp_age):"
1612,E:\DATN\dataframe\train_file\27.txt,        self.gp_age = gp_age
1613,E:\DATN\dataframe\train_file\27.txt,"        print(f""Grandparent age: {self.gp_age}"")"
1614,E:\DATN\dataframe\train_file\27.txt,class ParentB(Grandparent):
1615,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, pb_age, gp_age):"
1616,E:\DATN\dataframe\train_file\27.txt,        self.pb_age = pb_age
1617,E:\DATN\dataframe\train_file\27.txt,"        print(f""ParentB age: {self.pb_age}"")"
1618,E:\DATN\dataframe\train_file\27.txt,class ParentA(Grandparent):
1619,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, pa_age, pb_age, gp_age):"
1620,E:\DATN\dataframe\train_file\27.txt,        self.pa_age = pa_age
1621,E:\DATN\dataframe\train_file\27.txt,"        print(f""ParentA age: {self.pa_age}"")"
1622,E:\DATN\dataframe\train_file\27.txt,"        super().__init__(pb_age, gp_age)"
1623,E:\DATN\dataframe\train_file\27.txt,"class Children(ParentA, ParentB):"
1624,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, c_age, pa_age, pb_age, gp_age):"
1625,E:\DATN\dataframe\train_file\27.txt,        self.c_age = c_age
1626,E:\DATN\dataframe\train_file\27.txt,"        print(f""Children age: {self.c_age}"")"
1627,E:\DATN\dataframe\train_file\27.txt,"        super().__init__(pa_age, pb_age, gp_age)"
1628,E:\DATN\dataframe\train_file\27.txt,"Children(c_age=""15"", pa_age=""40"", pb_age=""45"", gp_age=""70"")"
1629,E:\DATN\dataframe\train_file\27.txt,# >>> Children age: 15
1630,E:\DATN\dataframe\train_file\27.txt,# >>> ParentA age: 40
1631,E:\DATN\dataframe\train_file\27.txt,# >>> ParentB age: 45
1632,E:\DATN\dataframe\train_file\27.txt,# >>> Grandparent age: 70
1633,E:\DATN\dataframe\train_file\27.txt,"Mỗi lớp đều cần một tham số khác nhau khi khởi tạo nên theo thứ tự MRO biết trước, chúng ta có thể viết code như trên."
1634,E:\DATN\dataframe\train_file\27.txt,Tuy code chạy đúng như ý muốn nhưng mình tin chẳng ai muốn code như trên vì các lí do sau:
1635,E:\DATN\dataframe\train_file\27.txt,"Sai bản chất: trừ khi ParentA và ParentB chỉ được khởi tạo đúng một lần và chỉ dùng để tạo lớp Children, với code trên khi tạo đối tượng thuộc lớp ParentA hoặc ParentB sẽ bị lỗi dư tham số."
1636,E:\DATN\dataframe\train_file\27.txt,"Quá cứng nhắc: Vì tham số truyền vào __init__ dựa trên MRO nên sẽ phụ thuộc thứ tự khai báo của lớp, nên chỉ cần thay đổi lại thứ tự có thể làm code chạy bị lỗi."
1637,E:\DATN\dataframe\train_file\27.txt,Khó tái sử dụng: Giả sử như chúng ta có thêm lớp ParentC và muốn tạo lớp đa kế thừa từ ParentA và ParentC.
1638,E:\DATN\dataframe\train_file\27.txt,"Khi đó ta phải viết lại __init__ của ParentA để đa kế thừa, điều này có thể làm ảnh hưởng đến lớp Children hiện tại."
1639,E:\DATN\dataframe\train_file\27.txt,Cách giải quyết: sử dụng **kwargs trong __init__.
1640,E:\DATN\dataframe\train_file\27.txt,Khi đó chúng ta cần phải thiết kế lại tất cả các phương thức __init__ của tất cả các lớp:
1641,E:\DATN\dataframe\train_file\27.txt,class Grandparent:
1642,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, gp_age, **kwargs):"
1643,E:\DATN\dataframe\train_file\27.txt,        self.gp_age = gp_age
1644,E:\DATN\dataframe\train_file\27.txt,"        print(f""Grandparent age: {self.gp_age}"")"
1645,E:\DATN\dataframe\train_file\27.txt,class ParentB(Grandparent):
1646,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, pb_age, **kwargs):"
1647,E:\DATN\dataframe\train_file\27.txt,        self.pb_age = pb_age
1648,E:\DATN\dataframe\train_file\27.txt,"        print(f""ParrentB age: {self.pb_age}"")"
1649,E:\DATN\dataframe\train_file\27.txt,class ParentA(Grandparent):
1650,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, pa_age, **kwargs):"
1651,E:\DATN\dataframe\train_file\27.txt,        self.pa_age = pa_age
1652,E:\DATN\dataframe\train_file\27.txt,"        print(f""ParentA age: {self.pa_age}"")"
1653,E:\DATN\dataframe\train_file\27.txt,"class Children(ParentA, ParentB):"
1654,E:\DATN\dataframe\train_file\27.txt,"    def __init__(self, c_age, **kwargs):"
1655,E:\DATN\dataframe\train_file\27.txt,        self.c_age = c_age
1656,E:\DATN\dataframe\train_file\27.txt,"        print(f""Children age: {self.c_age}"")"
1657,E:\DATN\dataframe\train_file\27.txt,"Children(c_age=""15"", pa_age=""40"", pb_age=""45"", gp_age=""70"")"
1658,E:\DATN\dataframe\train_file\27.txt,# >>> Children age: 15
1659,E:\DATN\dataframe\train_file\27.txt,# >>> ParentA age: 40
1660,E:\DATN\dataframe\train_file\27.txt,# >>> ParentB age: 45
1661,E:\DATN\dataframe\train_file\27.txt,# >>> Grandparent age: 70
1662,E:\DATN\dataframe\train_file\27.txt,"Code vẫn trả về kết quả như ý nhưng gọn hơn và dễ bảo trì, mở rộng hơn!"
1663,E:\DATN\dataframe\train_file\27.txt,Chúng ta vẫn có thể giải quyết trường hợp này bằng cách gọi phương thức khởi tạo trực tiếp nếu bạn đảm bảo không bị ghi đè cho lớp Grandparent hoặc việc ghi đè không gây ảnh hưởng gì (nhưng mình vẫn khuyến khích sử dụng super() hơn vì lí do bảo trì và mở rộng!)
1664,E:\DATN\dataframe\train_file\27.txt,Kết bài
1665,E:\DATN\dataframe\train_file\27.txt,Qua bài này mình đã trình bày với các bạn:
1666,E:\DATN\dataframe\train_file\27.txt,Gọi phương thức từ lớp cha bằng super() hoặc trực tiếp
1667,E:\DATN\dataframe\train_file\27.txt,Khái niệm MRO và ý nghĩa tham số của super()
1668,E:\DATN\dataframe\train_file\27.txt,Diamond Problem và cách giải quyết bằng super()
1669,E:\DATN\dataframe\train_file\27.txt,Nếu bài viết có chỗ nào không rõ hoặc sai thì xin hãy cho mình biết.
1670,E:\DATN\dataframe\train_file\27.txt,Cảm ơn các bạn đã dành thời gian đọc bài viết này!
1671,E:\DATN\dataframe\train_file\28.txt,Ánh xạ là một cấu trúc dữ liệu có tính ứng dụng rất cao trong lập trình.
1672,E:\DATN\dataframe\train_file\28.txt,"Về bản chất, cấu trúc dữ liệu này được cài đặt thủ công (dựa trên cây nhị phân tự cân bằng hoặc bảng băm), tuy nhiên việc cài đặt thủ công rất dài dòng và phức tạp, lại dễ xảy ra nhầm lẫn."
1673,E:\DATN\dataframe\train_file\28.txt,"Vì thế, những ngôn ngữ lập trình hiện đại đã giải quyết việc này bằng cách cài đặt sẵn nó."
1674,E:\DATN\dataframe\train_file\28.txt,"Trong C++ và Python, chúng lần lượt có tên là map và dictionary."
1675,E:\DATN\dataframe\train_file\28.txt,"Trong Python, ánh xạ được xây dựng sẵn bằng container dictionary."
1676,E:\DATN\dataframe\train_file\28.txt,"Nó là một tập hợp các phần tử ở dạng khóa - giá trị (key - value), nhưng lại không có tính thứ tự."
1677,E:\DATN\dataframe\train_file\28.txt,"Một phần tử key - value được gọi là một item, trong mỗi item thì key và value được phân biệt với nhau bằng một toán tử :."
1678,E:\DATN\dataframe\train_file\28.txt,"Trong dictionary, mỗi item lại được phân tách với nhau bằng toán tử"
1679,E:\DATN\dataframe\train_file\29.txt,Tập hợp (Set) và một số ứng dụng
1680,E:\DATN\dataframe\train_file\29.txt,I. Giới thiệu chung
1681,E:\DATN\dataframe\train_file\29.txt,"Với những ai đã và đang học lập trình, đặc biệt là lập trình thi đấu, thì những cấu trúc dữ liệu như set, map hay dictionary có lẽ là rất quen thuộc."
1682,E:\DATN\dataframe\train_file\29.txt,"Tên gọi của chúng có thể khác nhau ở các ngôn ngữ, nhưng tác dụng thì không hề thay đổi."
1683,E:\DATN\dataframe\train_file\29.txt,"Ứng dụng của chúng lớn đến mức, nhiều tài liệu khi hướng dẫn về lập trình cơ bản cũng đưa những cấu trúc dữ liệu này vào giảng dạy song song với mảng hay danh sách liên kết,..."
1684,E:\DATN\dataframe\train_file\29.txt,"Đúng như tên gọi của nó, tập hợp (set) là một cấu trúc dữ liệu dạng giống như mảng, lưu một danh sách các phần tử."
1685,E:\DATN\dataframe\train_file\29.txt,"Bản chất cấu trúc này được xây dựng dựa trên cấu trúc dữ liệu cây tìm kiếm nhị phân, nhưng nó đã phổ biến đến mức người ta quên đi cách cài đặt gốc của nó."
1686,E:\DATN\dataframe\train_file\29.txt,"Tuy nhiên, trong C++ và trong Python thì cấu trúc dữ liệu này sẽ có những sự khác biệt nhất định."
1687,E:\DATN\dataframe\train_file\29.txt,"Trong bài viết này, tôi sẽ giới thiệu tới các bạn về cách sử dụng chúng, cũng như minh họa một vài bài toán để bạn đọc hiểu hơn về ứng dụng của những cấu trúc này."
1688,E:\DATN\dataframe\train_file\29.txt,Sử dụng set trong C++
1689,E:\DATN\dataframe\train_file\29.txt,"Trong C++, set là một associative container của thư viện Template chuẩn C++ (STL) (những container mà kiểm soát phần tử bằng giá trị chứ không phải bằng vị trí thì gọi là associative containers)."
1690,E:\DATN\dataframe\train_file\29.txt,"Nó sử dụng để lưu trữ các phần tử có cùng kiểu dữ liệu, tuy nhiên các phần tử đó không được lặp lại."
1691,E:\DATN\dataframe\train_file\29.txt,Những phần tử được lưu trong set gọi là khóa.
1692,E:\DATN\dataframe\train_file\29.txt,"Trong set sử dụng sẵn phép so sánh mặc định là less, nghĩa là phần tử đứng trước sẽ nhỏ hơn phần tử đứng sau (theo phép so sánh)."
1693,E:\DATN\dataframe\train_file\29.txt,"Khi sử dụng set, các bạn có thể viết lại hàm so sánh theo ý muốn của mình."
1694,E:\DATN\dataframe\train_file\29.txt,"Để khai báo một set, ta sử dụng những cú pháp sau:"
1695,E:\DATN\dataframe\train_file\29.txt,#include <set>
1696,E:\DATN\dataframe\train_file\29.txt,using namespace std;
1697,E:\DATN\dataframe\train_file\29.txt,// Khởi tạo một set rỗng.
1698,E:\DATN\dataframe\train_file\29.txt,set <{Kiểu_phần_tử}> {Tên_set};
1699,E:\DATN\dataframe\train_file\29.txt,// Tạo một set từ mảng khác.
1700,E:\DATN\dataframe\train_file\29.txt,Có thể tạo ra set từ một đoạn của mảng.
1701,E:\DATN\dataframe\train_file\29.txt,set <{Kiểu_phần_tử}> {Tên_set}({Phạm_vi_trên_mảng});
1702,E:\DATN\dataframe\train_file\29.txt,"Ví dụ, dưới đây ta tạo ra một set gồm toàn số nguyên từ một mảng cho trước (vector cũng sử dụng tương tự):"
1703,E:\DATN\dataframe\train_file\29.txt,#include <set>
1704,E:\DATN\dataframe\train_file\29.txt,using namespace std;
1705,E:\DATN\dataframe\train_file\29.txt,"    int a[] = {1, 5, 2, 4, 3};"
1706,E:\DATN\dataframe\train_file\29.txt,"    set < int > integers(a, a + 5); // integers = {1, 2, 3, 4, 5}."
1707,E:\DATN\dataframe\train_file\29.txt,Các thao tác với set trong C++
1708,E:\DATN\dataframe\train_file\29.txt,Duyệt set
1709,E:\DATN\dataframe\train_file\29.txt,"Các phần tử trong set không thể truy cập trực tiếp qua vị trí, mà buộc phải sử dụng vòng lặp để duyệt."
1710,E:\DATN\dataframe\train_file\29.txt,"Vì set là một container thuộc STL, nên các phần tử của nó có thể duyệt qua bằng iterator theo cú pháp:"
1711,E:\DATN\dataframe\train_file\29.txt,// Khai báo biến lặp.
1712,E:\DATN\dataframe\train_file\29.txt,set < {Kiểu_phần_tử} > :: iterator {Tên_biến_lặp};
1713,E:\DATN\dataframe\train_file\29.txt,// Duyệt set.
1714,E:\DATN\dataframe\train_file\29.txt,for ({Biến_lặp} = {Địa_chỉ_đầu}; {Biến_lặp} != {Địa_chỉ_cuối}; ++{Biến_lặp})
1715,E:\DATN\dataframe\train_file\29.txt,"Chẳng hạn, với một set kiểu số nguyên là"
1716,E:\DATN\dataframe\train_file\29.txt,"integers, ta duyệt qua nó như sau:"
1717,E:\DATN\dataframe\train_file\29.txt,set < int > :: iterator it;
1718,E:\DATN\dataframe\train_file\29.txt,for (it = integers.begin(); it != integers.end(); ++it)
1719,E:\DATN\dataframe\train_file\29.txt,    cout << *it << endl;
1720,E:\DATN\dataframe\train_file\29.txt,Với set
1721,E:\DATN\dataframe\train_file\29.txt,"\text{integers} = \{1, 2, 3, 4, 5\};"
1722,E:\DATN\dataframe\train_file\29.txt,"integers={1,2,3,4,5}; đoạn chương trình trên sẽ có kết quả là:"
1723,E:\DATN\dataframe\train_file\29.txt,Các hàm dựng sẵn
1724,E:\DATN\dataframe\train_file\29.txt,"Container set đã xây dựng sẵn một số hàm để thao tác với set, cụ thể tôi trình bày ở bảng dưới đây."
1725,E:\DATN\dataframe\train_file\29.txt,"Để sử dụng hàm, ta dùng cú pháp: {Tên_set}.{Tên_hàm}."
1726,E:\DATN\dataframe\train_file\29.txt,Coi rằng kích thước của set hiện tại là
1727,E:\DATN\dataframe\train_file\29.txt,Viết hàm so sánh cho set
1728,E:\DATN\dataframe\train_file\29.txt,Hàm so sánh của set có thể được viết riêng theo ý các bạn theo cú pháp sau:
1729,E:\DATN\dataframe\train_file\29.txt,struct cmp
1730,E:\DATN\dataframe\train_file\29.txt,"    bool operator() ({Kiểu_phần_tử} x, {Kiểu_phần_tử} y)"
1731,E:\DATN\dataframe\train_file\29.txt,        return {Quan_hệ_x_và_y};
1732,E:\DATN\dataframe\train_file\29.txt,"set <{Kiểu_phần_tử}, cmp> {Tên_set};"
1733,E:\DATN\dataframe\train_file\29.txt,"Trong hàm so sánh trên, phần tử"
1734,E:\DATN\dataframe\train_file\29.txt,"x sẽ đại diện cho phần tử đứng trước trong set,"
1735,E:\DATN\dataframe\train_file\29.txt,y đại diện cho phần tử đứng sau.
1736,E:\DATN\dataframe\train_file\29.txt,Nếu như hàm đó trả về kết quả true thì phần tử
1737,E:\DATN\dataframe\train_file\29.txt,x sẽ được xếp đứng trước phần tử
1738,E:\DATN\dataframe\train_file\29.txt,"y trong set, ngược lại thì hai phần tử sẽ đổi chỗ cho nhau."
1739,E:\DATN\dataframe\train_file\29.txt,"Ví dụ, muốn tạo một set lưu các số nguyên nhưng theo thứ tự giảm dần, ta làm như sau:"
1740,E:\DATN\dataframe\train_file\29.txt,#include <set>
1741,E:\DATN\dataframe\train_file\29.txt,using namespace std;
1742,E:\DATN\dataframe\train_file\29.txt,struct cmp
1743,E:\DATN\dataframe\train_file\29.txt,"    bool operator() (int x, int y)"
1744,E:\DATN\dataframe\train_file\29.txt,        return x > y;
1745,E:\DATN\dataframe\train_file\29.txt,"    int arr[] = {1, 5, 2, 4, 3};"
1746,E:\DATN\dataframe\train_file\29.txt,"    set < int, cmp > integers(arr, arr + 5); // integers = {5, 4, 3, 2, 1}."
1747,E:\DATN\dataframe\train_file\29.txt,Các cấu trúc multiset và unordered_set
1748,E:\DATN\dataframe\train_file\29.txt,"Ngoài ra, trong STL C++ còn xây dựng hai associative container khác gần giống với set:"
1749,E:\DATN\dataframe\train_file\29.txt,multi_set: Cấu trúc này giống hệt như set nhưng cho phép lưu trữ nhiều phần tử có cùng khóa với nhau.
1750,E:\DATN\dataframe\train_file\29.txt,Các bạn có thể tìm hiểu thêm về cấu trúc này tại <i></i>
1751,E:\DATN\dataframe\train_file\29.txt,"unordered_set: Cấu trúc này cũng giống như set, nhưng các phần tử khi thêm vào sẽ không được sắp xếp theo thứ tự, nên các thao tác thêm và tìm kiếm phần tử chỉ tốn thời gian"
1752,E:\DATN\dataframe\train_file\29.txt,Nhưng cũng chính vì thế mà cấu trúc này sẽ không có các hàm tìm kiếm như lower_bound() và upper_bound().
1753,E:\DATN\dataframe\train_file\29.txt,Các bạn tìm hiểu thêm về cấu trúc này tại <i></i>
1754,E:\DATN\dataframe\train_file\29.txt,Sử dụng set trong Python
1755,E:\DATN\dataframe\train_file\29.txt,"Trong ngôn ngữ Python, set có hơi khác biệt một chút so với C++."
1756,E:\DATN\dataframe\train_file\29.txt,"Vẫn là một danh sách lưu các phần tử phân biệt, tuy nhiên các phần tử lưu trong set của Python sẽ không có tính thứ tự (không được sắp xếp)."
1757,E:\DATN\dataframe\train_file\29.txt,"Nhưng điều thuận tiện là nó có thể lưu trữ các phần tử với kiểu khác nhau, chẳng hạn như các phần tử kiểu chuỗi, số và list có thể được lưu cùng trong một set."
1758,E:\DATN\dataframe\train_file\29.txt,"Để khai báo một set trong Python, ta sử dụng một số cú pháp sau:"
1759,E:\DATN\dataframe\train_file\29.txt,# Khai báo set rỗng.
1760,E:\DATN\dataframe\train_file\29.txt,{Tên_set} = set()
1761,E:\DATN\dataframe\train_file\29.txt,# Khởi tạo set có sẵn các phần tử.
1762,E:\DATN\dataframe\train_file\29.txt,"{Tên_set} = {{Phần_tử_thứ_nhất}, {Phần_tử_thứ_hai},...}"
1763,E:\DATN\dataframe\train_file\29.txt,# Tạo set từ một list có sẵn.
1764,E:\DATN\dataframe\train_file\29.txt,{Tên_set} = set({Tên_list})
1765,E:\DATN\dataframe\train_file\29.txt,Lấy ví dụ:
1766,E:\DATN\dataframe\train_file\29.txt,set1 = set()
1767,E:\DATN\dataframe\train_file\29.txt,"set2 = {""Vũ Quế Lâm"", 1, ['a', 'b', 'c']}"
1768,E:\DATN\dataframe\train_file\29.txt,"set3 = set([1, 4, 2, 2, 5, 5])  # set3 = {1, 4, 2, 5}"
1769,E:\DATN\dataframe\train_file\29.txt,"Vậy có thể các bạn sẽ thắc mắc, nếu như ta muốn có một cấu trúc được sắp xếp giống như set của C++ trong Python thì phải làm sao?"
1770,E:\DATN\dataframe\train_file\29.txt,"Câu trả lời là cấu trúc đó không tồn tại trong Python, vì bản chất cài đặt của set ở hai ngôn ngữ là khác nhau."
1771,E:\DATN\dataframe\train_file\29.txt,"Nhưng các bạn có thể cải tiến dictionary trong Python để thu được một cấu trúc tương tự, điều này sẽ được đề cập tới trong bài viết sau."
1772,E:\DATN\dataframe\train_file\29.txt,Các thao tác với set trong Python
1773,E:\DATN\dataframe\train_file\29.txt,Duyệt set
1774,E:\DATN\dataframe\train_file\29.txt,"Các phần tử trong set của Python không có thứ tự nên không thể truy cập thông qua vị trí, mà buộc phải sử dụng vòng lặp:"
1775,E:\DATN\dataframe\train_file\29.txt,for {Biến_đại_diện} in {Tên_set}:
1776,E:\DATN\dataframe\train_file\29.txt,"set1 = {5, 6, 7, 4}"
1777,E:\DATN\dataframe\train_file\29.txt,for item in set1:
1778,E:\DATN\dataframe\train_file\29.txt,Kết quả đoạn chương trình trên như sau:
1779,E:\DATN\dataframe\train_file\29.txt,Kiểm tra phần tử có ở trong set hay không
1780,E:\DATN\dataframe\train_file\29.txt,Sử dụng in hoặc not in để kiểm tra một phần tử có trong set hay không.
1781,E:\DATN\dataframe\train_file\29.txt,"myset = {10, 15, 19, 14}"
1782,E:\DATN\dataframe\train_file\29.txt,print(10 in myset)
1783,E:\DATN\dataframe\train_file\29.txt,print(15 not in myset)
1784,E:\DATN\dataframe\train_file\29.txt,Các hàm dựng sẵn
1785,E:\DATN\dataframe\train_file\29.txt,"Tương tự như trong C++, set trong Python cũng đã được xây dựng sẵn một số hàm hỗ trợ, cụ thể như bảng dưới đây."
1786,E:\DATN\dataframe\train_file\29.txt,Kí hiệu kích thước của set
1787,E:\DATN\dataframe\train_file\29.txt,s là
1788,E:\DATN\dataframe\train_file\29.txt,∣s∣:
1789,E:\DATN\dataframe\train_file\29.txt,"Ngoài ra trong set của Python còn khá nhiều hàm tích hợp khác, các bạn có thể xem kĩ hơn cả ví dụ minh họa tại <i></i>"
1790,E:\DATN\dataframe\train_file\29.txt,Một số bài toán minh họa
1791,E:\DATN\dataframe\train_file\29.txt,Bài toán 1
1792,E:\DATN\dataframe\train_file\29.txt,"Tèo chuẩn bị tổ chức một bữa tiệc và anh ấy có nhiều thanh chocolate, trong đó có một số thanh chocolate cùng loại."
1793,E:\DATN\dataframe\train_file\29.txt,"Anh ấy muốn tặng chocolate cho bạn bè của mình một cách hoàn hảo, tức là mỗi người bạn của Tèo chỉ nhận được một thanh chocolate, và không có hai người bạn nào nhận được cùng một loại chocolate."
1794,E:\DATN\dataframe\train_file\29.txt,Hãy cho biết Tèo có thể tặng chocolate cho tối đa bao nhiêu người bạn?
1795,E:\DATN\dataframe\train_file\29.txt,Dòng đầu tiên chứa số nguyên
1796,E:\DATN\dataframe\train_file\29.txt,n chỉ số lượng thanh chocolate mà Tèo đang có.
1797,E:\DATN\dataframe\train_file\29.txt,Dòng thứ hai chứa
1798,E:\DATN\dataframe\train_file\29.txt,n số nguyên
1799,E:\DATN\dataframe\train_file\29.txt,"a_1, a_2, ..., a_n"
1800,E:\DATN\dataframe\train_file\29.txt, là loại của thanh chocolate thứ
1801,E:\DATN\dataframe\train_file\29.txt,1 \le n \le 10^6
1802,E:\DATN\dataframe\train_file\29.txt,1≤n≤10
1803,E:\DATN\dataframe\train_file\29.txt,0 \le a_i \le 10^9; \forall i: 1 \le i \le n
1804,E:\DATN\dataframe\train_file\29.txt,0≤a
1805,E:\DATN\dataframe\train_file\29.txt,≤10
1806,E:\DATN\dataframe\train_file\29.txt,;∀i:1≤i≤n.
1807,E:\DATN\dataframe\train_file\29.txt,Số nguyên duy nhất là số lượng người bạn tối đa mà Tèo có thể phát chocolate.
1808,E:\DATN\dataframe\train_file\29.txt,Sample Input:
1809,E:\DATN\dataframe\train_file\29.txt,1 2 2
1810,E:\DATN\dataframe\train_file\29.txt,Sample Output:
1811,E:\DATN\dataframe\train_file\29.txt,Ý tưởng của bài toán này rất rõ ràng là đếm số lượng phần tử khác nhau trong dãy số ban đầu.
1812,E:\DATN\dataframe\train_file\29.txt,Ta có một vài cách để làm bài toán này:
1813,E:\DATN\dataframe\train_file\29.txt,Sắp xếp lại dãy số rồi duyệt lại cả dãy để xác định các phần tử phần biệt.
1814,E:\DATN\dataframe\train_file\29.txt,Cách làm này hơi dài dòng và không đúng chủ đề nên tôi không đề cập.
1815,E:\DATN\dataframe\train_file\29.txt,Đếm phân phối các phần tử trong dãy số ban đầu.
1816,E:\DATN\dataframe\train_file\29.txt,Cách làm này chỉ mất phức tạp
1817,E:\DATN\dataframe\train_file\29.txt,)) - không phù hợp với ràng buộc của bài toán là
1818,E:\DATN\dataframe\train_file\29.txt,a_i \le 10^9
1819,E:\DATN\dataframe\train_file\29.txt,≤10
1820,E:\DATN\dataframe\train_file\29.txt,Tạo ra một set từ dãy số ban đầu rồi đưa ra kích thước của set đó - cũng chính là số lượng phần tử phân biệt trong set.
1821,E:\DATN\dataframe\train_file\29.txt,Cách làm này ngắn gọn và phù hợp nhất cho bài này.
1822,E:\DATN\dataframe\train_file\29.txt,Độ phức tạp chung của giải thuật sẽ là
1823,E:\DATN\dataframe\train_file\29.txt,Ngôn ngữ C++:
1824,E:\DATN\dataframe\train_file\29.txt,#include <bits/stdc++.h>
1825,E:\DATN\dataframe\train_file\29.txt,using namespace std;
1826,E:\DATN\dataframe\train_file\29.txt,    int n;
1827,E:\DATN\dataframe\train_file\29.txt,    cin >> n;
1828,E:\DATN\dataframe\train_file\29.txt,    vector < int > a(n);
1829,E:\DATN\dataframe\train_file\29.txt,    for (int i = 0; i < n; ++i)
1830,E:\DATN\dataframe\train_file\29.txt,        cin >> a[i];
1831,E:\DATN\dataframe\train_file\29.txt,"    set < int > unique_elements(a.begin(), a.end());"
1832,E:\DATN\dataframe\train_file\29.txt,    cout << unique_elements.size();
1833,E:\DATN\dataframe\train_file\29.txt,Ngôn ngữ Python:
1834,E:\DATN\dataframe\train_file\29.txt,if __name__ == '__main__':
1835,E:\DATN\dataframe\train_file\29.txt,    n = int(input())
1836,E:\DATN\dataframe\train_file\29.txt,    a = [int(x) for x in input().split()]
1837,E:\DATN\dataframe\train_file\29.txt,Bài toán 2
1838,E:\DATN\dataframe\train_file\29.txt,Hãy gọi một số là
1839,E:\DATN\dataframe\train_file\29.txt,k - tốt nếu nó chứa tất cả các chữ số không vượt quá
1840,E:\DATN\dataframe\train_file\29.txt,"k \ (0, ..., k)"
1841,E:\DATN\dataframe\train_file\29.txt,"k (0,...,k)."
1842,E:\DATN\dataframe\train_file\29.txt,Bi có một số
1843,E:\DATN\dataframe\train_file\29.txt,k và một mảng
1844,E:\DATN\dataframe\train_file\29.txt,A chứa
1845,E:\DATN\dataframe\train_file\29.txt,n số.
1846,E:\DATN\dataframe\train_file\29.txt,Tìm giúp Bi xem có bao nhiêu số đẹp
1847,E:\DATN\dataframe\train_file\29.txt,k trong
1848,E:\DATN\dataframe\train_file\29.txt,A (đếm từng số mỗi khi nó xuất hiện trong mảng
1849,E:\DATN\dataframe\train_file\29.txt,Hãy xác định có bao nhiêu số
1850,E:\DATN\dataframe\train_file\29.txt,k - tốt trong dãy
1851,E:\DATN\dataframe\train_file\29.txt,Dòng đầu tiên chứa
1852,E:\DATN\dataframe\train_file\29.txt,n và
1853,E:\DATN\dataframe\train_file\29.txt,k tương ứng với đề bài.
1854,E:\DATN\dataframe\train_file\29.txt,"n dòng tiếp theo, mỗi dòng chứa một số"
1855,E:\DATN\dataframe\train_file\29.txt, - phần tử thứ
1856,E:\DATN\dataframe\train_file\29.txt,i của mảng
1857,E:\DATN\dataframe\train_file\29.txt,A \ (1 \le i \le n)
1858,E:\DATN\dataframe\train_file\29.txt,A (1≤i≤n).
1859,E:\DATN\dataframe\train_file\29.txt,1 \le n \le 10^5
1860,E:\DATN\dataframe\train_file\29.txt,1≤n≤10
1861,E:\DATN\dataframe\train_file\29.txt,0 \le k \le 9
1862,E:\DATN\dataframe\train_file\29.txt,0≤k≤9.
1863,E:\DATN\dataframe\train_file\29.txt,1 \le a_i \le 10^9; \forall i: 1 \le i \le n
1864,E:\DATN\dataframe\train_file\29.txt,1≤a
1865,E:\DATN\dataframe\train_file\29.txt,≤10
1866,E:\DATN\dataframe\train_file\29.txt,;∀i:1≤i≤n.
1867,E:\DATN\dataframe\train_file\29.txt,In ra số lượng số
1868,E:\DATN\dataframe\train_file\29.txt,k - tốt trong dãy
1869,E:\DATN\dataframe\train_file\29.txt,Sample Input:
1870,E:\DATN\dataframe\train_file\29.txt,2 1
1871,E:\DATN\dataframe\train_file\29.txt,Sample Output:
1872,E:\DATN\dataframe\train_file\29.txt,Ứng với mỗi số
1873,E:\DATN\dataframe\train_file\29.txt,", sử dụng đếm phân phối hoặc set để đếm các chữ số khác nhau của nó mà không vượt quá"
1874,E:\DATN\dataframe\train_file\29.txt,k. Nếu số lượng chữ số khác nhau đó đúng bằng
1875,E:\DATN\dataframe\train_file\29.txt,k + 1
1876,E:\DATN\dataframe\train_file\29.txt,k+1 thì số
1877,E:\DATN\dataframe\train_file\29.txt, là số
1878,E:\DATN\dataframe\train_file\29.txt,"k - tốt, ngược lại thì không phải."
1879,E:\DATN\dataframe\train_file\29.txt,"Sử dụng set tất nhiên sẽ cài đặt ngắn gọn hơn rất nhiều, nên tôi khuyến khích các bạn sử dụng cách này."
1880,E:\DATN\dataframe\train_file\29.txt,Độ phức tạp:
1881,E:\DATN\dataframe\train_file\29.txt,O\big(n \times \log(k)\big)
1882,E:\DATN\dataframe\train_file\29.txt,O(n×log(k)).
1883,E:\DATN\dataframe\train_file\29.txt,Ngôn ngữ C++:
1884,E:\DATN\dataframe\train_file\29.txt,#include <bits/stdc++.h>
1885,E:\DATN\dataframe\train_file\29.txt,using namespace std;
1886,E:\DATN\dataframe\train_file\29.txt,"void enter(int &n, int &k, vector < string > &a)"
1887,E:\DATN\dataframe\train_file\29.txt,    cin >> n >> k;
1888,E:\DATN\dataframe\train_file\29.txt,    a.resize(n + 1);
1889,E:\DATN\dataframe\train_file\29.txt,    for (int i = 1; i <= n; ++i)
1890,E:\DATN\dataframe\train_file\29.txt,        cin >> a[i];
1891,E:\DATN\dataframe\train_file\29.txt,"void solution(int n, int k, vector < string > &a)"
1892,E:\DATN\dataframe\train_file\29.txt,    int res = 0;
1893,E:\DATN\dataframe\train_file\29.txt,    for (int i = 1; i <= n; ++i)
1894,E:\DATN\dataframe\train_file\29.txt,        set < char > digits;
1895,E:\DATN\dataframe\train_file\29.txt,        for (char d: a[i])
1896,E:\DATN\dataframe\train_file\29.txt,            if (d - '0' > k)
1897,E:\DATN\dataframe\train_file\29.txt,        res += (digits.size() == k + 1);
1898,E:\DATN\dataframe\train_file\29.txt,    cout << res;
1899,E:\DATN\dataframe\train_file\29.txt,"    int n, k;"
1900,E:\DATN\dataframe\train_file\29.txt,    vector < string > a;
1901,E:\DATN\dataframe\train_file\29.txt,"    enter(n, k, a);"
1902,E:\DATN\dataframe\train_file\29.txt,"    solution(n, k, a);"
1903,E:\DATN\dataframe\train_file\29.txt,    return 0;
1904,E:\DATN\dataframe\train_file\29.txt,Ngôn ngữ Python:
1905,E:\DATN\dataframe\train_file\29.txt,if __name__ == '__main__':
1906,E:\DATN\dataframe\train_file\29.txt,"    n, k = map(int, input().split())"
1907,E:\DATN\dataframe\train_file\29.txt,    res = 0
1908,E:\DATN\dataframe\train_file\29.txt,    for _ in range(n):
1909,E:\DATN\dataframe\train_file\29.txt,        a = input()
1910,E:\DATN\dataframe\train_file\29.txt,        digits = set()
1911,E:\DATN\dataframe\train_file\29.txt,        for d in a:
1912,E:\DATN\dataframe\train_file\29.txt,            if int(d) > k:
1913,E:\DATN\dataframe\train_file\29.txt,        if len(digits) == k + 1:
1914,E:\DATN\dataframe\train_file\29.txt,            res += 1
1915,E:\DATN\dataframe\train_file\29.txt,V. Tài liệu tham khảo
1916,E:\DATN\dataframe\train_file\3.txt,Ứng dụng Deep Learning xây dựng bộ dịch Tiếng Việt mới về Tiếng Việt cũ
1917,E:\DATN\dataframe\train_file\3.txt,Xin chào các bạn.
1918,E:\DATN\dataframe\train_file\3.txt,Nếu các bạn đã theo dõi trong bài viết trước của mình  thì có thấy là mình đã giới thiệu một ứng dụng nhỏ đó chính là chuyển đổi từ Tiếng Việt cũ về Tiếng Việt mới và trong phần cuối cùng của bài viết đó mình có đề cập đến một phần mới đó là ứng dụng chuyển đổi từ Tiếng Việt mới về Tiếng Việt cũ và cũng đã giới thiệu một mô hình Deep Learning được gợi ý để thực hiện vấn đề này đó chính là LSTM - Long Short Term Memory tuy nhiên mình vẫn chưa có thời gian viết rõ ràng cho các bạn.
1919,E:\DATN\dataframe\train_file\3.txt,Và bài viết này giúp giải thích rõ ràng hơn về vấn đề đó.
1920,E:\DATN\dataframe\train_file\3.txt,Mình tin rằng đây sẽ là một chủ đề hết sức thú vị đó.
1921,E:\DATN\dataframe\train_file\3.txt,OK chúng ta bắt đầu thôi các bạn nhé.
1922,E:\DATN\dataframe\train_file\3.txt,Tổng quan về Tiếng Việt mới.
1923,E:\DATN\dataframe\train_file\3.txt,"Trước hết cần phải nói lại một chút về vấn đề này, dù rằng cộng đồng mạng phản đối khá gay gắt về vấn đề này tuy nhiên đứng trên khía cạnh kĩ thuật mà nói thì chúng ta thấy có rất nhiều ứng dụng hay ho có thể thực hiện từ đề xuất cải tiến Tiếng Việt mới này."
1924,E:\DATN\dataframe\train_file\3.txt,Tất nhiên ý kiến này của mình chỉ dựa trên quan điểm kĩ thuật thôi nhé các bạn.
1925,E:\DATN\dataframe\train_file\3.txt,Giống như  mình đã đề cập khá kĩ về phương pháp chuyển đổi của GS Bùi Hiển.
1926,E:\DATN\dataframe\train_file\3.txt,Trên khía cạnh kĩ thuật các bạn có thể thực hiện nó dễ dàng bằng một Regex như sau:
1927,E:\DATN\dataframe\train_file\3.txt,class VnConverter(object):
1928,E:\DATN\dataframe\train_file\3.txt,"    def __init__(self, str):"
1929,E:\DATN\dataframe\train_file\3.txt,        self.str = str
1930,E:\DATN\dataframe\train_file\3.txt,"            ['k(h|H)', 'x'],"
1931,E:\DATN\dataframe\train_file\3.txt,"            ['K(h|H)', 'X'],"
1932,E:\DATN\dataframe\train_file\3.txt,"(h|H))|q', 'k'],"
1933,E:\DATN\dataframe\train_file\3.txt,"(h|H))|Q', 'K'],"
1934,E:\DATN\dataframe\train_file\3.txt,"            ['t(r|R)|c(h|H)', 'c'],"
1935,E:\DATN\dataframe\train_file\3.txt,"            ['T(r|R)|C(h|H)', 'C'],"
1936,E:\DATN\dataframe\train_file\3.txt,"            ['d|g(i|I)|r', 'z'],"
1937,E:\DATN\dataframe\train_file\3.txt,"            ['D|G(i|I)|R', 'Z'],"
1938,E:\DATN\dataframe\train_file\3.txt,"            ['g(i|ì|í|ỉ|ĩ|ị|I|Ì|Í|Ỉ|Ĩ|Ị)', r'z\1'],"
1939,E:\DATN\dataframe\train_file\3.txt,"            ['G(i|ì|í|ỉ|ĩ|ị|I|Ì|Í|Ỉ|Ĩ|Ị)', r'Z\1'],"
1940,E:\DATN\dataframe\train_file\3.txt,"            ['đ', 'd'],"
1941,E:\DATN\dataframe\train_file\3.txt,"            ['Đ', 'D'],"
1942,E:\DATN\dataframe\train_file\3.txt,"            ['p(h|H)', 'f'],"
1943,E:\DATN\dataframe\train_file\3.txt,"            ['P(h|H)', 'F'],"
1944,E:\DATN\dataframe\train_file\3.txt,"            ['(g|G)(h|H)', 'g'],"
1945,E:\DATN\dataframe\train_file\3.txt,"            ['t(h|H)', 'w'],"
1946,E:\DATN\dataframe\train_file\3.txt,"            ['T(h|H)', 'W'],"
1947,E:\DATN\dataframe\train_file\3.txt,"            ['(n|N)(h|H)', 'n\'']"
1948,E:\DATN\dataframe\train_file\3.txt,Về mặt toán học chúng ta có thể thấy đây là một ánh xạ từ một tập từ vựng vocabulary trong Tiếng Việt hiện hành sang một tập từ vựng mới nhỏ hơn tạm gọi là vocabulary Bùi Hiển.
1949,E:\DATN\dataframe\train_file\3.txt,Với biểu thức chính quy như trên chúng ta có thể dễ dàng thực hiện việc chuyển đổi này bằng một hàm như sau.
1950,E:\DATN\dataframe\train_file\3.txt,Các bạn viết trong cùng class VnConverter bên trên nhé:
1951,E:\DATN\dataframe\train_file\3.txt,   def convert(self):
1952,E:\DATN\dataframe\train_file\3.txt,        for map in self.maps:
1953,E:\DATN\dataframe\train_file\3.txt,"            self.str = re.sub(re.compile(map[0]), map[1], self.str)"
1954,E:\DATN\dataframe\train_file\3.txt,        return self.str
1955,E:\DATN\dataframe\train_file\3.txt,Việc chuyển đổi này được coi là một hàm tuyến tính và chúng ta có thể có kết quả như sau:  Tuy nhiên như chúng ta đã biết.
1956,E:\DATN\dataframe\train_file\3.txt,Chính vì phương pháp này làm giảm đi số lượng kí tự nên rõ ràng việc chúng ta cố tình suy đoán xem chữ mới này biếu diễn bằng chữ cũ nào là một việc vô cùng khó khăn hay nói cách khác chúng ta không thể sử dụng một biểu thức chính quy để chuyển đổi một cách tuyến tính được.
1957,E:\DATN\dataframe\train_file\3.txt,Đây là một biến đổi dạng phi tuyến và là một vấn đề khá là khoai tây nếu như chúng ta không áp dụng các phương pháp của học máy hiện đại.
1958,E:\DATN\dataframe\train_file\3.txt,Chúng ta sẽ cùng thảo luận kĩ hơn về vấn đề này trong phần sau nhé
1959,E:\DATN\dataframe\train_file\3.txt,Chuyển chữ mới về chữ cũ - làm như thế nào??
1960,E:\DATN\dataframe\train_file\3.txt,Như mình đã đề cập bên trên thì việc chuyển đổi từ chữ mới về chữ cũ có thể được biểu diễn bằng một hàm như sau:
1961,E:\DATN\dataframe\train_file\3.txt,Một câu hỏi cho các bạn là hàm f trên là gì.
1962,E:\DATN\dataframe\train_file\3.txt,Tôi cũng không biết cụ thể nó là như thế nào và tôi tin rằng các bạn cũng vậy.
1963,E:\DATN\dataframe\train_file\3.txt,Chính vì thế việc cần làm của chúng ta đó là tìm ra hàm f nêu trên.
1964,E:\DATN\dataframe\train_file\3.txt,Các phương pháp đi tìm hàm f ẩn cho mỗi vấn đề thương làm người ta liên tưởng đến Machine Learning và thật đúng như vậy.
1965,E:\DATN\dataframe\train_file\3.txt,Tất cả mọi thứ phức tạp nhất trên cuộc đời này để có thể biểu diễn bằng một hàm f dạng như thế.
1966,E:\DATN\dataframe\train_file\3.txt,Trong Machine Learning chúng có thể là một matrix giống như Linear Regression cũng có thể là một hyperplane giống như trong SVM hoặc cũng có thể là một mạng nơ ron giống như trong cách tiếp cận của Deep Learning và còn là những thứ gì khác nữa mà hiện tại con người chưa khám phá ra được.
1967,E:\DATN\dataframe\train_file\3.txt,Vấn đề mà chúng ta đang đề cập đến tại đây là một dạng của machine translation hay còn gọi là dịch máy.
1968,E:\DATN\dataframe\train_file\3.txt,Chắc có lẽ một công cụ đã không còn xa lạ gì với tất cả chúng ta đó chính là Google Dịch về bản chất nó cũng sử dụng các kĩ thuật Deep Learning mà tôi sẽ trình bày với các bạn trong bài viết này.
1969,E:\DATN\dataframe\train_file\3.txt,Nhưng không phải là để dịch Tiếng Anh sang Tiếng Việt mà là để dịch Tiếq Việt sang Tiếng Việt
1970,E:\DATN\dataframe\train_file\3.txt,Việc dịch này được thực hiện dựa trên một mô hình gọi là Sequence to Sequence mà mình sẽ giới thiệu chi tiết cho các bạn sau đây.
1971,E:\DATN\dataframe\train_file\3.txt,Nhưng trước hết có thể bạn sẽ có một câu hỏi rằng tại sao không sử dụng phương pháp dịch từng từ một rồi ghép chúng lại với nhau.
1972,E:\DATN\dataframe\train_file\3.txt,Câu trả lời là việc dịch như thế đôi khi làm cho câu dịch bị mất đi ý nghĩa và đọc lên cảm thấy rất là vô hồn hơn nữa nó là mất đi các quy tắc về ngữ pháp trong ngôn ngữ đích nếu như chúng ta không xây dựng một tập luật - rules để xác định cách biểu diễn ngôn ngữ đích sao cho đúng ngữ pháp.
1973,E:\DATN\dataframe\train_file\3.txt,Mô hình Sequence to Sequence giải quyết được hoàn toàn hai vấn đề trên.
1974,E:\DATN\dataframe\train_file\3.txt,Bây giờ chúng ta sẽ cùng nhau tìm hiểu về mô hình thần thánh này nhé
1975,E:\DATN\dataframe\train_file\3.txt,Mô hình Sequence to Sequence
1976,E:\DATN\dataframe\train_file\3.txt,Có thể nói mô hình Sequence to Sequence mang lại một hiệu quả vô cùng to lớn cho thế giới hiện đại của chúng ta.
1977,E:\DATN\dataframe\train_file\3.txt,"Rất nhiều những ý tưởng mang tầm cỡ thế kĩ được sinh ra từ chúng như các trợ lý ảo, các hệ thống dịch tự động, các hệ thống tự động sinh caption cho ảnh / video hay chatbot."
1978,E:\DATN\dataframe\train_file\3.txt,Về bản chất mô hình này gồm có hai pha.
1979,E:\DATN\dataframe\train_file\3.txt,Chúng ta có thể hiểu nôm na như sau:
1980,E:\DATN\dataframe\train_file\3.txt,Pha 1 - Encoder: Pha encoder này có nhiệm vụ hiểu được thông tin của dữ liệu đầu vào.
1981,E:\DATN\dataframe\train_file\3.txt,Việc hiểu này có nghĩa là mô hình hóa được bản chất của dữ lệu đầu vào.
1982,E:\DATN\dataframe\train_file\3.txt,Chẳng hạn như trong bài toán của chúng ta đó chính là Tiếng Việt mới.
1983,E:\DATN\dataframe\train_file\3.txt,Thông thường người ta sẽ sử dụng mạng nơ ron hồi quy - RNN để biểu diễn thông tin cho các dữ liệu trong NLP vì dữ liệu NLP có đặc tính là phụ thuộc theo chuỗi (từ sau phụ thuộc vào từ đứng trước đó).
1984,E:\DATN\dataframe\train_file\3.txt,Đây cũng chính là lý do người ta lựa chọn RNN để mô hình hóa ngôn ngữ trong dịch máy.
1985,E:\DATN\dataframe\train_file\3.txt,Tránh tình trạng sinh ra những câu vô nghĩa như bên trên mình đã đề cập
1986,E:\DATN\dataframe\train_file\3.txt,Pha 2 - Decoder Pha decoder này có nhiệm vụ chuyển đổi từ output của pha 1.
1987,E:\DATN\dataframe\train_file\3.txt,Tức là một thought vector - vector suy diễn biểu diễn ngữ nghĩa của câu nguồn - sang cấu trúc của câu đích (câu cần dịch).
1988,E:\DATN\dataframe\train_file\3.txt,Chúng ta có thể thấy rõ điều này trong sơ đồ sau:
1989,E:\DATN\dataframe\train_file\3.txt,Mạng nơ ron LSTM - Long Short Term Memory
1990,E:\DATN\dataframe\train_file\3.txt,Trong các bước encoder và decoder trong mô hình seq2seq người ta thường sử dụng một kiến trúc mở rộng của mạng nơ ron hồi quy RNN đó chính là LSTM.
1991,E:\DATN\dataframe\train_file\3.txt,Mạng LSTM được sinh ra với mục đích giúp cho RNN có thể nhớ được những phụ thuộc xa trong chuỗi dữ liệu.
1992,E:\DATN\dataframe\train_file\3.txt,"Điều này cũng giống như cách mà bộ nhớ của con người hoạt động, chúng ta không bắt đầu suy nghĩ của chúng ta từ con số 0 (đây là cách mà các mạng nơ ron truyền thống áp dụng) mà chúng ta sẽ liên tưởng và ghép nối các thông tin từ các sự kiện đã xảy ra trước đó."
1993,E:\DATN\dataframe\train_file\3.txt,Đây chính là tư tưởng của mạng RNN.
1994,E:\DATN\dataframe\train_file\3.txt,Tuy nhiên trong mạng RNN truyền thống chỉ lấy đầu ra của bước trước đó làm đầu vào của bước hiện tại.
1995,E:\DATN\dataframe\train_file\3.txt,Tuy nhiên do một số vấn đề về mất mát hoặc bùng nổ đạo hàm - vanishing / exploding gradient trong quá trình tính toán back propagation mà mạng RNN truyền thống không thể nhớ được các phụ thuộc xa trong dữ liệu.
1996,E:\DATN\dataframe\train_file\3.txt,Tức là nó bị đãng trí.
1997,E:\DATN\dataframe\train_file\3.txt,Để khắc phục tình trạng đãng trí này người ta đề xuất mô hình LSTM bằng cách thêm vào một số cải tiến như sau:
1998,E:\DATN\dataframe\train_file\3.txt,"Thêm vào mạng một trạng thái tế bào - cell state sử dụng để lưu trữ và lan truyền các thông tin có ích trong mạng, nó tương tự như một bộ nhớ cục bộ của mạng."
1999,E:\DATN\dataframe\train_file\3.txt,Bổ sung thêm cổng quên - forget gate để loại bỏ những thông tin không quan trọng.
2000,E:\DATN\dataframe\train_file\3.txt,Việc quyết định thông tin nào được giữ lại thông tin nào được loại bỏ đi chính là ở bước này.
2001,E:\DATN\dataframe\train_file\3.txt,Và đương nhiên là chúng ta cần tìm ra một ma trận
2002,E:\DATN\dataframe\train_file\3.txt, để khi nhân ma trận này với thông tin đầu vào chúng ta sẽ quyết định được thông tin đó có đi vào trạng thái tế bào ở lần lặp tiếp theo hay không.
2003,E:\DATN\dataframe\train_file\3.txt,Bổ sung một cổng input - input gate và cũng với một ma trận
2004,E:\DATN\dataframe\train_file\3.txt, để thể hiện thông tin mới được đưa vào (ví dụ như từ hiện tại mà mạng LSTM đang chạy qua).
2005,E:\DATN\dataframe\train_file\3.txt,Mình chỉ nói ở mức cơ bản như vậy thôi nhé.
2006,E:\DATN\dataframe\train_file\3.txt,Các bạn muốn tìm hiểu có thể tham khảo thêm trong .
2007,E:\DATN\dataframe\train_file\3.txt,Giờ chúng ta sẽ tìm hiểu xem cách mà chúng ta cần triển khai một bộ dịch Tiếng Việt như thế nào.
2008,E:\DATN\dataframe\train_file\3.txt,Xây dựng bộ dịch Tiếng Việt mới sang Tiếng Việt cũ
2009,E:\DATN\dataframe\train_file\3.txt,Bước 1: Thu thập dữ liệu
2010,E:\DATN\dataframe\train_file\3.txt,Dữ liệu là một thứ không thể thiếu được với bất kì một ứng dụng Machine Learning nào.
2011,E:\DATN\dataframe\train_file\3.txt,Chúng ta sẽ không thể làm được gì nếu như không có dữ liệu phải không nào.
2012,E:\DATN\dataframe\train_file\3.txt,Các bạn có thể viết các tool crawler để crawl các dữ liệu từ trên mạng về rồi lưu vào file.
2013,E:\DATN\dataframe\train_file\3.txt,Tuy nhiên trong đây mình có sử dụng một tập dữ liệu nhỏ mà mình crawl được từ trên các trang báo mạng về rồi tổng hợp thành một file các bạn có thể download nó về .
2014,E:\DATN\dataframe\train_file\3.txt,"Tiếp theo, do mô hình LSTM sẽ nhận đầu vào là từng câu trong tập dữ liệu nên chúng ta cần phải thực hiện bước tách câu cho tiếng việt và thêm kí tự kết thúc (ví dụ như dấu chấm) vào cuối câu đó."
2015,E:\DATN\dataframe\train_file\3.txt,Các bạn có thể download thêm nhiều dữ liệu khác và đặt vào cùng một thư mục data như hình sau:
2016,E:\DATN\dataframe\train_file\3.txt,Sau khi chuẩn bị xong dữ liệu chúng ta tiến hành load dữ liệu nhé
2017,E:\DATN\dataframe\train_file\3.txt,Bước 2: Xây dựng tập dữ liệu
2018,E:\DATN\dataframe\train_file\3.txt,Bước này khá đơn giản cũng không có gì phải bàn nhiều.
2019,E:\DATN\dataframe\train_file\3.txt,Các bạn tiến hành đọc tất cả các file dữ liệu của các bạn trong thư mục data/ vừa rồi
2020,E:\DATN\dataframe\train_file\3.txt,DATA_PATH = 'data/'
2021,E:\DATN\dataframe\train_file\3.txt,class DataLoader(object):
2022,E:\DATN\dataframe\train_file\3.txt,"    def __init__(self, path = DATA_PATH):"
2023,E:\DATN\dataframe\train_file\3.txt,        self.path = path
2024,E:\DATN\dataframe\train_file\3.txt,    def load_source_data(self):
2025,E:\DATN\dataframe\train_file\3.txt,        files = glob.glob('{}*.txt'.format(self.path))
2026,E:\DATN\dataframe\train_file\3.txt,"        data = [open(f, 'rb').read().decode('utf-8') for f in files]"
2027,E:\DATN\dataframe\train_file\3.txt,        return data
2028,E:\DATN\dataframe\train_file\3.txt,Tiếp theo chúng ta cần viết một hàm tách tập dữ liệu txt của chúng ta thành các câu đơn lẻ.
2029,E:\DATN\dataframe\train_file\3.txt,Kết quả là chúng ta sẽ có một list các câu đơn lẻ trong tập dữ liệu.
2030,E:\DATN\dataframe\train_file\3.txt,Ở đây để cho đơn giản mình sử dụng một công cụ tách câu của thư viện nltk.
2031,E:\DATN\dataframe\train_file\3.txt,Các bạn thực hiện như sau
2032,E:\DATN\dataframe\train_file\3.txt,   def load_source_sentences(self):
2033,E:\DATN\dataframe\train_file\3.txt,        source_data = self.load_source_data()
2034,E:\DATN\dataframe\train_file\3.txt,"        return [sent.replace('\n', ' ') for d in tqdm(source_data) for sent in sent_tokenize(d)]"
2035,E:\DATN\dataframe\train_file\3.txt,Chúng ta thử xem kết quả thực hiện của hàm trên.
2036,E:\DATN\dataframe\train_file\3.txt,if __name__ == '__main__':
2037,E:\DATN\dataframe\train_file\3.txt,    old_sentences = DataLoader().load_source_sentences()
2038,E:\DATN\dataframe\train_file\3.txt,">>> ['Đối với tôi, câu chuyện này bắt đầu 15 năm trước, khi tôi còn là một bác sĩ tế bần tại Đại học Chicago."
2039,E:\DATN\dataframe\train_file\3.txt,"', 'Tôi chăm sóc những người đang hấp hối và gia đình của họ ở Nam Chicago.']"
2040,E:\DATN\dataframe\train_file\3.txt,Đây chính là các câu ở trong tiếng việt của chúng ta sử dụng.
2041,E:\DATN\dataframe\train_file\3.txt,Giờ chúng ta sẽ sử dụng hàm convert trong class VnConverter phía trên để thực hiện chuyển đổi câu này sang Tiếng Việt mới nhé.
2042,E:\DATN\dataframe\train_file\3.txt,   def load_dict_sentences(self):
2043,E:\DATN\dataframe\train_file\3.txt,        source_sentences = self.load_source_sentences()
2044,E:\DATN\dataframe\train_file\3.txt,        return [VnConverter(sent).convert() for sent in source_sentences]
2045,E:\DATN\dataframe\train_file\3.txt,chúng ta cũng thử xem kết quả của hàm này xem sao:
2046,E:\DATN\dataframe\train_file\3.txt,if __name__ == '__main__':
2047,E:\DATN\dataframe\train_file\3.txt,    new_sentences = DataLoader().load_dict_sentences()
2048,E:\DATN\dataframe\train_file\3.txt,"    >>> ['Dối với tôi, kâu cuyện này bắt dầu 15 năm cướk, xi tôi kòn là một bák sĩ tế bần tại Dại họk Cikago."
2049,E:\DATN\dataframe\train_file\3.txt,"', ""Tôi căm sók n'ữq qười daq hấp hối và za dìn' kủa họ ở Nam Cikago.""]"
2050,E:\DATN\dataframe\train_file\3.txt,Vậy là chúng ta đã có hai tập dữ liệu việc còn lại là dump nó ra thành từng file.
2051,E:\DATN\dataframe\train_file\3.txt,Chúng ta sử dụng hàm sau
2052,E:\DATN\dataframe\train_file\3.txt,"   def dump_to_txt(self, sentences, filename):"
2053,E:\DATN\dataframe\train_file\3.txt,"        with open(file=filename, mode='a') as file:"
2054,E:\DATN\dataframe\train_file\3.txt,            for sent in sentences:
2055,E:\DATN\dataframe\train_file\3.txt,                file.write(sent + '\n')
2056,E:\DATN\dataframe\train_file\3.txt,"Như vậy sau bước chuẩn bị dữ liệu chúng ta đã có hai file, file nguồn và file đích tương ứng với nhau về số dòng."
2057,E:\DATN\dataframe\train_file\3.txt,"File nguồn chính là Tiếng Việt mới của Bùi Hiển, file nguồn là Tiếng Việt của chúng ta đang dùng."
2058,E:\DATN\dataframe\train_file\3.txt,Chúng ta tiến hành chia dữ liệu thành hai phần traning và tessting nữa là xong.
2059,E:\DATN\dataframe\train_file\3.txt,Các bạn có thể thực hiện như sau:
2060,E:\DATN\dataframe\train_file\3.txt,   ratio = 0.8
2061,E:\DATN\dataframe\train_file\3.txt,"    DataLoader().dump_to_txt(sentences=old_sentences[:int(len(old_sentences) * ratio)], filename=DATA_PATH + 'train_old_sentences.txt')"
2062,E:\DATN\dataframe\train_file\3.txt,"    DataLoader().dump_to_txt(sentences=new_sentences[:int(len(new_sentences) * ratio)], filename=DATA_PATH + 'train_new_sentences.txt')"
2063,E:\DATN\dataframe\train_file\3.txt,"    DataLoader().dump_to_txt(sentences=old_sentences[int(len(old_sentences) * ratio):], filename=DATA_PATH + 'test_old_sentences.txt')"
2064,E:\DATN\dataframe\train_file\3.txt,"    DataLoader().dump_to_txt(sentences=new_sentences[int(len(new_sentences) * ratio):], filename=DATA_PATH + 'test_new_sentences.txt')"
2065,E:\DATN\dataframe\train_file\3.txt,Sau bước này chúng ta sẽ có tập dữ liệu như sau:
2066,E:\DATN\dataframe\train_file\3.txt,Tập dữ liệu này sẽ được sử dụng để training mô hình học máy của chúng ta.
2067,E:\DATN\dataframe\train_file\3.txt,Training mô hình
2068,E:\DATN\dataframe\train_file\3.txt,Về mặt lý thuyết chúng ta có thể tự impliment một mô hình Machine Translation với các thư viện của Tensorflow tuy nhiên trong phạm vi của bài viết quá dài mình không thể trình bày hết các bước impliment được nên mình quyết định sử dụng một thư viện hỗ trợ khá tốt việc training các mô hình dịch máy đó chính là .
2069,E:\DATN\dataframe\train_file\3.txt,Các bạn cài đặt theo như hướng dẫn và tiến hành trainng bằng câu lệnh như sau:
2070,E:\DATN\dataframe\train_file\3.txt,cd data
2071,E:\DATN\dataframe\train_file\3.txt,python -m sockeye.train --source train_new_sentences.txt \
2072,E:\DATN\dataframe\train_file\3.txt,                       --target train_old_sentences.txt \
2073,E:\DATN\dataframe\train_file\3.txt,                       --validation-source test_new_sentences.txt \
2074,E:\DATN\dataframe\train_file\3.txt,                       --validation-target test_old_sentences.txt \
2075,E:\DATN\dataframe\train_file\3.txt,                        --num-embed 256 \
2076,E:\DATN\dataframe\train_file\3.txt,                        --rnn-num-hidden 512 \
2077,E:\DATN\dataframe\train_file\3.txt,                        --rnn-attention-type dot \
2078,E:\DATN\dataframe\train_file\3.txt,                        --max-seq-len 60 \
2079,E:\DATN\dataframe\train_file\3.txt,                        --decode-and-evaluate 500 \
2080,E:\DATN\dataframe\train_file\3.txt,                       --output model_sockeye
2081,E:\DATN\dataframe\train_file\3.txt,Sau khi training một thời gian đủ dài (khoảng 20 epochs) các bạn sẽ thu được một model dịch máy (khoảng 10GB) và sử dụng model đó trong việc dịch ngược từ Tiếng Việt mới về Tiếng Việt cũ.
2082,E:\DATN\dataframe\train_file\3.txt,Dịch ngược Tiếng Việt mới về Tiếng Việt cũ
2083,E:\DATN\dataframe\train_file\3.txt,Sau khi có mô hình các bạn có thể dịch ngược một câu Tiếng Việt mới bất kì như sau:
2084,E:\DATN\dataframe\train_file\3.txt,"echo ""Căm năm coq kõi qười ta."""
2085,E:\DATN\dataframe\train_file\3.txt,| python -m sockeye.translate --models model_sockeye --use-cpu
2086,E:\DATN\dataframe\train_file\3.txt,>>> Trăm năm trong cõi người ta.
2087,E:\DATN\dataframe\train_file\3.txt,"echo ""Và nó xôq cỉ zõ kái zì daq xảy za Một số kâu hỏi dượk dặt za qay lập tứk."""
2088,E:\DATN\dataframe\train_file\3.txt,| python -m sockeye.translate --models model_sockeye --use-cpu
2089,E:\DATN\dataframe\train_file\3.txt,>>> Và nó không chỉ rõ cái gì đang xảy ra Một số câu hỏi được đặt ra ngay lập tức.
2090,E:\DATN\dataframe\train_file\3.txt,Độ chính xác của mô hình hiện tại mình đang sử dụng khoảng 70% do thời gian training không nhiều cũng như dữ liệu training không đủ.
2091,E:\DATN\dataframe\train_file\3.txt,Bạn đọc có thể tự mình tạo thêm dữ liệu với các bước ở trên đồng thời có thể tự impliment một bộ Machine Translation của riêng mình mà không phụ thuộc vào thư viện của bên thứ 3.
2092,E:\DATN\dataframe\train_file\3.txt,Chúc các bạn cuối tuần vui vẻ.
2093,E:\DATN\dataframe\train_file\3.txt,Source code
2094,E:\DATN\dataframe\train_file\3.txt,Các bạn có thể tham khảo source code của bài viết tại
2095,E:\DATN\dataframe\train_file\3.txt,Với mô hình Deep Learning chúng ta hoàn toàn có thể xây dựng được một bộ dịch từ Tiếng Việt của Bùi Hiển về Tiếng Việt hiện tại.
2096,E:\DATN\dataframe\train_file\3.txt,"Tuy nhiên mình không khuyến khích điều này, mặc dù nó chứng minh một điều rằng nếu như nắm trong tay công nghệ, chúng ta hoàn toàn có thể giải quyết được đa số vấn đề của thế giới."
2097,E:\DATN\dataframe\train_file\3.txt,"Vậy nên, Dù là thay đổi bất cứ điều gì, chúng ta là dân công nghệ thì không phải sợ."
2098,E:\DATN\dataframe\train_file\30.txt,Cây và Tính toán biểu thức
2099,E:\DATN\dataframe\train_file\30.txt,I. Cây
2100,E:\DATN\dataframe\train_file\30.txt,Định nghĩa cây và các khái niệm quan trọng
2101,E:\DATN\dataframe\train_file\30.txt,"Trong chuyên đề này, cấu trúc dữ liệu mà chúng ta quan tâm đến là Cấu trúc cây."
2102,E:\DATN\dataframe\train_file\30.txt,"Thực tế, các bài toán dùng trực tiếp cây có rất ít, kèm theo sự phát triển của các ngôn ngữ lập trình khiến cho việc cài đặt thủ công những cấu trúc dữ liệu theo mô hình cây không còn cần thiết nữa."
2103,E:\DATN\dataframe\train_file\30.txt,"Vì vậy, mục tiêu của tôi là giới thiệu tới các bạn những khái niệm căn bản về cây, chủ yếu là để phục vụ cho các cấu trúc dữ liệu phức tạp hơn sau này mà dựa trên mô hình cây (chẳng hạn như Interval Tree hay Binary Indexed Tree,...)."
2104,E:\DATN\dataframe\train_file\30.txt,"Cây là một cấu trúc dữ liệu gồm một tập hữu hạn các nút (nodes), giữa các nút có một quan hệ phân cấp gọi là quan hệ ""cha - con""."
2105,E:\DATN\dataframe\train_file\30.txt,Có một nút đặc biệt trên cây gọi là nút gốc (root).
2106,E:\DATN\dataframe\train_file\30.txt,Cây cũng là một đối tượng có thể định nghĩa đệ quy:
2107,E:\DATN\dataframe\train_file\30.txt,"Mỗi nút là một cây, nút đó cũng là gốc của cây ấy."
2108,E:\DATN\dataframe\train_file\30.txt,n là một nút và
2109,E:\DATN\dataframe\train_file\30.txt,"n_1, n_2, \dots, n_k"
2110,E:\DATN\dataframe\train_file\30.txt,",…,n"
2111,E:\DATN\dataframe\train_file\30.txt, lần lượt là gốc của các cây
2112,E:\DATN\dataframe\train_file\30.txt,"T_1, T_2, \dots, T_k"
2113,E:\DATN\dataframe\train_file\30.txt,",…,T"
2114,E:\DATN\dataframe\train_file\30.txt, sao cho các cây này đôi một không có nút chung.
2115,E:\DATN\dataframe\train_file\30.txt,Thì nếu cho nút
2116,E:\DATN\dataframe\train_file\30.txt,n trở thành nút cha của các nút
2117,E:\DATN\dataframe\train_file\30.txt,"n_1, n_2, \dots, n_k"
2118,E:\DATN\dataframe\train_file\30.txt,",…,n"
2119,E:\DATN\dataframe\train_file\30.txt, ta sẽ thu được một cây mới
2120,E:\DATN\dataframe\train_file\30.txt,T. Cây này có nút gốc là
2121,E:\DATN\dataframe\train_file\30.txt,"n, còn các cây"
2122,E:\DATN\dataframe\train_file\30.txt,"T_1, T_2, \dots, T_k"
2123,E:\DATN\dataframe\train_file\30.txt,",…,T"
2124,E:\DATN\dataframe\train_file\30.txt, trở thành các cây con (subtree) của gốc.
2125,E:\DATN\dataframe\train_file\30.txt,"Ngoài ra, người ta còn quy ước có tồn tại cây không có nút nào, gọi là cây rỗng (null tree)."
2126,E:\DATN\dataframe\train_file\30.txt,Hình vẽ dưới đây minh họa một cây:
2127,E:\DATN\dataframe\train_file\30.txt,"Trên cây này, chúng ta có một số khái niệm sau:"
2128,E:\DATN\dataframe\train_file\30.txt,A là cha của các nút
2129,E:\DATN\dataframe\train_file\30.txt,"B, C, D;"
2130,E:\DATN\dataframe\train_file\30.txt,"B,C,D; còn"
2131,E:\DATN\dataframe\train_file\30.txt,"G, H, I"
2132,E:\DATN\dataframe\train_file\30.txt,"G,H,I là các nút con của nút"
2133,E:\DATN\dataframe\train_file\30.txt,Số các con của một nút được gọi là cấp của nút đó.
2134,E:\DATN\dataframe\train_file\30.txt,"chẳng hạn, cấp của nút"
2135,E:\DATN\dataframe\train_file\30.txt,A là
2136,E:\DATN\dataframe\train_file\30.txt,"3, cấp của nút"
2137,E:\DATN\dataframe\train_file\30.txt,B là
2138,E:\DATN\dataframe\train_file\30.txt,"2, \dots"
2139,E:\DATN\dataframe\train_file\30.txt,"2,…"
2140,E:\DATN\dataframe\train_file\30.txt,Nút có cấp bằng
2141,E:\DATN\dataframe\train_file\30.txt,0 được gọi là nút lá (hay nút tận cùng).
2142,E:\DATN\dataframe\train_file\30.txt,Những nút không phải lá được gọi là các nút nhánh.
2143,E:\DATN\dataframe\train_file\30.txt,"Trong cây trên, các nút"
2144,E:\DATN\dataframe\train_file\30.txt,"E, F, C, G, J, K, I"
2145,E:\DATN\dataframe\train_file\30.txt,"E,F,C,G,J,K,I là các nút lá, còn lại là nút nhánh."
2146,E:\DATN\dataframe\train_file\30.txt,Cấp cao nhất của một nút trên cây gọi là cấp của cây đó.
2147,E:\DATN\dataframe\train_file\30.txt,Cây ở hình trên có cấp bằng
2148,E:\DATN\dataframe\train_file\30.txt,"Các nút trên cây được chia thành nhiều mức, mỗi nút sẽ được gán một số nguyên gọi là mức của nút."
2149,E:\DATN\dataframe\train_file\30.txt,Nút gốc của cây có quy ước mức bằng
2150,E:\DATN\dataframe\train_file\30.txt,"1, sau đó nếu nút cha có mức là"
2151,E:\DATN\dataframe\train_file\30.txt,i thì nút con sẽ có mức là
2152,E:\DATN\dataframe\train_file\30.txt,i + 1
2153,E:\DATN\dataframe\train_file\30.txt,"Chẳng hạn, nút"
2154,E:\DATN\dataframe\train_file\30.txt,A có mức là
2155,E:\DATN\dataframe\train_file\30.txt,1; các nút
2156,E:\DATN\dataframe\train_file\30.txt,"B, C, D"
2157,E:\DATN\dataframe\train_file\30.txt,"B,C,D có mức là"
2158,E:\DATN\dataframe\train_file\30.txt,2;\dots
2159,E:\DATN\dataframe\train_file\30.txt,2;…
2160,E:\DATN\dataframe\train_file\30.txt,Chiều cao (hay chiều sâu) của cây là số mức lớn nhất của nút trên cây đó.
2161,E:\DATN\dataframe\train_file\30.txt,Cây trên có chiều cao là
2162,E:\DATN\dataframe\train_file\30.txt,Một tập hợp các cây phân biệt được gọi là rừng.
2163,E:\DATN\dataframe\train_file\30.txt,Một cây nếu bỏ đi nút gốc thì sẽ tạo ra một rừng các cây con.
2164,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân
2165,E:\DATN\dataframe\train_file\30.txt,Định nghĩa và tính chất của cây nhị phân
2166,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân là một dạng quan trọng của cấu trúc cây.
2167,E:\DATN\dataframe\train_file\30.txt,"Rất nhiều cấu trúc dữ liệu được thiết kế dựa trên mô hình cây nhị phân như Heap, Interval Tree hay Binary Indexed Tree,...Đặc điểm của cây nhị phân là mọi nút trên cây chỉ có tối đa hai nhánh con, phân ra làm nhánh con trái và nhánh con phải."
2168,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân có một số dạng đặc biệt cần lưu ý:
2169,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân suy biến (degenerate binary tree): Các nút không phải là lá chỉ có một nhánh con.
2170,E:\DATN\dataframe\train_file\30.txt,"Có thể có ba dạng của cây nhị phân suy biến: Cây lệch trái (a), cây lệch phải (b) và cây ziczac (c)."
2171,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân hoàn chỉnh (complete binary tree): Xét cây có chiều cao là
2172,E:\DATN\dataframe\train_file\30.txt,"h, nếu mọi nút có mức nhỏ hơn"
2173,E:\DATN\dataframe\train_file\30.txt,h - 1
2174,E:\DATN\dataframe\train_file\30.txt,h−1 đều có đúng hai nút con thì đó là một cây nhị phân hoàn chỉnh.
2175,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân đầy đủ (full binary tree): Mọi nút có mức nhỏ hơn hoặc bằng
2176,E:\DATN\dataframe\train_file\30.txt,h - 1
2177,E:\DATN\dataframe\train_file\30.txt,h−1 đều có đúng
2178,E:\DATN\dataframe\train_file\30.txt,2 nút con.
2179,E:\DATN\dataframe\train_file\30.txt,Đây có thể xem là trường hợp đặc biệt của cây nhị phân hoàn chỉnh.
2180,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân có một số tính chất sau đây:
2181,E:\DATN\dataframe\train_file\30.txt,"Trong các cây nhị phân có cùng số lượng nút như nhau thì cây nhị phân suy biến có chiều cao lớn nhất, còn cây nhị phân hoàn chỉnh có chiều cao nhỏ nhất."
2182,E:\DATN\dataframe\train_file\30.txt,Số lượng nút tối đa trên mức
2183,E:\DATN\dataframe\train_file\30.txt,i của cây nhị phân là
2184,E:\DATN\dataframe\train_file\30.txt,"2^{i - 1},"
2185,E:\DATN\dataframe\train_file\30.txt,i−1
2186,E:\DATN\dataframe\train_file\30.txt,", tối thiểu là"
2187,E:\DATN\dataframe\train_file\30.txt,1 \ (i \ge 1)
2188,E:\DATN\dataframe\train_file\30.txt,1 (i≥1).
2189,E:\DATN\dataframe\train_file\30.txt,Số lượng nút tối đa trên một cây nhị phân có chiều cao
2190,E:\DATN\dataframe\train_file\30.txt,h là
2191,E:\DATN\dataframe\train_file\30.txt,"2^h - 1,"
2192,E:\DATN\dataframe\train_file\30.txt,"−1, tối thiểu là"
2193,E:\DATN\dataframe\train_file\30.txt,h \ (h \ge 1)
2194,E:\DATN\dataframe\train_file\30.txt,h (h≥1).
2195,E:\DATN\dataframe\train_file\30.txt,Cây nhị phân hoàn chỉnh có
2196,E:\DATN\dataframe\train_file\30.txt,n nút thì chiều cao của nó là
2197,E:\DATN\dataframe\train_file\30.txt,h = \left\lfloor{\log_2(n)}\right\rfloor + 1
2198,E:\DATN\dataframe\train_file\30.txt,h=⌊log
2199,E:\DATN\dataframe\train_file\30.txt,(n)⌋+1.
2200,E:\DATN\dataframe\train_file\30.txt,Biểu diễn cây nhị phân
2201,E:\DATN\dataframe\train_file\30.txt,"Để biểu diễn cây nhị phân, cách phổ biến nhất là sử dụng mảng."
2202,E:\DATN\dataframe\train_file\30.txt,"Đối với một cây nhị phân đầy đủ, ta có thể đánh số cho các nút của cây theo thứ tự lần lượt từ mức"
2203,E:\DATN\dataframe\train_file\30.txt,"1, hết mức này tới mức khác và từ trái qua phải đối với các nút ở mỗi mức:"
2204,E:\DATN\dataframe\train_file\30.txt,Hình 1: Đánh số các nút trên cây
2205,E:\DATN\dataframe\train_file\30.txt,Đánh số theo cách này thì con của nút thứ
2206,E:\DATN\dataframe\train_file\30.txt,i sẽ là các nút thứ
2207,E:\DATN\dataframe\train_file\30.txt,2i
2208,E:\DATN\dataframe\train_file\30.txt,2i và
2209,E:\DATN\dataframe\train_file\30.txt,2i + 1;
2210,E:\DATN\dataframe\train_file\30.txt,2i+1; cha của nút thứ
2211,E:\DATN\dataframe\train_file\30.txt,i là nút thứ
2212,E:\DATN\dataframe\train_file\30.txt,Như vậy ta có thể sử dụng một mảng
2213,E:\DATN\dataframe\train_file\30.txt,"tree để biểu diễn cây, nút thứ"
2214,E:\DATN\dataframe\train_file\30.txt,i của cây được lưu trữ bằng phần tử
2215,E:\DATN\dataframe\train_file\30.txt,"Chẳng hạn với cây ở hình bên trên, thì mảng"
2216,E:\DATN\dataframe\train_file\30.txt,tree sẽ như sau:
2217,E:\DATN\dataframe\train_file\30.txt,"Tuy nhiên, cách lưu trữ này có một nhược điểm là trong trường hợp cây nhị phân không đầy đủ, thì trên mảng sẽ tồn tại rất nhiều vị trí trống, gây lãng phí bộ nhớ."
2218,E:\DATN\dataframe\train_file\30.txt,"Nhưng với khả năng lưu trữ của máy tính hiện nay thì vấn đề này không quá quan trọng, nên cách sử dụng mảng vẫn rất được ưu tiên trong các bài toán lập trình sử dụng cây."
2219,E:\DATN\dataframe\train_file\30.txt,Các phép duyệt cây nhị phân
2220,E:\DATN\dataframe\train_file\30.txt,Phép thăm (visit) các nút trên cây theo một hệ thống sao cho mỗi nút chỉ được thăm một lần gọi là phép duyệt cây.
2221,E:\DATN\dataframe\train_file\30.txt,"Coi rằng một nút nếu như không có nút con trái hoặc nút con phải thì ta sẽ tạo một nút giả là con của nó, nếu một cây rỗng thì ta cũng tạo một nút giả làm gốc của nó."
2222,E:\DATN\dataframe\train_file\30.txt,"Khi đó, có ba cách duyệt cây thường được sử dụng:"
2223,E:\DATN\dataframe\train_file\30.txt,Duyệt theo thứ tự trước (preorder traversal)
2224,E:\DATN\dataframe\train_file\30.txt,"Khi duyệt cây theo thứ tự trước, thì một nút bất kì sẽ luôn được thăm trước hai nút con của nó."
2225,E:\DATN\dataframe\train_file\30.txt,Mã giả có thể mô tả như sau:
2226,E:\DATN\dataframe\train_file\30.txt,# Duyệt nhánh cây có n là nút gốc của nhánh.
2227,E:\DATN\dataframe\train_file\30.txt,def visit(n):
2228,E:\DATN\dataframe\train_file\30.txt,    # Nếu n không phải một nút rỗng thì thăm con của nó.
2229,E:\DATN\dataframe\train_file\30.txt,    if not empty(n):
2230,E:\DATN\dataframe\train_file\30.txt,Quá trình thăm cây sẽ bắt đầu bằng việc gọi visit({Nút_gốc_cây}).
2231,E:\DATN\dataframe\train_file\30.txt,Xét cây ở hình
2232,E:\DATN\dataframe\train_file\30.txt,"1, các nút trên cây sẽ được thăm theo thứ tự:"
2233,E:\DATN\dataframe\train_file\30.txt,"A, B, C, D, E, F, G"
2234,E:\DATN\dataframe\train_file\30.txt,Duyệt theo thứ tự giữa (inorder traversal)
2235,E:\DATN\dataframe\train_file\30.txt,"Khi duyệt cây theo thứ tự giữa, thì một nút bất kỳ sẽ được thăm sau nút con trái và thăm trước nút con phải của nó."
2236,E:\DATN\dataframe\train_file\30.txt,Mã giả có thể mô tả như sau:
2237,E:\DATN\dataframe\train_file\30.txt,# Duyệt nhánh cây có n là nút gốc của nhánh.
2238,E:\DATN\dataframe\train_file\30.txt,def visit(n):
2239,E:\DATN\dataframe\train_file\30.txt,    # Nếu n không phải một nút rỗng thì thăm con của nó.
2240,E:\DATN\dataframe\train_file\30.txt,    if not empty(n):
2241,E:\DATN\dataframe\train_file\30.txt,Quá trình thăm cây sẽ bắt đầu bằng việc gọi visit({Nút_gốc_cây}).
2242,E:\DATN\dataframe\train_file\30.txt,Xét cây ở hình
2243,E:\DATN\dataframe\train_file\30.txt,"1, các nút trên cây sẽ được thăm theo thứ tự:"
2244,E:\DATN\dataframe\train_file\30.txt,"C, B, D, A, F, E, G"
2245,E:\DATN\dataframe\train_file\30.txt,Duyệt theo thứ tự sau (postorder traversal)
2246,E:\DATN\dataframe\train_file\30.txt,"Khi duyệt cây theo thứ tự sau, thì một nút bất kì sẽ được thăm sau hai nút con của nó."
2247,E:\DATN\dataframe\train_file\30.txt,Mã giả có thể mô tả như sau:
2248,E:\DATN\dataframe\train_file\30.txt,# Duyệt nhánh cây có n là nút gốc của nhánh.
2249,E:\DATN\dataframe\train_file\30.txt,def visit(n):
2250,E:\DATN\dataframe\train_file\30.txt,    # Nếu n không phải một nút rỗng thì thăm con của nó.
2251,E:\DATN\dataframe\train_file\30.txt,    if not empty(n):
2252,E:\DATN\dataframe\train_file\30.txt,Quá trình thăm cây sẽ bắt đầu bằng việc gọi visit({Nút_gốc_cây}).
2253,E:\DATN\dataframe\train_file\30.txt,Xét cây ở hình
2254,E:\DATN\dataframe\train_file\30.txt,"1, các nút trên cây sẽ được thăm theo thứ tự:"
2255,E:\DATN\dataframe\train_file\30.txt,"C, D, B, F, G, E, A"
2256,E:\DATN\dataframe\train_file\30.txt,Biểu diễn biểu thức số học bằng cây nhị phân
2257,E:\DATN\dataframe\train_file\30.txt,Có rất rất nhiều những ứng dụng khác nhau của cấu trúc cây trong cuộc sống cũng như trong Tin học.
2258,E:\DATN\dataframe\train_file\30.txt,"Chẳng hạn như mục lục của các cuốn sách, tổ chức thư mục trên máy tính,...Trong phần này, tôi sẽ giới thiệu tới các bạn một ứng dụng rất quan trọng của cây trong các bài toán Tin học, đó là biểu diễn các biểu thức số học."
2259,E:\DATN\dataframe\train_file\30.txt,"Kí pháp trung tố, tiền tố và hậu tố"
2260,E:\DATN\dataframe\train_file\30.txt,"Một biểu thức số học gồm các phép toán hai ngôi bằng một cây nhị phân, trong đó các nút lá biểu thị các hằng hoặc biến (toán hạng), còn các nút không phải lá biểu thị các toán tử hai ngôi (những phép toán như cộng, trừ, nhân, chia, đồng dư, lũy thừa,...phải có hai toán hạng thì gọi chung là phép toán hai ngôi)."
2261,E:\DATN\dataframe\train_file\30.txt,Mỗi phép toán trong một nút sẽ tác động lên hai biểu thức con nằm ở cây con bên trái và cây con bên phải của nó.
2262,E:\DATN\dataframe\train_file\30.txt,"Chẳng hạn, biểu thức"
2263,E:\DATN\dataframe\train_file\30.txt,(6 + 5) \times (7 \div 2 - 4)
2264,E:\DATN\dataframe\train_file\30.txt,(6+5)×(7÷2−4) có thể được biểu diễn bằng cây nhị phân dưới đây:
2265,E:\DATN\dataframe\train_file\30.txt,"Trong cuộc sống hàng ngày, chúng ta vẫn thường viết các biểu thức số học theo dạng toán tử ở giữa hai toán hạng."
2266,E:\DATN\dataframe\train_file\30.txt,"Nhưng thực tế, có tới ba dạng kí pháp được sử dụng để biểu diễn các biểu thức số học."
2267,E:\DATN\dataframe\train_file\30.txt,"Với cây nhị phân biểu diễn biểu thức trong hình trên, ta có:"
2268,E:\DATN\dataframe\train_file\30.txt,"Nếu duyệt cây theo thứ tự trước, ta sẽ thu được biểu thức"
2269,E:\DATN\dataframe\train_file\30.txt,\times + 6 \ 5 - \div 7 \ 2 \ 4
2270,E:\DATN\dataframe\train_file\30.txt,×+6 5−÷7 2 4.
2271,E:\DATN\dataframe\train_file\30.txt,"Đây là dạng tiền tố (prefix) của biểu thức, hay còn gọi là kí pháp Ba Lan."
2272,E:\DATN\dataframe\train_file\30.txt,"Trong dạng này, toán tử được viết trước hai toán hạng tương ứng."
2273,E:\DATN\dataframe\train_file\30.txt,"Nếu duyệt cây theo thứ tự giữa, ta sẽ thu được biểu thức"
2274,E:\DATN\dataframe\train_file\30.txt,6 + 5 \times 7 \div 2 - 4
2275,E:\DATN\dataframe\train_file\30.txt,6+5×7÷2−4.
2276,E:\DATN\dataframe\train_file\30.txt,Kí pháp này sẽ chưa đúng với biểu thức ban đầu do thiếu các dấu ngoặc.
2277,E:\DATN\dataframe\train_file\30.txt,Đây gọi là dạng trung tố (infix) của biểu thức.
2278,E:\DATN\dataframe\train_file\30.txt,"Ở dạng này, nếu như thêm vào quá trình duyệt việc bổ sung các cặp dấu ngoặc vào mỗi biểu thức con, thì ta sẽ thu được biểu thức đầy đủ là"
2279,E:\DATN\dataframe\train_file\30.txt,"((6 + 5) \times ((7 \div 2) - 4))),"
2280,E:\DATN\dataframe\train_file\30.txt,"((6+5)×((7÷2)−4))), nhưng thực ra chỉ cần thêm đủ dấu ngoặc để biểu thức chính xác là được."
2281,E:\DATN\dataframe\train_file\30.txt,"Nếu duyệt cây theo thứ tự sau, ta sẽ thu được biểu thức"
2282,E:\DATN\dataframe\train_file\30.txt,6 \ 5 + 7 \ 2 \div 4 - \times
2283,E:\DATN\dataframe\train_file\30.txt,6 5+7 2÷4−×.
2284,E:\DATN\dataframe\train_file\30.txt,"Đây là dạng hậu tố (postfix) của biểu thức, còn gọi là ***kí pháp nghịch đảo Ba Lan (RPN)***."
2285,E:\DATN\dataframe\train_file\30.txt,"Trong kí pháp này, toán tử được viết sau hai toán hạng tương ứng."
2286,E:\DATN\dataframe\train_file\30.txt,"Nếu sử dụng kí pháp tiền tố và hậu tố thì biểu thức không cần có các dấu ngoặc vẫn có thể tính toán bình thường, trong khi kí pháp trung tố buộc phải có dấu ngoặc thì mới tránh được sự mập mờ."
2287,E:\DATN\dataframe\train_file\30.txt,Chuyển biểu thức từ dạng trung tố sang hậu tố
2288,E:\DATN\dataframe\train_file\30.txt,"Đối với máy tính, việc tính toán bằng kí pháp hậu tố sẽ là khoa học hơn, và đơn giản hơn sử dụng kí pháp trung tố (việc không cần sử dụng các dấu ngoặc đã giảm một lượng lớn phép xử lý)."
2289,E:\DATN\dataframe\train_file\30.txt,"Chính vì thế, trên các ngôn ngữ lập trình chúng ta vẫn có thể viết biểu thức dạng trung tố, nhưng trước khi chương trình dịch dịch nó ra mã máy, thì các biểu thức đều sẽ được chuyển về dạng hậu tố."
2290,E:\DATN\dataframe\train_file\30.txt,Một thuật toán rất hiệu quả để chuyển biểu thức dạng trung tố sang hậu tố là sử dụng ngăn xếp.
2291,E:\DATN\dataframe\train_file\30.txt,Dưới đây tôi sẽ trình bày giải thuật đó.
2292,E:\DATN\dataframe\train_file\30.txt,Trước hết ta sẽ phân chia các toán tử theo độ ưu tiên.
2293,E:\DATN\dataframe\train_file\30.txt,Trong bài viết này tôi sẽ chỉ xét
2294,E:\DATN\dataframe\train_file\30.txt,5 loại toán tử:
2295,E:\DATN\dataframe\train_file\30.txt,Các toán tử * và / có độ ưu tiên cao nhất bằng
2296,E:\DATN\dataframe\train_file\30.txt,Các toán tử + và - có độ ưu tiên cao thứ ba bằng
2297,E:\DATN\dataframe\train_file\30.txt,Toán tử ( có độ ưu tiên nhỏ nhất bằng
2298,E:\DATN\dataframe\train_file\30.txt,"Ngoài ra vẫn còn các toán tử ^ (lũy thừa) và % (đồng dư), nếu như có những toán tử này trong biểu thức thì các bạn chỉ cần xử lý tương tự."
2299,E:\DATN\dataframe\train_file\30.txt,"Tiếp theo, ta sẽ duyệt tuần tự từng phần tử"
2300,E:\DATN\dataframe\train_file\30.txt,"x trong biểu thức trung tố, rồi xử lý như sau:"
2301,E:\DATN\dataframe\train_file\30.txt,x là dấu ngoặc mở ( thì đẩy nó vào ngăn xếp.
2302,E:\DATN\dataframe\train_file\30.txt,"x là dấu ngoặc đóng thì lấy ra các phần tử trong ngăn xếp và đưa nó vào biểu thức hậu tố, cho tới khi lấy ra tới phần tử ( thì dừng lại."
2303,E:\DATN\dataframe\train_file\30.txt,x là các toán tử thì lấy ra các phần tử trong ngăn xếp có độ ưu tiên lớn hơn hoặc bằng
2304,E:\DATN\dataframe\train_file\30.txt,"x, nối vào biểu thức hậu tố tới khi phần tử ở đỉnh ngăn xếp có độ ưu tiên nhỏ hơn"
2305,E:\DATN\dataframe\train_file\30.txt,x hoặc ngăn xếp rỗng.
2306,E:\DATN\dataframe\train_file\30.txt,x là toán hạng thì nối nó vào biểu thức hậu tố.
2307,E:\DATN\dataframe\train_file\30.txt,"Sau khi duyệt xong toàn bộ biểu thức, nếu ngăn xếp vẫn chưa rỗng thì lấy ra các phần tử trong ngăn xếp và đưa vào biểu thức hậu tố."
2308,E:\DATN\dataframe\train_file\30.txt,Ngôn ngữ C++:
2309,E:\DATN\dataframe\train_file\30.txt,// Xét độ ưu tiên của kí tự x.
2310,E:\DATN\dataframe\train_file\30.txt,int priority(char x)
2311,E:\DATN\dataframe\train_file\30.txt,    if (x == '*' || x == '/')
2312,E:\DATN\dataframe\train_file\30.txt,        return 2;
2313,E:\DATN\dataframe\train_file\30.txt,    else if (x == '+' || x == '-')
2314,E:\DATN\dataframe\train_file\30.txt,        return 1;
2315,E:\DATN\dataframe\train_file\30.txt,    else if (x == '(')
2316,E:\DATN\dataframe\train_file\30.txt,        return 0;
2317,E:\DATN\dataframe\train_file\30.txt,// Chuyển đổi biểu thức trung tố s sang dạng hậu tố.
2318,E:\DATN\dataframe\train_file\30.txt,vector < string > change_to_postfix(string s)
2319,E:\DATN\dataframe\train_file\30.txt,    stack < char > st;
2320,E:\DATN\dataframe\train_file\30.txt,    vector < string > postfix;
2321,E:\DATN\dataframe\train_file\30.txt,"    int i = 0, n = s.size();"
2322,E:\DATN\dataframe\train_file\30.txt,    while (i < n)
2323,E:\DATN\dataframe\train_file\30.txt,        // Nếu s[i] là kí tự ngoặc mở thì đẩy vào ngăn xếp.
2324,E:\DATN\dataframe\train_file\30.txt,        if (s[i] == '(')
2325,E:\DATN\dataframe\train_file\30.txt,"        // Nếu s[i] là ngoặc đóng thì pop từ stack ra, thêm vào biểu thức hậu tố"
2326,E:\DATN\dataframe\train_file\30.txt,        // tới khi gặp kí tự ngoặc mở.
2327,E:\DATN\dataframe\train_file\30.txt,Lưu ý pop cả ngoặc mở ra.
2328,E:\DATN\dataframe\train_file\30.txt,        else if (s[i] == ')')
2329,E:\DATN\dataframe\train_file\30.txt,            while (st.top() != '(')
2330,E:\DATN\dataframe\train_file\30.txt,        // Nếu s[i] là chữ số đầu của một toán hạng thì xử lý để lấy toàn bộ số đó.
2331,E:\DATN\dataframe\train_file\30.txt,        else if (s[i] >= '0' && s[i] <= '9')
2332,E:\DATN\dataframe\train_file\30.txt,            string number;
2333,E:\DATN\dataframe\train_file\30.txt,            while (i < n && s[i] >= '0' && s[i] <= '9')
2334,E:\DATN\dataframe\train_file\30.txt,                number += s[i];
2335,E:\DATN\dataframe\train_file\30.txt,        // Nếu s[i] là toán tử thì xử lý dựa trên độ ưu tiên.
2336,E:\DATN\dataframe\train_file\30.txt,            while (!st.empty() && priority(st.top()) >= priority(s[i]))
2337,E:\DATN\dataframe\train_file\30.txt,    // Nếu ngăn xếp vẫn chưa rỗng thì lấy nốt các phần tử ra cho vào biểu thức hậu tố.
2338,E:\DATN\dataframe\train_file\30.txt,    while (!st.empty())
2339,E:\DATN\dataframe\train_file\30.txt,    return postfix;
2340,E:\DATN\dataframe\train_file\30.txt,Ngôn ngữ Python:
2341,E:\DATN\dataframe\train_file\30.txt,# Xét độ ưu tiên của kí tự x.
2342,E:\DATN\dataframe\train_file\30.txt,def priority(x):
2343,E:\DATN\dataframe\train_file\30.txt,    if x == '*' or x == '/':
2344,E:\DATN\dataframe\train_file\30.txt,        return 2
2345,E:\DATN\dataframe\train_file\30.txt,    elif x == '+' or x == '-':
2346,E:\DATN\dataframe\train_file\30.txt,        return 1
2347,E:\DATN\dataframe\train_file\30.txt,    elif x == '(':
2348,E:\DATN\dataframe\train_file\30.txt,        return 0
2349,E:\DATN\dataframe\train_file\30.txt,# Chuyển đổi biểu thức trung tố s sang dạng hậu tố.
2350,E:\DATN\dataframe\train_file\30.txt,def change_to_postfix(s):
2351,E:\DATN\dataframe\train_file\30.txt,"    st, postfix = [], []"
2352,E:\DATN\dataframe\train_file\30.txt,    i = 0
2353,E:\DATN\dataframe\train_file\30.txt,    while i < len(s):
2354,E:\DATN\dataframe\train_file\30.txt,        # Nếu s[i] là kí tự ngoặc mở thì đẩy vào ngăn xếp.
2355,E:\DATN\dataframe\train_file\30.txt,        if s[i] == '(':
2356,E:\DATN\dataframe\train_file\30.txt,            i += 1
2357,E:\DATN\dataframe\train_file\30.txt,"        # Nếu s[i] là ngoặc đóng thì pop từ stack ra, thêm vào biểu thức hậu tố"
2358,E:\DATN\dataframe\train_file\30.txt,        # tới khi gặp kí tự ngoặc mở.
2359,E:\DATN\dataframe\train_file\30.txt,Lưu ý pop cả ngoặc mở ra.
2360,E:\DATN\dataframe\train_file\30.txt,        elif s[i] == ')':
2361,E:\DATN\dataframe\train_file\30.txt,            while st[-1] != '(':
2362,E:\DATN\dataframe\train_file\30.txt,        # Nếu s[i] là chữ số đầu của một toán hạng thì xử lý để lấy toàn bộ số đó.
2363,E:\DATN\dataframe\train_file\30.txt,        elif '0' <= s[i] <= '9':
2364,E:\DATN\dataframe\train_file\30.txt,            number = 0
2365,E:\DATN\dataframe\train_file\30.txt,            while i < len(s) and 0 <= s[i] <= 9:
2366,E:\DATN\dataframe\train_file\30.txt,                number = number * 10 + int(s[i])
2367,E:\DATN\dataframe\train_file\30.txt,                i += 1
2368,E:\DATN\dataframe\train_file\30.txt,        # Nếu s[i] là toán tử thì xử lý dựa trên độ ưu tiên.
2369,E:\DATN\dataframe\train_file\30.txt,            while len(st) > 0 and priority(st[-1]) >= priority(s[i]):
2370,E:\DATN\dataframe\train_file\30.txt,            i += 1
2371,E:\DATN\dataframe\train_file\30.txt,    # Nếu ngăn xếp vẫn chưa rỗng thì lấy nốt các phần tử ra
2372,E:\DATN\dataframe\train_file\30.txt,    # rồi cho vào biểu thức hậu tố.
2373,E:\DATN\dataframe\train_file\30.txt,    while len(st) > 0:
2374,E:\DATN\dataframe\train_file\30.txt,    return postfix
2375,E:\DATN\dataframe\train_file\30.txt,Tính toán giá trị biểu thức
2376,E:\DATN\dataframe\train_file\30.txt,"Khi biểu diễn một biểu thức số học bằng cây nhị phân, thì khi tính toán, máy tính sẽ tính giá trị của biểu thức ở hai nhánh con, rồi mới gộp giá trị của chúng dựa trên toán tử ở nút gốc."
2377,E:\DATN\dataframe\train_file\30.txt,Điều này khiến cho việc tính toán bằng cách duyệt cây theo thứ tự sau để tạo ra kí pháp hậu tố trở nên rất hợp lí.
2378,E:\DATN\dataframe\train_file\30.txt,"Giữa thế kỉ XX, nhà logic học người Ba Lan Jan Lukasiewicz đã chứng minh được rằng, biểu thức hậu tố không cần phải có dấu ngoặc vẫn có thể tính được đúng đắn bằng cách đọc lần lượt biểu thức từ trái qua phải, và dùng một ngăn xếp để lưu các kết quả trung gian."
2379,E:\DATN\dataframe\train_file\30.txt,Dưới đây tôi sẽ trình bày lại thuật toán này.
2380,E:\DATN\dataframe\train_file\30.txt,"Trước tiên, chuyển biểu thức trung tố cần tính toán sang dạng hậu tố bằng thuật toán đã nêu ở phần"
2381,E:\DATN\dataframe\train_file\30.txt,"Sau đó, duy trì một ngăn xếp để lưu trữ các kết quả trung gian."
2382,E:\DATN\dataframe\train_file\30.txt,Ban đầu khởi tạo ngăn xếp rỗng.
2383,E:\DATN\dataframe\train_file\30.txt,Tuần tự đọc biểu thức hậu tố đã chuyển đổi từ trái qua phải.
2384,E:\DATN\dataframe\train_file\30.txt,"Với mỗi phần tử, ta kiểm tra:"
2385,E:\DATN\dataframe\train_file\30.txt,Nếu phần tử này là một toán hạng thì đẩy nó vào ngăn xếp.
2386,E:\DATN\dataframe\train_file\30.txt,"Nếu phần tử này là một toán tử x, thì ta lấy từ ngăn xếp ra hai giá trị"
2387,E:\DATN\dataframe\train_file\30.txt,", rồi đẩy giá trị"
2388,E:\DATN\dataframe\train_file\30.txt, vào lại ngăn xếp (áp dụng toán tử x với hai giá trị lấy ra).
2389,E:\DATN\dataframe\train_file\30.txt,"Sau khi kết thúc quá trình trên, toàn bộ biểu thức đã được đọc xong."
2390,E:\DATN\dataframe\train_file\30.txt,"Lúc này trong ngăn xếp chỉ còn lại một giá trị duy nhất, đó chính là giá trị của biểu thức."
2391,E:\DATN\dataframe\train_file\30.txt,Ngôn ngữ C++:
2392,E:\DATN\dataframe\train_file\30.txt,double get_expression_value(string s)
2393,E:\DATN\dataframe\train_file\30.txt,    vector < string > postfix = change_to_postfix(s);
2394,E:\DATN\dataframe\train_file\30.txt,"    // Stack lưu các toán hạng, kiểu dữ liệu double vì"
2395,E:\DATN\dataframe\train_file\30.txt,    // phép chia có thể tạo ra kết quả số thực.
2396,E:\DATN\dataframe\train_file\30.txt,    stack < double > st;
2397,E:\DATN\dataframe\train_file\30.txt,    for (string e: postfix)
2398,E:\DATN\dataframe\train_file\30.txt,"        // Lưu ý: Do các phần tử trong mảng postfix có kiểu dữ liệu là string,"
2399,E:\DATN\dataframe\train_file\30.txt,        // nên khi xử lý các phần tử ta cần phải đặt chúng trong cặp dấu nháy
2400,E:\DATN\dataframe\train_file\30.txt,"        // kép """" thay vì cặp nháy đơn '', nếu không chương trình sẽ bị lỗi."
2401,E:\DATN\dataframe\train_file\30.txt,"        if (e == ""+"" || e== ""-"" || e== ""*"" || e== ""/"" || e == '%')"
2402,E:\DATN\dataframe\train_file\30.txt,            double v1 = st.top();
2403,E:\DATN\dataframe\train_file\30.txt,            double v2 = st.top();
2404,E:\DATN\dataframe\train_file\30.txt,"            if (e == ""+"")"
2405,E:\DATN\dataframe\train_file\30.txt,                st.push(v2 + v1);
2406,E:\DATN\dataframe\train_file\30.txt,"            else if (e == ""-"")"
2407,E:\DATN\dataframe\train_file\30.txt,                st.push(v2 - v1);
2408,E:\DATN\dataframe\train_file\30.txt,"            else if (e == ""*"")"
2409,E:\DATN\dataframe\train_file\30.txt,                st.push(v2 * v1);
2410,E:\DATN\dataframe\train_file\30.txt,"            else if (e == ""/"")"
2411,E:\DATN\dataframe\train_file\30.txt,                st.push(v2 / v1);
2412,E:\DATN\dataframe\train_file\30.txt,"        // Nếu phần tử này là toán hạng, chuyển toàn bộ nó sang số và đưa vào stack."
2413,E:\DATN\dataframe\train_file\30.txt,            double number = 0;
2414,E:\DATN\dataframe\train_file\30.txt,            for (int j = 0; j < e.size(); ++j)
2415,E:\DATN\dataframe\train_file\30.txt,                number = number * 10 + (e[j] - '0');
2416,E:\DATN\dataframe\train_file\30.txt,    // Trả ra kết quả của biểu thức.
2417,E:\DATN\dataframe\train_file\30.txt,    return st.top();
2418,E:\DATN\dataframe\train_file\30.txt,Ngôn ngữ Python:
2419,E:\DATN\dataframe\train_file\30.txt,def get_expression_value(s):
2420,E:\DATN\dataframe\train_file\30.txt,    postfix = change_to_postfix(s)
2421,E:\DATN\dataframe\train_file\30.txt,    for e in postfix:
2422,E:\DATN\dataframe\train_file\30.txt,        # Nếu phần tử này là toán tử thì sử dụng nó với hai toán hạng ở đỉnh stack.
2423,E:\DATN\dataframe\train_file\30.txt,        if e == '+' or e == '-' or e == '*' or e == '/':
2424,E:\DATN\dataframe\train_file\30.txt,            v1 = float(st[-1])
2425,E:\DATN\dataframe\train_file\30.txt,            v2 = float(st[-1])
2426,E:\DATN\dataframe\train_file\30.txt,            if e == '+':
2427,E:\DATN\dataframe\train_file\30.txt,                st.append(v2 + v1)
2428,E:\DATN\dataframe\train_file\30.txt,            elif e == '-':
2429,E:\DATN\dataframe\train_file\30.txt,                st.append(v2 - v1)
2430,E:\DATN\dataframe\train_file\30.txt,            elif e == '*':
2431,E:\DATN\dataframe\train_file\30.txt,                st.append(v2 * v1)
2432,E:\DATN\dataframe\train_file\30.txt,            elif e == '/':
2433,E:\DATN\dataframe\train_file\30.txt,                st.append(v2 / v1)
2434,E:\DATN\dataframe\train_file\30.txt,        # Nếu phần tử này là toán hạng thì đẩy nó vào stack.
2435,E:\DATN\dataframe\train_file\30.txt,    return st[-1]
2436,E:\DATN\dataframe\train_file\30.txt,Tài liệu tham khảo
2437,E:\DATN\dataframe\train_file\31.txt,Nhận diện và so sánh khuôn mặt bằng máy học trong những năm trở lại đây là một đề tài rất hot nhận được sự quan tâm của rất nhiều doanh nghiệp bởi vì khả năng ứng dụng rộng rãi.
2438,E:\DATN\dataframe\train_file\31.txt,"Nó giúp cho những việc như điểm hay EKYC khác hàng trở nên 1 cách đơn giản, tự động và độ chính xác của rất cao."
2439,E:\DATN\dataframe\train_file\31.txt,Thế nhưng không ít lập trình viên trong chúng ta gặp khó khăn khi phải xây dựng 1 hệ thống như thế vì không phải ai cũng đủ hiểu biết về máy học để có thể tự bắt đầu.
2440,E:\DATN\dataframe\train_file\31.txt,Rất may là vì độ hot của đề tài này nên đã có rất nhiều open source hỗ trợ chúng ta.
2441,E:\DATN\dataframe\train_file\31.txt,Một trong số đó là deepface.
2442,E:\DATN\dataframe\train_file\31.txt,"Thư viện deepface được viết để sử dụng với python3 và nó được tích hợp sẵn rất nhiều model nhận diện, so sánh tốt nhất hiện này (state of the art) như là: VGG-Face, Google FaceNet, OpenFace, Facebook DeepFace, DeepID, ArcFace, Dlib và SFace"
2443,E:\DATN\dataframe\train_file\32.txt,BLoC Hay MVVM + GetX – Đâu là “Chân Lý” cho phát triển dự án bằng Flutter?
2444,E:\DATN\dataframe\train_file\32.txt,"Trước khi đi vào tìm kiếm và so sánh giữa các Kiến trúc khi triển khai trên Flutter – Dart để xem Kiến trúc nào sẽ phù hợp, tối ưu, thuận tiện, dễ triển khai … hơn thì mình xin phép kể về hành trình và lý do mình viết bài viết này để chia sẻ và mong muốn nhận được góp ý của mọi người."
2445,E:\DATN\dataframe\train_file\32.txt,Với nền tảng đã làm Android/IOS Native nên Team mình tự tin nhận 1 dự án A phát triển bằng Flutter – Dart để vừa làm và vừa học.
2446,E:\DATN\dataframe\train_file\32.txt,Do Team mình ít người và cũng không có ai có kinh nghiệm với Flutter trước đó nên team chọn hướng tiếp cận theo phong cách Free Style.
2447,E:\DATN\dataframe\train_file\32.txt,"Sau khi hoàn thành dự án A, mình cũng nhận thấy rất nhiều nhược điểm của Free Style ảnh hưởng trực tiếp đến chất lượng sản phẩm, trải nghiệm người dùng, khả năng fix bug và maintain …."
2448,E:\DATN\dataframe\train_file\32.txt,Nên mình mới tìm kiếm 1 Kiến trúc nào đó tối ưu và phù hợp với Flutter.
2449,E:\DATN\dataframe\train_file\32.txt,"Mình tìm thấy 2 gợi ý được nhiều người nhắc đến: Bloc, MVVM (Nếu còn cái nào hay hơn nhờ mọi người góp ý giúp mình nhé  )."
2450,E:\DATN\dataframe\train_file\32.txt,Chính vì thế mình đã nghiên cứu và cùng chia sẻ với mọi người về những gì mình đọc và hiểu được trong quá trình nghiên cứu.
2451,E:\DATN\dataframe\train_file\32.txt,Ở bài viết này mình sẽ nói đến BLoC và MVVM + GetX (2 cái mà mình được nghe nhiều nhất trong các diễn đàn)
2452,E:\DATN\dataframe\train_file\32.txt,BLoC và MVVM là gì?
2453,E:\DATN\dataframe\train_file\32.txt,"BLoC Pattern (Business Logic Component) mục đích là tách code business logic ra khỏi UI thay vì code gộp chung cả logic và UI vô cùng 1 file, để sau này spec mới có yêu cầu sửa code business logic hay sửa UI sẽ dễ dàng sửa hơn."
2454,E:\DATN\dataframe\train_file\32.txt,MVVM (Model – View – View Model) xây dựng một mô hình mà View Model tương tác với Model để cung cấp dữ liệu cho View.
2455,E:\DATN\dataframe\train_file\32.txt,Sau khi đọc xong lý thuyết thì mình thấy MVVM và BLoC khá giống nhau về bản chất (đều tách logic ra view) vậy chúng khác nhau ở điểm nào?
2456,E:\DATN\dataframe\train_file\32.txt,Mình có làm sample và tìm đọc 1 số bài so sánh giữa BLoC & MVVM + GetX thì thấy điểm mấu chốt khác nhau chủ yếu là Tương tác giữa BLoC/Controller và View:
2457,E:\DATN\dataframe\train_file\32.txt,BLoC và View giao tiếp với nhau thông qua các State và Event.
2458,E:\DATN\dataframe\train_file\32.txt,BLoC không để lộ bất kỳ phương thức nào ra ngoài.
2459,E:\DATN\dataframe\train_file\32.txt,BLoC thông báo cập nhật cho View qua emit() emit(SuccessState(data));
2460,E:\DATN\dataframe\train_file\32.txt,View thông báo cập nhật data cho BLoC qua add() BlocProvider.of<LoginBloc>(context).add(LoginUsernameChanged(text)
2461,E:\DATN\dataframe\train_file\32.txt,Controller và View giao tiếp trực qua instance của Controller
2462,E:\DATN\dataframe\train_file\32.txt,View đăng kí lắng nghe thay đổi của Controller để cập nhật View var userName = Constants.EMPTY.obs; userName.value = text;
2463,E:\DATN\dataframe\train_file\32.txt,View thông báo cập nhật data cho Controller qua api của Controller controller.setUserName(value);
2464,E:\DATN\dataframe\train_file\32.txt,Một điểm khác biệt thú vị như là BLoC giao tiếp thông qua các Event không chỉ với UI mà còn với các phần khác nhau của ứng dụng.
2465,E:\DATN\dataframe\train_file\32.txt,ví dụ: nó sẽ nhận được một Event sau khi nhận được thông báo về firebase hoặc khi data trong DB thay đổi.
2466,E:\DATN\dataframe\train_file\32.txt,"=> Sau khi nghiên cứu và demo BLoC (sử dụng Flutter Bloc Plugin) và MVVM + GetX thì thực sự có cảm tình với BLoC hơn, nhưng nếu để nên bàn cân mình cũng không thấy giữa MVVM và BLoC có gì khác biệt nhiều."
2467,E:\DATN\dataframe\train_file\32.txt,"GetX liệu có ""Hoàn Hảo"" không?"
2468,E:\DATN\dataframe\train_file\32.txt,"Nhân tiên, Mình cũng có đọc và nghe mọi người bảo GetX chỉ nên dùng với những dự án nhỏ, làm nhanh còn những dự án lớn hơn cần maintain liên tục thì nên sử dụng BLoC."
2469,E:\DATN\dataframe\train_file\32.txt,Mình cũng đã tìm hiểu và thấy 1 số lý do sau khiến 1 số người ngại sử dụng GetX:
2470,E:\DATN\dataframe\train_file\32.txt,"GetX chứa rất nhiều thứ như State Management, DI, Navigate, Internationalization, Change Theme, Network, Database … chính vì thế nó lại là nhược điểm vì lắm ứng dụng bạn không cần nhiều module đến thế và chúng cũng dễ bị out of date."
2471,E:\DATN\dataframe\train_file\32.txt,GetX sử dụng Static Context
2472,E:\DATN\dataframe\train_file\32.txt,Module get_connect hỗ trợ cả API REST và GraphQL trong khi một dự án thự tế không cần nhiều như thế
2473,E:\DATN\dataframe\train_file\32.txt,Thỉnh thoảng sẽ gặp vấn đề với Hot Reload do cơ chế Dependency Injection bên trong của GetX dẫn đến việc GetXController có thể bị remove khi chúng t Hot Reload
2474,E:\DATN\dataframe\train_file\32.txt,Nhiều Code không có hoặc thiếu tài liệu
2475,E:\DATN\dataframe\train_file\32.txt,Khó khăn trong việc code UnitTest
2476,E:\DATN\dataframe\train_file\32.txt,Tỉ lệ Unit Test và Widget Testing trong source code thấp
2477,E:\DATN\dataframe\train_file\32.txt,BLoC Base Source
2478,E:\DATN\dataframe\train_file\32.txt,Mình có để link chia sẻ về Demo Base BLoC
2479,E:\DATN\dataframe\train_file\32.txt,State Management:
2480,E:\DATN\dataframe\train_file\32.txt,Dependence Injection:
2481,E:\DATN\dataframe\train_file\32.txt,Mock Network:
2482,E:\DATN\dataframe\train_file\32.txt,Nếu mình có nhận xét cái gì sai hoặc thiếu sót thì nhờ mn góp ý nhé.
2483,E:\DATN\dataframe\train_file\32.txt,Tài liệu tham khảo
2484,E:\DATN\dataframe\train_file\33.txt,Sự phát triển của Machine learning đã có nhiều bước đột phá và được sử dụng rộng rãi trong những năm gần đây.
2485,E:\DATN\dataframe\train_file\33.txt,Với sự giúp đỡ của nhiều tools và frameworks để đơn giản hóa việc inference và logging service.
2486,E:\DATN\dataframe\train_file\33.txt,"Nhưng thông thường, bước triển khai ML service thường bị bỏ qua và không được biết đến rộng rãi như dựng mô hình ML."
2487,E:\DATN\dataframe\train_file\33.txt,"Tuy nhiên trong ML cycle, traing ML model chỉ chiếm 20 phần trăm của dự án."
2488,E:\DATN\dataframe\train_file\33.txt,"Đặc biệt, khi deploy mô hình AI cho người dùng cuối thường khá sơ sài và target chính để demo ở MVC phase."
2489,E:\DATN\dataframe\train_file\33.txt,"Do đó, làm thế nào chúng ta có thể quản lý mô hình AI trong thực tế và làm cho AI cycle được triển khai nhanh chóng."
2490,E:\DATN\dataframe\train_file\33.txt,Chúng ta sẽ đi sâu vào một số phương pháp best practices trong phát triển phần mềm và cách được ứng dụng vào dự án AI tương ứng.
2491,E:\DATN\dataframe\train_file\33.txt,Mọi người có thể vào  này để xem rõ hơn.
2492,E:\DATN\dataframe\train_file\33.txt,Mình chọn bài toàn phân tích ngữ nghĩa của twitter cho hands-on Project vì bài toàn khá đơn giản và visulize được một pipeline cụ thể trong dự án ML.
2493,E:\DATN\dataframe\train_file\33.txt,Ý tưởng của dự án là lấy dữ liệu từ của tweet của user và phân tính nội dung tình cảm của nó.
2494,E:\DATN\dataframe\train_file\33.txt,"Sau đó, tổng hợp văn bản cảm xúc từ từng user để phân tích thêm cảm xúc của họ trong những đoạn tweet gần đây."
2495,E:\DATN\dataframe\train_file\33.txt,Khả năng tính toán không được cải thiện nhiều ở CPU usage nhưng  cho ta thấy được the runtime of torchscript tốt hơn nhiều so với mô hình thuần PyTorch.
2496,E:\DATN\dataframe\train_file\33.txt,"Code load model rất đơn giản và được standardize torch.jit.load, mô hình cũng được lưu thành ScriptModule format và sẽ không thay đổi cách load kể cả khi mình thay đổi hoàn toàn model."
2497,E:\DATN\dataframe\train_file\33.txt,"Để tối ưu hóa hơn nữa khả năng tính toán của mô hình, các kỹ thuật như quantization hoặc pruning có thể được áp dụng nhưng yêu cầu đi sâu vào nghiên cứu kiến trúc mô hình và mỗi kiến trúc có phương pháp pruning riêng."
2498,E:\DATN\dataframe\train_file\33.txt,TVM framework có thể được sử dụng để tự động lựa chọn optmized mô hình nhưng cần nhiều thời gian và tài nguyên GPU để chọn trình biên dịch và điều chỉnh kiến trúc phù hợp.
2499,E:\DATN\dataframe\train_file\33.txt,Quá trình tối ưu hóa thật rất phức tạp và refer một blog dành riêng của nó và mình sẽ đề cập khi khác.
2500,E:\DATN\dataframe\train_file\33.txt,"Đối với mô hình PyTorch, cách đơn giản nhất là chuyển đổi sang định dạng JIT và dễ dàng đạt được hiệu suất 5-> 10%"
2501,E:\DATN\dataframe\train_file\34.txt,"Hiểu đơn giản thì một chương trình đang thực thi được gọi là tiến trình, hay nói cách khác, tiến trình là một thực thể của chương trình đang chạy, thực thể này có thể được gán và thực thị bởi một trình xử lý."
2502,E:\DATN\dataframe\train_file\34.txt,Hai phần tử cốt lõi của một tiến trình là code của chương trình và tập dữ liệu liên quan đến đoạn code đó.
2503,E:\DATN\dataframe\train_file\34.txt,Một chương trình thực thi như một tiến trình được xác định duy nhất bởi các tham số khác nhau.
2504,E:\DATN\dataframe\train_file\34.txt,Các tham số này được lưu trữ trong Process Control Block (PCB) cho mỗi tiến trình.
2505,E:\DATN\dataframe\train_file\34.txt,"Hệ điều hành thực thi nhiều hoạt động khác nhau trong khi tạo một tiến trình, khi sử dụng PCB để theo dõi trạng thái thực thi của từng tiến trình."
2506,E:\DATN\dataframe\train_file\34.txt,Định thời tiến trình là rất quan trọng để chọn và loại bỏ tiến trình đang chạy dựa trên một chiến lược hoặc thuật toán cụ thể.
2507,E:\DATN\dataframe\train_file\34.txt,"Các mục tiêu chính của quá trình định thời tiến trình là giữ cho CPU luôn bận rộn và cung cấp thời gian phản hồi ""có thể chấp nhận được"" cho tất cả các chương trình."
2508,E:\DATN\dataframe\train_file\34.txt,Hệ điều hành đa chương trình cho phép nhiều tiến trình được tải vào bộ nhớ thực thi tại một thời điểm và tiến trình được tải chia sẻ CPU bằng cách sử dụng ghép kênh thời gian
2509,E:\DATN\dataframe\train_file\35.txt,Explainable AI - Bạn có hiểu model của bạn không?
2510,E:\DATN\dataframe\train_file\35.txt,Giới thiệu Explainable AI
2511,E:\DATN\dataframe\train_file\35.txt,"Sự thành công của Deep Neural Network (DNN - mạng nơ-ron sâu) đã mang đến những bước tiến lớn trong các ứng dụng, nghiên cứu A.I (trí tuệ nhân tạo)."
2512,E:\DATN\dataframe\train_file\35.txt,"Mặc dù vô cùng thành công, nhưng DNN hoạt động giống như một chiếc hộp đen, ta không biết tại sao mạng nơ-ron lại đưa ra một quyết định cụ thể."
2513,E:\DATN\dataframe\train_file\35.txt,"Do đó, khi một hệ thống A.I dự đoán sai, ta không hề biết tại sao hệ thống đó lại dự đoán sai, để lại chúng ta ngơ ngác chấp nhận rằng với trường hợp này thì chúng dự đoán sai."
2514,E:\DATN\dataframe\train_file\35.txt,"Vì vậy, khả năng có thể diễn giải, hiểu một model A.I là cần thiết."
2515,E:\DATN\dataframe\train_file\35.txt,"Để có thể tạo ra một hệ thống A.I đáng tin tưởng, ta cần phải có một model có thể giải thích tại sao chúng lại đưa ra dự đoán như vậy."
2516,E:\DATN\dataframe\train_file\35.txt,"Nói rộng hơn, việc tạo ra một hệ thống A.I có thể tự diễn giải được chia làm 3 giai đoạn sử dụng."
2517,E:\DATN\dataframe\train_file\35.txt,"Trước hết, khi khả năng của A.I yếu hơn con người rất nhiều và không sẵn sàng để deploy, việc có một model tự diễn giải lúc này sẽ giúp chúng ta xác định nguyên nhân của sự thất bại của chúng, để các A.I Engineer có thể cải tiến model theo một hướng rõ ràng."
2518,E:\DATN\dataframe\train_file\35.txt,"Thứ hai, nếu khả năng của A.I ngang cơ với con người, việc có thể tự diễn giải có thể tạo dựng sự tin tưởng cho model đó đối với người dùng."
2519,E:\DATN\dataframe\train_file\35.txt,"Thứ ba, nếu khả năng của A.I vượt con người, ta có thể dùng model đó hướng dẫn con người học tác vụ đó."
2520,E:\DATN\dataframe\train_file\35.txt,CAM - Class Activation Map
2521,E:\DATN\dataframe\train_file\35.txt,"Trong phần này, mình sẽ nói về cách tạo ra Class Activation Map (CAM) sử dụng Global Average Pooling (GAP) trong CNN."
2522,E:\DATN\dataframe\train_file\35.txt,Một Class Activation Map cho một class cụ thể sẽ biểu thị những vùng được cho là quan trọng ở trong ảnh dùng để nhận diện class đó (Hình 1).
2523,E:\DATN\dataframe\train_file\35.txt,"Để có thể tạo các Maps đó, nhóm tác giả của paper CAM đã tạo nên một mạng nơ-ron riêng lấy ý tưởng từ InceptionNet."
2524,E:\DATN\dataframe\train_file\35.txt,"Ngay trước layer softmax để đưa ra output của mạng, ta thực hiện GAP, rồi mới đưa feature đã được GAP vào lớp Fully-Connected (FC) cuối sử dụng softmax để phân loại."
2525,E:\DATN\dataframe\train_file\35.txt,"Sử dụng kiến trúc này, ta có thể xác định được vùng quan trọng trong bức ảnh bằng việc ánh xạ lại weight của output layer lên feature map từ lớp Convolution (Conv), kĩ thuật này được gọi là Class Activation Mapping (Hình 2)."
2526,E:\DATN\dataframe\train_file\35.txt,"Nhìn vào Hình 2, GAP sẽ đưa ra trung bình về mặt vị trí của từng feature map trong lớp Conv cuối."
2527,E:\DATN\dataframe\train_file\35.txt,"Để có thể đưa ra dự đoán của một class, ta thực hiện một phép cộng sử dụng trọng số"
2528,E:\DATN\dataframe\train_file\35.txt,w (weighted sum) lên toàn bộ các unit sau khi GAP.
2529,E:\DATN\dataframe\train_file\35.txt,"Tương tự, ta thực hiện weighted sum lên từng feature map trong lớp Conv cuối để thu được CAM."
2530,E:\DATN\dataframe\train_file\35.txt," Phía trên là toàn bộ ý tưởng để tạo ra CAM, tiếp theo mình sẽ đi rõ vào cách thực hiện gồm khá nhiều toán, các bạn có thể bỏ qua nếu muốn."
2531,E:\DATN\dataframe\train_file\35.txt,Cách thực hiện
2532,E:\DATN\dataframe\train_file\35.txt,"Với một ảnh đầu vào, gọi"
2533,E:\DATN\dataframe\train_file\35.txt,"(x,y) là activation của feature map thứ"
2534,E:\DATN\dataframe\train_file\35.txt,k (unit
2535,E:\DATN\dataframe\train_file\35.txt,k) trong lớp Conv cuối tại vị trí
2536,E:\DATN\dataframe\train_file\35.txt,"(x, y)"
2537,E:\DATN\dataframe\train_file\35.txt,Gọi kết quả của phép GAP là
2538,E:\DATN\dataframe\train_file\35.txt,", với unit"
2539,E:\DATN\dataframe\train_file\35.txt,"k, kết quả khi áp dụng GAP là"
2540,E:\DATN\dataframe\train_file\35.txt,"F^k = \sum_{x, y}f_k(x,y)"
2541,E:\DATN\dataframe\train_file\35.txt,Với class
2542,E:\DATN\dataframe\train_file\35.txt,"c, input trước khi đưa vào softmax"
2543,E:\DATN\dataframe\train_file\35.txt,S_c = \sum_k w_k^c F^k
2544,E:\DATN\dataframe\train_file\35.txt, là weight của unit
2545,E:\DATN\dataframe\train_file\35.txt,k ứng với class
2546,E:\DATN\dataframe\train_file\35.txt,"c. Cuối cùng, đầu ra softmax cho class"
2547,E:\DATN\dataframe\train_file\35.txt,c là
2548,E:\DATN\dataframe\train_file\35.txt,P_c = \frac{exp(S_c)}{\sum_c exp(S_c)}
2549,E:\DATN\dataframe\train_file\35.txt,"F^k= \sum_{x, y}f_k(x,y)"
2550,E:\DATN\dataframe\train_file\35.txt,"(x,y) vào class score"
2551,E:\DATN\dataframe\train_file\35.txt,", ta thu được:"
2552,E:\DATN\dataframe\train_file\35.txt,"S_c = \sum_k w_k^c \sum_{x, y} f_k(x,y)=\sum_{x, y} \sum_k w_k^c f_k(x,y)"
2553,E:\DATN\dataframe\train_file\35.txt, là CAM cho class
2554,E:\DATN\dataframe\train_file\35.txt,"c, mỗi điểm tọa độ"
2555,E:\DATN\dataframe\train_file\35.txt,"(x, y)"
2556,E:\DATN\dataframe\train_file\35.txt,"(x,y) trong CAM sẽ được tính theo công thức:"
2557,E:\DATN\dataframe\train_file\35.txt,"M_c(x,y) = \sum_k w_k^c f_k(x,y)"
2558,E:\DATN\dataframe\train_file\35.txt,"Ta có thể thấy,"
2559,E:\DATN\dataframe\train_file\35.txt,"S_c = \sum_{x,y}M_c(x,y)"
2560,E:\DATN\dataframe\train_file\35.txt,"(x,y), do đó,"
2561,E:\DATN\dataframe\train_file\35.txt,"(x,y) sẽ biểu thị độ quan trọng của vị trí"
2562,E:\DATN\dataframe\train_file\35.txt,"(x,y) ứng với class"
2563,E:\DATN\dataframe\train_file\35.txt,"Nhưng kích thước của feature map từ lớp Conv cuối khá là nhỏ, vì vậy, để thu được CAM trên ảnh, ta sử dụng một phép upsampling đơn giản CAM cho bằng với kích thước của ảnh đầu vào là xong."
2564,E:\DATN\dataframe\train_file\35.txt,Grad-CAM: CAM nhưng sử dụng Gradient
2565,E:\DATN\dataframe\train_file\35.txt,"Một điểm yếu của CAM là chỉ có thể sử dụng được lên feature maps trong lớp Conv ngay trước khi đưa vào lớp output, và chỉ phù hợp với các model mà sử dụng GAP trước khi đưa vào lớp output (feature maps -> GAP -> output prediction)."
2566,E:\DATN\dataframe\train_file\35.txt,Grad-CAM sử dụng tín hiệu của gradient để kết hợp các feature maps mà không cần phải thay đổi kiến trúc của mạng (thêm vào GAP) (Hình 4).
2567,E:\DATN\dataframe\train_file\35.txt,"Grad-CAM là một trường hợp Generalized của CAM, có thể sử dụng với bất kì kiến trúc mạng nào."
2568,E:\DATN\dataframe\train_file\35.txt,"Ý tưởng của Grad-CAM cũng giống với CAM, ta tận dụng thông tin về không gian ở trong các lớp Conv để có thể hiểu vùng nào là quan trọng đối với một class cụ thể."
2569,E:\DATN\dataframe\train_file\35.txt,"Grad-CAM có thể sử dụng lên bất kì feature maps từ bất kì layer nào ở trong mạng, nhưng để chứng minh độ hiệu quả cũng như tính giải thích cao của mô hình, paper Grad-CAM sử dụng lớp Conv cuối, vì lớp Conv cuối thường là lớp chứa nhiều thông tin nhất (Hình 5)."
2570,E:\DATN\dataframe\train_file\35.txt,Các feature maps được sinh ra từ lớp Conv cuối kí hiệu là
2571,E:\DATN\dataframe\train_file\35.txt,"A^1, A^2, A^3"
2572,E:\DATN\dataframe\train_file\35.txt,"Lúc này, ở CAM, ta sẽ phải thực hiện GAP và theo sau đó là một lớp FC."
2573,E:\DATN\dataframe\train_file\35.txt,"Tuy nhiên, trong Grad-CAM, sau đó có thể là gì cũng được, có thể là vài lớp FC, hay Conv, kí hiệu là ""any neural network layers"" ở trên Hình 5."
2574,E:\DATN\dataframe\train_file\35.txt,Yêu cầu duy nhất là các layers chèn thêm phía sau layer sinh ra
2575,E:\DATN\dataframe\train_file\35.txt,"A^1, A^2, A^3"
2576,E:\DATN\dataframe\train_file\35.txt, phải khả vi để có thể lấy được gradient.
2577,E:\DATN\dataframe\train_file\35.txt,Sự khác biết giữa CAM và Grad-CAM lúc này là cách tính weight cho từng feature map
2578,E:\DATN\dataframe\train_file\35.txt,"A^1, A^2, A^3"
2579,E:\DATN\dataframe\train_file\35.txt, để tạo nên heatmap.
2580,E:\DATN\dataframe\train_file\35.txt,"Ở CAM, các giá trị weight này được lấy từ weight của lớp GAP với lớp FC cuối của mạng, còn trong Grad-CAM, ta sử dụng giá trị ""alpha"" dựa trên gradient."
2581,E:\DATN\dataframe\train_file\35.txt," Phía trên là toàn bộ ý tưởng để tạo ra heatmap sử dụng Grad-CAM, tiếp theo mình sẽ đi rõ vào cách thực hiện gồm khá nhiều toán, các bạn có thể bỏ qua nếu muốn."
2582,E:\DATN\dataframe\train_file\35.txt,Cách thực hiện
2583,E:\DATN\dataframe\train_file\35.txt,Grad-CAM sẽ gồm 3 bước:
2584,E:\DATN\dataframe\train_file\35.txt,Bước 1: Tính gradient.
2585,E:\DATN\dataframe\train_file\35.txt,Ta cần phải tính gradient của
2586,E:\DATN\dataframe\train_file\35.txt, ứng với feature map activation
2587,E:\DATN\dataframe\train_file\35.txt, sinh ra từ một lớp Conv:
2588,E:\DATN\dataframe\train_file\35.txt,\frac {\partial y^c}{\partial A^k}
2589,E:\DATN\dataframe\train_file\35.txt,∂A
2590,E:\DATN\dataframe\train_file\35.txt,∂y
2591,E:\DATN\dataframe\train_file\35.txt, (Hình 6).
2592,E:\DATN\dataframe\train_file\35.txt,"Bước 2: Tính ""alpha""."
2593,E:\DATN\dataframe\train_file\35.txt,"Ta sẽ tính giá trị ""alpha"" bằng trung bình gradients."
2594,E:\DATN\dataframe\train_file\35.txt,"Gradient thu được ở bước 1 là một tensor 3 chiều (channels, height, width)."
2595,E:\DATN\dataframe\train_file\35.txt,"Ta thực hiện GAP lên Gradient đó, thu được tensor weight"
2596,E:\DATN\dataframe\train_file\35.txt,"α có chiều (channels, 1, 1) (Hình 7)."
2597,E:\DATN\dataframe\train_file\35.txt,Bước 3: Tạo Class Activation Map.
2598,E:\DATN\dataframe\train_file\35.txt,Ta thực hiện weighted sum kết hợp với hàm ReLU để tạo ra heatmap (CAM).
2599,E:\DATN\dataframe\train_file\35.txt,L^c_{grad-CAM} = ReLU(\sum_k a_k^c A^k)
2600,E:\DATN\dataframe\train_file\35.txt,grad−CAM
2601,E:\DATN\dataframe\train_file\35.txt,"Nếu để ý công thức, các bạn có thể thấy nó hơi giống kĩ thuật Attention thường sử dụng ở trong Computer Vision."
2602,E:\DATN\dataframe\train_file\35.txt,"Kết quả của Grad-CAM, các bạn có thể tìm thấy ở hình dưới."
2603,E:\DATN\dataframe\train_file\35.txt,"Ablation-CAM: CAM nhưng không sử dụng Gradient, sử dụng loại bỏ thông tin"
2604,E:\DATN\dataframe\train_file\35.txt,Ablation-CAM nêu ra một vài nhược điểm của Grad-CAM như sau:
2605,E:\DATN\dataframe\train_file\35.txt,Grad-CAM dựa vào dòng chảy của gradient từ output layer đến Conv layer mong muốn để tạo ra Class Activation Map.
2606,E:\DATN\dataframe\train_file\35.txt,"Nhưng mỗi layer lại là một hàm phi tuyến tính của ảnh đầu vào cũng như là của những layer trước đó, vì vậy, Grad-CAM chịu ảnh hưởng của gradient saturation, dẫn đến việc gradient trong quá trình backprop nhỏ dần rồi biến mất, ảnh hưởng đến chất lượng Visualization"
2607,E:\DATN\dataframe\train_file\35.txt,"Model chỉ cần thực hiện forward pass để dưa ra prediction, vậy tại sao lại giải thích prediction của model sử dụng backprop để lấy gradient?"
2608,E:\DATN\dataframe\train_file\35.txt,Ý tưởng của Ablation-CAM đến từ việc Ablation (loại bỏ) đi thông tin của feature maps.
2609,E:\DATN\dataframe\train_file\35.txt,Morcos và đồng bọn [1] đã thực hiện Ablation Analysis (thử nghiệm loại bỏ) để tìm ra độ quan trọng của từng unit trong layer đối với model.
2610,E:\DATN\dataframe\train_file\35.txt,"Họ kết luận rằng, với một model mà có tính generalized cao thì sẽ ít phụ thuộc vào một neuron hơn, và việc Ablation (đặt giá trị của neuron đó = 0) sẽ không làm ảnh hưởng đến hiệu suất của model."
2611,E:\DATN\dataframe\train_file\35.txt,"Tuy nhiên, Morcos và đồng bọn lại chưa phân tích đến ảnh hưởng của việc Ablation tới một class cụ thể."
2612,E:\DATN\dataframe\train_file\35.txt,"Sau đó, Zhou và đồng bọn [2] đã cho thấy việc bỏ đi một feature map từ output feature maps của một layer có ảnh hưởng nghiêm trọng đến đầu ra logit từ output layer của model (Hình 8)."
2613,E:\DATN\dataframe\train_file\35.txt,Ablation-CAM cho rằng việc đó thể hiện được độ quan trọng của feature map bị bỏ đi đó lên class cần xác định.
2614,E:\DATN\dataframe\train_file\35.txt,"Vì vậy, thay vì sử dụng GAP lên ma trận gradient, Ablation-CAM thực hiện Ablation từng feature map trong feature maps đầu ra của một lớp Conv, và sử dụng chúng làm weight."
2615,E:\DATN\dataframe\train_file\35.txt," Phía trên là toàn bộ ý tưởng để tạo ra heatmap sử dụng Ablation-CAM, tiếp theo mình sẽ đi rõ vào cách thực hiện gồm khá nhiều toán, các bạn có thể bỏ qua nếu muốn."
2616,E:\DATN\dataframe\train_file\35.txt,Cách thực hiện
2617,E:\DATN\dataframe\train_file\35.txt,Xét việc ta cần tạo ra Class Activation Map cho một ảnh đầu vào
2618,E:\DATN\dataframe\train_file\35.txt,"I. Thực hiện forward pass qua model, ta thu được đầu ra logit ứng với class"
2619,E:\DATN\dataframe\train_file\35.txt,c là
2620,E:\DATN\dataframe\train_file\35.txt, này là giá trị của một hàm phi tuyến tính của feature map
2621,E:\DATN\dataframe\train_file\35.txt,A^k \neq 0
2622,E:\DATN\dataframe\train_file\35.txt,Đặt toàn bộ giá trị của feature map
2623,E:\DATN\dataframe\train_file\35.txt,A^k = 0
2624,E:\DATN\dataframe\train_file\35.txt,"=0, thực hiện forward pass ảnh"
2625,E:\DATN\dataframe\train_file\35.txt,"I lần nữa qua model, thu được"
2626,E:\DATN\dataframe\train_file\35.txt, này có thể giảm so với
2627,E:\DATN\dataframe\train_file\35.txt,"Lúc này,"
2628,E:\DATN\dataframe\train_file\35.txt,y_k^c = f(A^k)
2629,E:\DATN\dataframe\train_file\35.txt,A^k = 0
2630,E:\DATN\dataframe\train_file\35.txt,Ta có slope mô tả ảnh hưởng của việc ablation feature map
2631,E:\DATN\dataframe\train_file\35.txt, như sau:
2632,E:\DATN\dataframe\train_file\35.txt,slope = \frac{y^c - y_k^c}{||A_k||}
2633,E:\DATN\dataframe\train_file\35.txt,∣∣A
2634,E:\DATN\dataframe\train_file\35.txt,∣∣
2635,E:\DATN\dataframe\train_file\35.txt,−y
2636,E:\DATN\dataframe\train_file\35.txt,"Nhưng trong Ablation-CAM, ta sẽ sử dụng một biến thể của slope trên để đo độ quan trọng của"
2637,E:\DATN\dataframe\train_file\35.txt, với class
2638,E:\DATN\dataframe\train_file\35.txt,c bởi vì mẫu số norm A (
2639,E:\DATN\dataframe\train_file\35.txt,∣∣A
2640,E:\DATN\dataframe\train_file\35.txt,∣∣) có giá trị cực kì lớn so với tử số
2641,E:\DATN\dataframe\train_file\35.txt,y^c - y_k^c
2642,E:\DATN\dataframe\train_file\35.txt,−y
2643,E:\DATN\dataframe\train_file\35.txt,"Vì vậy, công thức biến đổi để tính weight là:"
2644,E:\DATN\dataframe\train_file\35.txt,w_k^c = \frac{y^c - y_k^c}{y^c}
2645,E:\DATN\dataframe\train_file\35.txt,−y
2646,E:\DATN\dataframe\train_file\35.txt, có thể hiểu là fraction of drop trong logit output của class
2647,E:\DATN\dataframe\train_file\35.txt,c khi feature map
2648,E:\DATN\dataframe\train_file\35.txt,A^k = 0
2649,E:\DATN\dataframe\train_file\35.txt,Ta thu được Class Activation Map bằng weighted sum và ReLU tương tự như Grad-CAM:
2650,E:\DATN\dataframe\train_file\35.txt,L^c_{Ablation-CAM} = ReLU(\sum_k w_k^c A^k)
2651,E:\DATN\dataframe\train_file\35.txt,Ablation−CAM
2652,E:\DATN\dataframe\train_file\35.txt,"A. S. Morcos, D. G. Barrett, N. C. Rabinowitz, and M. Botvinick."
2653,E:\DATN\dataframe\train_file\35.txt,On the importance of single directions for generalization.
2654,E:\DATN\dataframe\train_file\35.txt,"ICLR, 2018."
2655,E:\DATN\dataframe\train_file\35.txt,"B. Zhou, Y."
2656,E:\DATN\dataframe\train_file\35.txt,"Sun, D. Bau, and A. Torralba."
2657,E:\DATN\dataframe\train_file\35.txt,Revisiting the importance of individual units in cnns via ablation.
2658,E:\DATN\dataframe\train_file\35.txt,"arXiv preprint arXiv:1806.02891, 2018."
2659,E:\DATN\dataframe\train_file\35.txt, Một thư viện chứa rất nhiều các phương pháp CAM
2660,E:\DATN\dataframe\train_file\35.txt,Interpretable Machine Learning bản dịch tiếng Việt:
2661,E:\DATN\dataframe\train_file\36.txt,CÁC MÔ HÌNH TRONG BÀI TOÁN SPEECH TO TEXT (S2T)
2662,E:\DATN\dataframe\train_file\36.txt,"Ở 2 bài trước, mình đã trình bày về dữ liệu âm thanh."
2663,E:\DATN\dataframe\train_file\36.txt,Bước tiếp theo chúng ta sẽ cùng tìm hiểu về các mô hình trong bài toán speech to text.
2664,E:\DATN\dataframe\train_file\36.txt,Cách tiếp cận thống kê trong bài toán S2T
2665,E:\DATN\dataframe\train_file\36.txt,Mục tiêu chính của bài toán S2T là xây dựng một mô hình thống kê để dự đoán các chuỗi văn bản (W) dựa trên các vector đặc trưng (X).
2666,E:\DATN\dataframe\train_file\36.txt,Có thể giải thích mô hình thống kê như sau: tìm kiếm tất cả các chuỗi từ có thể có (hạn chế độ dài tối đa) và tìm một chuỗi từ phù hợp nhất với đặc điểm âm thanh đầu vào.
2667,E:\DATN\dataframe\train_file\36.txt,Các bước được trình bày ở hình sau:
2668,E:\DATN\dataframe\train_file\36.txt,Acoustic Model (Mô hình âm thanh)
2669,E:\DATN\dataframe\train_file\36.txt,"Mô hình âm thanh là một mô hình phức tạp, mô hình hóa mối quan hệ giữa tín hiệu âm thanh và các đơn vị ngữ âm trong ngôn ngữ."
2670,E:\DATN\dataframe\train_file\36.txt,HMM-GMM Acoustic model
2671,E:\DATN\dataframe\train_file\36.txt,HMM (Mô hình Markov ẩn)
2672,E:\DATN\dataframe\train_file\36.txt,Mô hình Markov ẩn với ba trạng thái:
2673,E:\DATN\dataframe\train_file\36.txt,"Mô hình Markov ẩn (HMM) là mô hình thống kê máy trạng thái, cho phép chúng ta xem xét đến hai thành phần là sự kiện quan sát được và các sự kiện ẩn."
2674,E:\DATN\dataframe\train_file\36.txt,"Ví dụ trong nhận dạng giọng nói thì sự kiện quan sát được là các đặc trưng âm học của tiếng nói, còn sự kiện ẩn là các từ."
2675,E:\DATN\dataframe\train_file\36.txt,HMM bao gồm các thành phần chính sau:
2676,E:\DATN\dataframe\train_file\36.txt,"Q = q1, q2, …, qN: là tập của N trạng thái."
2677,E:\DATN\dataframe\train_file\36.txt,"** A = a11, q12, …, ann*: là ma trận chuyển trạng thái (transition matrix) với aij là xác suất để trạng thái j xuất hiện tại thời điểm t+1 khi trạng thái i đã xuất hiện tại thời điểm t."
2678,E:\DATN\dataframe\train_file\36.txt,"O = o1, o2, …, oT: là một chuỗi T các quan sát tại các thời điểm t khác nhau."
2679,E:\DATN\dataframe\train_file\36.txt,"Tương ứng với mỗi trạng thái tại thời điểm t sẽ có một tập V = {o1, o2, …, om} là tập tất cả các quan sát có thể được quan sát thấy trong mỗi trạng thái."
2680,E:\DATN\dataframe\train_file\36.txt,𝐵 = {𝑏𝑗 (𝑣𝑘 )}: B là phân bố xác suất quan sát được các quan sát o trong trạng thái qj.
2681,E:\DATN\dataframe\train_file\36.txt,"Π = {π1, π2, …, πN}: tập các phân bố xác suất cho trạng thái khởi đầu, πi là xác suất để trạng thái i được chọn tại thời điểm khởi đầu t = 1 (có thể hiểu như khi chúng ta khởi tạo tham số cho các mô hình Deep Learning)."
2682,E:\DATN\dataframe\train_file\36.txt,"=> Ở hình trên biểu diễn một ví dụ của HMM với 3 trạng thái Q = q1, q2, q3."
2683,E:\DATN\dataframe\train_file\36.txt,"Tại mỗi trạng thái q, các sự kiện quan sát được là V = (v1, v2, v3, v4) và B = (b1, b2, b3, b4) là phân bố xác suất quan sát được sự kiện với bj(k) là xác suất quan sát được sự kiện vk trong trạng thái qj."
2684,E:\DATN\dataframe\train_file\36.txt,"Đối với HMM, có 3 bài toán chính:"
2685,E:\DATN\dataframe\train_file\36.txt,Bài toán 1: Computing likelihood
2686,E:\DATN\dataframe\train_file\36.txt,"Cho biết trước mô hình HMM λ(π, A, B) và chuỗi quan sát O=O1, O2, …, OT."
2687,E:\DATN\dataframe\train_file\36.txt,Xác định likelihood P(O|λ).
2688,E:\DATN\dataframe\train_file\36.txt,"Ví dụ trong nhận dạng tiếng nói, ta có quan sát O là tín hiệu tiếng nói và λ là mô hình, vậy bài toán cần giải là tính likelihood P để mô hình λ quan sát được O."
2689,E:\DATN\dataframe\train_file\36.txt,Bài toán 2: Decoding
2690,E:\DATN\dataframe\train_file\36.txt,"Cho một chuỗi quan sát O và mô hình HMM λ(A,B,π), xác định chuỗi Q tốt nhất."
2691,E:\DATN\dataframe\train_file\36.txt,"Trong nhận dạng tiếng nói thì đây chính là bài toán nhận dạng, khi quan sát O là tín hiệu tiếng nói thì bài toán là tìm chuỗi âm vị Q tương ứng với tín hiệu này."
2692,E:\DATN\dataframe\train_file\36.txt,Bài toán 3: Learning
2693,E:\DATN\dataframe\train_file\36.txt,"Co một chuỗi quan sát O và tập các trạng thái của HMM, điều chỉnh các tham số λ = {A, B, π} của HMM để P(O| λ) lớn nhất."
2694,E:\DATN\dataframe\train_file\36.txt,Đây chính là bài toán huấn luyện mô hình HMM.
2695,E:\DATN\dataframe\train_file\36.txt,"Có thể giải quyết 3 bài toán trên bằng 3 thuật toán sau: Forward, Viterbi, Baum Welch."
2696,E:\DATN\dataframe\train_file\36.txt,Các bạn có thể tìm hiểu thêm về các thuật toán này tại .
2697,E:\DATN\dataframe\train_file\36.txt,"Trong HMM, 1 âm vị thường được biểu diễn bằng HMM tuyến tính 3 hoặc 5 trạng thái"
2698,E:\DATN\dataframe\train_file\36.txt,Có 1 câu hỏi đặt ra là: Các quan sát được tạo ra bằng cách nào?
2699,E:\DATN\dataframe\train_file\36.txt,Câu trả lời là sử dụng GMM (Gaussian Mixture Model).
2700,E:\DATN\dataframe\train_file\36.txt,GMM là một mô hình phân phối để đánh giá khả năng các quan sát được tạo ra.
2701,E:\DATN\dataframe\train_file\36.txt,Việc đào tạo HMM-GMM được giải quyết bằng Tối đa hóa kỳ vọng (Expectation Maximization - EM).
2702,E:\DATN\dataframe\train_file\36.txt,Các bạn có thể tìm hiểu rõ hơn về GMM và EM qua bài viết .
2703,E:\DATN\dataframe\train_file\36.txt,HMM-DNN Acoustic model
2704,E:\DATN\dataframe\train_file\36.txt,Kiến trúc HMM-DNN tiếp cận mô hình âm thanh theo một cách khác.
2705,E:\DATN\dataframe\train_file\36.txt,"Thay vì đi tìm kiếm câu trả lời cho P(X|W), thì HMM-DNN trực tiếp trả lời cho P(W|X)."
2706,E:\DATN\dataframe\train_file\36.txt,"DNN dự đoán xác suất trạng thái của một khung thoại, trong khi HMM kết hợp các dự đoán của DNN để dự đoán trạng thái tiếp theo."
2707,E:\DATN\dataframe\train_file\36.txt,Language Modeling (Mô hình ngôn ngữ)
2708,E:\DATN\dataframe\train_file\36.txt,Mô hình ngôn ngữ được biểu diễn bằng P(W).
2709,E:\DATN\dataframe\train_file\36.txt,Mô hình ngôn ngữ thống kê là loại mô hình gán xác suất cho các chuỗi từ.
2710,E:\DATN\dataframe\train_file\36.txt,N-gram language model
2711,E:\DATN\dataframe\train_file\36.txt,"Công thức: P(w|h), tính xác suất của từ w khi biết trước các từ trước nó h"
2712,E:\DATN\dataframe\train_file\36.txt,Ví dụ: P(yêu|Tôi là một cô gái đáng)
2713,E:\DATN\dataframe\train_file\36.txt,"Ở đây, w = yêu, h = Tôi là một cô gái đáng ."
2714,E:\DATN\dataframe\train_file\36.txt,"Tính xác suất trên bằng phương pháp đếm tần suất tương đối, trong đó chúng ta cần sử dụng một kho ngữ liệu (corpus) lớn."
2715,E:\DATN\dataframe\train_file\36.txt,"Từ kho ngữ liệu này, đếm số lần xuất hiện của “Tôi là một cô gái đáng”, sau đó đếm số lần xuất hiện của “yêu"" sau nó."
2716,E:\DATN\dataframe\train_file\36.txt,P(yêu|Tôi là một cô gái đáng) = C(Tôi là một cô gái đáng yêu)/C(Tôi là một cô gái đáng)
2717,E:\DATN\dataframe\train_file\36.txt,"Thử tượng tưởng, nếu corpus bạn lên đến hàng triệu, hàng trăm nghìn từ thì tính toán này có khả thi không?"
2718,E:\DATN\dataframe\train_file\36.txt,"Mô hình N-gram có thể giải quyết vấn đề này, thay vì tính toán xác suất bằng cách sử dụng toàn bộ kho dữ liệu, thì sẽ ước tính nó chỉ bằng một vài từ (N) đã xuất hiện trước đó."
2719,E:\DATN\dataframe\train_file\36.txt,"Trong đó n có thể là 1(unigram), 2(bigram), 3(trigram)"
2720,E:\DATN\dataframe\train_file\36.txt,Có thể thấy nhược điểm của các mô hình ngôn ngữ thống kê là được đào tạo dựa trên 1 kho ngữ liệu cố định.
2721,E:\DATN\dataframe\train_file\36.txt,"Nếu dữ liệu ở ngoài tập ngữ liệu này, sẽ dẫn đến xác suất bằng 0."
2722,E:\DATN\dataframe\train_file\36.txt,"Ngoài ra còn thiếu tính tổng quát khi tùy vào từng thể loại, từng chủ đề thì sẽ có các cách kết hợp câu, từ khác nhau."
2723,E:\DATN\dataframe\train_file\36.txt,"Để giải quyết vấn đề này, chúng ta có thể sử dụng các mô hình ngôn ngữ học sâu."
2724,E:\DATN\dataframe\train_file\36.txt,"Gần đây, trong lĩnh vực NLP, các mô hình ngôn ngữ dựa trên mạng nơ ron ngày càng trở nên phổ biến hơn."
2725,E:\DATN\dataframe\train_file\36.txt,Mình sẽ kết thúc bài này tại đây.
2726,E:\DATN\dataframe\train_file\36.txt,Qua bài này chúng ta đã hiểu rõ phần nào về kiến trúc bài toán S2T.
2727,E:\DATN\dataframe\train_file\36.txt,Mình sẽ viết thêm về cách huấn luyện cũng như sử dụng các mô hình deep learning thay vì mô hình thống kê trong các bài sau.
2728,E:\DATN\dataframe\train_file\36.txt,Các bạn cùng đón đọc nhé.
2729,E:\DATN\dataframe\train_file\36.txt,Tài liệu tham khảo
2730,E:\DATN\dataframe\train_file\37.txt,XỬ LÝ DỮ LIỆU ÂM THANH
2731,E:\DATN\dataframe\train_file\37.txt,"Cũng giống như các bài toán Deep Learning khác, việc đầu tiên chúng ta cần làm là xử lý dữ liệu."
2732,E:\DATN\dataframe\train_file\37.txt,"Vậy với dữ liệu audio, các bước tiền xử lý sẽ như thế nào?"
2733,E:\DATN\dataframe\train_file\37.txt,"Trong bài viết này, mình sẽ trình bày chi tiết về vấn đề này."
2734,E:\DATN\dataframe\train_file\37.txt,Sử dụng các thư viện âm thanh trong python để lấy đặc trưng
2735,E:\DATN\dataframe\train_file\37.txt,Thư viện python hỗ trợ xử lý âm thanh
2736,E:\DATN\dataframe\train_file\37.txt,"Một số thư viện python hỗ trợ xử lý âm thanh như librosa, scipy, torchaudio."
2737,E:\DATN\dataframe\train_file\37.txt,Tất cả đều cho phép bạn đọc các tệp âm thanh ở các định dạng khác nhau.
2738,E:\DATN\dataframe\train_file\37.txt,Bước đầu tiên là tải tệp lên:
2739,E:\DATN\dataframe\train_file\37.txt,Bạn có thể biểu diễn sóng âm thanh như sau:
2740,E:\DATN\dataframe\train_file\37.txt,Dữ liệu tín hiệu âm thanh (Audio Signal Data)
2741,E:\DATN\dataframe\train_file\37.txt,"Khi âm thanh được lưu trong một tệp, nó sẽ ở định dạng nén."
2742,E:\DATN\dataframe\train_file\37.txt,"Khi tệp được tải, nó sẽ được giải nén và chuyển đổi thành một mảng Numpy."
2743,E:\DATN\dataframe\train_file\37.txt,Mỗi phần tử trong mảng này đại diện cho biên độ của sóng âm thanh ở 1/sample_rate khoảng thời gian của giây.
2744,E:\DATN\dataframe\train_file\37.txt,Ví dụ với file âm thanh ở trên dài 278.521s với sample rate là 16000hz thì số lượng samples của file sẽ là 278.52 * 16000=4456336
2745,E:\DATN\dataframe\train_file\37.txt,Biên độ của tần số ở giây thứ 1 là:
2746,E:\DATN\dataframe\train_file\37.txt,"Bây giờ, chúng ta tiếp tục nhóm âm thanh lấy mẫu thành các đoạn dài 20 mili giây."
2747,E:\DATN\dataframe\train_file\37.txt,Biểu diễn dưới dạng biểu đồ đường cho khoảng thời gian 20ms này:
2748,E:\DATN\dataframe\train_file\37.txt,Chúng ta có thể thấy đoạn ghi âm này chỉ dài 1/50 giây.
2749,E:\DATN\dataframe\train_file\37.txt,Nhưng ngay cả đoạn ghi âm ngắn này cũng là một bản trộn lẫn phức tạp của các tần số âm thanh khác nhau.
2750,E:\DATN\dataframe\train_file\37.txt,"Có một số âm thanh trầm, một số âm thanh tầm trung và thậm chí một số âm thanh cường độ cao."
2751,E:\DATN\dataframe\train_file\37.txt,Nhưng khi những tần số khác nhau này kết hợp với nhau lại tạo nên âm thanh phức tạp của giọng nói của con người.
2752,E:\DATN\dataframe\train_file\37.txt,"Để làm cho dữ liệu này dễ dàng hơn cho mạng nơ-ron xử lý, chúng ta sẽ tách sóng âm thanh phức tạp này thành các phần thành phần của nó."
2753,E:\DATN\dataframe\train_file\37.txt,Vậy thì tách như thế nào ???
2754,E:\DATN\dataframe\train_file\37.txt,"Thử hình dung theo ví dụ này, mọi người sẽ thấy dễ hiểu hơn."
2755,E:\DATN\dataframe\train_file\37.txt,"Trong âm nhạc, ta thường có các hợp âm."
2756,E:\DATN\dataframe\train_file\37.txt,Giả sử bạn đánh hợp âm C Major trên đàn piano.
2757,E:\DATN\dataframe\train_file\37.txt,"m thanh này là sự kết hợp của 3 nốt nhạc C, E và G. Chúng ta cần tách âm thanh phức tạp này thành các nốt riêng lẻ để biết rằng chúng là C, E và G. Đây chính là ý tưởng phân tích âm thanh thành các thành phần của nó."
2758,E:\DATN\dataframe\train_file\37.txt,Chúng ta thực hiện việc phân tích này dựa vào biến đổi Fourier.
2759,E:\DATN\dataframe\train_file\37.txt,Biến đổi Fourier
2760,E:\DATN\dataframe\train_file\37.txt,"Theo wikipedia, tính chất của biến đổi Fourier:"
2761,E:\DATN\dataframe\train_file\37.txt,"Với phép biến đổi Fourier, chúng ta chuyển đổi một tín hiệu từ miền thời gian sang miền tần số."
2762,E:\DATN\dataframe\train_file\37.txt,Biến đổi Fourier không chỉ cung cấp các tần số có trong tín hiệu mà còn cung cấp độ lớn của mỗi tần số có trong tín hiệu.
2763,E:\DATN\dataframe\train_file\37.txt,"Tuy nhiên, hạn chế của biểu diễn miền tần số là không có thông tin về thời gian."
2764,E:\DATN\dataframe\train_file\37.txt,"Trong phần trước, chúng ta đã chia tín hiệu thành các giá trị tần số của nó, chúng sẽ đóng vai trò là features cho mạng nơ ron nhận dạng giọng nói."
2765,E:\DATN\dataframe\train_file\37.txt,"Nhưng khi áp dụng FFT cho tín hiệu của mình, nó chỉ cung cấp các giá trị tần số và chúng ta bị mất dấu thông tin thời gian."
2766,E:\DATN\dataframe\train_file\37.txt,"Do đó, chúng ta cần tìm một cách khác để tính toán các features sao cho các giá trị tần số và thời gian đều được quan sát."
2767,E:\DATN\dataframe\train_file\37.txt,Spectrogram có thể giải quyết được vấn đề này.
2768,E:\DATN\dataframe\train_file\37.txt,Biểu diễn trực quan các tần số của một tín hiệu nhất định với thời gian được gọi là Spectrogram.
2769,E:\DATN\dataframe\train_file\37.txt,"Trong biểu đồ biểu diễn Spectrogram - một trục biểu thị thời gian, trục thứ hai biểu thị tần số và màu sắc biểu thị độ lớn (biên độ) của tần số quan sát tại một thời điểm cụ thể."
2770,E:\DATN\dataframe\train_file\37.txt,Màu sắc tươi sáng thể hiện tần số mạnh.
2771,E:\DATN\dataframe\train_file\37.txt,Các tần số nhỏ hơn từ (0–1kHz) là mạnh (sáng).
2772,E:\DATN\dataframe\train_file\37.txt,(Các tần số mạnh chỉ nằm trong khoảng từ 0 đến 1kHz vì đoạn âm thanh này là lời nói của con người. )
2773,E:\DATN\dataframe\train_file\37.txt,Tạo Spectrogram
2774,E:\DATN\dataframe\train_file\37.txt,Ý tưởng chính là chia tín hiệu âm thanh thành các khung nhỏ hơn (cửa sổ) và tính toán DFT (hoặc FFT) cho mỗi cửa sổ đó.
2775,E:\DATN\dataframe\train_file\37.txt,"Bằng cách này, chúng tôi sẽ nhận được tần số cho mỗi cửa sổ và số cửa sổ sẽ đại diện cho thời gian."
2776,E:\DATN\dataframe\train_file\37.txt,"Để không làm mất một vài tần số khi lấy các cửa sổ một cách liên tục, chúng ta thường giữ cho các cửa sổ này chồng lên nhau (overlap)."
2777,E:\DATN\dataframe\train_file\37.txt,"Đối với tác vụ nhận dạng giọng nói thông thường, bạn nên sử dụng cửa sổ dài từ 20 đến 30 ms. Một con người không thể nói nhiều hơn một âm vị trong khoảng thời gian này."
2778,E:\DATN\dataframe\train_file\37.txt,Đầu ra của thuật toán DFT (hoặc FFT) là 1 mảng các số đại diện cho các biên độ của các tần số khác nhau trong cửa sổ.
2779,E:\DATN\dataframe\train_file\37.txt,Ma trận 2D thu được là biểu đồ Spectrogram.
2780,E:\DATN\dataframe\train_file\37.txt,Thử biểu diễn Spectrograms bằng code:
2781,E:\DATN\dataframe\train_file\37.txt,"Nhìn vào biểu đồ trên, chúng ta không thể thấy rõ được các thông tin về tần số, biên độ mà Spectrogram thể hiện."
2782,E:\DATN\dataframe\train_file\37.txt,Điều này được giải thích là do khả năng nhận thức âm thanh của con người.
2783,E:\DATN\dataframe\train_file\37.txt,Hầu hết những âm thanh mà chúng ta nghe được đều tập trung xung quanh một dải tần số và biên độ khá hẹp.
2784,E:\DATN\dataframe\train_file\37.txt,"Vì vậy, trong nhiều bài toán (đặc biệt là nhận dạng giọng nói), Spectrogram không phải là sự lựa chọn hoàn hảo."
2785,E:\DATN\dataframe\train_file\37.txt,"Vì vậy ta cần thêm vài bước tính nữa để thu được dạng MFCC hoặc Mel Spectrogram, tốt hơn, phổ biến hơn, hiệu quả hơn Spectrogram."
2786,E:\DATN\dataframe\train_file\37.txt,Mel Spectrogram
2787,E:\DATN\dataframe\train_file\37.txt,Mel Scale
2788,E:\DATN\dataframe\train_file\37.txt,Các nghiên cứu đã chỉ ra rằng con người không cảm nhận được tần số trên thang đo tuyến tính.
2789,E:\DATN\dataframe\train_file\37.txt,Con người có thể dễ dàng phân biệt được âm thanh với tần số thấp hơn tần số cao.
2790,E:\DATN\dataframe\train_file\37.txt,"hầu hết con người có thể dễ dàng nhận ra sự khác biệt giữa âm thanh 100 Hz và 200 Hz nhưng lại khó nhận ra sự khác biệt giữa 2000 và 2100 Hz, mặc dù khoảng cách giữa hai bộ âm thanh là như nhau."
2791,E:\DATN\dataframe\train_file\37.txt,Đây là cách con người cảm nhận các tần số.
2792,E:\DATN\dataframe\train_file\37.txt,"Đây là điều khiến Mel Scale trở thành nền tảng cơ bản trong các ứng dụng Máy học đối với âm thanh, vì nó bắt chước nhận thức của con người về âm thanh."
2793,E:\DATN\dataframe\train_file\37.txt,Sự chuyển đổi từ thang đo Hertz sang thang đo Mel như sau:
2794,E:\DATN\dataframe\train_file\37.txt,Decibel Scale
2795,E:\DATN\dataframe\train_file\37.txt,"Trong thang đo này, 0 dB là hoàn toàn im lặng."
2796,E:\DATN\dataframe\train_file\37.txt,"Từ đó, các đơn vị đo lường tăng lên theo cấp số nhân."
2797,E:\DATN\dataframe\train_file\37.txt,"10 dB lớn hơn 10 lần so với 0 dB, 20 dB lớn hơn 100 lần và 30 dB lớn hơn 1000 lần."
2798,E:\DATN\dataframe\train_file\37.txt,"Trên thang đo này, âm thanh trên 100 dB bắt đầu trở nên lớn đến mức không thể chịu nổi."
2799,E:\DATN\dataframe\train_file\37.txt,"Để xử lý âm thanh một cách chân thực, cách xử lý của Mel Spectrogram như sau:"
2800,E:\DATN\dataframe\train_file\37.txt,"Tần số (trục y) được thay thế bằng giá trị Logarithmic của nó, gọi là Mel Scale."
2801,E:\DATN\dataframe\train_file\37.txt,"Biên độ được thay thế bằng giá trị Logarithmic của nó, gọi là Decibel Scale để chỉ ra màu sắc."
2802,E:\DATN\dataframe\train_file\37.txt,"Chúng ta thử vẽ lại Spectrogram ở trên, thay thế tần số bằng Mel Scale:"
2803,E:\DATN\dataframe\train_file\37.txt,"Biểu đồ này biểu diễn tốt hơn Spectrograms, nhưng phần lớn vẫn còn tối và không mang đủ thông tin hữu ích."
2804,E:\DATN\dataframe\train_file\37.txt,Thử sửa đổi nó để sử dụng Decibel Scale thay vì Biên độ.
2805,E:\DATN\dataframe\train_file\37.txt,Đến đây thì thông tin của Audio đã được thể hiện rất rõ ràng trên hình ảnh của Mel Spectrogram.
2806,E:\DATN\dataframe\train_file\37.txt,"Ngoài Mel Spectrogram, thì đặc trưng MFCC cũng thường được sử dụng để trích xuất đặc trưng âm thanh."
2807,E:\DATN\dataframe\train_file\37.txt,Các bạn có thể tìm hiểu kĩ hơn ở .
2808,E:\DATN\dataframe\train_file\37.txt,"Ở bài này, mình đã trình bày về một số đặc trưng âm thanh thường được sử dụng trong bài toán Speech To Text."
2809,E:\DATN\dataframe\train_file\37.txt,Bài tiếp theo mình sẽ trình bày về cách tiếp cận các mô hình trong bài toán này.
2810,E:\DATN\dataframe\train_file\37.txt,Cảm ơn các bạn đã đón đọc và xem tiếp bài của mình nhé.
2811,E:\DATN\dataframe\train_file\37.txt,👋👋👋
2812,E:\DATN\dataframe\train_file\37.txt,Tài liệu tham khảo
2813,E:\DATN\dataframe\train_file\38.txt,"Nếu như trong các bài toán computer vision đầu vào là ảnh, trong nlp đầu vào là text thì trong bài toán speech to text (automatic speech recognition) đầu vào sẽ là audio."
2814,E:\DATN\dataframe\train_file\38.txt,"Trong bài viết này, mình sẽ trình bày một số lý thuyết chung về âm thanh."
2815,E:\DATN\dataframe\train_file\38.txt,"Theo wikipedia, âm thanh là các dao động cơ học (biến đổi vị trí qua lại) của các phân tử, nguyên tử hay các hạt làm nên vật chất và lan truyền trong vật chất như các sóng."
2816,E:\DATN\dataframe\train_file\38.txt,"Âm thanh, giống như nhiều sóng, được đặc trưng bởi tần số, bước sóng, chu kỳ, biên độ và vận tốc lan truyền (tốc độ âm thanh)."
2817,E:\DATN\dataframe\train_file\38.txt,"Âm thanh là dạng tín hiệu liên tục, trong khi máy tính làm việc với các con số rời rạc."
2818,E:\DATN\dataframe\train_file\38.txt,"Vì vậy, để thuận lợi trong việc lưu trữ, truyền tải, xử lý, tín hiệu âm thanh được chuyển sang dạng số (digital sound) - chính là những file audio với định dạng mp3, wav chúng ta thường nghe trên máy tính hoặc điện thoại."
2819,E:\DATN\dataframe\train_file\38.txt,Ta có định dạng file wav là định dạng giữ nguyên gốc nhưng dung lượng rất lớn (khoảng 10Mb cho mỗi phút nhạc).
2820,E:\DATN\dataframe\train_file\38.txt,"Vì vậy, để tiện việc lưu trữ hay chia sẻ, chúng ta cần nén lại dưới các định dạng khác như mp3, ogg, … Cách để giảm kích thước tập tin là chỉnh sửa một trong các thông số (sample rate, bitrate hoặc channels)"
2821,E:\DATN\dataframe\train_file\39.txt,Một số thuật toán tối ưu trong DeepLearning
2822,E:\DATN\dataframe\train_file\39.txt,Vài lời bộc bạch
2823,E:\DATN\dataframe\train_file\39.txt,"Đây là lần đầu tiên mình viết những bài viết mở và public như vậy, nếu như bài viết có bất cứ sai sót, hay góp ý gì cứ thì đừng ngại nói cho mình biết trong phần bình luận để mình sửa nhé."
2824,E:\DATN\dataframe\train_file\39.txt,Chúc mọi người đọc vui vẻ
2825,E:\DATN\dataframe\train_file\39.txt,Gradient decent (GD)
2826,E:\DATN\dataframe\train_file\39.txt,Gradient decent là một thuật toán cơ bản trong machine learning nói chung và deep learning nói riêng để tối ưu các tham số cho mô hình học máy.
2827,E:\DATN\dataframe\train_file\39.txt,Ý tưởng cơ bản nhất của gradient decent là dựa vào tính chất
2828,E:\DATN\dataframe\train_file\39.txt,-\nabla f(x)
2829,E:\DATN\dataframe\train_file\39.txt,−∇f(x) luôn hướng về phía cực trị của hàm số
2830,E:\DATN\dataframe\train_file\39.txt,"f(x), và càng gần với cực trị thì giá trị của"
2831,E:\DATN\dataframe\train_file\39.txt,-\nabla f(x)
2832,E:\DATN\dataframe\train_file\39.txt,−∇f(x) càng tiến về không.
2833,E:\DATN\dataframe\train_file\39.txt,Vì thế để tìm kiếm cực trị lân cận của một hàm số
2834,E:\DATN\dataframe\train_file\39.txt,"f(x) bất kì, ta chọn một điểm"
2835,E:\DATN\dataframe\train_file\39.txt, để bắt đầu thuật toán GD và cập nhật giá trị của
2836,E:\DATN\dataframe\train_file\39.txt, theo công thức truy hồi sau:
2837,E:\DATN\dataframe\train_file\39.txt,x_{n+1}=x_n-\eta\cdot\nabla f(x_n)
2838,E:\DATN\dataframe\train_file\39.txt,−η⋅∇f(x
2839,E:\DATN\dataframe\train_file\39.txt,"Trong đó,"
2840,E:\DATN\dataframe\train_file\39.txt,η được gọi là tốc độ học của thuật toán.
2841,E:\DATN\dataframe\train_file\39.txt,"Đối với gradient decent, người ta thường chọn"
2842,E:\DATN\dataframe\train_file\39.txt,η có độ lớn khoảng
2843,E:\DATN\dataframe\train_file\39.txt,0.01 đến
2844,E:\DATN\dataframe\train_file\39.txt,0.0001 tùy vào loại dữ liệu.
2845,E:\DATN\dataframe\train_file\39.txt,"Gradient trong GD thường được tính bằng hai cách, cách đầu tiên là dùng analytical gradient, có được bằng cách áp dụng công thức đạo hàm vào hàm mất mát để tính Gradient, ưu điểm của phương pháp này là khối lượng tính toán nhẹ và độ chính xác cao, nhưng nhược điểm là đôi lúc ta sẽ gặp những bài toán mà hàm mất mát phức tạp đến nỗi không thể tính được công thức đạo hàm."
2846,E:\DATN\dataframe\train_file\39.txt,"Điều đó dẫn đến cách tính thứ hai đó là numerical Gradient, cách làm này tuy độ chính xác không cao và khối lượng tính toán lớn nhưng bù lại thì nó có thể dùng cho mọi trường hợp hàm mất mát."
2847,E:\DATN\dataframe\train_file\39.txt,numerical gradient thường được dùng để kiểm tra analytical gradient để bào đảm ta tính đúng Gradient.
2848,E:\DATN\dataframe\train_file\39.txt,Numerical gradient được tính bằng cách sử dụng công thức sai phân hướng tâm:
2849,E:\DATN\dataframe\train_file\39.txt,2ϵ
2850,E:\DATN\dataframe\train_file\39.txt,f(x+ϵ)−f(x−ϵ)
2851,E:\DATN\dataframe\train_file\39.txt,Gradient decent với momentum
2852,E:\DATN\dataframe\train_file\39.txt,"Trong một số trường hợp, thuật toán GD của chúng ta không tìm được một global minimum để thuật toán thu được một kết quả tốt mà lại bị kẹt tại một local minimum, không mong muốn."
2853,E:\DATN\dataframe\train_file\39.txt,"Để khắc phục điểm trừ này, ta thêm vào công thức cập nhật gradient nhân tố"
2854,E:\DATN\dataframe\train_file\39.txt, có công thức như sau:
2855,E:\DATN\dataframe\train_file\39.txt,v_n=\gamma v_{n-1}+\nabla f(x_n)
2856,E:\DATN\dataframe\train_file\39.txt,n−1
2857,E:\DATN\dataframe\train_file\39.txt,+∇f(x
2858,E:\DATN\dataframe\train_file\39.txt,γ trong công thức trên thường được đặt là
2859,E:\DATN\dataframe\train_file\39.txt,0.9 và từ đó công thức GD với momentum có công thức như sau
2860,E:\DATN\dataframe\train_file\39.txt,−v
2861,E:\DATN\dataframe\train_file\39.txt,\Leftrightarrow x_{n+1}=x_n-\gamma v_{n-1}-\nabla f(x_n)
2862,E:\DATN\dataframe\train_file\39.txt,⇔x
2863,E:\DATN\dataframe\train_file\39.txt,−γv
2864,E:\DATN\dataframe\train_file\39.txt,n−1
2865,E:\DATN\dataframe\train_file\39.txt,−∇f(x
2866,E:\DATN\dataframe\train_file\39.txt,"Trong đó, nhìn theo góc nhìn vật lí thì"
2867,E:\DATN\dataframe\train_file\39.txt,\gamma v_{n-1}
2868,E:\DATN\dataframe\train_file\39.txt,n−1
2869,E:\DATN\dataframe\train_file\39.txt, biểu thì cho “đà” của quả banh màu vàng giúp quả banh vàng vượt qua local minimum không mong muốn và thành phần gradient cơ bản
2870,E:\DATN\dataframe\train_file\39.txt,\nabla f(x_n)
2871,E:\DATN\dataframe\train_file\39.txt,∇f(x
2872,E:\DATN\dataframe\train_file\39.txt,"), vì thế mà việc thêm “đà” này còn được gọi là rò rỉ động lượng, tức năng lượng ở lần cập nhật trước bị rò rỉ qua lần cập nhật sau với hệ số"
2873,E:\DATN\dataframe\train_file\39.txt,Nesterov accelerated gradient decent (NAG)
2874,E:\DATN\dataframe\train_file\39.txt,Tuy momentum giúp viên bi vàng vượt được dốc để tiến đến cực trị mong muốn nhưng điều này đồng thời cũng khiến nó dao động rất lâu xung quanh điểm cực tiểu trước khi dừng lại.
2875,E:\DATN\dataframe\train_file\39.txt,"Tuy nhiên, với Nesterov GD thì điều này sẽ được khắc phục."
2876,E:\DATN\dataframe\train_file\39.txt,"Với hai thuật toán trước, ta chỉ tính Gradient tại điểm đang xét, nhưng với NAG, gradient được tính tại điểm ở “tương lai”:"
2877,E:\DATN\dataframe\train_file\39.txt,Thay vì cập nhật với:
2878,E:\DATN\dataframe\train_file\39.txt,v_n=\gamma v_{n-1}+\nabla f(x_n)
2879,E:\DATN\dataframe\train_file\39.txt,n−1
2880,E:\DATN\dataframe\train_file\39.txt,+∇f(x
2881,E:\DATN\dataframe\train_file\39.txt,NAG cập nhật với:
2882,E:\DATN\dataframe\train_file\39.txt,v_n=\gamma v_{n-1}+\nabla f(x_n-\gamma v_{n-1})
2883,E:\DATN\dataframe\train_file\39.txt,n−1
2884,E:\DATN\dataframe\train_file\39.txt,+∇f(x
2885,E:\DATN\dataframe\train_file\39.txt,−γv
2886,E:\DATN\dataframe\train_file\39.txt,n−1
2887,E:\DATN\dataframe\train_file\39.txt,\Leftrightarrow x_{n+1}=x_n-v_n=x_n-\gamma v_{n-1}-\nabla f(x_n-\gamma v_{n-1})
2888,E:\DATN\dataframe\train_file\39.txt,⇔x
2889,E:\DATN\dataframe\train_file\39.txt,−v
2890,E:\DATN\dataframe\train_file\39.txt,−γv
2891,E:\DATN\dataframe\train_file\39.txt,n−1
2892,E:\DATN\dataframe\train_file\39.txt,−∇f(x
2893,E:\DATN\dataframe\train_file\39.txt,−γv
2894,E:\DATN\dataframe\train_file\39.txt,n−1
2895,E:\DATN\dataframe\train_file\39.txt,Cập nhật với NAG
2896,E:\DATN\dataframe\train_file\39.txt,GD with momentum
2897,E:\DATN\dataframe\train_file\39.txt,Stochastic gradient decent (SGD)
2898,E:\DATN\dataframe\train_file\39.txt,Cập nhật Gradient chỉ với một điểm dữ liệu ngẫu nhiên và làm điều này trên toàn bộ dữ liệu.
2899,E:\DATN\dataframe\train_file\39.txt,Mỗi lần thuật toán đi qua hết tất cả các điểm dữ liệu gọi là một epoch.
2900,E:\DATN\dataframe\train_file\39.txt,"Để huấn luyện với SGD, ta có thể sẽ phải chạy nhiều epoch."
2901,E:\DATN\dataframe\train_file\39.txt,Ưu điểm của SGD là tốc độ tính toán rất nhanh và không cần nhiều bộ nhớ.
2902,E:\DATN\dataframe\train_file\39.txt,Vì thế phương pháp này được ứng dụng rất nhiều trong mảng online learning.
2903,E:\DATN\dataframe\train_file\39.txt,Batch and mini batch
2904,E:\DATN\dataframe\train_file\39.txt,"Thay vì dùng một điểm để cập nhật, ta chia nhiều điểm vào chung một batch rồi dùng để cập nhật Gradient."
2905,E:\DATN\dataframe\train_file\39.txt,điều này giúp tận dụng dữ liệu và cũng cải thiện tốc độ tính toán.
2906,E:\DATN\dataframe\train_file\39.txt,"Hàm mất mát của SGD và Batch, mini batch GD không phải bao giờ cũng giảm nhưng nhìn chung là hội tụ càng về cuối."
2907,E:\DATN\dataframe\train_file\39.txt,Phương pháp này được sử dụng rộng rãi trong các bài toán Deep learning.
2908,E:\DATN\dataframe\train_file\39.txt,Stopping criteria
2909,E:\DATN\dataframe\train_file\39.txt,Có các chú ý sau khi dừng thuật toán GD:
2910,E:\DATN\dataframe\train_file\39.txt,"Giới hạn số vòng lặp, hay số epoch để hạn chế tình trạng GD không tìm được nghiệm do learning rate quá lớn hoặc tránh tình trạng model của chúng ta bị overfit."
2911,E:\DATN\dataframe\train_file\39.txt,Nhược điểm là đôi khi thuật toán GD chưa tìm được nghiệm thì đã bị dừng lại
2912,E:\DATN\dataframe\train_file\39.txt,"So sánh giá trị gradient tại hai lần cập nhật liên tiếp, khi giá trị này đủ nhỏ thì dừng thuật toán."
2913,E:\DATN\dataframe\train_file\39.txt,Nhược điểm là đôi khi việc tính gradient như vậy sẽ không có lợi khi dùng SGD hoặc mini batch vì sẽ tốn nhiều bộ nhớ khi có quá nhiều dữ liệu khiến ta không có được lợi thế khi dùng phương pháp này
2914,E:\DATN\dataframe\train_file\39.txt,"So sánh giá trị của hàm mất mát của nghiệm tại hai lần cập nhật liên tiếp, khi nào giá trị này đủ nhỏ thì dừng lại."
2915,E:\DATN\dataframe\train_file\39.txt,"Nhược điểm của phương pháp này là nếu tại một thời điểm, điểm cập nhật của ta rơi vào vị trí điểm uốn tương đối bằng phẳng thì thuật toán cũng dừng lại trước khi đạt giá trị mong muốn."
2916,E:\DATN\dataframe\train_file\39.txt,Phương pháp cuối cùng là kiểm tra sau một vài lần cập nhật nhất định.
2917,E:\DATN\dataframe\train_file\39.txt,Việc này giúp giảm khối lượng tính toán cũng như giúp thuật toán vượt được những điểm uốn và tím được cực trị phù hợp.
2918,E:\DATN\dataframe\train_file\39.txt,Advance optimization
2919,E:\DATN\dataframe\train_file\39.txt,"Một số những trở ngại lớn trong bài toán tối ưu là các local minimum, các điểm uốn (điểm yên ngựa), và vấn đề tiêu biến/ bùng nổ Gradient (Vanishing/ exploding Gradient), ..."
2920,E:\DATN\dataframe\train_file\39.txt,"Trong một số trường hợp, việc chọn learning rate phù hợp có thể trở thành một vấn đề nhức nhối."
2921,E:\DATN\dataframe\train_file\39.txt,"Vấn đề này sẽ được giải quyết với AdaGrad, vì thuật toán này sẽ coi learning rate là một tham số biến thiên sau mỗi lần chạy thuật toán."
2922,E:\DATN\dataframe\train_file\39.txt,"AdaGrad thường được dùng trong các vấn đề về sparse feature (đặc trưng thưa), ví dụ như các bài toán về xử lí ngôn ngữ tự nhiên, quảng cáo điện toán, và lọc cộng tác."
2923,E:\DATN\dataframe\train_file\39.txt,"Thường những những đặc trưng này ít khi được cập nhật để có thể được tối ưu những lại mang những ý nghĩa vô cùng to lớn, còn những đặc trưng có tần số xuất hiện cao thì được cập nhật liên tục."
2924,E:\DATN\dataframe\train_file\39.txt,"Vì thế, việc có một learning rate cố định hoặc là quá cao đối với những feature được cập nhật nhiều lần hoặc là quá thấp đối với những feature ít được cập nhật."
2925,E:\DATN\dataframe\train_file\39.txt,Công thức của AdaGrad như sau:
2926,E:\DATN\dataframe\train_file\39.txt,n−1
2927,E:\DATN\dataframe\train_file\39.txt,w_n=w_{n-1}-\frac{\eta}{\sqrt{s_n+\epsilon}}\odot g_t
2928,E:\DATN\dataframe\train_file\39.txt,n−1
2929,E:\DATN\dataframe\train_file\39.txt,⊙g
2930,E:\DATN\dataframe\train_file\39.txt,Trong đó
2931,E:\DATN\dataframe\train_file\39.txt, thường được chọn bằng
2932,E:\DATN\dataframe\train_file\39.txt,AdaGrad với lr=0.4
2933,E:\DATN\dataframe\train_file\39.txt,AdaGrad với lr=2
2934,E:\DATN\dataframe\train_file\39.txt,"Ta có thể hiểu sự thay đổi learning rate này như một hệ số “ma sát”, “ma sát” này có giá trị lớn ở dốc và có giá trị nhỏ ở vùng bằng phẳng."
2935,E:\DATN\dataframe\train_file\39.txt,Phân tích ưu và nhược của AdaGrad:
2936,E:\DATN\dataframe\train_file\39.txt,"Hoạt động tốt với bài toán sparse feature, cụ thể là tối ưu các bài toán lồi, không dao động nhiều khi đạt vào cực tiểu cần thiết."
2937,E:\DATN\dataframe\train_file\39.txt,Learning rate được tự động điều chỉnh cho phù hợp
2938,E:\DATN\dataframe\train_file\39.txt,Chi phí tính toán không tăng nếu so với SGD
2939,E:\DATN\dataframe\train_file\39.txt,"Trong deep learning, các bài toán thường không hoàn toàn lồi và có nhiều local minimum gây nhiễu."
2940,E:\DATN\dataframe\train_file\39.txt, trong công thức cập nhật tăng một cách dường như tuyến tính khiến cho learning rate bị thu nhỏ nhanh.
2941,E:\DATN\dataframe\train_file\39.txt,"AdaGrad với tốc độ học thay đổi để thích nghi với dữ liệu là một phương pháp tuyệt vời trong các bài toán tối ưu lồi, thế nhưng nó vẫn có những hạn chế như đã nêu trên."
2942,E:\DATN\dataframe\train_file\39.txt,Vì thế RMSProp được đề xuất để khác phục những vấn đề của AdaGrad bằng cách kế thừa ý tưởng từ phương pháp momentum trong gradient decent làm rò rỉ các giá trị của
2943,E:\DATN\dataframe\train_file\39.txt, trong công thức cập nhật.
2944,E:\DATN\dataframe\train_file\39.txt,Cụ thể công thức của RMSProp là:
2945,E:\DATN\dataframe\train_file\39.txt,s_n=\gamma s_{n-1}+(1-\gamma)g_n^2
2946,E:\DATN\dataframe\train_file\39.txt,n−1
2947,E:\DATN\dataframe\train_file\39.txt,+(1−γ)g
2948,E:\DATN\dataframe\train_file\39.txt,w_n=w_{n-1}-\frac{\eta}{\sqrt{s_n+\epsilon}}\odot g_t
2949,E:\DATN\dataframe\train_file\39.txt,n−1
2950,E:\DATN\dataframe\train_file\39.txt,⊙g
2951,E:\DATN\dataframe\train_file\39.txt,Việc làm cho
2952,E:\DATN\dataframe\train_file\39.txt, bị rò rỉ cũng đồng thời chuẩn hóa giá của trị số đứng trước giá trị của
2953,E:\DATN\dataframe\train_file\39.txt,", vì thế mà giải quyết được vấn đề learning rate bị thu nhỏ khiến thuật toán dừng sớm."
2954,E:\DATN\dataframe\train_file\39.txt,"Ta thấy rằng RMSProp kế thừa được những ưu điểm của AdaGrad về việc tự điều chỉnh learning rate, thuật toán đã đi được xa hơn so với AdaGrad với cùng learning rate"
2955,E:\DATN\dataframe\train_file\39.txt,"Trong một bài toán tối ưu thường gặp, ta muốn thuật toán của mình đầu tiên vượt qua những local minimum nhiễu một cách dễ dàng, nhưng khi đạt được global minimum thì sẽ không dao động quá lâu mà tìm được vị trí phù hợp ngay."
2956,E:\DATN\dataframe\train_file\39.txt,Điều này thúc đẩy ta tìm kiếm một thuật có hành vi được mô tả như trên.
2957,E:\DATN\dataframe\train_file\39.txt,"Có một thuật toán đã hội tụ đủ mọi ưu điểm của những phương pháp trước đó, đó chính là Adam, được sử dụng rất phổ biến trong bài toán deep learning."
2958,E:\DATN\dataframe\train_file\39.txt,Thuật toán của Adam được ví như một quả bóng có khối lượng lớn và có ma sát vì nó có động lượng rò rỉ để vượt qua các local minimum để tiến đến gobal ninimum và không dao động lâu vì có ma sát kế thừa từ AdaGrad
2959,E:\DATN\dataframe\train_file\39.txt,Thuật toán của Adam như sau:
2960,E:\DATN\dataframe\train_file\39.txt,n−1
2961,E:\DATN\dataframe\train_file\39.txt,+(1−β
2962,E:\DATN\dataframe\train_file\39.txt,s_n=\beta_2 s_{n-1}+(1-\beta_2)g_n^2
2963,E:\DATN\dataframe\train_file\39.txt,n−1
2964,E:\DATN\dataframe\train_file\39.txt,+(1−β
2965,E:\DATN\dataframe\train_file\39.txt,"\hat{v}_n=\frac{v_n}{1-\beta_1^n}, \hat{s}_n=\frac{s_n}{1-\beta_2^n}"
2966,E:\DATN\dataframe\train_file\39.txt,1−β
2967,E:\DATN\dataframe\train_file\39.txt,1−β
2968,E:\DATN\dataframe\train_file\39.txt,g'_n=\frac{\eta \hat{v}_n}{\sqrt{\hat{s}_n}+\epsilon}
2969,E:\DATN\dataframe\train_file\39.txt,−g
2970,E:\DATN\dataframe\train_file\39.txt,"Trong đó,"
2971,E:\DATN\dataframe\train_file\39.txt, thường được chọn là
2972,E:\DATN\dataframe\train_file\39.txt,0.9 và
2973,E:\DATN\dataframe\train_file\39.txt,Các giá trị
2974,E:\DATN\dataframe\train_file\39.txt, cũng thường được cho bằng
2975,E:\DATN\dataframe\train_file\39.txt,"Tuy nhiên, Adam tuy có lợi thế về learning rate và động lượng nhưng trong một số trường hợp nhất định, Adam sẽ bắt đầu phân kì."
2976,E:\DATN\dataframe\train_file\39.txt,"Có một bài báo đã nêu lên và phân tích điều này: [Zaheer et al., 2018]"
2977,E:\DATN\dataframe\train_file\39.txt,So sánh các thuật toán tối ưu:
2978,E:\DATN\dataframe\train_file\39.txt,"Ngoài ra, ta vẫn có thể sử dụng các thuật toán đơn giản như SGD với momentum, hoặc chỉ SGD nhưng kết hợp với bộ định thời tốc độ học ( Learning rate scheduling) để đạt được tốc độ học mong muốn."
2979,E:\DATN\dataframe\train_file\39.txt,Tài liệu tham khảo
2980,E:\DATN\dataframe\train_file\39.txt,Sách Machine Learning Cơ bản.
2981,E:\DATN\dataframe\train_file\39.txt,Tác giả: bác Vũ Hữu Tiệp
2982,E:\DATN\dataframe\train_file\39.txt,Sách Dive into deep learning.
2983,E:\DATN\dataframe\train_file\39.txt,Nhiều tác giả.
2984,E:\DATN\dataframe\train_file\39.txt,Ngoài ra mình còn tham khảo một số nguồn ngoài khác nhưng chính thì chỉ có hai nguồn dẫn trên thôi .
2985,E:\DATN\dataframe\train_file\4.txt,"Nếu các bạn làm Machine Learning một thời gian đủ lâu thì cũng không còn lạ lẫm gì với hai khái niệm này nữa tuy nhiên đôi khi có một vài tài liệu viết không được rõ ràng về vấn đề này, hay nói đúng hơn là sử dụng hơi tuỳ tiện khiến những người mới đọc và làm Machine Learning cảm thấy sốc và choáng vì thấy có những chỗ thì gọi là tối ưu parameter trường hợp khác lại gọi là lựa chọn hyperparameter và ngược lại thật là loạn cào cào."
2986,E:\DATN\dataframe\train_file\4.txt,Mình xin mạn phép được giải thích kĩ hơn hai khái niệm này và từng trường hợp cụ thể tránh sau này chúng ta sử dụng thuật ngữ không đúng.
2987,E:\DATN\dataframe\train_file\4.txt,Có lẽ do thời quen thường dịch Hyperparameter là siêu tham số nên chúng ta thường ngầm định nó giống Model Parameter nhưng có phần khủng hơn.
2988,E:\DATN\dataframe\train_file\4.txt,Thực ra hai khái niệm này là hoàn toàn tách biệt.
2989,E:\DATN\dataframe\train_file\4.txt,Nếu như Model parameter được mô hình sinh ra từ chính tập dữ liệu huấn luyện thì Model Hyperparameter lại hoàn toàn khác.
2990,E:\DATN\dataframe\train_file\4.txt,Nó hoàn toàn nằm ngoài mô hình và không phụ thuộc và tập dữ liệu huấn luyện.
2991,E:\DATN\dataframe\train_file\40.txt,Jira là phần mềm quản lý công việc hàng đầu cho các nhóm phát triển phần mềm.
2992,E:\DATN\dataframe\train_file\40.txt,"Kiểm soát các tác vụ, các lỗi phát sinh cũng như chỉ định các công việc là các hoạt động quan trọng trong quản lý dự án."
2993,E:\DATN\dataframe\train_file\40.txt,"Thông thường, các nhà quản lý dự án sẽ gặp nhiều khó khăn trong việc xử lý và kiểm soát một lượng lớn thông tin."
2994,E:\DATN\dataframe\train_file\40.txt,"Để giải quyết vấn đề này, Jira đã ra đời để giúp tối ưu quy trình và các dự án được hoạt động trơn tru hơn."
2995,E:\DATN\dataframe\train_file\40.txt,Bài viết sau sẽ giới thiệu với bạn tổng quan các điều cần biết về Jira.
2996,E:\DATN\dataframe\train_file\40.txt,Jira là một công cụ đám mây để theo dõi các công việc và quản lý dự án.
2997,E:\DATN\dataframe\train_file\40.txt,Công cụ này được thiết kế để tăng cường phối hợp nhóm trong phát triển phầm mềm Agile.
2998,E:\DATN\dataframe\train_file\40.txt,"Ngoài ra, Jira cũng cung cấp một bộ theo dõi bug và tiến độ toàn diện trong toàn bộ vòng đời phát triển phần mềm."
2999,E:\DATN\dataframe\train_file\40.txt,"Phần mềm Jira tạo điều kiện thuận lợi cho việc lập kế hoạch, theo dõi cũng như bàn giao sản phẩm."
3000,E:\DATN\dataframe\train_file\40.txt,"Bắt đầu với dựng Backlog & phiên Planning, phần mềm quản lý dự án này cho phép bạn phác thảo toàn bộ tiến độ dự án và đảm bảo sự cộng tác với vô số công cụ."
3001,E:\DATN\dataframe\train_file\40.txt,Tính năng quản lý bản phát hành sẽ giúp người dùng theo dõi các dự án trên các bản phát hành.
3002,E:\DATN\dataframe\train_file\40.txt,"Ngoài ra, Jira cũng cung cấp các báo cáo toàn diện về tiến độ và hiệu suất."
3003,E:\DATN\dataframe\train_file\40.txt,Jira cung cấp các template được thiết lập sẵn cho tất cả các chức năng và cho phép thay đổi chúng theo nhu cầu của nhóm và doanh nghiệp.
3004,E:\DATN\dataframe\train_file\40.txt,Mọi đội nhóm trong nhiều ngành nghề khác nhau có thể sử dụng hiệu quả.
3005,E:\DATN\dataframe\train_file\40.txt,"Mặc dù Jira ban đầu được thiết kế cho các nhóm Công nghệ thông tin, nhưng hiện nay nhiều nhóm bao gồm marketing, nhân sự, sale, … đều đang sử dụng phần mềm này do khả năng quản lý và tuỳ chỉnh mạnh mẽ của nó."
3006,E:\DATN\dataframe\train_file\40.txt,Quản lý và theo dõi tiến độ của dự án.
3007,E:\DATN\dataframe\train_file\40.txt,"Quản lý các tasks, bugs, sự cải tiến, những tính năng mới hoặc bất kỳ vấn đề xảy ra."
3008,E:\DATN\dataframe\train_file\40.txt,Tạo ra và lưu trữ lại những bộ lọc có cấu hình cao xuyên suốt mọi vấn đề trong hệ thống.
3009,E:\DATN\dataframe\train_file\40.txt,Chia sẻ bộ lọc với người sử dụng khác hoặc đăng ký và nhận kết quả qua hệ thống email định kỳ.
3010,E:\DATN\dataframe\train_file\40.txt,Xây dựng quy trình làm việc tương thích với từng yêu cầu của dự án và quy trình của doanh nghiệp.
3011,E:\DATN\dataframe\train_file\40.txt,Bảng dashboard cung cấp cho người sử dụng một không gian riêng.
3012,E:\DATN\dataframe\train_file\40.txt,Nhóm xem mọi thông tin liên quan đến cá nhân.
3013,E:\DATN\dataframe\train_file\40.txt,"Cung cấp nhiều loại báo cáo thống kê với những biểu đồ khác nhau, phù hợp với nhiều loại hình dự án và đối tượng người sử dụng."
3014,E:\DATN\dataframe\train_file\40.txt,"Dễ dàng tích hợp với các hệ thống ứng dụng khác (như Email, Excel, RSS,…)."
3015,E:\DATN\dataframe\train_file\40.txt,"Có thể chạy trên hầu hết các nền tảng, hệ điều hành và cơ sở dữ liệu."
3016,E:\DATN\dataframe\train_file\40.txt,Jira giúp bạn lập biểu đồ ý tưởng của mình và truyền đạt chúng cho nhóm của bạn thông qua Roadmap.
3017,E:\DATN\dataframe\train_file\40.txt,Tính năng này cho phép bạn chia sẻ các kế hoạch lớn và phân công nhiệm vụ cá nhân hiệu quả.
3018,E:\DATN\dataframe\train_file\40.txt,Ứng dụng này có tất cả các tính năng bạn cần để giúp các team Agile/Scrum đi đúng hướng.
3019,E:\DATN\dataframe\train_file\40.txt,"Đối với các user story riêng lẻ, bạn có thể tạo các báo cáo như biểu đồ tổng hợp và đối với quản lý nhóm, bạn cũng có thể theo dõi khối lượng công việc cực kì chi tiết."
3020,E:\DATN\dataframe\train_file\40.txt,Khả năng tích hợp mạnh mẽ .
3021,E:\DATN\dataframe\train_file\40.txt,Ứng dụng cho phép tích hợp dễ dàng với các phần mềm bên thứ 3 khác.
3022,E:\DATN\dataframe\train_file\40.txt,Ví dụ: với Hipchat và Sack để nhận thông báo và giao tiếp.
3023,E:\DATN\dataframe\train_file\40.txt,"Hơn 3000 add-ons/plugins có sẵn, giúp customize Jira với các nhu cầu và nhiệm vụ khác nhau."
3024,E:\DATN\dataframe\train_file\40.txt,"Jira cho phép người dùng tùy chỉnh trải nghiệm của họ bằng cách tạo và tùy chỉnh các phần tử khác nhau, chẳng hạn như bảng, biểu mẫu, tiến trình, báo cáo, trường và hơn thế nữa."
3025,E:\DATN\dataframe\train_file\40.txt,Phần mềm được sử dụng cho một số nhiệm vụ khác nhau của các loại người dùng khác nhau.
3026,E:\DATN\dataframe\train_file\40.txt,"Cho dù bạn là nhà phát triển, người quản lý, người quản lý dự án hay kỹ sư, bạn sẽ có thể sử dụng Jira để đáp ứng nhu cầu kinh doanh của mình"
3027,E:\DATN\dataframe\train_file\41.txt,Xây dựng bài toán tự động xóa vật thể bất kì bằng Deep Learning
3028,E:\DATN\dataframe\train_file\41.txt,Giới thiệu về bài toán Automatic Object Removal
3029,E:\DATN\dataframe\train_file\41.txt,"Trong thời đại bùng nổ của kĩ thuật số, đặc biệt sự phát triển vượt bậc của các nền tảng mạng xã hội."
3030,E:\DATN\dataframe\train_file\41.txt,"Nhu cầu về chia sẻ hình ảnh, hay thiết kế ấn phẩm đang ngày càng được chú trọng quan tâm hơn."
3031,E:\DATN\dataframe\train_file\41.txt,"Chính vì vây, các ứng dụng liên quan đến chỉnh sửa hình ảnh là rất cần thiết."
3032,E:\DATN\dataframe\train_file\41.txt,"Trong đó, Xoá vật thể không mong muốn, dư thừa là một trong những thao tác phổ biến khi chỉnh sửa ảnh."
3033,E:\DATN\dataframe\train_file\41.txt,"Không chỉ dành riêng với các nhà photoshop chuyên nghiệp, mà ngay đến những người dùng bình thường cũng đã có nhu cầu sử dụng cao."
3034,E:\DATN\dataframe\train_file\41.txt,Hình 1: Người (ô màu đỏ) là thứ bạn muốn xóa.
3035,E:\DATN\dataframe\train_file\41.txt,Input và Output của bài toán
3036,E:\DATN\dataframe\train_file\41.txt,"Xoá đối tượng trong ảnh (Object Removal), cụ thể là xoá đối tượng người dùng muốn xoá, xoá đối tượng dư thừa."
3037,E:\DATN\dataframe\train_file\41.txt,Đó là một thao tác thường được sử dụng trong chỉnh sửa ảnh.
3038,E:\DATN\dataframe\train_file\41.txt,"Input: Đưa vào một bức ảnh với kích thước bất kỳ, nhập loại đối tượng bạn muốn xoá."
3039,E:\DATN\dataframe\train_file\41.txt,Output: Một bức ảnh sau khi đã xoá đối tượng và có cùng kích thước với bức ảnh đầu vào.
3040,E:\DATN\dataframe\train_file\41.txt,Hình 2: Input và Output của bài toán.
3041,E:\DATN\dataframe\train_file\41.txt,Hướng tiếp cận của bài toán
3042,E:\DATN\dataframe\train_file\41.txt,"Khi tìm hiểu của các bên khác triển khai bài toán này, ví dụ như Tool Content-Aware Fill trong phần mềm Photoshop, Remove Objects from Photos Online with Ease | PicsArt, ... mình nhận thấy rằng: Mỗi ứng dụng tuy có cách triển khai khác nhau, đi từ đơn giản cho đến phức tạp nhưng nhìn tổng quan các ứng dụng đều có chung một cách giải quyết:"
3043,E:\DATN\dataframe\train_file\41.txt,Hình 3: Hướng tiếp cận của bài toán.
3044,E:\DATN\dataframe\train_file\41.txt,"Ngoài ra, cũng có khá nhiều các paper đã ra mắt, nghiên cứu về phần này."
3045,E:\DATN\dataframe\train_file\41.txt,Có thể kể đến như:
3046,E:\DATN\dataframe\train_file\41.txt,Phương pháp Adversarial Scene Editing: Automatic Object Removal from Weak Supervision[1]: Phương pháp này là một mô hình được phát triển từ mạng GAN (Generative Adversarial Networks) thông qua các nhãn theo cấp của ảnh mà không cần các thông tin về hộp giới hạn (boundary box) hay vùng đối tượng (mask).
3047,E:\DATN\dataframe\train_file\41.txt,"Ứng dụng Person Remover: People removal in images using Pix2Pix and YOLO[2]: Xác định đối tượng bằng mô hình YOLO, sau đó từ ảnh cut đối tượng, ta chạy qua mô hình Pix2Pix để sinh ra ảnh mới."
3048,E:\DATN\dataframe\train_file\41.txt,"(lúc đầu mình cũng làm theo cách này, nhưng mà ôi giời ôi, đến đoạn training Pix2Pix thì không được như mơ 😁)"
3049,E:\DATN\dataframe\train_file\41.txt,Hình 4: Kiến trúc của phương pháp Adversarial Scene Editing.
3050,E:\DATN\dataframe\train_file\41.txt,"Mỗi phương pháp kể trên đều có những ưu, nhược điểm của riêng nó như:"
3051,E:\DATN\dataframe\train_file\41.txt,Phương pháp tạo vùng (mask) của Adversarial Scene Editing cho kết quả tốt hơn với việc sử dụng YOLO.
3052,E:\DATN\dataframe\train_file\41.txt,Bằng chứng là các vùng bị xoá sẽ nhỏ hơn thay vì một ô vuông như bài toán Person Remover.
3053,E:\DATN\dataframe\train_file\41.txt,Kết quả khi sử dụng mask rõ ràng tốt hơn.
3054,E:\DATN\dataframe\train_file\41.txt,Sử dụng 2 model riêng biệt như bài toán Person Remover lại có vẻ tốt cho việc cải tiến.
3055,E:\DATN\dataframe\train_file\41.txt,Dễ dàng có thể đào tạo lại để có kết quả tốt 1 trong 2 model.
3056,E:\DATN\dataframe\train_file\41.txt,"Từ những điểm này, mình xin đề xuất phương pháp tiếp cận mới, lấy được các ưu điểm của 2 phương pháp trên."
3057,E:\DATN\dataframe\train_file\41.txt,Đó là:
3058,E:\DATN\dataframe\train_file\41.txt,"Sử dụng DeepLabv3 hoặc FCN để Phân vùng ảnh, hình dáng chi tiết của mọi đối tượng có trong ảnh."
3059,E:\DATN\dataframe\train_file\41.txt,"Sau đó sử dụng thuật toán Candy để sinh ra Edge, tiền xử lý để vẽ lại mask những object cần xoá."
3060,E:\DATN\dataframe\train_file\41.txt,"Cuối cùng, chạy tất cả qua Image Inpainting (model được chọn là EdgeConnect, để lấp đầy vùng cần xoá, ảnh đầu ra không còn chứa các đối tượng mình mong muốn mà nhìn vẫn rất tự nhiên."
3061,E:\DATN\dataframe\train_file\41.txt,Cách giải quyết bài toán
3062,E:\DATN\dataframe\train_file\41.txt,"Vì những mô hình Image Segmentation như DeepLabV3, FCN, ... đã quá quen thuộc rồi nên mình xin phép không đề cập đến, mà đi thẳng vào phần chính của chúng ta."
3063,E:\DATN\dataframe\train_file\41.txt,Mô hình EdgeConnect
3064,E:\DATN\dataframe\train_file\41.txt,Ý tưởng của mô hình
3065,E:\DATN\dataframe\train_file\41.txt,"“Lines first, color next” hiểu theo nghĩa đơn giản đó là đường nét trước, màu sắc tiếp theo."
3066,E:\DATN\dataframe\train_file\41.txt,"Đây là cách mà các nghệ sĩ làm việc, tạo nên bức tranh của mình."
3067,E:\DATN\dataframe\train_file\41.txt,"Rõ ràng, để hoàn thành một tác phẩm, người nghệ sĩ sẽ phải tạo phác thảo bố cục cho bức ảnh trước."
3068,E:\DATN\dataframe\train_file\41.txt,"Các cạnh, đường đóng vai trò quan trọng tạo dựng không gian, hình dạng của đối tượng trong cảnh."
3069,E:\DATN\dataframe\train_file\41.txt,"Từ điều đó, tác giả của mô hình tin rằng: mô hình cải thiện và tạo ra các chi tiết tốt, trước hết cần cải thiện cấu trúc hình ảnh thông qua cạnh của nó."
3070,E:\DATN\dataframe\train_file\41.txt,"Việc tạo cạnh, là một nhiệm vụ dễ dàng hơn so với các nhiệm vụ khác."
3071,E:\DATN\dataframe\train_file\41.txt,"Hình 5: Input đầu vào, tạo cạnh và kết quả của mạng."
3072,E:\DATN\dataframe\train_file\41.txt,Kiến trúc của mô hình
3073,E:\DATN\dataframe\train_file\41.txt,Mô hình EdgeConnect được chia thành hai phần:
3074,E:\DATN\dataframe\train_file\41.txt,Edge Generation: tập trung việc tạo các cạnh ảo ở các vùng missing pixel.
3075,E:\DATN\dataframe\train_file\41.txt,"(như bức ảnh giữa hình 5 - phần màu đen là được vẽ bằng Canny Edge Detector, phần màu xanh là do Edge Generation sinh ra)"
3076,E:\DATN\dataframe\train_file\41.txt,Image Completion: sử dụng các cạnh ảo và ước tính cường độ pixel RGB cho các vùng missing pixel để sinh ra 1 ảnh hoàn chỉnh.
3077,E:\DATN\dataframe\train_file\41.txt,Hình 6: Kiến trúc của mô hình EdgeConnect.
3078,E:\DATN\dataframe\train_file\41.txt,"Về chi tiết cách xây dựng mô hình, hàm loss và training đánh giá, tác giả cũng đã nói rõ trong paper, bạn nào hứng thú có thể đọc tìm hiểu nhá!"
3079,E:\DATN\dataframe\train_file\41.txt,"Ngoài ra, về các chỉ số đánh giá tác giả sử dụng trong paper, hay xa hơn là cho các bài toán Image Generation, mình cũng đã có một bài viết trên viblo nói về phần này 😁"
3080,E:\DATN\dataframe\train_file\41.txt,Link bài ở đây nhá:
3081,E:\DATN\dataframe\train_file\41.txt,2.2.Xây dựng bài toán automatic object removal
3082,E:\DATN\dataframe\train_file\41.txt,Hình 7:Hướng giải quyết bài toán Xóa vật thử tự động.
3083,E:\DATN\dataframe\train_file\41.txt,Trình tự thực hiện như sau:
3084,E:\DATN\dataframe\train_file\41.txt,"Đầu tiên, cho một ảnh bất kỳ chứa đối tượng cần xóa (ví dụ hình 6 là mình muốn xóa người trong hình)"
3085,E:\DATN\dataframe\train_file\41.txt,"Tiếp theo, chạy qua mô hình DeepLabV3 hoặc FCN để ra được một mask như hình (các bạn cũng có thể chọn các mô hình khác để thay thế, sở dĩ mình chọn vì nó có sẵn trong Torchvision của Pytorch, chỉ cần lôi ra dùng thôi 😁)"
3086,E:\DATN\dataframe\train_file\41.txt,"Tiếp đến, xử lý output của mô hình segment: tạo mask mới chỉ chứa mỗi object cần xóa, tạo ảnh xám, tạo ảnh chứa cạnh."
3087,E:\DATN\dataframe\train_file\41.txt,"Cuối cùng, cho chạy qua mô hình EdgeConnect gồm 2 phần Edge Generator và Image Completion (như hình 6)"
3088,E:\DATN\dataframe\train_file\41.txt,"Kết quả, sẽ tạo ra một bức ảnh mới đã hoàn toàn xóa người 😋."
3089,E:\DATN\dataframe\train_file\41.txt,2.3.Thực nghiệm
3090,E:\DATN\dataframe\train_file\41.txt,"Sau khi đã xây dựng xong, và đây là kết quả mình test với một số ảnh:"
3091,E:\DATN\dataframe\train_file\41.txt,"Tuy đã giải quyết được khá nhiều vấn đề của bài toán Image Generation, nhưng thời gian xử lý còn khá là lâu, khoảng 25-35s."
3092,E:\DATN\dataframe\train_file\41.txt,"Điều này, có thể cải thiện bằng việc thay đổi mô hình phần segment, chuyển mô hình EdgeConnect về dạng TensorRT, ..."
3093,E:\DATN\dataframe\train_file\41.txt,"Bài toán chỉ có thể xoá được đối tượng trong ảnh, còn cụ thể đối tượng đó là gì thì chưa xoá được (ví dụ cùng là 1 bức ảnh có 2 người, bài toán mới chỉ giải quyết vấn đề xoá người, còn chưa giải quyết vấn đề chỉ xoá 1 trong 2 người)."
3094,E:\DATN\dataframe\train_file\41.txt,Tự động xoá vật thể là một chủ đề còn khá mới mẻ trong lĩnh vực AI nói chung và Computer Vision nói riêng.
3095,E:\DATN\dataframe\train_file\41.txt,Mình đã tiến hành trình bày và giải quyết từng nội dung như sau:
3096,E:\DATN\dataframe\train_file\41.txt,"Giới thiệu về bài toán Tự động xoá vật thể trong ảnh, một vài công trình liên quan."
3097,E:\DATN\dataframe\train_file\41.txt,"Cùng với đó, đề xuất phương pháp tiếp cận và hướng giải quyết vấn đề."
3098,E:\DATN\dataframe\train_file\41.txt,"Giới thiệu sơ qua về mô hình EdgeConnect (ý tưởng, kiến trúc mô hình)"
3099,E:\DATN\dataframe\train_file\41.txt,"Xây dựng bài toán Object Removal, kết quả thực nghiệm mà mình thu được."
3100,E:\DATN\dataframe\train_file\41.txt,Tài liệu tham khảo
3101,E:\DATN\dataframe\train_file\41.txt,"Rakshith Shetty, Mario Fritz, and Bernt Schiele."
3102,E:\DATN\dataframe\train_file\41.txt,“Adversarial Scene Editing: Automatic Object Removal from Weak Supervision”.
3103,E:\DATN\dataframe\train_file\41.txt,In: NeurIPS.
3104,E:\DATN\dataframe\train_file\41.txt,Javier Gamazo.
3105,E:\DATN\dataframe\train_file\41.txt,“Person Remover: People removal in images using Pix2Pix and YOLO”.
3106,E:\DATN\dataframe\train_file\41.txt,In: 2019.
3107,E:\DATN\dataframe\train_file\41.txt,"Kamyar Nazeri, Eric Ng, Tony Joseph, Faisal Z. Qureshi, Mehran Ebrahimi, “EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning,” Proc."
3108,E:\DATN\dataframe\train_file\41.txt,"International Conference on Computer Vision (ICCV), 2019."
3109,E:\DATN\dataframe\train_file\42.txt,How Does Programming Language Help in AI Development?
3110,E:\DATN\dataframe\train_file\42.txt,"So, did you hear that Facebook is now Meta?"
3111,E:\DATN\dataframe\train_file\42.txt,"Well, of course, you did."
3112,E:\DATN\dataframe\train_file\42.txt,Whom am I kidding?
3113,E:\DATN\dataframe\train_file\42.txt,"But you had a little bit of idea of that, but you actually don’t know what all this metaverse and Artificial intelligence and all that stuff work like."
3114,E:\DATN\dataframe\train_file\42.txt,"Before we jump into that let me tell you that it is worth jumping into this, and trust me that you are going to love this article."
3115,E:\DATN\dataframe\train_file\42.txt,You can not even imagine what could be possible with AI-powered tools and Artificial intelligence development by .
3116,E:\DATN\dataframe\train_file\42.txt,There are numerous opportunities and vast possibilities to explore in this field.
3117,E:\DATN\dataframe\train_file\42.txt,"I am not exaggerating but in marketing, there are so many AI-powered tools and technologies that can make your work very easy."
3118,E:\DATN\dataframe\train_file\42.txt,"Well, It’s one of the benefits of Artificial intelligence."
3119,E:\DATN\dataframe\train_file\42.txt,can be useful in many ways.
3120,E:\DATN\dataframe\train_file\42.txt,So why don’t you try to develop an AI-powered tool?
3121,E:\DATN\dataframe\train_file\42.txt,Not lying you can make a hell of money with that thing.
3122,E:\DATN\dataframe\train_file\42.txt,"But first of all, you will need to understand what kind of programming languages you need to build an Artificial Intelligence."
3123,E:\DATN\dataframe\train_file\42.txt,Well more specifically let me introduce some of the Programming languages to build an AI.
3124,E:\DATN\dataframe\train_file\42.txt,Wait do you know what AI is?
3125,E:\DATN\dataframe\train_file\42.txt,So you will need to know that first.
3126,E:\DATN\dataframe\train_file\42.txt,What the Hell is Artificial intelligence
3127,E:\DATN\dataframe\train_file\42.txt,"Artificial intelligence particularly depends on an Intelligent machine, or you can say that it means a literal intelligent machine that can solve any particular problem."
3128,E:\DATN\dataframe\train_file\42.txt,You will be wrong if you say that you’ve never witnessed artificial intelligence.
3129,E:\DATN\dataframe\train_file\42.txt,"People don’t believe without proof, so let me tell you this, did you ever talk with Alexa, Siri, or Google, well what do you call it?"
3130,E:\DATN\dataframe\train_file\42.txt,It is artificial intelligence at your fingertips sir.
3131,E:\DATN\dataframe\train_file\42.txt,3 Best Programming languages to Build an AI
3132,E:\DATN\dataframe\train_file\42.txt,Python is a high-level programming language.
3133,E:\DATN\dataframe\train_file\42.txt,Which is used for general purposes.
3134,E:\DATN\dataframe\train_file\42.txt,Developers like this language because of its particular benefits of it.
3135,E:\DATN\dataframe\train_file\42.txt,"First of all, it is well equipped and has a simple syntax."
3136,E:\DATN\dataframe\train_file\42.txt,Not to mention its high maintainability.
3137,E:\DATN\dataframe\train_file\42.txt,The best benefit of python is that you will get to handle high-level projects that will be friendly to handle.
3138,E:\DATN\dataframe\train_file\42.txt,Machine learning is that part of Artificial intelligence that helps them to make algorithms.
3139,E:\DATN\dataframe\train_file\42.txt,So which is the most popular framework of Python?
3140,E:\DATN\dataframe\train_file\42.txt,Before revealing its name let’s discuss its benefits.
3141,E:\DATN\dataframe\train_file\42.txt,"Well, it is an open-source machine learning library."
3142,E:\DATN\dataframe\train_file\42.txt,"It is non-other than TensorFlow, yes it is the best framework of Python."
3143,E:\DATN\dataframe\train_file\42.txt,"With the help of Python, TensorFlow can train deep neural networks."
3144,E:\DATN\dataframe\train_file\42.txt,There are so many libraries on this list.
3145,E:\DATN\dataframe\train_file\42.txt,Let me name you some of them.
3146,E:\DATN\dataframe\train_file\42.txt,Machine learning is not the only field where you can use this library.
3147,E:\DATN\dataframe\train_file\42.txt,You can also use this library in .
3148,E:\DATN\dataframe\train_file\42.txt,Which is indeed used to maintain mathematical expression.
3149,E:\DATN\dataframe\train_file\42.txt,It’s a whole different topic.
3150,E:\DATN\dataframe\train_file\42.txt,Sure we are going to discuss that but at some other time.
3151,E:\DATN\dataframe\train_file\42.txt,Python is the easiest language and you will be stunned by its benefits.
3152,E:\DATN\dataframe\train_file\42.txt,"Talking about AI, Lisp is one of the oldest programming languages in circulation for the development of AI."
3153,E:\DATN\dataframe\train_file\42.txt,"Actually, Lisp is the short form of list processing."
3154,E:\DATN\dataframe\train_file\42.txt,"Well, List Processing is not the only thing done by the Lisp."
3155,E:\DATN\dataframe\train_file\42.txt,But surely it is one of its applications.
3156,E:\DATN\dataframe\train_file\42.txt,Lisp originated in 1958.
3157,E:\DATN\dataframe\train_file\42.txt,"Thanks to John McCarthy, the language got high on performance and now it is able to address the problems of Artificial intelligence."
3158,E:\DATN\dataframe\train_file\42.txt,This all happened in mere 4 years of its origination.
3159,E:\DATN\dataframe\train_file\42.txt,I mean McCarthy helped Lisp in 1962.
3160,E:\DATN\dataframe\train_file\42.txt,"Well, developers do not prefer the language that much."
3161,E:\DATN\dataframe\train_file\42.txt,Because it has a complicated syntax and difficult libraries.
3162,E:\DATN\dataframe\train_file\42.txt,Although there are some projects in which Lisp can be a great choice of adopting a programming language.
3163,E:\DATN\dataframe\train_file\42.txt,Rapid Prototype
3164,E:\DATN\dataframe\train_file\42.txt,It has dynamic object creation
3165,E:\DATN\dataframe\train_file\42.txt,Modifies programs as data
3166,E:\DATN\dataframe\train_file\42.txt,Has garbage collection
3167,E:\DATN\dataframe\train_file\42.txt,"Java, there is no one who has not heard this name."
3168,E:\DATN\dataframe\train_file\42.txt,"Well, I heard it and I know pretty much about it."
3169,E:\DATN\dataframe\train_file\42.txt,"So, let me give that knowledge to you."
3170,E:\DATN\dataframe\train_file\42.txt,You can use java on any platform from anywhere.
3171,E:\DATN\dataframe\train_file\42.txt,"Well, you can do this with the virtual machine."
3172,E:\DATN\dataframe\train_file\42.txt,"The developers of android can work with Kotlin, also Java is a native language for ."
3173,E:\DATN\dataframe\train_file\42.txt,There is nothing new about this and every mobile application developer knows that AI can be very profitable and is one of the best application development trends.
3174,E:\DATN\dataframe\train_file\42.txt,"Java does not only work for android app development, it has its own library to do natural language processing."
3175,E:\DATN\dataframe\train_file\42.txt,You can also check out the libraries mentioned below.
3176,E:\DATN\dataframe\train_file\42.txt,Deep Java Library
3177,E:\DATN\dataframe\train_file\42.txt,Java has an object-oriented design and it is much easier to work with.
3178,E:\DATN\dataframe\train_file\42.txt,The bottom line is that you can build an AI-powered tool on your own but you will have to have a knowledge of all kinds of programming languages.
3179,E:\DATN\dataframe\train_file\42.txt,"Well, the list is long, but these three are languages that are the most relevant to building AI tools and technology."
3180,E:\DATN\dataframe\train_file\42.txt,So why don’t you try to learn one of them and build a tool that can help everyone?
3181,E:\DATN\dataframe\train_file\42.txt,by Top App Development Companies - one of the top AI development companies.
3182,E:\DATN\dataframe\train_file\43.txt,Machine learning (Học máy) là một ứng dụng của trí tuệ nhân tạo (AI) cung cấp cho các hệ thống khả năng tự động học hỏi và cải thiện từ kinh nghiệm mà không cần được lập trình rõ ràng.
3183,E:\DATN\dataframe\train_file\43.txt,Một trong những phần khó trong Học máy là đánh giá hiệu suất của Mô hình.
3184,E:\DATN\dataframe\train_file\43.txt,Vậy làm cách nào để đo lường sự thành công của một mô hình học máy?
3185,E:\DATN\dataframe\train_file\43.txt,Làm thế nào chúng ta biết khi nào nên dừng việc đào tạo và đánh giá và gọi nó là tốt?
3186,E:\DATN\dataframe\train_file\43.txt,Và Nên chọn số liệu nào để đánh giá mô hình?
3187,E:\DATN\dataframe\train_file\43.txt,"Trong Bài viết này, chúng tôi sẽ cố gắng giải đáp những điều này."
3188,E:\DATN\dataframe\train_file\43.txt,Một khía cạnh quan trọng của các thước đo đánh giá là khả năng phân biệt giữa các kết quả của mô hình.
3189,E:\DATN\dataframe\train_file\43.txt,Đánh giá giúp bạn hiểu thêm về Mô hình của mình.
3190,E:\DATN\dataframe\train_file\43.txt,Nó cho biết liệu mô hình của bạn đã ghi nhớ hay đã học.
3191,E:\DATN\dataframe\train_file\43.txt,"Điều này rất quan trọng nếu mô hình của bạn chỉ ghi nhớ thay vì học, mô hình sẽ chỉ hoạt động tốt đối với dữ liệu đã được huấn luyện và làm cho mô hình không hiệu quả."
3192,E:\DATN\dataframe\train_file\43.txt,Để đảm bảo rằng mô hình của bạn biết được điều quan trọng là sử dụng nhiều số liệu đánh giá để đánh giá mô hình.
3193,E:\DATN\dataframe\train_file\43.txt,Bởi vì một mô hình có thể hoạt động tốt khi sử dụng một số liệu đánh giá trong khi hiệu suất có thể giảm đối với một số liệu đánh giá khác.
3194,E:\DATN\dataframe\train_file\43.txt,Việc sử dụng nhiều chỉ số đánh giá là rất quan trọng trong việc đảm bảo rằng mô hình của bạn đang hoạt động chính xác và tối ưu.
3195,E:\DATN\dataframe\train_file\43.txt,Overfitting và Underfitting là hai nguyên nhân lớn nhất dẫn đến hiệu suất kém của các thuật toán học máy.
3196,E:\DATN\dataframe\train_file\43.txt,Overfitting: Xảy ra khi Mô hình hoạt động tốt đối với một tập hợp dữ liệu cụ thể (Dữ liệu đã biết) và do đó có thể không phù hợp với dữ liệu bổ sung (Dữ liệu không xác định).
3197,E:\DATN\dataframe\train_file\43.txt,Underfitting: Xảy ra khi mô hình không thể nắm bắt đầy đủ cấu trúc cơ bản của dữ liệu.
3198,E:\DATN\dataframe\train_file\43.txt,Tổng quát hóa: đề cập đến mức độ áp dụng của các khái niệm được học bởi một mô hình học máy đối với các ví dụ cụ thể mà mô hình không nhìn thấy khi nó đang học.
3199,E:\DATN\dataframe\train_file\43.txt,"Có các số liệu khác nhau cho các nhiệm vụ phân loại, hồi quy, xếp hạng, phân cụm, mô hình hóa chủ đề, v.v."
3200,E:\DATN\dataframe\train_file\44.txt,"Data Repository là một thuật ngữ chung được sử dụng để chỉ nơi lưu trữ dữ liệu đã được thu thập, tổ chức và cô lập để nó có thể được sử dụng cho các hoạt động kinh doanh hoặc khai thác để báo cáo và phân tích dữ liệu."
3201,E:\DATN\dataframe\train_file\44.txt,Nó có thể là một cơ sở hạ tầng cơ sở dữ liệu nhỏ hoặc lớn với một hoặc nhiều cơ sở dữ liệu để quản lý và lưu trữ các bộ dữ liệu.
3202,E:\DATN\dataframe\train_file\44.txt,"Trong bài viết này, mình sẽ cung cấp một cái nhìn tổng quan về các loại Data Repository khác nhau."
3203,E:\DATN\dataframe\train_file\44.txt,"Cơ sở dữ liệu là một tập hợp dữ liệu hoặc thông tin, được thiết kế để lưu trữ, tìm kiếm và truy xuất và sửa đổi dữ liệu và một hệ thống quản lý cơ sở dữ liệu, hoặc DBMS, là một tập hợp các chương trình tạo và duy trì cơ sở dữ liệu."
3204,E:\DATN\dataframe\train_file\44.txt,"Nó cho phép bạn lưu trữ, sửa đổi và trích xuất thông tin từ cơ sở dữ liệu bằng cách sử dụng một chức năng gọi là truy vấn."
3205,E:\DATN\dataframe\train_file\44.txt,"Mặc dù Database và DBMS khác nhau, tuy nhiên các thuật ngữ thường được sử dụng thay thế cho nhau."
3206,E:\DATN\dataframe\train_file\44.txt,Có nhiều loại cơ sở dữ liệu khác nhau.
3207,E:\DATN\dataframe\train_file\44.txt,"Một số yếu tố ảnh hưởng đến việc lựa chọn cơ sở dữ liệu, chẳng hạn như kiểu dữ liệu và cấu trúc, cơ chế truy vấn, yêu cầu độ trễ, tốc độ giao dịch và độ lớn dữ liệu, ở đây mình sẽ giới thiệu hai loại cơ sở dữ liệu chính là cơ sở dữ liệu liên quan và không quan hệ."
3208,E:\DATN\dataframe\train_file\44.txt,"Cơ sở dữ liệu quan hệ, còn được gọi là RDBMS, xây dựng dựa trên các nguyên tắc tổ chức của các tệp phẳng, với dữ liệu được tổ chức thành một định dạng bảng với các hàng và cột theo cấu trúc và lược đồ được xác định rõ."
3209,E:\DATN\dataframe\train_file\44.txt,"Tuy nhiên, không giống như các tệp phẳng, RDBMS được tối ưu hóa cho các hoạt động dữ liệu và truy vấn liên quan đến nhiều bảng và khối lượng dữ liệu lớn hơn nhiều."
3210,E:\DATN\dataframe\train_file\44.txt,"Ngôn ngữ truy vấn có cấu trúc, hoặc SQL, là ngôn ngữ truy vấn tiêu chuẩn cho cơ sở dữ liệu quan hệ."
3211,E:\DATN\dataframe\train_file\44.txt,"Cơ sở dữ liệu phi quan hệ, còn được gọi là NoSQL."
3212,E:\DATN\dataframe\train_file\44.txt,"Các cơ sở dữ liệu phi quan hệ đã xuất hiện để đáp ứng với khối lượng, tính đa dạng và tốc độ mà dữ liệu được tạo ra ngày nay, chủ yếu bị ảnh hưởng bởi những tiến bộ trong điện toán đám mây, Internet of things và sự phát triển social media."
3213,E:\DATN\dataframe\train_file\44.txt,"Được xây dựng để tối ưu tốc độ, tính linh hoạt và quy mô lớn, cơ sở dữ liệu phi quan hệ cho phép lưu trữ dữ liệu theo kiểu không có lược đồ hoặc không có ràng buộc."
3214,E:\DATN\dataframe\train_file\44.txt,NoSQL được sử dụng rộng rãi để xử lý dữ liệu lớn.
3215,E:\DATN\dataframe\train_file\44.txt,"Kho dữ liệu hoạt động như một kho lưu trữ trung tâm hợp nhất thông tin đến từ các nguồn khác nhau và hợp nhất thông qua quy trình trích xuất, chuyển đổi và tải, còn được gọi là quy trình ETL (Extract - Transform - Load), thành một cơ sở dữ liệu toàn diện cho phân tích và trí thông minh kinh doanh."
3216,E:\DATN\dataframe\train_file\44.txt,"Ở cấp độ cao, quy trình ETL giúp bạn trích xuất dữ liệu từ các nguồn dữ liệu khác nhau, chuyển đổi dữ liệu thành trạng thái sạch và có thể sử dụng và tải dữ liệu vào Data Warehouse của doanh nghiệp."
3217,E:\DATN\dataframe\train_file\44.txt,"Liên quan đến Data Warehouse là các khái niệm về Data Mart và Data Lake, mình sẽ đề cập sau"
3218,E:\DATN\dataframe\train_file\45.txt,"Data sources có thể là là data nội bộ hoặc data từ bên ngoài của tổ chức, chúng có thể là nguồn dữ liệu chính, phụ hoặc đến từ tổ chức thứ."
3219,E:\DATN\dataframe\train_file\45.txt,Dữ liệu chính đề cập đến dữ liệu thu được trực tiếp từ nguồn của bạn.
3220,E:\DATN\dataframe\train_file\45.txt,"Nó có thể là từ source nội bộ như dữ liệu từ các ứng dụng tổ chức, CRM, nhân sự hoặc quy trình làm việc."
3221,E:\DATN\dataframe\train_file\45.txt,"Nó cũng có thể bao gồm dữ liệu bạn thu thập trực tiếp thông qua các cuộc khảo sát, phỏng vấn, thảo luận, quan sát."
3222,E:\DATN\dataframe\train_file\45.txt,"Dữ liệu phụ đề cập đến thông tin được lấy từ các nguồn hiện có, chẳng hạn như cơ sở dữ liệu bên ngoài, bài báo nghiên cứu, ấn phẩm, tài liệu training và internet, hồ sơ tài chính có sẵn dưới dạng dữ liệu công cộng."
3223,E:\DATN\dataframe\train_file\45.txt,"Nó có thể bao gồm dữ liệu được thu thập thông qua các cuộc khảo sát, phỏng vấn, thảo luận, quan sát được thực hiện bên ngoài."
3224,E:\DATN\dataframe\train_file\45.txt,Dữ liệu của bên thứ ba là dữ liệu bạn đã mua từ các nhà tổng hợp thu thập dữ liệu từ nhiều nguồn khác nhau và kết hợp nó thành các bộ dữ liệu đầy đủ hoàn toàn cho mục đích bán dữ liệu.
3225,E:\DATN\dataframe\train_file\45.txt,"Database có thể là nguồn dữ liệu của primary data, second data và third-party data."
3226,E:\DATN\dataframe\train_file\45.txt,"Hầu hết các tổ chức có các ứng dụng nội bộ để quản lý quy trình, quy trình làm việc và khách hàng của họ."
3227,E:\DATN\dataframe\train_file\45.txt,Web là một nguồn dữ liệu phong phú có sẵn trong phạm vi công cộng.
3228,E:\DATN\dataframe\train_file\45.txt,"Các trang social media như Facebook, Twitter, Google, YouTube."
3229,E:\DATN\dataframe\train_file\45.txt,Instagram đang ngày càng được sử dụng nhiều hơn trong mục đích tìm nguồn dữ liệu và ý kiến của người dùng.
3230,E:\DATN\dataframe\train_file\45.txt,Các doanh nghiệp đang sử dụng các nguồn dữ liệu này để có những insight cho tổ chức của mình.
3231,E:\DATN\dataframe\train_file\45.txt,"Dữ liệu cảm biến được sản xuất bởi các thiết bị đeo được, tòa nhà thông minh, thành phố thông minh, điện thoại thông minh, thiết bị y tế, thậm chí các thiết bị gia dụng là một nguồn dữ liệu được sử dụng rộng rãi."
3232,E:\DATN\dataframe\train_file\45.txt,"Trao đổi dữ liệu là nguồn dữ liệu của bên thứ 3 liên quan đến việc chia sẻ dữ liệu giữa các nhà cung cấp dữ liệu và người tiêu dùng dữ liệu, cá nhân, tổ chức và chính phủ có thể là nhà cung cấp dữ liệu và người tiêu dùng dữ liệu."
3233,E:\DATN\dataframe\train_file\45.txt,"Dữ liệu được trao đổi có thể bao gồm dữ liệu đến từ các ứng dụng kinh doanh, thiết bị cảm biến, hoạt động truyền thông xã hội, dữ liệu vị trí hoặc dữ liệu hành vi của người tiêu dùng."
3234,E:\DATN\dataframe\train_file\45.txt,Các cuộc khảo sát thu thập thông tin thông qua các câu hỏi được phân phối cho một nhóm người được chọn.
3235,E:\DATN\dataframe\train_file\45.txt,Ví dụ: đánh giá sự quan tâm của các khách hàng hiện tại trong việc chi tiêu cho một phiên bản cập nhật của sản phẩm.
3236,E:\DATN\dataframe\train_file\45.txt,Khảo sát có thể thông qua web hoặc dựa trên giấy.
3237,E:\DATN\dataframe\train_file\45.txt,"Dữ liệu điều tra dân số cũng là một nguồn thường được sử dụng để thu thập dữ liệu hộ gia đình, chẳng hạn như sự giàu có và thu nhập hoặc dữ liệu dân số, ví dụ."
3238,E:\DATN\dataframe\train_file\45.txt,Các cuộc phỏng vấn là nguồn để thu thập dữ liệu.
3239,E:\DATN\dataframe\train_file\45.txt,"Ví dụ, một cuộc phỏng vấn được thực hiện để hiểu những thách thức hàng ngày mà một giám đốc dịch vụ khách hàng phải đối mặt."
3240,E:\DATN\dataframe\train_file\45.txt,Các cuộc phỏng vấn có thể được thông qua web hoặc quan sát trực tiếp.
3241,E:\DATN\dataframe\train_file\45.txt,"Các nghiên cứu bao gồm giám sát người tham gia trong một môi trường cụ thể hoặc trong khi thực hiện một nhiệm vụ, công việc cụ thể."
3242,E:\DATN\dataframe\train_file\45.txt,"Ví dụ, quan sát người dùng điều hướng một trang web thương mại điện tử để đánh giá."
3243,E:\DATN\dataframe\train_file\45.txt,"Họ có thể dễ dàng tìm thấy sản phẩm và thực hiện dữ liệu mua hàng từ các cuộc khảo sát, phỏng vấn, quan sát."
3244,E:\DATN\dataframe\train_file\45.txt,"Các nghiên cứu có thể có sẵn dưới dạng dữ liệu chính, phụ và bên thứ 3.Thảo luận nhóm là kỹ thuật thu thập dữ liệu phổ biến nhất trong nghiên cứu định tính."
3245,E:\DATN\dataframe\train_file\45.txt,Các dữ liệu được thu thập thông qua một cuộc thảo luận giữa một nhóm đối tượng nghiên cứu dưới sự dẫn dắt của người điều khiển chương trình (moderator).
3246,E:\DATN\dataframe\train_file\45.txt,Yêu cầu cần có của một moderator như sau: Có khả năng quan sát và kỹ năng tiếp xúc Hướng mục tiêu vào dàn bài thảo luận Có khả năng dẫn dắt và là người biết lắng nghe.
3247,E:\DATN\dataframe\train_file\45.txt,"Xóa bỏ các thành kiến, đồng cảm và khuyến khích các thành viên khác đưa ra ý kiến."
3248,E:\DATN\dataframe\train_file\45.txt,Nguồn dữ liệu chưa bao giờ năng động và đa dạng như ngày nay.
3249,E:\DATN\dataframe\train_file\45.txt,Việc bổ sung dữ liệu chính của bạn với các nguồn dữ liệu phụ và bên thứ 3 có thể giúp bạn khám phá các vấn đề và giải pháp theo những cách mới và có ý nghĩa.
3250,E:\DATN\dataframe\train_file\45.txt,Tham khảo từ khoá học Data Analyst của IBM
3251,E:\DATN\dataframe\train_file\46.txt,Observer is a behavioral design pattern that lets you define a subscription mechanism to notify multiple objects about any events that happen to the object they’re observing.
3252,E:\DATN\dataframe\train_file\46.txt,"Observer là một behavioral design pattern ( mẫu thiết kế hành vi), cho phép chúng ta xác định cơ chế subcription để notify cho nhiều đối tượng về bất kỳ sự kiện nào xảy ra với đối tượng mà họ observing."
3253,E:\DATN\dataframe\train_file\46.txt,Hãy tưởng tượng chúng ta đang thiết kế tính năng subcribe cho trang blog của mình.
3254,E:\DATN\dataframe\train_file\46.txt,Cho phép các người xem theo dõi các bài viết mới mà họ quan tâm.
3255,E:\DATN\dataframe\train_file\46.txt,Người xem có thể ghé thăm trang blog mỗi ngày để kiểm tra xem có bài viết mới hay không.
3256,E:\DATN\dataframe\train_file\46.txt,"Nhưng nhiều khi vài ngày hoặc vài tuần ta mới viết bài mới , điều đó khiến các lần kiểm tra của người xem trở nên vô nghĩa."
3257,E:\DATN\dataframe\train_file\46.txt,"Hoặc cách khác, chúng ta sẽ gửi hàng loạt email cho tất cả người xem mỗi khi có bài viết mới, điều này sẽ tiết kiệm thời gian của người xem."
3258,E:\DATN\dataframe\train_file\46.txt,"Nhưng đồng thời, nó cũng sẽ làm khó chịu những người xem khác - những người xem không quan tâm đến các bài viết mới của mình."
3259,E:\DATN\dataframe\train_file\46.txt,"Cả 2 hướng tiếp cận trên đều gây lãng phí tài nguyên (thời gian) để kiểm tra trạng thái ( tính sẵn có) của bài viết, hoặc lãng phí tài nguyên (chi phí vận hành) để thông báo dư thừa cho người xem."
3260,E:\DATN\dataframe\train_file\46.txt,"Để giải quyết vấn đề này, Observer patterns được đưa ra."
3261,E:\DATN\dataframe\train_file\46.txt,Observer mô tả cơ chế observing (quan sát) trạng thái sẵn có của các bài viết mới (publisher) để notify (thông báo) chỉ cho các người xem (subscriber) đã đăng ký theo dõi blog của mình.
3262,E:\DATN\dataframe\train_file\46.txt,Publisher phát hành các sự kiện mà các object khác quan tâm.
3263,E:\DATN\dataframe\train_file\46.txt,Những sự kiện này xảy ra khi Publisher thay đổi trạng thái hoặc thực hiện một số hành vi.
3264,E:\DATN\dataframe\train_file\46.txt,Publisher có các phương thức cho phép Subcriber mới tham gia (.Subcribe) và Subscriber hiện tại rời khỏi danh sách (.UnSubscribe).
3265,E:\DATN\dataframe\train_file\46.txt,"Khi một sự kiện mới xảy ra, Publisher xem qua danh sách đăng ký (listSubcriber) và gọi phương thức thông báo được khai báo trong interface của từng người đăng ký."
3266,E:\DATN\dataframe\train_file\46.txt,(subscriber[i].Update) Subscriber khai báo giao diện thông báo (Subscriber interface).
3267,E:\DATN\dataframe\train_file\46.txt,"Trong hầu hết các trường hợp, nó bao gồm một phương pháp duy nhất .Update."
3268,E:\DATN\dataframe\train_file\46.txt,Phương thức có thể có một số tham số (params) cho phép Publisher chuyển một số thông tin sự kiện.
3269,E:\DATN\dataframe\train_file\46.txt,Các Subcriber thực hiện một số hành động để phản hồi lại các thông báo (notify) do Publisher đưa ra.
3270,E:\DATN\dataframe\train_file\46.txt,Tất cả các Class này phải triển khai cùng một interface.
3271,E:\DATN\dataframe\train_file\46.txt,"Thông thường, subscriber cần một số thông tin theo ngữ cảnh (context data) để xử lý .Update một cách chính xác."
3272,E:\DATN\dataframe\train_file\46.txt,"Vì lý do này, Publisher thường chuyển một số context data làm tham số của phương thức .Update."
3273,E:\DATN\dataframe\train_file\46.txt,"Publisher có thể chuyển chính nó làm tham số, cho phép Subscriber lấy trực tiếp bất kỳ dữ liệu bắt buộc nào."
3274,E:\DATN\dataframe\train_file\46.txt,Client tạo các object Publisher và Subsciber riêng biệt và sau đó đăng ký Subsciber cho các cập nhật của Publisher
3275,E:\DATN\dataframe\train_file\47.txt,Giám sát mọi thứ với Python Exporter cho Prometheus
3276,E:\DATN\dataframe\train_file\47.txt,Python Exporter là gì?
3277,E:\DATN\dataframe\train_file\47.txt,Python exporter là công cụ được viết bằng Python giúp chúng ta chạy một web server chứa các thông số chúng ta đã thu thập được và biểu thị chúng ta theo một cách để Prometheus có thể hiểu được.
3278,E:\DATN\dataframe\train_file\47.txt,"Nếu các bạn chưa biết thì Prometheus là công cụ giám sát có hỗ trợ 2 cơ chế pull và push để lấy dữ liệu (metrics) từ các ứng dụng về, thường được kết hợp với Grafana để visualize lên thành các biểu đồ."
3279,E:\DATN\dataframe\train_file\47.txt,"Nếu như các bạn đã quen với việc dựng các service database, web server, queue,... thì chắc không còn lạ gì với những công cụ giúp chúng ta xuất ra các thông số (metrics), dễ dàng có thể tìm thấy các công cụ được xây dựng sẵn cho từng ứng dụng với từ khóa ""Tên ứng dụng + exporter""."
3280,E:\DATN\dataframe\train_file\47.txt,"Tuy nhiên các công cụ được xây dựng sẵn thì sẽ xây dựng cho nhưng mô hình chung để đáp ứng được nhiều nhất những trường hợp sử dụng, nên việc thiếu đi những thông số đặc thù cho từng trường hợp là rất hay gặp."
3281,E:\DATN\dataframe\train_file\47.txt,Chính vì vậy Python Exporter được sinh ra để giải quyết vấn đề này.
3282,E:\DATN\dataframe\train_file\47.txt,Các kiểu dữ liệu của Prometheus
3283,E:\DATN\dataframe\train_file\47.txt,Bởi vì Prometheus cung cấp các kiểu dữ liệu khác nhau để mô hình hóa trên các biểu đồ khác nhau nên chúng ta sẽ cần biết kiểu dữ liệu nào mình sẽ xử dụng cho từng trường hợp.
3284,E:\DATN\dataframe\train_file\47.txt,"Tại thời điểm này tháng 5/2022 thì Prometheus đang hỗ trợ 6 kiểu dữ liệu chính, ta sẽ đi qua từng kiểu dữ liệu với các cách sử dụng tương ứng:"
3285,E:\DATN\dataframe\train_file\47.txt,"Đây là kiểu metric hoạt động như một bộ đếm, chỉ có thể tăng mà không thể giảm."
3286,E:\DATN\dataframe\train_file\47.txt,Khi exporter chạy lại từ đầu thì giá trị của counter sẽ bị reset về 0.
3287,E:\DATN\dataframe\train_file\47.txt,Khi expose metric counter ra ngoài thì tên sẽ được tự động thêm vế '_total ' vào phía sau
3288,E:\DATN\dataframe\train_file\47.txt,from prometheus_client import Counter
3289,E:\DATN\dataframe\train_file\47.txt,"c = Counter('my_failures', 'Description of counter')"
3290,E:\DATN\dataframe\train_file\47.txt,c.inc()     # Increment by 1
3291,E:\DATN\dataframe\train_file\47.txt,c.inc(1.6)  # Increment by given value
3292,E:\DATN\dataframe\train_file\47.txt,"Đây là kiểu metric có thể tăng hoặc giảm, phù hợp set cho các thông tin có thể tăng giảm liên tục như số request/s"
3293,E:\DATN\dataframe\train_file\47.txt,from prometheus_client import Gauge
3294,E:\DATN\dataframe\train_file\47.txt,"g = Gauge('my_inprogress_requests', 'Description of gauge')"
3295,E:\DATN\dataframe\train_file\47.txt,g.inc()      # Increment by 1
3296,E:\DATN\dataframe\train_file\47.txt,g.dec(10)    # Decrement by given value
3297,E:\DATN\dataframe\train_file\47.txt,g.set(4.2)   # Set to a given value
3298,E:\DATN\dataframe\train_file\47.txt,"Summary sẽ dùng để theo dõi độ trễ của một task, thời gian hoàn thành task đó."
3299,E:\DATN\dataframe\train_file\47.txt,from prometheus_client import Summary
3300,E:\DATN\dataframe\train_file\47.txt,"s = Summary('request_latency_seconds', 'Description of summary')"
3301,E:\DATN\dataframe\train_file\47.txt,s.observe(4.7)    # Observe 4.7 (seconds in this case)
3302,E:\DATN\dataframe\train_file\47.txt,Kiểu metric này sẽ theo dõi size và số lượng của sự kiện.
3303,E:\DATN\dataframe\train_file\47.txt,Ví dụ ta muốn tìm số phần trăm hoặc số lượng request đến Server mất hơn 1s để trả lời.
3304,E:\DATN\dataframe\train_file\47.txt,from prometheus_client import Histogram
3305,E:\DATN\dataframe\train_file\47.txt,"h = Histogram('request_latency_seconds', 'Description of histogram')"
3306,E:\DATN\dataframe\train_file\47.txt,h.observe(4.7)    # Observe 4.7 (seconds in this case)
3307,E:\DATN\dataframe\train_file\47.txt,Kiểu metric là kiểu key - value thường dùng để lưu trữ thông tin về target
3308,E:\DATN\dataframe\train_file\47.txt,from prometheus_client import Info
3309,E:\DATN\dataframe\train_file\47.txt,"i = Info('my_build_version', 'Description of info')"
3310,E:\DATN\dataframe\train_file\47.txt,"i.info({'version': '1.2.3', 'buildhost': 'foo@bar'})"
3311,E:\DATN\dataframe\train_file\47.txt,Kiểu metric này được dùng để theo dõi trạng thái của service hoặc task
3312,E:\DATN\dataframe\train_file\47.txt,from prometheus_client import Enum
3313,E:\DATN\dataframe\train_file\47.txt,"e = Enum('my_task_state', 'Description of enum',"
3314,E:\DATN\dataframe\train_file\47.txt,"        states=['starting', 'running', 'stopped'])"
3315,E:\DATN\dataframe\train_file\47.txt,"Như vậy chúng ta đã có những hiểu biết về kiểu dữ liệu của Prometheus, bây giờ chúng ta sẽ thực hành để giám sát một số thông tin."
3316,E:\DATN\dataframe\train_file\47.txt,"Nội dung thực nghiệm: Thực hiện giám sát số người chơi đang online thông qua API có sẵn, thực hiện chạy web server ở port 8192 để expose ra metrics cho server Prometheus."
3317,E:\DATN\dataframe\train_file\47.txt,Từ server Prometheus sẽ cấu hình để pull dữ liệu từ web server trên.
3318,E:\DATN\dataframe\train_file\47.txt,Sử dụng Grafana để visualize data từ prometheus Server.
3319,E:\DATN\dataframe\train_file\47.txt,Nội dung API trả về:
3320,E:\DATN\dataframe\train_file\47.txt,Import một vài thư viện cần thiết
3321,E:\DATN\dataframe\train_file\47.txt,"import requests, time"
3322,E:\DATN\dataframe\train_file\47.txt,"from prometheus_client import start_http_server, Gauge"
3323,E:\DATN\dataframe\train_file\47.txt,"Khai báo các biến global, ở đây vì để giám sát số lượng người chơi có tính chất tăng giảm nên ta chọn kiểu dữ liệu Gauge"
3324,E:\DATN\dataframe\train_file\47.txt,"keys = [""sbSdp7SUm7eDk5ey326bztEvMbjTAasdsIByF"", ""vfKIyG9GZDBqZE0I3D555555kzIftu6mIjCD"", ""vLLifd1524ORZYJyZQPHEpbfUai7878zQA""]"
3325,E:\DATN\dataframe\train_file\47.txt,"total_player = Gauge('total_players', 'All players in 3 servers')"
3326,E:\DATN\dataframe\train_file\47.txt,"pvp_player = Gauge('pvp_players', 'Number of players in PVP server')"
3327,E:\DATN\dataframe\train_file\47.txt,"pve_player = Gauge('pve_players', 'Number of players in PVE server')"
3328,E:\DATN\dataframe\train_file\47.txt,"vanilla_player = Gauge('vanilla_players', 'Number of players in Vanilla server')"
3329,E:\DATN\dataframe\train_file\47.txt,Thêm đối tượng Server
3330,E:\DATN\dataframe\train_file\47.txt,class Server:
3331,E:\DATN\dataframe\train_file\47.txt,"    def __init__(self, name, player_online, max_players):"
3332,E:\DATN\dataframe\train_file\47.txt,        self.name = name
3333,E:\DATN\dataframe\train_file\47.txt,        self.player_online = player_online
3334,E:\DATN\dataframe\train_file\47.txt,        self.max_players = max_players
3335,E:\DATN\dataframe\train_file\47.txt,"Viết hàm giúp lấy thông tin từ API, set dữ liệu lấy được từ API vào biến player đã khai báo"
3336,E:\DATN\dataframe\train_file\47.txt,def get_server_info():
3337,E:\DATN\dataframe\train_file\47.txt,"    data = requests.get(""https://unturned-servers.net/api/?object=servers&element=detail&key="" + keys[0]).json()"
3338,E:\DATN\dataframe\train_file\47.txt,"    serverPVE = Server(data[""name""], data[""players""], data[""maxplayers""])"
3339,E:\DATN\dataframe\train_file\47.txt,"    data = requests.get(""https://unturned-servers.net/api/?object=servers&element=detail&key="" + keys[1]).json()"
3340,E:\DATN\dataframe\train_file\47.txt,"    serverPVP = Server(data[""name""], data[""players""], data[""maxplayers""])"
3341,E:\DATN\dataframe\train_file\47.txt,"    data = requests.get(""https://unturned-servers.net/api/?object=servers&element=detail&key="" + keys[2]).json()"
3342,E:\DATN\dataframe\train_file\47.txt,"    serverVanilla = Server(data[""name""], data[""players""], data[""maxplayers""])"
3343,E:\DATN\dataframe\train_file\47.txt,    total_player.set(serverPVE.player_online + serverPVP.player_online + serverVanilla.player_online)
3344,E:\DATN\dataframe\train_file\47.txt,"Khởi động http server tại port 8192, viết thêm vòng while để liên tục cập nhật số players mới mỗi 1 phút"
3345,E:\DATN\dataframe\train_file\47.txt,def main():
3346,E:\DATN\dataframe\train_file\47.txt,    while True:
3347,E:\DATN\dataframe\train_file\47.txt,Toàn bộ code có nội dung như sau:
3348,E:\DATN\dataframe\train_file\47.txt,"import requests, time"
3349,E:\DATN\dataframe\train_file\47.txt,"from prometheus_client import start_http_server, Gauge"
3350,E:\DATN\dataframe\train_file\47.txt,"keys = [""sbSdp7SUm7eDk5ey326bztEvMbjTA15IByF"", ""vfKIyG9GZDBqZE0I3DwGoSLkzIftu6mIjCD"", ""vLLifd1524ORZYJyZQPHEpbfUaigppczQA""]"
3351,E:\DATN\dataframe\train_file\47.txt,"total_player = Gauge('total_players', 'All players in 3 servers')"
3352,E:\DATN\dataframe\train_file\47.txt,"pvp_player = Gauge('pvp_players', 'Number of players in PVP server')"
3353,E:\DATN\dataframe\train_file\47.txt,"pve_player = Gauge('pve_players', 'Number of players in PVE server')"
3354,E:\DATN\dataframe\train_file\47.txt,"vanilla_player = Gauge('vanilla_players', 'Number of players in Vanilla server')"
3355,E:\DATN\dataframe\train_file\47.txt,class Server:
3356,E:\DATN\dataframe\train_file\47.txt,"    def __init__(self, name, player_online, max_players):"
3357,E:\DATN\dataframe\train_file\47.txt,        self.name = name
3358,E:\DATN\dataframe\train_file\47.txt,        self.player_online = player_online
3359,E:\DATN\dataframe\train_file\47.txt,        self.max_players = max_players
3360,E:\DATN\dataframe\train_file\47.txt,def get_server_info():
3361,E:\DATN\dataframe\train_file\47.txt,"    data = requests.get(""https://unturned-servers.net/api/?object=servers&element=detail&key="" + keys[0]).json()"
3362,E:\DATN\dataframe\train_file\47.txt,"    serverPVE = Server(data[""name""], data[""players""], data[""maxplayers""])"
3363,E:\DATN\dataframe\train_file\47.txt,"    data = requests.get(""https://unturned-servers.net/api/?object=servers&element=detail&key="" + keys[1]).json()"
3364,E:\DATN\dataframe\train_file\47.txt,"    serverPVP = Server(data[""name""], data[""players""], data[""maxplayers""])"
3365,E:\DATN\dataframe\train_file\47.txt,"    data = requests.get(""https://unturned-servers.net/api/?object=servers&element=detail&key="" + keys[2]).json()"
3366,E:\DATN\dataframe\train_file\47.txt,"    serverVanilla = Server(data[""name""], data[""players""], data[""maxplayers""])"
3367,E:\DATN\dataframe\train_file\47.txt,    total_player.set(serverPVE.player_online + serverPVP.player_online + serverVanilla.player_online)
3368,E:\DATN\dataframe\train_file\47.txt,def main():
3369,E:\DATN\dataframe\train_file\47.txt,    while True:
3370,E:\DATN\dataframe\train_file\47.txt,"Khá đơn giản đúng không, sau khi chạy thì truy cập địa chỉ localhost:8192 ta có thông tin như sau:"
3371,E:\DATN\dataframe\train_file\47.txt,"ở gần cuối ta đã thấy thông tin về số players (pve_players, pvp_players, vanilla_players) như kỳ vọng."
3372,E:\DATN\dataframe\train_file\47.txt,Cấu hình Prometheus
3373,E:\DATN\dataframe\train_file\47.txt,Tại file config prometheus.yml ta thêm job để scrape dữ liệu từ web server đã chạy như hình:
3374,E:\DATN\dataframe\train_file\47.txt,Sau đó ta cần restart service Prometheus để cập nhật job mới.
3375,E:\DATN\dataframe\train_file\47.txt,Bạn có thể check xem Prometheus đã cào được dữ liệu về chưa ở dashboard thường chạy port 9090.
3376,E:\DATN\dataframe\train_file\47.txt,Vẽ biểu đồ trên Grafana
3377,E:\DATN\dataframe\train_file\47.txt,"Ta chọn tạo thêm dashboard nếu chưa có dashboard, sau đó chọn add Panel ở góc trên bên phải"
3378,E:\DATN\dataframe\train_file\47.txt,Tiếp tục ta điền vào metrics cần visualize như hình:
3379,E:\DATN\dataframe\train_file\47.txt,Apply thêm vào Dashboard có sẵn xong nhìn cũng tạm ổn )))
3380,E:\DATN\dataframe\train_file\47.txt,Bài viết đã giúp các bạn viết tool bằng python expose ra bất cứ thông tin nào bạn muốn monitor thông qua Prometheus.
3381,E:\DATN\dataframe\train_file\47.txt,Hy vọng bài viết này sẽ giúp bạn phần nào đó trong công việc.
3382,E:\DATN\dataframe\train_file\47.txt,Tài liệu tham khảo
3383,E:\DATN\dataframe\train_file\48.txt,Xây dựng Base kết nối API
3384,E:\DATN\dataframe\train_file\48.txt,Bài toán đặt ra
3385,E:\DATN\dataframe\train_file\48.txt,"Với Laravel, Bạn có thể dùng nhiều mô hình phát triển phổ biến như dưới đây:"
3386,E:\DATN\dataframe\train_file\48.txt,Dùng blade kết hợp html/css/js làm frontend và dữ liệu truy vấn trực tiếp mà không thông qua API.
3387,E:\DATN\dataframe\train_file\48.txt,"Trường hợp này, chung source."
3388,E:\DATN\dataframe\train_file\48.txt,"Dùng balde làm frontend, phần xử lý giao diện tích hợp Vuejs/Reactjs/Angular."
3389,E:\DATN\dataframe\train_file\48.txt,"Laravel dùng để làm backend, viết api."
3390,E:\DATN\dataframe\train_file\48.txt,"Trường hợp này, chung source."
3391,E:\DATN\dataframe\train_file\48.txt,Dùng Vuejs/Reactjs/Angular làm frontend và dùng Laravel làm backend (api).
3392,E:\DATN\dataframe\train_file\48.txt,Frontend và backend là 2 source độc lập nhau.
3393,E:\DATN\dataframe\train_file\48.txt,Frontend lấy dữ liệu thông qua API.
3394,E:\DATN\dataframe\train_file\48.txt,Là trường hợp 2&3 nhưng api không xử lý logic nghiệp vụ trên code đó mà chỉ là trạm trung chuyển để gọi api gateway tập trung khác.
3395,E:\DATN\dataframe\train_file\48.txt,"Với trường hợp 4, câu hỏi đặt ra là làm thế nào quản lý được các api gọi sang api gateway tập trung ở server khác?"
3396,E:\DATN\dataframe\train_file\48.txt,Trong Laravel vấn đề trên có thể được giải quyết thông qua việc tạo ra class base để quản lý kết nối đến api gateway.
3397,E:\DATN\dataframe\train_file\48.txt,Bước 1: Tạo thư mục App/Services
3398,E:\DATN\dataframe\train_file\48.txt,Cấu trúc thư mục và file
3399,E:\DATN\dataframe\train_file\48.txt,Trong đó:
3400,E:\DATN\dataframe\train_file\48.txt,app/Services/BaseCallService.php: file chứa xử lý kết nối sang api gateway
3401,E:\DATN\dataframe\train_file\48.txt,app/Services/ServiceMapping.php: file chứa khai báo thông tin các api
3402,E:\DATN\dataframe\train_file\48.txt,app/Services/Api/StudentService.php: file xử lý thông tin sinh viên
3403,E:\DATN\dataframe\train_file\48.txt,app/Services/Api/TeacherService.php: file xử lý thông tin giáo viên
3404,E:\DATN\dataframe\train_file\48.txt,Bước 2: Code các file đã tạo
3405,E:\DATN\dataframe\train_file\48.txt,File BaseCallService
3406,E:\DATN\dataframe\train_file\48.txt,Đây sẽ là file xử lý kết nối sang api gateway.
3407,E:\DATN\dataframe\train_file\48.txt,"File này sẽ đón nhận params truyền vào, url (base url và endpoint), method cần gọi."
3408,E:\DATN\dataframe\train_file\48.txt,Các thông tin được cấu hình trong file ServiceMapping và gọi chúng ra thông qua hàm getMapping().
3409,E:\DATN\dataframe\train_file\48.txt,Dữ liệu sẽ được trả về trong hàm getData().
3410,E:\DATN\dataframe\train_file\48.txt,"Ngoài ra, nếu cần ngay dữ liệu giả thì gọi hàm getFakeData()."
3411,E:\DATN\dataframe\train_file\48.txt,namespace App\Services;
3412,E:\DATN\dataframe\train_file\48.txt,use GuzzleHttp\Client;
3413,E:\DATN\dataframe\train_file\48.txt,use Illuminate\Support\Facades\Http;
3414,E:\DATN\dataframe\train_file\48.txt,class BaseCallService
3415,E:\DATN\dataframe\train_file\48.txt,    protected $params = [];
3416,E:\DATN\dataframe\train_file\48.txt,    protected $headers = [];
3417,E:\DATN\dataframe\train_file\48.txt,    protected $isDummy = true;
3418,E:\DATN\dataframe\train_file\48.txt,    protected $endPoint;
3419,E:\DATN\dataframe\train_file\48.txt,    protected $method;
3420,E:\DATN\dataframe\train_file\48.txt,    protected $baseUrl;
3421,E:\DATN\dataframe\train_file\48.txt,    public function __construct($params)
3422,E:\DATN\dataframe\train_file\48.txt,    public function getData()
3423,E:\DATN\dataframe\train_file\48.txt,        if ($this->isDummy) {
3424,E:\DATN\dataframe\train_file\48.txt,            return $this->getFakeData();
3425,E:\DATN\dataframe\train_file\48.txt,            $client = new Client(['base_uri' => $this->baseUrl]);
3426,E:\DATN\dataframe\train_file\48.txt,            $response = $client->request(
3427,E:\DATN\dataframe\train_file\48.txt,"                    'form_params' => $this->params,"
3428,E:\DATN\dataframe\train_file\48.txt,"                    'timeout' => 100,"
3429,E:\DATN\dataframe\train_file\48.txt,                    'connect_timeout' => 100
3430,E:\DATN\dataframe\train_file\48.txt,            $body = $response->getBody();
3431,E:\DATN\dataframe\train_file\48.txt,            $contents = json_decode($body->getContents());
3432,E:\DATN\dataframe\train_file\48.txt,            $responseData = (array)$contents;
3433,E:\DATN\dataframe\train_file\48.txt,"                if(!array_key_exists('errorCode', $responseData)) $responseData['errorCode'] = 500;"
3434,E:\DATN\dataframe\train_file\48.txt,"                if(!array_key_exists('message', $responseData)) $responseData['message'] = '';"
3435,E:\DATN\dataframe\train_file\48.txt,"                if(!array_key_exists('data', $responseData)) $responseData['data'] = [];"
3436,E:\DATN\dataframe\train_file\48.txt,        } catch (\Exception $e) {
3437,E:\DATN\dataframe\train_file\48.txt,"                'status' => 1,"
3438,E:\DATN\dataframe\train_file\48.txt,"                'errorCode' => 500,"
3439,E:\DATN\dataframe\train_file\48.txt,"                'message' => $e->getMessage(),"
3440,E:\DATN\dataframe\train_file\48.txt,"                'message_dev' => 'Lỗi ngoại lệ khi call api gateway',"
3441,E:\DATN\dataframe\train_file\48.txt,                'data' => null
3442,E:\DATN\dataframe\train_file\48.txt,        return $responseData;
3443,E:\DATN\dataframe\train_file\48.txt,    public function getFakeData()
3444,E:\DATN\dataframe\train_file\48.txt,"            'status' => 0,"
3445,E:\DATN\dataframe\train_file\48.txt,"            'errorCode' => 0,"
3446,E:\DATN\dataframe\train_file\48.txt,"            'message' => 'Thành công',"
3447,E:\DATN\dataframe\train_file\48.txt,"            'message_dev' => 'Lấy danh sách thành công',"
3448,E:\DATN\dataframe\train_file\48.txt,"                    'id' => 1,"
3449,E:\DATN\dataframe\train_file\48.txt,"                    'fullname' => 'Phạm Văn Đoan',"
3450,E:\DATN\dataframe\train_file\48.txt,"                    'age' => 38,"
3451,E:\DATN\dataframe\train_file\48.txt,    private function getMap()
3452,E:\DATN\dataframe\train_file\48.txt,        $mappings = ServiceMapping::getMapping();
3453,E:\DATN\dataframe\train_file\48.txt,        $data = $mappings[get_class($this)];
3454,E:\DATN\dataframe\train_file\48.txt,        $data['params']['appCode'] = 'WEBPORTAL';
3455,E:\DATN\dataframe\train_file\48.txt,        $this->baseUrl = $data['baseURL'];
3456,E:\DATN\dataframe\train_file\48.txt,        $this->endPoint = !empty($this->endPoint) ?
3457,E:\DATN\dataframe\train_file\48.txt,$this->endPoint : $data['endPoint'];
3458,E:\DATN\dataframe\train_file\48.txt,        $this->method = $data['method'];
3459,E:\DATN\dataframe\train_file\48.txt,"        $this->params = array_merge($data['params'], $this->params);"
3460,E:\DATN\dataframe\train_file\48.txt,File ServiceMapping
3461,E:\DATN\dataframe\train_file\48.txt,"File này sẽ cấu hình, khai báo các api cần gọi thông qua cái gọi là service."
3462,E:\DATN\dataframe\train_file\48.txt,"Như vậy, khi cần kết nối đến api gateway nào thì ta sẽ tạo ra file service tương ứng trong thư mục ""app/Services/Api""."
3463,E:\DATN\dataframe\train_file\48.txt,"Sau đó, khai báo thông tin vào đây để ""BaseCallService"" gọi ra để so sánh với service mà client muốn gọi."
3464,E:\DATN\dataframe\train_file\48.txt,namespace App\Services;
3465,E:\DATN\dataframe\train_file\48.txt,use App\Services\Api\StudentService;
3466,E:\DATN\dataframe\train_file\48.txt,use App\Services\Api\TeacherService;
3467,E:\DATN\dataframe\train_file\48.txt,class ServiceMapping
3468,E:\DATN\dataframe\train_file\48.txt,    const EDUPHAM = 'xxx';
3469,E:\DATN\dataframe\train_file\48.txt,    public static function getMapping()
3470,E:\DATN\dataframe\train_file\48.txt,"                'baseURL'  => 'xxx',"
3471,E:\DATN\dataframe\train_file\48.txt,"                'endPoint' => 'api/v1/students',"
3472,E:\DATN\dataframe\train_file\48.txt,"                'method'   => 'GET',"
3473,E:\DATN\dataframe\train_file\48.txt,                    'lang' => 'vi'
3474,E:\DATN\dataframe\train_file\48.txt,"                'baseURL'  => 'xxx',"
3475,E:\DATN\dataframe\train_file\48.txt,"                'endPoint' => 'api/v1/teachers',"
3476,E:\DATN\dataframe\train_file\48.txt,"                'method'   => 'GET',"
3477,E:\DATN\dataframe\train_file\48.txt,                    'lang' => 'vi'
3478,E:\DATN\dataframe\train_file\48.txt,File StudentService
3479,E:\DATN\dataframe\train_file\48.txt,File này chuyển tiếp params do client truyền vào để nhận về kết quả từ api gateway thông qua hàm getData() ở class base.
3480,E:\DATN\dataframe\train_file\48.txt,namespace App\Services\Api;
3481,E:\DATN\dataframe\train_file\48.txt,use App\Services\BaseCallService;
3482,E:\DATN\dataframe\train_file\48.txt,class StudentService extends BaseCallService
3483,E:\DATN\dataframe\train_file\48.txt,    protected $params = [];
3484,E:\DATN\dataframe\train_file\48.txt,    protected $isDummy = false;
3485,E:\DATN\dataframe\train_file\48.txt,    public function __construct($params)
3486,E:\DATN\dataframe\train_file\48.txt,        $this->params = $params;
3487,E:\DATN\dataframe\train_file\48.txt,    public function getFakeData()
3488,E:\DATN\dataframe\train_file\48.txt,"            'status' => 0,"
3489,E:\DATN\dataframe\train_file\48.txt,"            'errorCode' => 0,"
3490,E:\DATN\dataframe\train_file\48.txt,"            'message' => 'Thành công',"
3491,E:\DATN\dataframe\train_file\48.txt,"            'message_dev' => 'Lấy danh sách Sinh viên thành công',"
3492,E:\DATN\dataframe\train_file\48.txt,"                    'id' => 1,"
3493,E:\DATN\dataframe\train_file\48.txt,"                    'fullname' => 'Phạm Văn Đoan',"
3494,E:\DATN\dataframe\train_file\48.txt,"                    'age' => 38,"
3495,E:\DATN\dataframe\train_file\48.txt,"                    'id' => 2,"
3496,E:\DATN\dataframe\train_file\48.txt,"                    'fullname' => 'Phạm Văn Đán',"
3497,E:\DATN\dataframe\train_file\48.txt,"                    'age' => 37,"
3498,E:\DATN\dataframe\train_file\48.txt,"                    'id' => 3,"
3499,E:\DATN\dataframe\train_file\48.txt,"                    'fullname' => 'Phạm Văn Đôn',"
3500,E:\DATN\dataframe\train_file\48.txt,"                    'age' => 36,"
3501,E:\DATN\dataframe\train_file\48.txt,File TeacherService
3502,E:\DATN\dataframe\train_file\48.txt,File này chuyển tiếp params do client truyền vào để nhận về kết quả từ api gateway thông qua hàm getData() ở class base.
3503,E:\DATN\dataframe\train_file\48.txt,namespace App\Services\Api;
3504,E:\DATN\dataframe\train_file\48.txt,use App\Services\BaseCallService;
3505,E:\DATN\dataframe\train_file\48.txt,class TeacherService extends BaseCallService
3506,E:\DATN\dataframe\train_file\48.txt,    protected $params = [];
3507,E:\DATN\dataframe\train_file\48.txt,    protected $isDummy = false;
3508,E:\DATN\dataframe\train_file\48.txt,    public function __construct($params)
3509,E:\DATN\dataframe\train_file\48.txt,        $this->params = $params;
3510,E:\DATN\dataframe\train_file\48.txt,    public function getFakeData()
3511,E:\DATN\dataframe\train_file\48.txt,"            'status' => 0,"
3512,E:\DATN\dataframe\train_file\48.txt,"            'errorCode' => 0,"
3513,E:\DATN\dataframe\train_file\48.txt,"            'message' => 'Thành công',"
3514,E:\DATN\dataframe\train_file\48.txt,"            'message_dev' => 'Lấy danh sách Giáo viên thành công',"
3515,E:\DATN\dataframe\train_file\48.txt,"                    'id' => 1,"
3516,E:\DATN\dataframe\train_file\48.txt,"                    'fullname' => 'Phạm Văn Đoan',"
3517,E:\DATN\dataframe\train_file\48.txt,"                    'age' => 38,"
3518,E:\DATN\dataframe\train_file\48.txt,"                    'id' => 2,"
3519,E:\DATN\dataframe\train_file\48.txt,"                    'fullname' => 'Phạm Văn Đán',"
3520,E:\DATN\dataframe\train_file\48.txt,"                    'age' => 37,"
3521,E:\DATN\dataframe\train_file\48.txt,Bước 2: Sử dụng
3522,E:\DATN\dataframe\train_file\48.txt,Tạo route
3523,E:\DATN\dataframe\train_file\48.txt,File: routes/api.php
3524,E:\DATN\dataframe\train_file\48.txt,"Route::get('/students', 'Api\StudentController@listing');"
3525,E:\DATN\dataframe\train_file\48.txt,"Route::get('/teachers', 'Api\TeacherController@listing');"
3526,E:\DATN\dataframe\train_file\48.txt,Tạo controller StudentController
3527,E:\DATN\dataframe\train_file\48.txt,File : app/Http/Controllers/Api/StudentController.php.
3528,E:\DATN\dataframe\train_file\48.txt,Ở controller chỉ cần khởi tạo mới đối tượng service tương ứng rồi truyền tham số vào.
3529,E:\DATN\dataframe\train_file\48.txt,namespace App\Http\Controllers\Api;
3530,E:\DATN\dataframe\train_file\48.txt,use App\Http\Controllers\Controller;
3531,E:\DATN\dataframe\train_file\48.txt,use Illuminate\Http\Request;
3532,E:\DATN\dataframe\train_file\48.txt,use App\Services\Api\StudentService;
3533,E:\DATN\dataframe\train_file\48.txt,class StudentController extends Controller
3534,E:\DATN\dataframe\train_file\48.txt,    public function listing()
3535,E:\DATN\dataframe\train_file\48.txt,        $response = (new StudentService([
3536,E:\DATN\dataframe\train_file\48.txt,"            'keyword' => 'StudentService',"
3537,E:\DATN\dataframe\train_file\48.txt,"            'page_index' => 1,"
3538,E:\DATN\dataframe\train_file\48.txt,"            'page_size' => 10,"
3539,E:\DATN\dataframe\train_file\48.txt,        return response()->json($response);
3540,E:\DATN\dataframe\train_file\48.txt,Tạo controller TeacherController
3541,E:\DATN\dataframe\train_file\48.txt,File : app/Http/Controllers/Api/TeacherController.php.
3542,E:\DATN\dataframe\train_file\48.txt,Ở controller chỉ cần khởi tạo mới đối tượng service tương ứng rồi truyền tham số vào.
3543,E:\DATN\dataframe\train_file\48.txt,namespace App\Http\Controllers\Api;
3544,E:\DATN\dataframe\train_file\48.txt,use App\Http\Controllers\Controller;
3545,E:\DATN\dataframe\train_file\48.txt,use Illuminate\Http\Request;
3546,E:\DATN\dataframe\train_file\48.txt,use App\Services\Api\TeacherService;
3547,E:\DATN\dataframe\train_file\48.txt,class TeacherController extends Controller
3548,E:\DATN\dataframe\train_file\48.txt,    public function listing()
3549,E:\DATN\dataframe\train_file\48.txt,        $response = (new TeacherService([
3550,E:\DATN\dataframe\train_file\48.txt,"            'keyword' => 'TeacherService',"
3551,E:\DATN\dataframe\train_file\48.txt,"            'page_index' => 1,"
3552,E:\DATN\dataframe\train_file\48.txt,"            'page_size' => 10,"
3553,E:\DATN\dataframe\train_file\48.txt,        return response()->json($response);
3554,E:\DATN\dataframe\train_file\48.txt,Bước 4: Test postman
3555,E:\DATN\dataframe\train_file\48.txt,Chạy các url tương ứng với phương thức GET để xem kết quả.
3556,E:\DATN\dataframe\train_file\48.txt,"Hy vọng, bài viết nhỏ này, sẽ giúp các Bạn tổ chức code được khoa học hơn, gọn gàng hơn và dễ quản lý kết nối hơn."
3557,E:\DATN\dataframe\train_file\48.txt,Chúc các bạn thành công!
3558,E:\DATN\dataframe\train_file\49.txt,Pythonic là gì?
3559,E:\DATN\dataframe\train_file\49.txt,Khái niệm Pythonic
3560,E:\DATN\dataframe\train_file\49.txt,Pythonic là một Idioms mô tả cách tiếp cận lập trình phù hợp với triết lý sáng lập của ngôn ngữ lập trình Python .
3561,E:\DATN\dataframe\train_file\49.txt,"Có nhiều cách để viết code tương tự nhau trong Python, nhưng có một cách được ưu thích hơn để thực hiện nó."
3562,E:\DATN\dataframe\train_file\49.txt,"Cách ưa thích này được gọi là “pythonic.” Ngược lại, code khó hiểu hoặc đọc giống như một bản phiên âm thô từ một ngôn ngữ lập trình khác được gọi là ""unpythonic""."
3563,E:\DATN\dataframe\train_file\49.txt,Triết lý viết code trong Python
3564,E:\DATN\dataframe\train_file\49.txt,Đẹp đẽ tốt hơn xấu xí
3565,E:\DATN\dataframe\train_file\49.txt,Minh bạch tốt hơn che đậy
3566,E:\DATN\dataframe\train_file\49.txt,Đơn giản tốt hơn phức tạp
3567,E:\DATN\dataframe\train_file\49.txt,Phức tạp tốt hơn rắc rối
3568,E:\DATN\dataframe\train_file\49.txt,Dễ đọc
3569,E:\DATN\dataframe\train_file\49.txt,Chúng ta hãy cùng tham khảo một vài ví dụ dưới đây.
3570,E:\DATN\dataframe\train_file\49.txt,i = 0
3571,E:\DATN\dataframe\train_file\49.txt,while i < mylist_length:
3572,E:\DATN\dataframe\train_file\49.txt,   i += 1
3573,E:\DATN\dataframe\train_file\49.txt,"Mặc dù đoạn code trên hoạt động tốt, nhưng nó không được coi là Pythonic."
3574,E:\DATN\dataframe\train_file\49.txt,Nó không phải là một idiom mà ngôn ngữ Python khuyến khích.
3575,E:\DATN\dataframe\train_file\49.txt,Chúng ta có thể cải thiện nó.
3576,E:\DATN\dataframe\train_file\49.txt,Một idiom điển hình trong Python để tạo tất cả các số trong list sẽ là sử dụng hàm range () được tích hợp sẵn:
3577,E:\DATN\dataframe\train_file\49.txt,for i in range(mylist_length):
3578,E:\DATN\dataframe\train_file\49.txt,"Tuy nhiên, đây vẫn không phải là Pythonic."
3579,E:\DATN\dataframe\train_file\49.txt,"Đây là cách Pythonic, được chính ngôn ngữ khuyến khích:"
3580,E:\DATN\dataframe\train_file\49.txt,for element in mylist:
3581,E:\DATN\dataframe\train_file\49.txt,7 Ví dụ về code pythonic
3582,E:\DATN\dataframe\train_file\49.txt,Hoán đổi giá trị giữa 2 biến
3583,E:\DATN\dataframe\train_file\49.txt,tmp = a
3584,E:\DATN\dataframe\train_file\49.txt,a = b
3585,E:\DATN\dataframe\train_file\49.txt,b = tmp
3586,E:\DATN\dataframe\train_file\49.txt,"a,b = b,a"
3587,E:\DATN\dataframe\train_file\49.txt,Sử dụng list
3588,E:\DATN\dataframe\train_file\49.txt,for i in range(10):
3589,E:\DATN\dataframe\train_file\49.txt,my_list = [i*2 for i in range(10)]
3590,E:\DATN\dataframe\train_file\49.txt,Duyệt mảng có đánh thứ tự
3591,E:\DATN\dataframe\train_file\49.txt,for i in range(len(my_list)):
3592,E:\DATN\dataframe\train_file\49.txt,"    print(i, ""-->"", my_list[i])"
3593,E:\DATN\dataframe\train_file\49.txt,"for i,item in enumerate(my_list):"
3594,E:\DATN\dataframe\train_file\49.txt,"    print(i, ""-->"",item)"
3595,E:\DATN\dataframe\train_file\49.txt,"a, *rest = [1, 2, 3]"
3596,E:\DATN\dataframe\train_file\49.txt,"# a = 1, rest = [2, 3]"
3597,E:\DATN\dataframe\train_file\49.txt,"a, *middle, c = [1, 2, 3, 4]"
3598,E:\DATN\dataframe\train_file\49.txt,"# a = 1, middle = [2, 3], c = 4"
3599,E:\DATN\dataframe\train_file\49.txt,Nối các phần tử trong mảng
3600,E:\DATN\dataframe\train_file\49.txt,"letters = ['s', 'p', 'a', 'm']"
3601,E:\DATN\dataframe\train_file\49.txt,for let in letters:
3602,E:\DATN\dataframe\train_file\49.txt,    s += let
3603,E:\DATN\dataframe\train_file\49.txt,"letters = ['s', 'p', 'a', 'm']"
3604,E:\DATN\dataframe\train_file\49.txt,word = ''.join(letters)
3605,E:\DATN\dataframe\train_file\49.txt,Kiểm tra điều kiện
3606,E:\DATN\dataframe\train_file\49.txt,if attr == True:
3607,E:\DATN\dataframe\train_file\49.txt,    print 'True!'
3608,E:\DATN\dataframe\train_file\49.txt,if attr == None:
3609,E:\DATN\dataframe\train_file\49.txt,    print 'attr is None!'
3610,E:\DATN\dataframe\train_file\49.txt,if attr:
3611,E:\DATN\dataframe\train_file\49.txt,    print 'attr is truthy!'
3612,E:\DATN\dataframe\train_file\49.txt,if not attr:
3613,E:\DATN\dataframe\train_file\49.txt,    print 'attr is falsey!'
3614,E:\DATN\dataframe\train_file\49.txt,if attr is None:
3615,E:\DATN\dataframe\train_file\49.txt,    print 'attr is None!'
3616,E:\DATN\dataframe\train_file\49.txt,Hoạt động của mảng
3617,E:\DATN\dataframe\train_file\49.txt,"a = [3, 4, 5]"
3618,E:\DATN\dataframe\train_file\49.txt,for i in a:
3619,E:\DATN\dataframe\train_file\49.txt,    if i > 4:
3620,E:\DATN\dataframe\train_file\49.txt,"a = [3, 4, 5]"
3621,E:\DATN\dataframe\train_file\49.txt,b = [i for i in a if i > 4]
3622,E:\DATN\dataframe\train_file\49.txt,"b = filter(lambda x: x > 4, a)"
3623,E:\DATN\dataframe\train_file\49.txt,"a = [3, 4, 5]"
3624,E:\DATN\dataframe\train_file\49.txt,for i in range(len(a)):
3625,E:\DATN\dataframe\train_file\49.txt,    a[i] += 3
3626,E:\DATN\dataframe\train_file\49.txt,"a = [3, 4, 5]"
3627,E:\DATN\dataframe\train_file\49.txt,a = [i + 3 for i in a]
3628,E:\DATN\dataframe\train_file\49.txt,"a = map(lambda i: i + 3, a)"
3629,E:\DATN\dataframe\train_file\5.txt,[Data Analysis] Phân tích dữ liệu xổ số miền Bắc
3630,E:\DATN\dataframe\train_file\5.txt,Có lẽ từ xổ số hay lottery đã không còn là cụm từ xa lạ đổi với mỗi người chúng ta.
3631,E:\DATN\dataframe\train_file\5.txt,Thậm chí dân chơi còn có một câu khá nổi tiếng ví von như sau:
3632,E:\DATN\dataframe\train_file\5.txt,Lô đề cờ bạc muôn đời thịnh Học hành chăm chỉ vạn kiếp suy
3633,E:\DATN\dataframe\train_file\5.txt,"Nghe mà muốn khóc quá chừng, mình làm Đa ta sai ừn vất vả là thế mà vẫn vạn kiếp suy thì tính sao bây giờ."
3634,E:\DATN\dataframe\train_file\5.txt,Trong một phút yếu lòng mình đã nghĩ đến việc thử phân tích dữ liệu xổ số miền Bắc từ một trang mạng để xem câu tục ngữ trên có thực sự có hiệu quả không.
3635,E:\DATN\dataframe\train_file\5.txt,OK không để mất thời gian của các bạn chúng ta sẽ bắt đầu ngay với một lĩnh vực mới trong khai phá dữ liệu đó chính là tính lô đề.
3636,E:\DATN\dataframe\train_file\5.txt,Let go....
3637,E:\DATN\dataframe\train_file\5.txt,Cơ sở lý thuyết
3638,E:\DATN\dataframe\train_file\5.txt,Nói qua một chút cho các bạn nào chưa hiểu về luật chơi xổ số hay nói chính xác hơn là chơi đề áp dụng trên toàn vịnh Bắc Bộ.
3639,E:\DATN\dataframe\train_file\5.txt,Kết quả đề của một hôm được tính bằng hai chữ số cuối của giải đặc biệt.
3640,E:\DATN\dataframe\train_file\5.txt,Và nếu người chơi đánh trúng thì giải thưởng sẽ là 1 ăn 70.
3641,E:\DATN\dataframe\train_file\5.txt,"Chỉ một luật chơi đơn giản như vậy mà làm cho rất nhiều người say mê đó các bạn ạ. Mình thì không thích những thứ thuộc về may mắn lắm, nói đúng hơn mình thích những thứ gì có thể tính toán được, có bằng chứng khoa học cụ thể."
3642,E:\DATN\dataframe\train_file\5.txt,Chính vì lý do đó nên từ trước đến giờ mình không mấy quan tâm đến việc chơi xổ số (thực ra hồi bé có chơi một lần nhưng bị thua nên không bao giờ chơi nữa :slight_smile:) nhưng tình cờ đọc được một bài viết chia sẻ trên mạng về cách tính toán soi lô đề nên với cái máu của một người thích các con số mình đã quyết định tải thử tập dữ liệu về và phân tích thử.
3643,E:\DATN\dataframe\train_file\5.txt,Các bạn có thể tải về tập dữ liệu này tại .
3644,E:\DATN\dataframe\train_file\5.txt,Thống kê đầy đủ và chi tiết từ năm 2002 đến năm 2017.
3645,E:\DATN\dataframe\train_file\5.txt,Sau khi có dữ liệu rồi chúng ta sẽ tiến hành xử lý chúng nhé
3646,E:\DATN\dataframe\train_file\5.txt,Chuẩn bị dữ liệu
3647,E:\DATN\dataframe\train_file\5.txt,Dữ liệu được tải về dưới dạng file .docx được lưu thành từng bảng cho từng năm.
3648,E:\DATN\dataframe\train_file\5.txt,Các bạn cứ tải hết về theo các link đã cung cấp sẽ thu được một tập dữ liệu như sau:
3649,E:\DATN\dataframe\train_file\5.txt,"Mở thử một file ra thì sẽ thấy mỗi file sẽ được lưu theo một bảng gồm các cột tương ứng với 12 tháng trong một năm, và các dồng tương ứng với các ngày trong một tháng"
3650,E:\DATN\dataframe\train_file\5.txt,Tuy nhiên để thuận tiện cho việc lập trình lấy dữ liệu sau này chúng ta sẽ cần tổng hợp lại dữ liệu này để lưu dưới dạng file xls hoặc csv chẳng hạn.
3651,E:\DATN\dataframe\train_file\5.txt,Rất đơn giản chúng ta chỉ cần copy lần lượt các bảng tại từng file vào trong một editor như  chẳng hạn.
3652,E:\DATN\dataframe\train_file\5.txt,Sau đó chúng ta lưu về thành một file tại local để tiện cho xử lý về sau.
3653,E:\DATN\dataframe\train_file\5.txt,Nếu các bạn lười thu thập có thể dùng sẵn file mà mình đã làm .
3654,E:\DATN\dataframe\train_file\5.txt,OK vậy là đã xong bước chuẩn bị dữ liệu giờ chúng ta sẽ tiếp tục sang bước tiếp theo đó là Tiền xử lý dữ liệu
3655,E:\DATN\dataframe\train_file\5.txt,Tiền xử lý dữ liệu
3656,E:\DATN\dataframe\train_file\5.txt,Sau khi đã thu thập được file dữ liệu rồi chúng ta sẽ tiến hành xử lý chúng.
3657,E:\DATN\dataframe\train_file\5.txt,Quan sát một lát thấy file dữ liệu của chúng ta được lưu dưới dạng bảng và chúng ta sẽ sử dụng một công cụ nào đó để chuyển chúng về dạng array có thể xử lý được.
3658,E:\DATN\dataframe\train_file\5.txt,Chúng ta sẽ sử dụng một thư viện nổi tiếng trong Python đó chính là pandas.
3659,E:\DATN\dataframe\train_file\5.txt,Nó chuyên dùng cho việc xử lý các dữ liệu thuộc dạng bảng.
3660,E:\DATN\dataframe\train_file\5.txt,Một thư viện khác để xử lý dữ liệu số rất nổi tiếng trong Python đó chính là Numpy Chúng ta tiến hành import các thư viện này vào như sau:
3661,E:\DATN\dataframe\train_file\5.txt,import pandas as pd
3662,E:\DATN\dataframe\train_file\5.txt,import numpy as np
3663,E:\DATN\dataframe\train_file\5.txt,Tiếp theo chúng ta sẽ load dữ liệu ra bằng lệnh sau:
3664,E:\DATN\dataframe\train_file\5.txt,file = 'loto.xls'
3665,E:\DATN\dataframe\train_file\5.txt,df = pd.read_excel(file)
3666,E:\DATN\dataframe\train_file\5.txt,Dữ liệu được sinh ra dưới dạng DataFrame như sau:
3667,E:\DATN\dataframe\train_file\5.txt,Quan sát thấy thư viện pandas đang sử dụng bằng số thực.
3668,E:\DATN\dataframe\train_file\5.txt,Chúng ta cần chuyển nó về thành số nguyên
3669,E:\DATN\dataframe\train_file\5.txt,df_matrix = df.as_matrix()
3670,E:\DATN\dataframe\train_file\5.txt,df_matrix = np.int_(df_matrix)
3671,E:\DATN\dataframe\train_file\5.txt,print df_matrix[-1]
3672,E:\DATN\dataframe\train_file\5.txt,Sau khi tiến hành in thử dòng cuối cùng của file dữ liệu thì chúng ta nhận được kết quả như sau:
3673,E:\DATN\dataframe\train_file\5.txt,Loại bỏ missing value
3674,E:\DATN\dataframe\train_file\5.txt,Giá trị -9223372036854775808 tương ứng với những giá trị NaN sau khi convert sang numpy điều này chứng tỏ rằng dữ liệu chúng ta đang bị thiếu hay trong Data Science gọi đó là các missing value chúng ta có một số cách xử lý chúng như sau:
3675,E:\DATN\dataframe\train_file\5.txt,Lấy giá trị trung bình của các giá trị còn lại thay vào missing value
3676,E:\DATN\dataframe\train_file\5.txt,Gán missing value = 0
3677,E:\DATN\dataframe\train_file\5.txt,Sử dụng phương pháp kNN - k Nearest Neighbor tính toán giá trị của missing value
3678,E:\DATN\dataframe\train_file\5.txt,Bỏ qua missing value trong tập dữ liệu
3679,E:\DATN\dataframe\train_file\5.txt,Tuy nhiên đối với dữ liệu của chúng ta là kết quả xổ số là các giá trị thực tế đòi hỏi tính chính xác tuyệt đối nên cách tốt nhất chính là bỏ qua không cần xử lý các giá trị bị thiếu.
3680,E:\DATN\dataframe\train_file\5.txt,Chúng ta quan sát thấy các giá trị bị thiếu tương ứng với các giá trị -9223372036854775808 hay trong trường hợp này là các giá trị âm - vì kết quả xổ số là một số không âm.
3681,E:\DATN\dataframe\train_file\5.txt,Nên chúng ta sẽ dùng một hàm bỏ qua các giá trị thiếu đồng thời xử lý các giá trị xổ số bằng cách lấy 2 chữ số cuổi cùng của giải đặc biệt - chính là số đề như sau:
3682,E:\DATN\dataframe\train_file\5.txt,def checker(d_arr):
3683,E:\DATN\dataframe\train_file\5.txt,    for i in d_arr:
3684,E:\DATN\dataframe\train_file\5.txt,        if i < 0:
3685,E:\DATN\dataframe\train_file\5.txt,            tmp.append(i % 100)
3686,E:\DATN\dataframe\train_file\5.txt,    return tmp
3687,E:\DATN\dataframe\train_file\5.txt,Và cuối cùng hàm load dữ liệu của chúng ta sẽ như sau:
3688,E:\DATN\dataframe\train_file\5.txt,def read_data():
3689,E:\DATN\dataframe\train_file\5.txt,    file = 'loto.xls'
3690,E:\DATN\dataframe\train_file\5.txt,    df = pd.read_excel(file)
3691,E:\DATN\dataframe\train_file\5.txt,    df_matrix = df.as_matrix()
3692,E:\DATN\dataframe\train_file\5.txt,    df_matrix = np.int_(df_matrix)
3693,E:\DATN\dataframe\train_file\5.txt,    df_matrix = [checker(d) for d in df_matrix]
3694,E:\DATN\dataframe\train_file\5.txt,    return np.array(df_matrix)
3695,E:\DATN\dataframe\train_file\5.txt,Trích xuất dòng và cột
3696,E:\DATN\dataframe\train_file\5.txt,"Quan sát dữ liệu của chúng ta cho thấy các hàng sẽ biểu diễn tương ứng với các ngày trong một năm, các cột sẽ biểu diễn tương ứng với các tháng trong một năm."
3697,E:\DATN\dataframe\train_file\5.txt,Chúng ta sẽ viết hai hàm để đọc dữ liệu dạng này
3698,E:\DATN\dataframe\train_file\5.txt,"def get_rows(data, s_row = 0, e_row = 1):"
3699,E:\DATN\dataframe\train_file\5.txt,    return data[s_row:e_row]
3700,E:\DATN\dataframe\train_file\5.txt,"def get_columns(data, s_col = 0, e_col = 12):"
3701,E:\DATN\dataframe\train_file\5.txt,    cols = [np.array(d)[s_col:e_col] for d in data]
3702,E:\DATN\dataframe\train_file\5.txt,    cols = data_concate(cols)
3703,E:\DATN\dataframe\train_file\5.txt,    return cols
3704,E:\DATN\dataframe\train_file\5.txt,Ví dụ như lấy dữ liệu của năm đầu tiên sẽ tương ứng với 31 dòng và 12 cột dữ liệu đầu tiên.
3705,E:\DATN\dataframe\train_file\5.txt,Chúng ta thực hiện như sau:
3706,E:\DATN\dataframe\train_file\5.txt,data = read_data()
3707,E:\DATN\dataframe\train_file\5.txt,"print get_rows(data, 0, 31)"
3708,E:\DATN\dataframe\train_file\5.txt,Chúng ta thấy rằng dữ liệu của chúng ta đang chứa hai chữ số cuối và những giá trị âm tương ứng với các missing value được lưu theo dạng 2d array chúng ta cần chuyển chúng về dạng 1d array và loại bỏ những số âm này đi trước khi xử lý
3709,E:\DATN\dataframe\train_file\5.txt,def data_concate(data):
3710,E:\DATN\dataframe\train_file\5.txt,    concate = np.concatenate(data)
3711,E:\DATN\dataframe\train_file\5.txt,    concate = np.array([num for num in concate if num >= 0])
3712,E:\DATN\dataframe\train_file\5.txt,    return concate
3713,E:\DATN\dataframe\train_file\5.txt,Quay về hàm main chúng ta thay đổi một chút để thấy kết quả
3714,E:\DATN\dataframe\train_file\5.txt,"print data_concate(get_rows(data, 0, 31))"
3715,E:\DATN\dataframe\train_file\5.txt,Và đây chính là toàn bộ các con đề trong năm đầu tiên tức năm 2002.
3716,E:\DATN\dataframe\train_file\5.txt,Chúng ta sẽ thử vẽ đồ thị biểu diễn phân phối của các con số này xem sao nhé.
3717,E:\DATN\dataframe\train_file\5.txt,Biểu diễn dữ liệu bằng đồ thị
3718,E:\DATN\dataframe\train_file\5.txt,Chúng ta sẽ biểu diễn dữ liệu bằng đồ thị với hàm sau:
3719,E:\DATN\dataframe\train_file\5.txt,def plot_data(data):
3720,E:\DATN\dataframe\train_file\5.txt,    counter = Counter(data)
3721,E:\DATN\dataframe\train_file\5.txt,"    labels, values = zip(*counter.items())"
3722,E:\DATN\dataframe\train_file\5.txt,    indexes = np.arange(len(labels))
3723,E:\DATN\dataframe\train_file\5.txt,    width = 0.5
3724,E:\DATN\dataframe\train_file\5.txt,"    plt.bar(indexes, values, width)"
3725,E:\DATN\dataframe\train_file\5.txt,"    plt.xticks(indexes + width * 0.5, labels)"
3726,E:\DATN\dataframe\train_file\5.txt,Với dữ liệu của năm đầu tiên chúng ta hay thử quan sát nhé
3727,E:\DATN\dataframe\train_file\5.txt,Những số đề phần đa xuất hiện khoảng 2 đến 4 lần trong một năm.
3728,E:\DATN\dataframe\train_file\5.txt,Cá biệt có những số xuất hiện chỉ một lần hoặc 8 hay 9 lần những rất ít khi xảy ra.
3729,E:\DATN\dataframe\train_file\5.txt,Kể ra thì cũng đúng với lý thuyết xác suất.
3730,E:\DATN\dataframe\train_file\5.txt,Nếu chúng ta coi việc quay giải xổ số giống như việc chúng ta đang ném ngẫu nhiên 365 hòn đá (tương ứng với 365 ngày trong năm) vào 100 cái nhà tương ứng với các số từ 0 đến 99 thì trung bình chúng ta sẽ có được giá trị của kì vọng như sau:
3731,E:\DATN\dataframe\train_file\5.txt,Trông thì có vẻ ngẫu nhiên đấy nhưng nhỡ đâu có quy luật gì đó trong đây thì sao.
3732,E:\DATN\dataframe\train_file\5.txt,"Thử đào tiếp một chút nữa xem sao nhé các bạn, biết đâu làm tìm thêm được một phương pháp tính lô mới."
3733,E:\DATN\dataframe\train_file\5.txt,Tính toán hàm mục tiêu
3734,E:\DATN\dataframe\train_file\5.txt,Hãy tưởng tượng rằng việc đánh xổ số của ta giống như một bài toán tối ưu tức là làm tăng tối đa giá trị của hàm mục tiêu ở đây tức là tăng tối đa phần thưởng bằng một số phương pháp nào đó.
3735,E:\DATN\dataframe\train_file\5.txt,Như đã đưa ra luật chơi ở phần đầu.
3736,E:\DATN\dataframe\train_file\5.txt,Chúng ta sẽ xây dựng hàm mục tiêu như sau:
3737,E:\DATN\dataframe\train_file\5.txt,"def loto_lost_func(loto_arr, rs = 0, price = 0):"
3738,E:\DATN\dataframe\train_file\5.txt,    total = - price * len(loto_arr)
3739,E:\DATN\dataframe\train_file\5.txt,    if rs in loto_arr:
3740,E:\DATN\dataframe\train_file\5.txt,        total = total + price * 70
3741,E:\DATN\dataframe\train_file\5.txt,    return total
3742,E:\DATN\dataframe\train_file\5.txt,Hàm trên nhận đầu vào gồm các tham số sau:
3743,E:\DATN\dataframe\train_file\5.txt,loto_arr là bảng chứa các con đề bạn đánh trong ngày cần tính
3744,E:\DATN\dataframe\train_file\5.txt,rs là kết quả xổ số (hai chữ số cuổi) của ngày cần tính
3745,E:\DATN\dataframe\train_file\5.txt,price là số tiền bỏ ra cho mỗi con đề.
3746,E:\DATN\dataframe\train_file\5.txt,Hãy chạy thử hàm trên
3747,E:\DATN\dataframe\train_file\5.txt,"print loto_lost_func(loto_arr=[12, 32, 44, 55], rs=22, price=20000)"
3748,E:\DATN\dataframe\train_file\5.txt,trong trường hợp này rs không trùng với bất kì số nào trong loto_arr tức hôm đó bạn không trúng đề và tổng số tiền bạn thu lại là -80000.
3749,E:\DATN\dataframe\train_file\5.txt,Nếu trong trường hợp này bạn trúng và kết quả của bạn sẽ khác
3750,E:\DATN\dataframe\train_file\5.txt,"print loto_lost_func(loto_arr=[12, 32, 44, 55], rs=12, price=20000)"
3751,E:\DATN\dataframe\train_file\5.txt,Trường hợp này bạn đã được lãi 1320000 do trúng số đề 12.
3752,E:\DATN\dataframe\train_file\5.txt,Khá là thú vị phải không.
3753,E:\DATN\dataframe\train_file\5.txt,Nhưng một vấn đề là làm cách nào để có thể tìm ra được loto_arr tức là các số cần đánh trong ngày hôm nay để có thể có xác suất trúng cao nhất.
3754,E:\DATN\dataframe\train_file\5.txt,Chúng ta hãy cùng nhau xem xét tiếp các trường hợp sau
3755,E:\DATN\dataframe\train_file\5.txt,Chơi xổ số kiểu gà mờ
3756,E:\DATN\dataframe\train_file\5.txt,Việc cần làm của chúng ta đó là lựa chọn ra được danh sách các con số có thể đem đánh trong một ngày.
3757,E:\DATN\dataframe\train_file\5.txt,Tuy nhiên rằng để cho khách quan chúng ta sẽ xét xem nếu áp dụng cùng một cách chơi cho tất cả các ngày trong năm thì chúng ta sẽ được lãi bao nhiều nhé.
3758,E:\DATN\dataframe\train_file\5.txt,Đầu tiên đó là lựa chọn ngẫu nhiên
3759,E:\DATN\dataframe\train_file\5.txt,Lựa chọn ngẫu nhiên 5 số
3760,E:\DATN\dataframe\train_file\5.txt,"Giả sử bạn lấy ngày sinh của bố mẹ, em gái, em trai và bạn tạo thành một bố số như sau loto_arr = [18, 5, 27, 6, 28] sau đó áp dụng bộ số này cho cả năm 2002 thử xem sao nhé."
3761,E:\DATN\dataframe\train_file\5.txt,Trước tiên là load dữ liệu của năm 2002 tương ứng với năm đầu tiên của tập dữ liệu.
3762,E:\DATN\dataframe\train_file\5.txt,Hàm load dữ liệu cho từng năm như sau:
3763,E:\DATN\dataframe\train_file\5.txt,"def get_data_range(s_year, e_year):"
3764,E:\DATN\dataframe\train_file\5.txt,    data = read_data()
3765,E:\DATN\dataframe\train_file\5.txt,"    data = get_rows(data, s_year * 31 + 1, e_year * 31 - 1)"
3766,E:\DATN\dataframe\train_file\5.txt,    return data_concate(data)
3767,E:\DATN\dataframe\train_file\5.txt,# Load data for 2002
3768,E:\DATN\dataframe\train_file\5.txt,"data_2002 = get_data_range(0, 1)"
3769,E:\DATN\dataframe\train_file\5.txt,Sau đó chúng ta sẽ tính toán tổng số tiền sẽ đạt được trong năm 2002 nếu như áp dụng bộ số ngẫu nhiên ngày sinh của chúng ta.
3770,E:\DATN\dataframe\train_file\5.txt,Hàm tính toán đó như sau
3771,E:\DATN\dataframe\train_file\5.txt,"def total_lost(test_data, loto_arr = None, price = 0):"
3772,E:\DATN\dataframe\train_file\5.txt,    total = 0
3773,E:\DATN\dataframe\train_file\5.txt,    for rs in test_data:
3774,E:\DATN\dataframe\train_file\5.txt,"        lost = loto_lost_func(loto_arr, rs=rs, price=price)"
3775,E:\DATN\dataframe\train_file\5.txt,        total += lost
3776,E:\DATN\dataframe\train_file\5.txt,    return total
3777,E:\DATN\dataframe\train_file\5.txt,"loto_arr = [18, 5, 27, 6, 28]"
3778,E:\DATN\dataframe\train_file\5.txt,"print total_lost(test_data=data_2002, loto_arr=loto_arr, price=20000)"
3779,E:\DATN\dataframe\train_file\5.txt,"Ồ kết quả là số âm, có vẻ không ổn lắm bởi có lần thua có lần được nếu cứ đánh hết 5 con tương đương 100000 VNĐ một ngày thì một năm chúng ta sẽ bị lỗ mất gần 10 triệu."
3780,E:\DATN\dataframe\train_file\5.txt,Thật là một con số không ổn cho việc đánh ngẫu nhiên.
3781,E:\DATN\dataframe\train_file\5.txt,Giờ thử cách khác xem sao
3782,E:\DATN\dataframe\train_file\5.txt,Lựa chọn ngẫu nhiên nhiều số
3783,E:\DATN\dataframe\train_file\5.txt,Khả năng 5 số thì xác suất trung hơi thấp nên chúng ta chấp nhận thương đau quất luôn 20 số một ngày cho chắc cú với hi vọng sẽ được nhiều tiền thưởng hơn.
3784,E:\DATN\dataframe\train_file\5.txt,Lôi hết ngày sinh của ông bà bố mẹ cụ kị nội ngoại ra chúng ta được một dãy số như sau:
3785,E:\DATN\dataframe\train_file\5.txt,"data_2002 = get_data_range(0, 1)"
3786,E:\DATN\dataframe\train_file\5.txt,"loto_arr = [18, 5, 27, 6, 28, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 2]"
3787,E:\DATN\dataframe\train_file\5.txt,"print total_lost(test_data=data_2002, loto_arr=loto_arr, price=20000)"
3788,E:\DATN\dataframe\train_file\5.txt,Quả này thua còn đau hơn lần trước nữa.
3789,E:\DATN\dataframe\train_file\5.txt,Tổng số tiền chúng ta mất đi sau khi cày cuốc một năm đó là 33 triệu 600 ngàn VNĐ.
3790,E:\DATN\dataframe\train_file\5.txt,Tại sao vẫn như vậy.
3791,E:\DATN\dataframe\train_file\5.txt,"Giờ thì đánh thử một con thôi, dân trong nghề gọi là bạch thủ xem thử xem ra sao."
3792,E:\DATN\dataframe\train_file\5.txt,Thử ngẫu nhiên một con duy nhất
3793,E:\DATN\dataframe\train_file\5.txt,Giờ chúng ta thử chỉ chơi một con duy nhất xem sao.
3794,E:\DATN\dataframe\train_file\5.txt,Ví dụ ngày sinh của bố mình chẳng hạn
3795,E:\DATN\dataframe\train_file\5.txt,loto_arr = [18]
3796,E:\DATN\dataframe\train_file\5.txt,"print total_lost(test_data=data_2002, loto_arr=loto_arr, price=20000)"
3797,E:\DATN\dataframe\train_file\5.txt,Thất bại có vẻ như ít nhất trong các lần chơi.
3798,E:\DATN\dataframe\train_file\5.txt,Hình như có một điều được rút ra đó là:
3799,E:\DATN\dataframe\train_file\5.txt,Nếu chọn ngẫu nhiên thì đánh càng nhiều thì sẽ thua càng nhiều
3800,E:\DATN\dataframe\train_file\5.txt,Đây là cách chơi mà những người chuyên nghiệp gọi là kiểu gà mờ tức là chẳng cần một tý kiến thức nào cả cũng có thể chơi được.
3801,E:\DATN\dataframe\train_file\5.txt,Giờ chúng ta thử tìm cách khác xem sao
3802,E:\DATN\dataframe\train_file\5.txt,Chơi xổ số kiểu thống kê
3803,E:\DATN\dataframe\train_file\5.txt,Chúng ta đã thấy rằng cách chơi kiểu gà mờ chỉ gây những thiệt hại to lớn cho chúng ta.
3804,E:\DATN\dataframe\train_file\5.txt,"Giờ chúng ta sẽ chơi theo một hướng đi khác, đó là sử dụng một số kĩ thuật thống kê vào chơi xổ số"
3805,E:\DATN\dataframe\train_file\5.txt,Dựa trên các số đề ra nhiều nhất
3806,E:\DATN\dataframe\train_file\5.txt,Một cách mơ hồ chúng ta có thể tin rằng các số ra nhiều nhất thì có khả năng sẽ đem lại cho chúng ta may mắn hơn.
3807,E:\DATN\dataframe\train_file\5.txt,Giờ chúng ta thử viết một hàm lấy ra top 10 số đề của năm 2002
3808,E:\DATN\dataframe\train_file\5.txt,"def get_top_loto(data, n_top = 3):"
3809,E:\DATN\dataframe\train_file\5.txt,    counter = Counter(data).most_common(n_top)
3810,E:\DATN\dataframe\train_file\5.txt,"    labels, values = zip(*counter)"
3811,E:\DATN\dataframe\train_file\5.txt,    return np.array(labels)
3812,E:\DATN\dataframe\train_file\5.txt,"data_2002 = get_data_range(0, 1)"
3813,E:\DATN\dataframe\train_file\5.txt,"loto_arr = get_top_loto(data_2002, n_top=10)"
3814,E:\DATN\dataframe\train_file\5.txt,print loto_arr
3815,E:\DATN\dataframe\train_file\5.txt,>>> [14 73 78 79 97 98  6 10 37 39]
3816,E:\DATN\dataframe\train_file\5.txt,Chúng ta sẽ sử dụng dữ liệu này để đánh đề trong năm 2003 xem số tiền thu được có ổn hơn không nhé
3817,E:\DATN\dataframe\train_file\5.txt,"data_2003 = get_data_range(1, 2)"
3818,E:\DATN\dataframe\train_file\5.txt,"print total_lost(test_data=data_2003, loto_arr=loto_arr, price=20000)"
3819,E:\DATN\dataframe\train_file\5.txt,Căng thật số tiền nhận được vẫn không ăn thua lắm.
3820,E:\DATN\dataframe\train_file\5.txt,Liệu rằng có phải do chúng ta đã có quá ít dữ liệu hay không.
3821,E:\DATN\dataframe\train_file\5.txt,Hãy thử lấy top 10 số ra nhiều nhất từ năm 2002 đến năm 2015 và áp dụng để chơi trong năm 2016 xem có khả quan hơn không
3822,E:\DATN\dataframe\train_file\5.txt,"data_2002_to_2015 = get_data_range(0, 14)"
3823,E:\DATN\dataframe\train_file\5.txt,"loto_arr = get_top_loto(data_2002_to_2015, n_top=10)"
3824,E:\DATN\dataframe\train_file\5.txt,print loto_arr
3825,E:\DATN\dataframe\train_file\5.txt,"data_2016 = get_data_range(14, 15)"
3826,E:\DATN\dataframe\train_file\5.txt,"print total_lost(test_data=data_2016, loto_arr=loto_arr, price=20000)"
3827,E:\DATN\dataframe\train_file\5.txt,>>> [36 10  6 39 17  1 15 60 14 32]
3828,E:\DATN\dataframe\train_file\5.txt,Kết quả không khả quan hơn thậm chí còn tệ hơn nữa chứng tỏ vấn đề không phải là dữ liệu nhiều hay ít
3829,E:\DATN\dataframe\train_file\5.txt,Để máy tính chọn hộ
3830,E:\DATN\dataframe\train_file\5.txt,Thôi thì chẳng tính toán gì nữa cả.
3831,E:\DATN\dataframe\train_file\5.txt,"Cách tốt nhất là nhờ máy tính chọn hộ, nó chọn số nào mình chơi số đó."
3832,E:\DATN\dataframe\train_file\5.txt,Mặc đời trôi luôn.
3833,E:\DATN\dataframe\train_file\5.txt,Chúng ta chỉnh lại một chút trong hàm total_lost như sau:
3834,E:\DATN\dataframe\train_file\5.txt,from random import randint
3835,E:\DATN\dataframe\train_file\5.txt,"def total_lost(test_data, loto_arr = None, price = 0):"
3836,E:\DATN\dataframe\train_file\5.txt,    total = 0
3837,E:\DATN\dataframe\train_file\5.txt,    for rs in test_data:
3838,E:\DATN\dataframe\train_file\5.txt,"        rand = randint(0,99)"
3839,E:\DATN\dataframe\train_file\5.txt,"        lost = loto_lost_func(loto_arr=[rand], rs=rs, price=price)"
3840,E:\DATN\dataframe\train_file\5.txt,        total += lost
3841,E:\DATN\dataframe\train_file\5.txt,    return total
3842,E:\DATN\dataframe\train_file\5.txt,"data_2016 = get_data_range(14, 15)"
3843,E:\DATN\dataframe\train_file\5.txt,"print total_lost(test_data=data_2016, price=20000)"
3844,E:\DATN\dataframe\train_file\5.txt,Nhận xét: có vẻ như phương pháp lựa chọn ngẫu nhiên cho kết quả tốt nhất nhưng vẫn không thể sinh cho chúng ta một đồng lãi
3845,E:\DATN\dataframe\train_file\5.txt,Bài học rút ra
3846,E:\DATN\dataframe\train_file\5.txt,Bây giờ bạn đã hiểu tại sao mà Phan Thị Inc nói không với ma túy nhưng lại tập trung hoạt động bảo kê mở sòng bạc chưa.
3847,E:\DATN\dataframe\train_file\5.txt,Có lý do cả đó các bạn ạ. Sau bài này mình cảm thấy cần rút ra một số bài học đó là:
3848,E:\DATN\dataframe\train_file\5.txt,Đừng có tìm quy luật cho những thứ ngẫu nhiên
3849,E:\DATN\dataframe\train_file\5.txt,May mắn chỉ đến một vài lần trong đời (thường là rất hiếm) nên đừng hi vọng chúng ta có thể gặp nó hàng ngày
3850,E:\DATN\dataframe\train_file\5.txt,Xổ số là lĩnh vực rất có lợi cho nhà đầu tư (công ty xổ số) chứ không bao giờ có lợi cho người chơi nó
3851,E:\DATN\dataframe\train_file\5.txt,Vì sao nên chơi xổ số.
3852,E:\DATN\dataframe\train_file\5.txt,Vì nó được tung hô là ích nước lợi nhà tức là tăng thêm thuế cho đất nước và tăng thu nhập cho nhà đầu tư tức công ty xổ số
3853,E:\DATN\dataframe\train_file\50.txt,Giới thiệu tool TorchStudio - Train AI mà không cần code nhiều
3854,E:\DATN\dataframe\train_file\50.txt,"Nếu đã từng train model Deep Learning, bạn sẽ thường phải thực hiện các bước sau:"
3855,E:\DATN\dataframe\train_file\50.txt,"Load dataset, split ra thành bộ train/validation/test"
3856,E:\DATN\dataframe\train_file\50.txt,"Load model, config hyperparameters"
3857,E:\DATN\dataframe\train_file\50.txt,Train model
3858,E:\DATN\dataframe\train_file\50.txt,Plot biểu đồ loss và accuracy trong quá trình train (có thể có hoặc không)
3859,E:\DATN\dataframe\train_file\50.txt,"Trong bài viết này, mình muốn giới thiệu đến các bạn TorchStudio, một ""IDE"" dành cho PyTorch."
3860,E:\DATN\dataframe\train_file\50.txt,"Thay vì phải tốn thời gian ngồi code các bước trên, TorchStudio có thể giúp cho các bạn nhanh chóng setup để train model chỉ với vài cú click chuột, thậm chí là không phải gõ một dòng code nào."
3861,E:\DATN\dataframe\train_file\50.txt,Nó sẽ thay bạn setup các module có sẵn trong phần mềm.
3862,E:\DATN\dataframe\train_file\50.txt,"Còn với những module không có sẵn, TorchStudio cũng sẽ cho phép bạn tự code để thêm vào như các extension mở rộng."
3863,E:\DATN\dataframe\train_file\50.txt,"Note: Hiện tại, do phần mềm còn khá mới, vẫn đang trong bản beta nên có thể có nhiều chức năng chưa được hoàn thiện."
3864,E:\DATN\dataframe\train_file\50.txt,Bạn có thể tải TorchStudio tại .
3865,E:\DATN\dataframe\train_file\50.txt,"Sau khi cài đặt xong, TorchStudio sẽ hỏi bạn muốn cài environment mới hay chọn cái có sẵn."
3866,E:\DATN\dataframe\train_file\50.txt,"Do phần mềm đang trong bản beta nên chức năng chọn environment đã có sẵn đang bị lỗi, tạm thời chưa dùng được."
3867,E:\DATN\dataframe\train_file\50.txt,"Vì thế, bạn hãy chịu khó để phần mềm cài environment mới từ đầu để tránh bị lỗi."
3868,E:\DATN\dataframe\train_file\50.txt,"Sau khi cài đặt xong, giao diện của TorchStudio sẽ xuất hiện như sau:"
3869,E:\DATN\dataframe\train_file\50.txt,Chọn dataset
3870,E:\DATN\dataframe\train_file\50.txt,"Ở bước này, ta sẽ chọn dataset dùng để train model, đồng thời config các tham số dùng cho dataset."
3871,E:\DATN\dataframe\train_file\50.txt,TorchStudio cho phép chọn các dataset của torchvision và viết thêm code nếu muốn augment dataset ở 2 mục transform và target_transform.
3872,E:\DATN\dataframe\train_file\50.txt,"Ngoài ra, bạn cũng có thể chọn Custom Dataset để tự code dataset nếu như trong torchvision không có hoặc muốn chạy với bộ dataset riêng."
3873,E:\DATN\dataframe\train_file\50.txt,"Khi đó, cột Definition sẽ cung cấp sẵn một template để bạn có thể tự code dataset của mình."
3874,E:\DATN\dataframe\train_file\50.txt,"Sau khi cài đặt xong, ta chỉ cần bấm Load (Ctrl + L) để phần mềm tự load dataset."
3875,E:\DATN\dataframe\train_file\50.txt,"Ở đây, mình sẽ lấy bộ MNIST làm ví dụ."
3876,E:\DATN\dataframe\train_file\50.txt,"Ở cột giữa, TorchStudio cho bạn lựa chọn số lượng dữ liệu sẽ được sử dụng để train model, và cách chia bao nhiêu % cho việc training và validation, bật shuffling hay không."
3877,E:\DATN\dataframe\train_file\50.txt,"Ngoài ra, TorchStudio còn cho phép bạn lướt qua từng cặp input-label, và phân tích bộ dataset theo 3 kiểu: Multilabel, ValuesDistribution (phân bố dữ liệu) và Multiclass."
3878,E:\DATN\dataframe\train_file\50.txt,"Ví dụ, với Multiclass:"
3879,E:\DATN\dataframe\train_file\50.txt,ValuesDistribution của bộ MNIST:
3880,E:\DATN\dataframe\train_file\50.txt,Chọn model và train
3881,E:\DATN\dataframe\train_file\50.txt,"Sau khi xong phần dataset, bạn hãy bấm nút New Model (có hình dấu cộng trong hình lục giác) ở bên phải tab Dataset để thêm tạo một model mới."
3882,E:\DATN\dataframe\train_file\50.txt,Bạn có thể tạo thêm nhiều model bằng cách bấm nút đó.
3883,E:\DATN\dataframe\train_file\50.txt,"Ở bước này, ta sẽ chọn một model để train."
3884,E:\DATN\dataframe\train_file\50.txt,TorchStudio có cung cấp vài model mẫu và cũng cho phép bạn chọn các model có sẵn của torchvision.
3885,E:\DATN\dataframe\train_file\50.txt,"Tương tự với Dataset, bạn có thể chọn Custom Model để tự code model của mình."
3886,E:\DATN\dataframe\train_file\50.txt,"Tuỳ vào model bạn chọn, TorchStudio sẽ cho phép bạn config model theo các tham số khác nhau."
3887,E:\DATN\dataframe\train_file\50.txt,"Ở đây, mình sẽ dùng model MNISTClassifier của torchstudio.models làm ví dụ."
3888,E:\DATN\dataframe\train_file\50.txt,"Sau khi chọn xong model, hãy nhấn Build (Ctrl+B) để torchstudio tự khởi tạo model."
3889,E:\DATN\dataframe\train_file\50.txt,"Khi load xong model, phần mềm sẽ visualize kiến trúc của model trong cột Graph (khá là giống với việc visualize bằng )."
3890,E:\DATN\dataframe\train_file\50.txt,"Cột Hyperparameters sẽ cho phép chúng ta cài đặt các siêu tham số dùng trong quá trình training như Loss, Metric, Optimizer, Scheduler, Batch Size và training epoch."
3891,E:\DATN\dataframe\train_file\50.txt,"Với các loss, metric, optimizer và scheduler, TorchStudio cũng cho phép ta tuỳ chỉnh từng thành phần riêng của chúng như learning rate, decay, etc."
3892,E:\DATN\dataframe\train_file\50.txt,"Dưới các dòng này, bạn có thể chọn một ảnh sample nhất định để theo dõi output của model đối với sample đó trong quá trình training theo từng epoch."
3893,E:\DATN\dataframe\train_file\50.txt,Bên phải là bảng metric và loss cũng sẽ được update trong quá trình training.
3894,E:\DATN\dataframe\train_file\50.txt,"Sau khi chọn xong hyperparameters, ta chỉ cần bấm Train để TorchStudio tự train model."
3895,E:\DATN\dataframe\train_file\50.txt,"Kết quả sau khi train xong, model đã nhận diện được chính xác số 4 ở bên trên:"
3896,E:\DATN\dataframe\train_file\50.txt,"Nếu bạn train nhiều model, TorchStudio cũng sẽ cho phép bạn so sánh performance của các model."
3897,E:\DATN\dataframe\train_file\50.txt,"Ví dụ, sau khi train 3 model, bạn hãy bấm nút Dashboard ở góc phải trên cùng."
3898,E:\DATN\dataframe\train_file\50.txt,TorchStudio sẽ tự động vẽ biểu đồ so sánh loss và metric cho bạn như dưới đây:
3899,E:\DATN\dataframe\train_file\50.txt,"Sau khi train xong, ta có thể export model ra dưới dạng TorchScript hoặc ONNX nếu muốn."
3900,E:\DATN\dataframe\train_file\50.txt,"Như vậy, trong hình trên, mình đã train được không những một mà đến 3 model (accuracy vẫn hơi thấp do mình chỉ dùng 10% dataset train cho nhanh) mà không cần phải gõ tí dòng code nào."
3901,E:\DATN\dataframe\train_file\50.txt,"Tiện hơn nữa, TorchStudio cũng tự lo phần biểu đồ về loss và accuracy hộ các bạn để các bạn có thể theo dõi trong lúc và sau khi training và so sánh các model với nhau."
3902,E:\DATN\dataframe\train_file\51.txt,Các bộ dữ liệu không cân bằng luôn là niềm đau trong mỗi bài toán học máy.
3903,E:\DATN\dataframe\train_file\51.txt,Để giải quyết vấn đề này bài báo  đã sử dụng đào tạo hai giai đoạn để tăng hiệu suất cho các lớp thiểu số và kết quả thu được khá khả quan khi không chỉ cải thiện độ chính xác trên các lớp thiểu số mà còn hạn chế việc giảm thiểu hiệu suất trên các lớp khác.
3904,E:\DATN\dataframe\train_file\51.txt,"Trong bài viết này, ta sẽ cũng tìm hiểu cách thức thực hiện của nhóm tác giả cũng như chi tiết kết quả thu được."
3905,E:\DATN\dataframe\train_file\51.txt,"Bằng cách tận dụng học sâu để tự động phân loại hình ảnh thu được từ trap camera (là cái ở hình minh họa bên dưới), các nhà sinh thái học có thể giám sát các nỗ lực bảo tồn đa dạng sinh học và tác động của biến đổi khí hậu đối với hệ sinh thái một cách hiệu quả hơn."
3906,E:\DATN\dataframe\train_file\51.txt,"Tuy vậy, do sự phân bố không cân đối giữa các bộ dữ liệu ảnh, các mẫu máy ảnh hiện tại thường thiên về các lớp vốn chiếm tỉ lệ đa số."
3907,E:\DATN\dataframe\train_file\51.txt,"Kết quả là, các mô hình đạt được tỉ lệ chính xác cao đối với một số nhóm đa số nhưng lại khó có thể đưa ra các kết quả đoán nhận đúng đối với nhiều lớp thiểu số.Từ vấn đề đó, bài toán mà không chỉ bài báo này mà còn các bài báo liên quan khác được liệt kê tập trung giải quyết là cố gắng cải thiện độ chính xác trên các lớp thiểu số và cùng với đó hạn chế tối đa số việc ảnh hướng xấu đến kết quả đoán nhận trên các lớp còn lại."
3908,E:\DATN\dataframe\train_file\51.txt,Quá trình thực nghiệm của các nhóm tác giả được thực hiện trên bộ dữ liệu .
3909,E:\DATN\dataframe\train_file\51.txt,"Đây là bộ dữ liệu được thu thập bằng cách triển khai 225 bẫy ảnh trên khắp 1.125 km 2  tại Vườn quốc gia Serengeti, Tanzania, để đánh giá động thái giữa các loài trong không gian và thời gian."
3910,E:\DATN\dataframe\train_file\51.txt,"Các máy ảnh đã hoạt động liên tục từ năm 2010 và đã tích lũy được 99.241 ngày bẫy ảnh và tạo ra 1,2 triệu bộ ảnh vào năm 2013 và chúng được cung cấp công khai tại địa chỉ  Phần dữ liệu được sử dụng để thực hiện thí nghiệm là season thứ 9 trong bộ Snapshot Serengeti và đã được thực hiện qua các bước tiền xử lý nhằm loại bỏ các dữ liệu không hợp lệ."
3911,E:\DATN\dataframe\train_file\51.txt,"Cuối cùng, bộ dữ liệu sau khi xử lý (sẽ được gọi là bộ dữ liệu ban đầu) chứa 194.000 ảnh với 52 lớp."
3912,E:\DATN\dataframe\train_file\51.txt,"Phân bố dữ liệu trong bộ này được thể hiện ở hình dưới đây và ta có thể thấy rõ rằng, chúng đang rất không cân bằng khi mà ba nhóm đa số chiếm xấp xỉ 75% tổng số dữ liệu."
3913,E:\DATN\dataframe\train_file\51.txt,"Giải quyết bài toán dữ liệu không cân bằng không phải là công việc mới xuất hiện và không chỉ vậy, đây còn là vấn đề điển hình của các bài toán liên quan đến hình ảnh thu được từ trap camera."
3914,E:\DATN\dataframe\train_file\51.txt,"Các nghiên cứu được công bố trước nghiên cứu này thường tìm đến các phương pháp bao gồm: khó quá thì bỏ quá - loại bỏ lớp hiếm khỏi bộ dữ liệu như , sử dụng hàm lỗi có trọng số  hay sử dụng kết hợp tăng cường hình ảnh bổ sung cho các lớp hiếm và kỹ thuật lấy mẫu mới ."
3915,E:\DATN\dataframe\train_file\51.txt,"Nhìn chung các phương pháp được tiếp cận để giảm thiểu sự mất cân bằng lớp thường được chia thanh hai loại chính: kĩ thuật cấp dữ liệu (làm thay đổi phân phối lớp của dữ liệu, chẳng hạn như lấy mẫu quá mức thiểu số ngẫu nhiên (ROS) và lấy mẫu dưới phần lớn ngẫu nhiên (RUS), ...) và cấp thuật toán (thay đổi trên chính quá trình huấn luyện chẳng hạn như thay thế hàm mất mát, ...)"
3916,E:\DATN\dataframe\train_file\51.txt,"Bên cạnh các phương pháp kể trên, huấn luyện hai giai đoạn, một kỹ thuật lai, gần đây đã được giới thiệu và cho thấy thu được kết quả tốt để huấn luyện , và sau đó nó được những người khác sử dụng để phân đoạn và phân loại hình ảnh."
3917,E:\DATN\dataframe\train_file\51.txt,"Do những kết quả đầy hứa hẹn này và khả năng áp dụng rộng rãi của đào tạo 2 giai đoạn, nhóm tác giả thử nghiệm đào tạo 2 giai đoạn đối với hình ảnh bẫy ảnh"
3918,E:\DATN\dataframe\train_file\52.txt,"Trong tất cả các loại Neural Network, em thích nhất là Convolutional Neural Network."
3919,E:\DATN\dataframe\train_file\52.txt,"Vì vậy hôm nay em sẽ làm một bài văn miêu tả về Receptive field là gì, tại sao chúng ta cần phải hiểu nó nếu muốn hiểu rõ cách CNN hoạt động."
3920,E:\DATN\dataframe\train_file\52.txt,"Như chúng ta đã biết NN được lấy cảm hứng từ hệ thần kinh não bộ của con người với receptive field cũng không ngoại lệ, vậy nên mình sẽ lấy một ví dụ về hệ thống thị giác của con người cho mọi người dễ hình dung."
3921,E:\DATN\dataframe\train_file\52.txt,Khi mà bạn tập trung nhìn vào một vật thể ở trước mặt thì khu vực nhìn thấy của mắt người sẽ được gọi là receptive field (field of view).
3922,E:\DATN\dataframe\train_file\52.txt,Hệ thống thị giác của chúng ta có hàng triệu tế bào thần kinh vì vậy với mỗi tế bào thần kinh nó sẽ phụ trách receptive field một phần hoặc một khu vực nhỏ trên tổng thế reptive field nhìn thấy (total field of view).
3923,E:\DATN\dataframe\train_file\52.txt,Hay nói cách khác thì mỗi neuron thần kinh sẽ được phép truy cập vào một khu vực và khu vực này được gọi là trường tiếp nhận của tế bào (cell's receptive field).
3924,E:\DATN\dataframe\train_file\52.txt,Mọi người có thể hình dung rõ hơn với hình minh họa phía dưới.
3925,E:\DATN\dataframe\train_file\52.txt,Sau khi mọi người đã mường tượng ra receptive field nó nà cái dì dồi thì chúng ta cùng đi vào chi tiết xem nó có tác dụng gì đối với CNN.
3926,E:\DATN\dataframe\train_file\52.txt,Gét gô...
3927,E:\DATN\dataframe\train_file\52.txt,Receptive field trong deep learning được định nghĩa là kích thước của một vùng (region) trong không gian đầu vào (input space) được nhìn thấy bởi pixel output qua một kernel/filter.
3928,E:\DATN\dataframe\train_file\52.txt,"Không giống với mạng fully connected network khi mà mỗi node trong layer phụ thuộc vào toàn bộ input đầu vào của mạng, thì đối với CNN nó chỉ phụ thuộc vào một vùng của input."
3929,E:\DATN\dataframe\train_file\52.txt,Vùng này trong input được gọi là receptive field.
3930,E:\DATN\dataframe\train_file\52.txt,"Để dễ hình dung mình sẽ lấy một ví dụ cụ thể, như chúng ta đã biết trong bài toán image segmentation nhiệm vụ là đi dự đoán từng pixel tương ứng ở input xem nó đang thuộc class tương ứng nào."
3931,E:\DATN\dataframe\train_file\52.txt,Vậy điều chúng ta mong muốn nhất ở đây sẽ là làm sao cho việc dự đoán pixel đó thuộc true class là cao nhất.
3932,E:\DATN\dataframe\train_file\52.txt,Mà điều kiện lý tưởng nhất cho điều này là tại mỗi output pixel nó có một receptive field thật lớn.
3933,E:\DATN\dataframe\train_file\52.txt,Điều này giúp cho việc model không bị bỏ qua những chi tiết quan trọng trong quá trình dự đoán.
3934,E:\DATN\dataframe\train_file\52.txt,Với feature map được tạo ra bởi layer đầu tiên (màu xanh lục) được tạo ra bởi kernel size = 3x3 với padding = 1 và stride = 2 thì có thể thấy ta sẽ thu được vùng receptive field 3x3 tương ứng bằng với kích thước của kernel size (tại mỗi vùng kernel trượt qua).
3935,E:\DATN\dataframe\train_file\52.txt,"Tiếp đến, ta sẽ xem xét đối với feature map (màu cam) của layer thứ 2 được tạo ra với thông số S, P và kernel tương tự, lúc này đối với mỗi pixel của feature map mới ta thu được một vùng receptive field 7x7 tương ứng."
3936,E:\DATN\dataframe\train_file\52.txt,Để cho dễ hình dung về việc từng pixel trong feature map nó sẽ nhìn thấy một vùng receptive field là bao nhiêu ta sẽ nhìn qua 2 hình nhỏ phía bên phải.
3937,E:\DATN\dataframe\train_file\52.txt,Với việc feature map được thay đổi kích thước bằng với kích thước của input.
3938,E:\DATN\dataframe\train_file\52.txt,Vùng màu vàng nhạt và vùng màu xanh dương nhạt biểu thị cho vùng receptive field tương ứng của từng pixel trên feature map layer 1 và layer 2.
3939,E:\DATN\dataframe\train_file\52.txt,"Nhìn vào hình minh họa kia chúng ta có thể đoán rằng, khi mạng càng sâu thì vùng receptive field càng lớn chăng"
3940,E:\DATN\dataframe\train_file\53.txt,Sinh ảnh cùng với MixNMatch: độ chân thực đến đáng gờm
3941,E:\DATN\dataframe\train_file\53.txt,"Dạo một vòng mấy trang chia sẻ kiên thức để chống lười, đập vào mắt mình một bài viết với tiêu đề khá giật tít, mà kiểu nó sẽ áp dụng được trong rất nhiều bài toán."
3942,E:\DATN\dataframe\train_file\53.txt,Vì vậy mạn phép đọc bài viết của tác giả sau đó dịch theo ý hiểu để diễn giải cho mọi người cùng thảo luận (Chứ cái này mình không có tự nghĩ ra :v) Bài viết giới thiệu về 1 kỹ thuật mang tên MixNMatch có nguồn gốc từ 1 paper có tên MixNMatch: Multifactor Disentanglement and Encoding for Conditional Image Generation ( ).
3943,E:\DATN\dataframe\train_file\53.txt,"Vậy nó có gì đặc biệt và có tính ứng dụng cao như vậy, cùng mình tìm hiểu nhé"
3944,E:\DATN\dataframe\train_file\53.txt,"MixNMatch là một kỹ thuật có khả năng kết hợp những phần khác nhau của nhiều bức ảnh thực để sinh ra một bức ảnh tổng hợp, sẽ mang các đặc trưng mà ta đưa vào."
3945,E:\DATN\dataframe\train_file\53.txt,"Nhìn vào bức ảnh trên, bức ảnh gen ra sẽ có những đặc trưng như sau: nền như bức ảnh đầu tiên, ngữ nghĩa (con chim) của bức ảnh 2, kích thước của bức ảnh 3 và vị trí của bức ảnh 4."
3946,E:\DATN\dataframe\train_file\53.txt,Thật chứ nhìn đến đấy thôi là mình đã phải tò mò đọc tiếp và muốn viết một bài về cái này rồi
3947,E:\DATN\dataframe\train_file\53.txt,"Nhắc tới sinh dữ liệu, chắc hẳn nhiều người nghĩ ngay tới GAN, mình cũng thế :v và nó đúng là như vậy thật."
3948,E:\DATN\dataframe\train_file\53.txt,MixNMatch là một kỹ thuật sinh ảnh có điều kiện sử dụng Generative Adversarial Network (GAN).
3949,E:\DATN\dataframe\train_file\53.txt,"Theo bài báo, MixNMatch chỉ cần 1 bounding box quanh đối tượng nền chứ không cần hộp cho tư thế, hình dạng, kết cấu của đối tượng (Nghe hơi vô lý nhưng đọc tiếp xem sao)."
3950,E:\DATN\dataframe\train_file\53.txt,Gét gô!
3951,E:\DATN\dataframe\train_file\53.txt,Ý tưởng chính
3952,E:\DATN\dataframe\train_file\53.txt,"Như đã đề cập, sẽ có sự xuất hiện của GAN ở đây."
3953,E:\DATN\dataframe\train_file\53.txt,"MixNMatch học cách tách rời các phần và mã hóa (encode) nền (background), tư thế đối tượng (pose), hình dạng (shape) và kết cấu (texture) khỏi các bức ảnh thực với mức giám sát ít nhất (ý mình hiểu giám sát ít nhất ở đây tức là chúng ta có dùng ít dữ liệu có nhãn nhất có thể)."
3954,E:\DATN\dataframe\train_file\53.txt,"Để đạt được đièu này, tác giả của paper đề xuất một khuôn khổ cho phép đồng thời học 1 bộ mã hóa (Encoder) các yếu tố tiềm ẩn từ hình ảnh thực thành một không gian mã tiềm ẩn không được xáo trộn và một trình sinh (Generator) để lấy các yếu tố tiềm ẩn từ không gian mã bị xáo trộn để tạo hình ảnh"
3955,E:\DATN\dataframe\train_file\53.txt,Bức ảnh đầu vào sẽ được đưa quan Encoder để tạo ra các latent codes.
3956,E:\DATN\dataframe\train_file\53.txt,"ở đây sẽ có 4 latent codes khác nhau, tương ứng là background, pose, shape, texture."
3957,E:\DATN\dataframe\train_file\53.txt,4 latent codes khác nhau sẽ được đưa vào FineGAN generator để sinh ra ảnh
3958,E:\DATN\dataframe\train_file\53.txt,"MixNMatch dựa trên FineGAN, vậy ta cùng xem qua cách  hoạt động"
3959,E:\DATN\dataframe\train_file\53.txt,"Như đã nói ở trên, input của FineGAN sẽ bao gồm 4 đặc trưng ngẫu nhiên khác loại nhau (ở đây là 4 latent code), gọi là (x, b, c, p)."
3960,E:\DATN\dataframe\train_file\53.txt,Cách hoạt động của FineGAN sẽ gồm 3 khối
3961,E:\DATN\dataframe\train_file\53.txt,"Background stage: Ở giai đoạn này, mô hình chỉ sinh ra nền, được điều chỉnh dựa trên latent one-hot background code b (chính là latent code của background)"
3962,E:\DATN\dataframe\train_file\53.txt,"Parent stage:giai đoạn chính trong đó mô hình tạo ra hình dạng (shape) và tạo dáng (pose) của đối tượng dựa trên latent one-hot parent code p và z, và ghép nó vào background đang có"
3963,E:\DATN\dataframe\train_file\53.txt,"Child stage:giai đoạn con, mô hình lấp đầy kết cấu của đối tượng (texture), được điều chỉnh dựa trên latent one-hot child code"
3964,E:\DATN\dataframe\train_file\53.txt,"Ở cả giải đoạn parent và child, FineGAN đều tạo ra mặt nạ của đối tượng để ghi lại hình dạng và kết cấu mà không cần giám sát"
3965,E:\DATN\dataframe\train_file\53.txt,"Trong quá trình training, FineGAN thực hiện với 2 ràng buộc"
3966,E:\DATN\dataframe\train_file\53.txt,Nhóm các mã con (child codes) thành 1 tập hợp rời rạc để mỗi tập hợp chứa cùng 1 mã cha (parent code).
3967,E:\DATN\dataframe\train_file\53.txt,Ràng buộc này ràng buộc rằng các spices of ducks (gia vị của vịt???)
3968,E:\DATN\dataframe\train_file\53.txt,khác nhau sẽ có hình dạng giống nhau nhưng kết cấu khác nhau
3969,E:\DATN\dataframe\train_file\53.txt,"Đối với mỗi hình ảnh được tạo ra, cặp mã con (child code) và mã nền (background code) luôn giống nhau, ngĩa là một con vịt sẽ luôn có nền là nước"
3970,E:\DATN\dataframe\train_file\53.txt,"Để tách nền, FIneGAN dựa vào hộp giới hạn của đối tượng (object’s bounding box)"
3971,E:\DATN\dataframe\train_file\53.txt,"Để gỡ rối các yếu tố khác, FineGAN dựa trên lý thuyết thông tin như trong InfoGAN (Phần này do chưa có nhiều thời gian nên mình chưa đọc) và áp đặt các ràng buộc giữa mối quan hệ của các latent code."
3972,E:\DATN\dataframe\train_file\53.txt,"Tuy nhiên FineGAN chỉ được điều chỉnh dựa trên các latent code được lấy mẫu, và không thể điều chỉnh trực tiếp trên hình ảnh thực tế để tạo ảnh."
3973,E:\DATN\dataframe\train_file\53.txt,"Do đó tác giả đề xuất một cách để trích xuất các latent codes kiểm soát nền, tư thế, hình dạng, kết cấu từ hỉnh ảnh thực, trong khi vẫn bảo toàn các thuộc tính phân chia thứ bậc của FineGAN."
3974,E:\DATN\dataframe\train_file\53.txt,Có 2 cách tiếp cận
3975,E:\DATN\dataframe\train_file\53.txt,Phần mở rộng của FineGAN: ý nghĩa là đọa tạo 1 bộ mã hóa để ảnh xạ 1 hình ảnh giả mạo sang latent code.
3976,E:\DATN\dataframe\train_file\53.txt,Tuy nhiên điều này theo tác giả là không hoạt động vì khoảng cách miền giữa hình ảnh thật và giả
3977,E:\DATN\dataframe\train_file\53.txt,"Thực hiện học đối nghịch, theo đó phân phối chung của hình ảnh thực và latent code tương ứng của chúng, cùng với phân phối chung giữa latent code và hình ảnh được tạo tương ứng từ generator được học sao cho khong thể phân biệt được, từ đó ảnh sinh ra sẽ gần với ảnh thật hơn (Cùng nghĩ lại kiến thức về mạng GAN với bài toán kinh điển: Generator cố gắng in ra tiền giả còn Discriminator cố gắng phân biệt tiền giả, song mục tiêu của chúng ta là tiền giả giống thật để Discriminator không nhận ra)"
3978,E:\DATN\dataframe\train_file\53.txt,Ưu điểm của phương pháp học đối nghịch ở đây là gì
3979,E:\DATN\dataframe\train_file\53.txt,"Bằng cách thực thi các phân phối mã hình ảnh phù hợp, trình Encoder học cách tạo ra các latent code phù hợp với việc phân phối các sampled codes với các thuộc tính tách rời mong muốn, trong khi trình Generator cố gắng tạo ra hình ảnh thực tế"
3980,E:\DATN\dataframe\train_file\53.txt,"Cụ thể, với mỗi hình ảnh thực đầu vào x, tác giả đề xuất 4 bộ mã riêng biệt để trích xuất: z, b, p ,c. Tuy nhiên nhưng mã này sẽ không đặt trực tiếp vào Generator để tái tạo ảnh (Điều này quá đơn thuần và thủ công)."
3981,E:\DATN\dataframe\train_file\53.txt,"Tác giá tận dụng các ý tưởng từ ALI và BiGAN để giúp các bộ mã hóa tìm hiểu ảnh xạ nghịch đảo, tức là 1 phép chiếu từ hình ảnh thực vào không gian mã, theo cách duy trì các thuộc tính tách rời mong muốn"
3982,E:\DATN\dataframe\train_file\53.txt,"Bài báo này để tìm hiểu sâu cũng như code thì cũng mất tương đối nhiều thời gian, vì vậy trong phạm vi bài viết này mình chỉ giới thiệu về ý tưởng chung của bài báo bởi tính ứng dụng của nó là vô cùng cao, nhất là trong việc sinh dữ liệu cho các bài toán."
3983,E:\DATN\dataframe\train_file\53.txt,"À dạo này mình có bị 1,2 cái Down vote, mình rất mong mn nếu thấy có vấn đề gì trong bài viết của mình có thể ngoài việc down vote ra kèm theo một vài nhận xét để mình có thể tiến bộ hơn trong việc chia sẻ kiến thức."
3984,E:\DATN\dataframe\train_file\53.txt,Cảm ơn mọi người đã đọc bài viết.
3985,E:\DATN\dataframe\train_file\53.txt,"Hà Nội giữa tháng 5 mưa lạnh đó, mọi người giữ gìn sức khỏe nhé!"
3986,E:\DATN\dataframe\train_file\53.txt,Tài liệu tham khảo
3987,E:\DATN\dataframe\train_file\54.txt,Mô hình Clean Architecture + Dagger 2 trong Android
3988,E:\DATN\dataframe\train_file\54.txt,"Chắc anh em cũng không còn xa lạ gì về các mô hình phát triển ứng dụng như MVP , MVVM , hay đỉnh cao hơn là ""God Activity"" 😆 (1 activity cân tất mọi logic)."
3989,E:\DATN\dataframe\train_file\54.txt,"Cá nhân mình cũng đã làm qua nhiều dự án và áp dụng từng mô hình khác nhau, chúng đều có những ưu nhược điểm riêng."
3990,E:\DATN\dataframe\train_file\54.txt,"Nhưng hôm nay mình sẽ giới thiệu về 1 mô hình ""khó nhai"" hơn 1 tí đó là ""Clean Architecture""."
3991,E:\DATN\dataframe\train_file\54.txt,Let 's go !!
3992,E:\DATN\dataframe\train_file\54.txt,Khái quát về mô hình Clean Architecture.
3993,E:\DATN\dataframe\train_file\54.txt,"Nghe đến từ ""Clean"" là chúng ta ít nhiều đã hiểu đây là một mô hình rất ""sạch sẽ"" để triển khai dự án."
3994,E:\DATN\dataframe\train_file\54.txt,"Nó được build dựa trên tư tưởng ""độc lập"" các layer kết hợp với các nguyên lí thiết kê hướng đối tượng và Coding Convention."
3995,E:\DATN\dataframe\train_file\54.txt,Vậy nguyên lí chung của mô hình này được triển khai ra sao ?
3996,E:\DATN\dataframe\train_file\54.txt,Chúng ta hãy xem qua mô hình dưới đây:
3997,E:\DATN\dataframe\train_file\54.txt,"Ở đây các layer , component bên trong không nên biết bất kì điều gì về các layer bên ngoài."
3998,E:\DATN\dataframe\train_file\54.txt,Có nghĩa là nếu layer bên trong có thay đổi về data thì không ảnh hưởng tới việc hiển thị của các layer ngoài hay định dạng data của các layer ngoài thay đổi thì data của các layer trong vẫn không ảnh hưởng gì .
3999,E:\DATN\dataframe\train_file\54.txt,Dễ hỉu )
4000,E:\DATN\dataframe\train_file\54.txt,Trước khi đi qua chi tiết về mô hình này chúng ta hãy nhắc lại 1 chút về 5 nguyên lí SOLID.
4001,E:\DATN\dataframe\train_file\54.txt,Single Responsibility : Mỗi một component nên chỉ có duy nhất 1 lí do để thay đổi - one responsibility.
4002,E:\DATN\dataframe\train_file\54.txt,"Open-closed : Bạn có thể dễ dàng mở rộng phạm vi , data của một đối tượng mà không cần phải thay đổi hay phá vỡ cấu trúc của nó."
4003,E:\DATN\dataframe\train_file\54.txt,Liskov Substitution : Nếu bạn có một class Object nào đó và những class con của nó .
4004,E:\DATN\dataframe\train_file\54.txt,Bạn có thể sử dụng base class để thay thế cách thể hiện cho những class con đó.
4005,E:\DATN\dataframe\train_file\54.txt,Interface Segregation: Break 1 interface lớn ra thành nhiều interface nhỏ để tránh khỏi việc 1 class phải implement quá nhiều method không cần thiết.
4006,E:\DATN\dataframe\train_file\54.txt,Dependency Inversion: Các component nên phụ thuộc vào abstract module thay vì các component cụ thể.
4007,E:\DATN\dataframe\train_file\54.txt,Các module cấp cao không nên phụ thuộc vào các module cấp thấp.
4008,E:\DATN\dataframe\train_file\54.txt,Có rất nhiều ý kiến khác nhau về việc chính xác có bao nhiêu layer được triển khai trong Clean Architecture.
4009,E:\DATN\dataframe\train_file\54.txt,"Nhưng mô hình này không được định rõ số layer một cách chính xác , mà ta sẽ adapt chúng theo yêu cầu của từng dự án."
4010,E:\DATN\dataframe\train_file\54.txt,"Để mọi thứ đơn giản hơn , ở đây mình sẽ triển khai qua 3 layer chính:"
4011,E:\DATN\dataframe\train_file\54.txt,Domain layer
4012,E:\DATN\dataframe\train_file\54.txt,Domain layer là tầng trung tâm của mô hình (Không có bất kì sự phụ thuộc nào với các tầng khác ).
4013,E:\DATN\dataframe\train_file\54.txt,"Nó chứa Entities , Repositories , Usecases."
4014,E:\DATN\dataframe\train_file\54.txt,Usecase tổng hợp data từ 1 hoặc nhiều repository.
4015,E:\DATN\dataframe\train_file\54.txt,"Tuy nhiên chúng chỉ sử dụng để chứa các interface/abstraction , tất cả implementation cần thiết sẽ được triển khai ở data layer và presentation layer."
4016,E:\DATN\dataframe\train_file\54.txt,Cấu trúc package:
4017,E:\DATN\dataframe\train_file\54.txt,"Ngoài việc chứa entities , repositories , usecase thì domain layer còn chứa Interface ""Mapper"" , dùng để convert các entities từ data layer sang models hoặc ngược lại."
4018,E:\DATN\dataframe\train_file\54.txt,Use cases giúp chúng ta tránh khỏi việc làm phình to Presenter hay ViewModel trong MVP hay MVVM.
4019,E:\DATN\dataframe\train_file\54.txt,Đảm bảo nguyên lí Single Responsibility Principle.
4020,E:\DATN\dataframe\train_file\54.txt,"Nó cũng sẽ làm cải thiện các tác vụ RUDT (Read , Update , Debug, Test) của dự án."
4021,E:\DATN\dataframe\train_file\54.txt,Khai báo lớp GetListCoinUseCase
4022,E:\DATN\dataframe\train_file\54.txt,Data layer
4023,E:\DATN\dataframe\train_file\54.txt,"Ở tầng data ta sẽ chỉ sử dụng những dependency cần thiết cho business logic , chịu trách nhiệm lấy data , lưu data và phân bổ data cho app qua domain layer"
4024,E:\DATN\dataframe\train_file\54.txt,"Chứa các Entity , logic để khởi tạo các lib cần thiết như retrofit , interceptor , room,... Ngoài ra là các implementation của repository , datasource từ domain layer."
4025,E:\DATN\dataframe\train_file\54.txt,Đây là cấu trúc package của tầng data
4026,E:\DATN\dataframe\train_file\54.txt,Presentation layer
4027,E:\DATN\dataframe\train_file\54.txt,Presentation layer cung cấp giao diện người dùng cho ứng dụng.
4028,E:\DATN\dataframe\train_file\54.txt,Layer này không chứa bất kì một business logic nào.
4029,E:\DATN\dataframe\train_file\54.txt,"Ở tầng này có thể triển khai theo nhiều mô hình khác nhau : MVC , MVP , MVVM,..."
4030,E:\DATN\dataframe\train_file\54.txt,Cấu trúc package
4031,E:\DATN\dataframe\train_file\54.txt,ViewModel nhận trực tiếp data từ Usecase cung cấp.
4032,E:\DATN\dataframe\train_file\54.txt,Lớp ListCoinViewModel:
4033,E:\DATN\dataframe\train_file\54.txt,Dependency Injection
4034,E:\DATN\dataframe\train_file\54.txt,"Trong Dagger 2 , các class sử dụng annotation  có trách nhiệm cung cấp các object có thể sử dụng để ""tiêm"" bất cứ lúc nào."
4035,E:\DATN\dataframe\train_file\54.txt,"Sử dụng  annotation để tiêm các dependency , nếu khai báo các constructor sử dụng  , Dagger 2 sẽ định nghĩa ra những instance của object này để sử dụng."
4036,E:\DATN\dataframe\train_file\54.txt,"Annotation  là 1 interface , được Dagger 2 sử dụng để generate code , cung cấp các module hoặc khai báo các method cung cấp dependency cần thiết để đáp ứng các request ."
4037,E:\DATN\dataframe\train_file\54.txt,Bạn có thể sử dụng  để thể hiện rằng chỉ có một instance được khai báo trong scope đã định sẵn.
4038,E:\DATN\dataframe\train_file\54.txt,Khai báo các module để cung cấp dependencies:
4039,E:\DATN\dataframe\train_file\54.txt,NetworkModule để cung cấp các dependency về các công cụ để request API:
4040,E:\DATN\dataframe\train_file\54.txt,"CoinDatasourceModule để cung cấp các dependency về datasource , repository sử dụng cho usecase và viewmodel:"
4041,E:\DATN\dataframe\train_file\54.txt,Tiếp theo là MainComponent có nhiệm vụ inject những dependency được khai báo với annotation  trong scope là MainActivity (Không trong subclass của nó )
4042,E:\DATN\dataframe\train_file\54.txt,Cuối cùng là gọi chúng ở MainActivity và sử dụng hoy
4043,E:\DATN\dataframe\train_file\54.txt,Trên đây là toàn bộ về cách triển khai mô hình Clean Architecture kết hợp với Dependency Injection framework là Dagger 2 .
4044,E:\DATN\dataframe\train_file\54.txt,Anh em đọc đê nhé xong cho xin cái upvote.
4045,E:\DATN\dataframe\train_file\54.txt,Project demo :
4046,E:\DATN\dataframe\train_file\54.txt,Tài liệu tham khảo
4047,E:\DATN\dataframe\train_file\55.txt,Distributed transaction - Transactional outbox pattern
4048,E:\DATN\dataframe\train_file\55.txt,"Với bài trước,  đã giúp Thảo - một SA nhiều năm kinh nghiệm xử lý bài toán data consistent - distributed transaction với MSA một cách ngon lành."
4049,E:\DATN\dataframe\train_file\55.txt,Thế nhưng vẫn còn một vấn đề đang bỏ ngỏ ở  cần giải quyết.
4050,E:\DATN\dataframe\train_file\55.txt,Trong trường hợp sau khi thực hiện xong business logic và persist data xuống database thành công nhưng publish message fail thì cần xử lý thế nào (application crash hoặc lost connection)?
4051,E:\DATN\dataframe\train_file\55.txt,Cùng đi tìm câu trả lời trong bài viết này nhé.
4052,E:\DATN\dataframe\train_file\55.txt,Gét gô!
4053,E:\DATN\dataframe\train_file\55.txt,1) Transactional outbox pattern?
4054,E:\DATN\dataframe\train_file\55.txt,Mình sẽ lấy ví dụ  để những bạn chưa đọc cũng có thể hiểu được.
4055,E:\DATN\dataframe\train_file\55.txt,Tuy nhiên mình khuyến khích nếu những ai chưa đọc hoặc chưa hiểu về SAGA pattern thì nên đọc trước khi tiếp tục nhé.
4056,E:\DATN\dataframe\train_file\55.txt,Thảo hiện tại là Solution Architect của team IT thuộc chuỗi cửa hàng Pizza và những con bug không thể fix.
4057,E:\DATN\dataframe\train_file\55.txt,"Thời buổi dịch bệnh khó khăn, chủ doanh nghiệp muốn Thảo thiết kế hệ thống bán hàng online để tăng doanh số."
4058,E:\DATN\dataframe\train_file\55.txt,Vì đã có thâm niên chục năm vén váy.. à nhầm.. vén tay áo.. nên Thảo rất nhanh apply ngay Microservices Architecture với 4 service chính và sử dụng SAGA pattern để handle distributed transaction:
4059,E:\DATN\dataframe\train_file\55.txt,Order service.
4060,E:\DATN\dataframe\train_file\55.txt,Payment service.
4061,E:\DATN\dataframe\train_file\55.txt,Restaurant service.
4062,E:\DATN\dataframe\train_file\55.txt,Delivery service.
4063,E:\DATN\dataframe\train_file\55.txt,"Sau khi Order service tạo order thành công, publish event ORDER_CREATED và Payment service consume event này để xử lý tiếp."
4064,E:\DATN\dataframe\train_file\55.txt,"Payment service thực hiện business logic, commit transaction xuống database và thực hiện publish event ORDER_PAID."
4065,E:\DATN\dataframe\train_file\55.txt,Tuy nhiên đúng lúc publish event thì... toạch.
4066,E:\DATN\dataframe\train_file\55.txt,"Application crash, và thế là mất toi message, order tắc ở đấy và khách hàng chờ dài cổ vẫn chưa thấy pizza đâu."
4067,E:\DATN\dataframe\train_file\55.txt,"Ok, hãy thử đóng vai Thảo và nghĩ cách giải quyết bài toán này trước khi đến phần tiếp theo nhé..."
4068,E:\DATN\dataframe\train_file\55.txt,1.1) Problem
4069,E:\DATN\dataframe\train_file\55.txt,Trước khi đi tìm giải pháp thì cần hiểu chính xác vấn đề cần giải quyết là gì:
4070,E:\DATN\dataframe\train_file\55.txt,Mất connection đến Message broker dẫn đến việc không publish được event.
4071,E:\DATN\dataframe\train_file\55.txt,Có thể mất message nếu application crash/restart.
4072,E:\DATN\dataframe\train_file\55.txt,Cần đảm bảo tính atomic và consistent với 2 method persist() và publish().
4073,E:\DATN\dataframe\train_file\55.txt,Hiểu nôm na là nếu persist() thành công thì việc publish cũng phải thành công (thành công được hiểu là event được publish đến Message broker).
4074,E:\DATN\dataframe\train_file\55.txt,"Nếu không publish được, hay nói cách khác là lost event thì persist() cần được rollback."
4075,E:\DATN\dataframe\train_file\55.txt,1.2) Solution
4076,E:\DATN\dataframe\train_file\55.txt,"Ok, đã clear được problem, thử nghĩ solution để giải quyết từng thứ xem thế nào nhé."
4077,E:\DATN\dataframe\train_file\55.txt,Nếu mất connection và không publish được event thì một cách đơn giản có thể nghĩ đến là retry.
4078,E:\DATN\dataframe\train_file\55.txt,"Những thứ cần quan tâm là retry trong bao lâu, bao nhiêu lần?"
4079,E:\DATN\dataframe\train_file\55.txt,"Cần store message ở đâu để đảm bảo nếu application crash/restart thì vẫn có message để retry: file, database, distributed storage?"
4080,E:\DATN\dataframe\train_file\55.txt,Nếu để đảm bảo vừa atomic mà vừa consistent thì chỉ có nhồi vào chung transaction thôi.
4081,E:\DATN\dataframe\train_file\55.txt,Có nghĩa là message/event cần được lưu và database và xử lý chung một transaction với business logic?
4082,E:\DATN\dataframe\train_file\55.txt,"Từ những idea trên, liệu bạn đã mường tượng ra tổng thể solution cần thực hiện là như thế nào chưa?"
4083,E:\DATN\dataframe\train_file\55.txt,Đi từng bước một nhé.
4084,E:\DATN\dataframe\train_file\55.txt,Create new table in database
4085,E:\DATN\dataframe\train_file\55.txt,"Bước đầu tiên, tạo một table mới đặt tên là outbox_table."
4086,E:\DATN\dataframe\train_file\55.txt,"Khi xử lý business logic, bên cạnh việc update các table liên quan, ta insert thêm một record vào table outbox_table, đương nhiên record này chứa những thông tin cần thiết để publish event (order_id, state) thậm chí có thể lưu luôn event message."
4087,E:\DATN\dataframe\train_file\55.txt,Như vậy vấn đề về atomic và consistent đã được giải quyết một cách triệt để và đơn giản bằng cách sử dụng local transaction.
4088,E:\DATN\dataframe\train_file\55.txt,Create relay publisher
4089,E:\DATN\dataframe\train_file\55.txt,"Như vậy các event được lưu trữ tại database, đảm bảo đầy đủ các tính chất quan trọng:"
4090,E:\DATN\dataframe\train_file\55.txt,"Consistency: nếu store business data thành công thì mới có event, và ngược lại."
4091,E:\DATN\dataframe\train_file\55.txt,Durability: một khi transaction commit thành công thì không thể lost message.
4092,E:\DATN\dataframe\train_file\55.txt,Message ordering: message lưu trữ tại database theo thứ tự rõ ràng để đảm bảo khi publish message không có chuyện message đến sau lại publish trước.
4093,E:\DATN\dataframe\train_file\55.txt,"Bây giờ đã một đống message đang chờ để publish, thì tất nhiên phải có publisher làm nhiệm vụ check xem đang có message nào không, nếu có thì publish."
4094,E:\DATN\dataframe\train_file\55.txt,"Tất nhiên vẫn không thể tránh trường hợp lost connection đến Message broker, vậy nên việc publish cần có cơ chế retry, và update message state sau khi publish thành công để tránh publish nhiều lần."
4095,E:\DATN\dataframe\train_file\55.txt,Pattern này là polling publisher.
4096,E:\DATN\dataframe\train_file\55.txt,Đại khái publisher sẽ query liên tục (theo chu kì) đến outbox_table để tìm event và publish.
4097,E:\DATN\dataframe\train_file\55.txt,"Một câu hỏi được đặt ra, vậy publisher này nên là một service độc lập hay là một service (class) nằm trong payment-service?"
4098,E:\DATN\dataframe\train_file\55.txt,Vì sẽ có tình huống payment-service crash còn nhiều event trong outbox_table đang chờ được publish.
4099,E:\DATN\dataframe\train_file\55.txt,Nếu relay-publisher thuộc payment-service thì lúc này message không được publish.
4100,E:\DATN\dataframe\train_file\55.txt,"Nhưng nếu relay-publisher là service độc lập thì nó cần access vào outbox_table của payment-service, có vẻ không hợp lý?"
4101,E:\DATN\dataframe\train_file\55.txt,Thử suy nghĩ và đưa ra câu trả lời cho riêng mình nhé.
4102,E:\DATN\dataframe\train_file\55.txt,Mình sẽ đưa ra ý kiến cá nhân ở phần cuối.
4103,E:\DATN\dataframe\train_file\55.txt,"Và đương nhiên, solution này là chính là transactional outbox pattern."
4104,E:\DATN\dataframe\train_file\55.txt,Alternative solution
4105,E:\DATN\dataframe\train_file\55.txt,Về cơ bản solution trên đã giải quyết được problem đưa ra ở đầu bài nếu sử dụng SQL (RDBMS).
4106,E:\DATN\dataframe\train_file\55.txt,"Tất nhiên, nó cũng có những nhược điểm cần chú ý:"
4107,E:\DATN\dataframe\train_file\55.txt,Nếu application sử dụng NoSQL thì cần cẩn thận vì không phải NoSQL nào cũng có thể support pattern này (do không đảm bảo tính chất quan trọng của transaction).
4108,E:\DATN\dataframe\train_file\55.txt,Extra call đến database để check có event nào cần publish không.
4109,E:\DATN\dataframe\train_file\55.txt,"Quay lại vấn đề ban đầu, mấu chốt quan trọng nhất để giải quyết bài toán ở chỗ cần biết chính xác transaction cho business logic đã được commit thành công chưa để thực hiện việc publish event."
4110,E:\DATN\dataframe\train_file\55.txt,Việc build event message hoàn toàn có thể thực hiện dựa trên business data... nhưng tất nhiên chẳng ai làm thế cả.
4111,E:\DATN\dataframe\train_file\55.txt,"Vì vậy có một biến thể khác để implement relay publisher, và cũng để giải quyết 2 vấn đề trên là apply transaction log tailing pattern."
4112,E:\DATN\dataframe\train_file\55.txt,"Nếu bạn đã làm việc MySQL thì chắc hẳn đã nghe đến binlog, hoặc nếu quen thuộc với  là WAL."
4113,E:\DATN\dataframe\train_file\55.txt,"Có thể hiểu đơn giản rằng transaction log giống như hộp đen của máy bay, lưu trữ tất cả lịch sử thay đổi dữ liệu của database."
4114,E:\DATN\dataframe\train_file\55.txt,Khi dữ liệu bị thay đổi thì database cần lưu trữ các thay đổi đó vào log file.
4115,E:\DATN\dataframe\train_file\55.txt,"Và việc đọc log file này có thể giúp chúng ta biết transaction nào được commit, data nào được thay đổi."
4116,E:\DATN\dataframe\train_file\55.txt,Từ có có thể build event để publish đến Message broker.
4117,E:\DATN\dataframe\train_file\55.txt,Mình không đi quá chi tiết vào các pattern này tránh loãng bài viết.
4118,E:\DATN\dataframe\train_file\55.txt,Nếu có nhu cầu hãy để lại comment để mình biết và giải thích kĩ hơn và có những so sánh trong bài viết tiếp theo nhé.
4119,E:\DATN\dataframe\train_file\55.txt,2) Case study: Notification service
4120,E:\DATN\dataframe\train_file\55.txt,Nhờ apply transactional outbox pattern mà Thảo đã gồng gánh quán Pizza và những con bug không thể fix qua bể khổ đầy đau thương.
4121,E:\DATN\dataframe\train_file\55.txt,"Quán làm ăn ngày một phát đạt, số lượng khách hàng tăng chóng mặt."
4122,E:\DATN\dataframe\train_file\55.txt,Vì vậy thời gian chuẩn bị đồ tăng lên đáng kể.
4123,E:\DATN\dataframe\train_file\55.txt,"Tránh làm sao được, đấy là vấn đề của nhân sự, của nhà bếp rồi, chứ đâu còn là của software để mà Thảo có thể vén váy.. à nhầm vén tay áo quẩy tiếp."
4124,E:\DATN\dataframe\train_file\55.txt,"Nhưng mà lương tâm nghề nghiệp thôi thúc Thảo phải làm điều gì đấy, chứ không thì nhận đồng lương cũng xót xa lắm."
4125,E:\DATN\dataframe\train_file\55.txt,"Thảo liền bánh vẽ ngay một feature mới: thông báo trạng thái order đến khách hàng thông qua các kênh như email, sms, phone call... Thế nhưng không phải khách hàng nào cũng cần thông báo, có ông muốn nhận thông báo, có bà lại không thích."
4126,E:\DATN\dataframe\train_file\55.txt,Thế phải để cho khách hàng chủ động chọn lựa thông báo khi order.
4127,E:\DATN\dataframe\train_file\55.txt,"Mặc dù feature này cũng không giúp cải thiện tốc độ nướng bánh của đầu bếp, nhưng ít nhất khách hàng cũng biết order của họ được thực hiện đến bước nào."
4128,E:\DATN\dataframe\train_file\55.txt,"Thực tế chẳng ông nào rảnh rỗi thế đâu, mình phải bịa ra để có cái còn viết tiếp ý mà."
4129,E:\DATN\dataframe\train_file\55.txt,"Ok, cùng xem Thảo biểu diễn nhé."
4130,E:\DATN\dataframe\train_file\55.txt,Gét gô!
4131,E:\DATN\dataframe\train_file\55.txt,Design & Flow
4132,E:\DATN\dataframe\train_file\55.txt,Đầu tiên cứ là phải phân tích requirement xem cụ tỉ dư lào và draft high level design.
4133,E:\DATN\dataframe\train_file\55.txt,Coi như việc phân tích đã xong nhé .
4134,E:\DATN\dataframe\train_file\55.txt,Thảo nhận ra ngay việc cần làm là tạo ra Notification platform với mục đích chuyên để gửi thông báo đến người dùng thông qua các kênh khác nhau.
4135,E:\DATN\dataframe\train_file\55.txt,Và một điều quan trọng là chỉ gửi đến những người đăng kí nhận thông báo.
4136,E:\DATN\dataframe\train_file\55.txt,Như vậy có thể tạm hình dung ra 3 components chính trong bài toán này:
4137,E:\DATN\dataframe\train_file\55.txt,Application: tất nhiên là notification-serivce rồi.
4138,E:\DATN\dataframe\train_file\55.txt,"Database: MySQL, Postgres... để thực hiện được transactional outbox pattern."
4139,E:\DATN\dataframe\train_file\55.txt,Subscriber: khách hàng muốn nhận thông báo.
4140,E:\DATN\dataframe\train_file\55.txt,Đọc tiếp flow bên dưới kết hợp với hình bên trên để hiểu hơn flow nhé:
4141,E:\DATN\dataframe\train_file\55.txt,"Đầu tiên, khi client order sẽ có checkbox để lựa chọn việc có nhận thông báo hay không, nhận qua hình thức nào."
4142,E:\DATN\dataframe\train_file\55.txt,Nếu có thì sau đó order-service sẽ gửi request tới notification-service để đăng kí nhận thông báo.
4143,E:\DATN\dataframe\train_file\55.txt,Ví dụ thông qua HTTP POST /subscribe.
4144,E:\DATN\dataframe\train_file\55.txt,Sau đó điều hướng đến SubscriptionService (class) để thực hiện business logic.
4145,E:\DATN\dataframe\train_file\55.txt,"Store thông tin vào subscription_table, có thể là một hoặc nhiều table khác, mình chỉ vẽ đại diện một table."
4146,E:\DATN\dataframe\train_file\55.txt,"Sau khi nhà bếp nhận thực đơn, hệ thống muốn gửi thông báo trạng thái order đến người dùng."
4147,E:\DATN\dataframe\train_file\55.txt,Lúc này order-service hoặc restaurant-service gửi message đến notification-service.
4148,E:\DATN\dataframe\train_file\55.txt,"Notification-service apply transactional outbox pattern như hình trên, store business data vào notification table và outbox message vào notify_outbox table."
4149,E:\DATN\dataframe\train_file\55.txt,"Tiếp theo và việc publish notification đến người dùng, hiện thời có 3 channel là sms, email, voice call tương ứng với 3 relay publisher."
4150,E:\DATN\dataframe\train_file\55.txt,Mỗi publisher sẽ chủ động monitor message của riêng mình để publish đến địa chỉ đích.
4151,E:\DATN\dataframe\train_file\55.txt,"Với design này có thể dễ dàng thêm các publisher một cách độc lập, dễ dàng scale."
4152,E:\DATN\dataframe\train_file\55.txt,"Client cũng dễ dàng trong việc lựa chọn việc nhận thông báo, và nhận qua hình thức nào."
4153,E:\DATN\dataframe\train_file\55.txt,"Một nước cờ quá hoàn hảo, quả không hổ danh Thảo SA."
4154,E:\DATN\dataframe\train_file\55.txt,Một tràng vỗ tay dành cho Thảo.
4155,E:\DATN\dataframe\train_file\55.txt,3) Limitation
4156,E:\DATN\dataframe\train_file\55.txt,"Tất nhiên rồi, chẳng có cách nào là hoàn hảo, transactional outbox pattern cũng bá đạo thật đấy nhưng vẫn có nhược điểm nhất định mà ta cần nắm rõ để xử lý bài toán cho tốt, cho triệt để."
4157,E:\DATN\dataframe\train_file\55.txt,Duplicate event: rất khó để đảm bảo việc message delivery là exactly once.
4158,E:\DATN\dataframe\train_file\55.txt,Vấn đề publish message thành công và chưa kịp update lại vào database (application crash) là chuyện hết sức bình thường.
4159,E:\DATN\dataframe\train_file\55.txt,Do vậy đầu consume cần đảm bảo được việc có thể xử lý duplicate message.
4160,E:\DATN\dataframe\train_file\55.txt,Hay nói cách khác là cần implement idempotent consumer.
4161,E:\DATN\dataframe\train_file\55.txt,Near real-time: chắc chắn là rất khó để đạt đến trạng thái real-time application.
4162,E:\DATN\dataframe\train_file\55.txt,Vấn đề là ta có chấp nhận có độ trễ không và độ trễ là bao nhiêu thì chấp nhận được.
4163,E:\DATN\dataframe\train_file\55.txt,After credit
4164,E:\DATN\dataframe\train_file\55.txt,Quay lại câu hỏi ở phần đầu publisher nên là một service độc lập hay là một inner-service?
4165,E:\DATN\dataframe\train_file\55.txt,"Theo quan điểm cá nhân, nó sẽ phụ thuộc vào bài toán cần giải quyết là gì, vấn đề có phức tạp hay không, yêu cầu letancy thế nào, có cần mở rộng trong tương lai không?"
4166,E:\DATN\dataframe\train_file\55.txt,"Ví dụ về notification-service phía trên, chắc chắn là việc chia thành các service độc lập là hiệu quả hơn."
4167,E:\DATN\dataframe\train_file\55.txt,Trong trường hợp thêm một channel mới ta chỉ việc implement service mới mà không cần sửa code cũ.
4168,E:\DATN\dataframe\train_file\55.txt,Nó giúp việc scale dễ dàng và bớt tốn kém.
4169,E:\DATN\dataframe\train_file\55.txt,Chỉ có thêm vấn đề nho nhỏ là cần monitor thêm chính service đó.
4170,E:\DATN\dataframe\train_file\55.txt,"Và như mình nói, vấn đề nho nhỏ nên có thể coi là không thành vấn đề."
4171,E:\DATN\dataframe\train_file\55.txt,Reference in series
4172,E:\DATN\dataframe\train_file\56.txt,Data Mining - Khai phá dữ liệu - [Data Science Series]
4173,E:\DATN\dataframe\train_file\56.txt,Data Mining là gì?
4174,E:\DATN\dataframe\train_file\56.txt,"Data mining – khai phá dữ liệu là quá trình phân loại, sắp xếp các tập hợp dữ liệu nhất định để xác định xu hướng, các mẫu và thiết lập các mối liên hệ hữu ích nhằm giải quyết các vấn đề nhờ phân tích dữ liệu."
4175,E:\DATN\dataframe\train_file\56.txt,"Mục tiêu của việc này là cho phép các doanh nghiệp có thể dự đoán được xu hướng tương lai, nhằm đưa ra các quyết định được hỗ trợ dữ liệu từ các tập dữ liệu khổng lồ"
4176,E:\DATN\dataframe\train_file\56.txt,Quá trình khai phá dữ liệu là một quá trình phức tạp bao gồm kho dữ liệu chuyên sâu cũng như các công nghệ tính toán.
4177,E:\DATN\dataframe\train_file\56.txt,Các giai đoạn trong Data mining
4178,E:\DATN\dataframe\train_file\56.txt,1.Thiết lập mục tiêu Data mining
4179,E:\DATN\dataframe\train_file\56.txt,"Giống như khi chúng ta nấu ăn, bước đầu tiên chúng ta cần thiết lập mục tiêu, rằng chúng ta sẽ nấu món gì, lượng dinh dưỡng cần thiết và chi phí bỏ ra là bao nhiêu,... Thì Data mining cũng tương tự như vậy."
4180,E:\DATN\dataframe\train_file\56.txt,Bước đầu tiên trong Data mining chính là bạn phải thiết lập mục tiêu.
4181,E:\DATN\dataframe\train_file\56.txt,"Rõ ràng, bạn phải xác định các câu hỏi chính cần được trả lời."
4182,E:\DATN\dataframe\train_file\56.txt,"Tuy nhiên, bên cạnh việc xác định các câu hỏi thì chúng ta cũng cần quan tâm đến chính là những chi phí phải bỏ ra và lợi ích từ của kết quả thu được từ Data mining."
4183,E:\DATN\dataframe\train_file\56.txt,"Chẳng hạn nếu bạn (hoặc công ty bạn  ) có rất nhiều tiền, thì chi phí không phải là đối tượng mà bạn cần quan tâm nữa, bạn có thể ném càng nhiều tiền khi cần thiết để có được câu trả lời cần thiết."
4184,E:\DATN\dataframe\train_file\56.txt,"Tuy nhiên, sự đánh đổi giữa chi phí-lợi ích luôn là công cụ trong việc xác định mục tiêu và phạm vi của Data mining."
4185,E:\DATN\dataframe\train_file\56.txt,Mức độ chính xác dự kiến từ kết quả cũng ảnh hưởng đến chi phí.
4186,E:\DATN\dataframe\train_file\56.txt,Mức độ chính xác cao từ Data mining sẽ tốn kém hơn và ngược lại.
4187,E:\DATN\dataframe\train_file\56.txt,"Do đó, sự đánh đổi lợi ích chi phí cho mức độ chính xác mong muốn là những cân nhắc quan trọng cho các mục tiêu của task Data mining."
4188,E:\DATN\dataframe\train_file\56.txt,Chọn dữ liệu
4189,E:\DATN\dataframe\train_file\56.txt,"Để nấu một món ăn ngon thì chúng ta cần những nguyên liệu thật sự chất lượng, tươi ngon."
4190,E:\DATN\dataframe\train_file\56.txt,Và trong Data mining cũng vậy.
4191,E:\DATN\dataframe\train_file\56.txt,Đầu ra của một task Data mining phần lớn phụ thuộc vào chất lượng dữ liệu được sử dụng.
4192,E:\DATN\dataframe\train_file\56.txt,"Đôi khi, dữ liệu có sẵn để xử lý."
4193,E:\DATN\dataframe\train_file\56.txt,"Ví dụ, các nhà bán lẻ thường có cơ sở dữ liệu lớn về các giao dịch và thông tin khách hàng."
4194,E:\DATN\dataframe\train_file\56.txt,"Tuy nhiên trong một số trường hợp, dữ liệu có thể không có sẵn để sử dụng."
4195,E:\DATN\dataframe\train_file\56.txt,"Trong những trường hợp như vậy, bạn phải xác định các nguồn dữ liệu khác hoặc thậm chí lên kế hoạch thu thập dữ liệu mới, bao gồm các cuộc khảo sác, loại dữ liệu, kích thước và tần suất thu thập của nó có ảnh hưởng trực tiếp đến chi phí thực hiện khai thác dữ liệu."
4196,E:\DATN\dataframe\train_file\56.txt,"Do đó, việc xác định đúng loại dữ liệu cần thiết cho Data mining có thể trả lời các câu hỏi với chi phí hợp lý là rất quan trọng."
4197,E:\DATN\dataframe\train_file\56.txt,Tiền xử lý dữ liệu
4198,E:\DATN\dataframe\train_file\56.txt,Tiền xử lý dữ liệu là một bước quan trọng trong Data mining.
4199,E:\DATN\dataframe\train_file\56.txt,"Giống như việc chúng ta phải sơ chế các nguyên liệu như rửa sạch, gọt vỏ, loại bỏ phần hư hại, thừa,.. trước khi đem chúng vào chế biến."
4200,E:\DATN\dataframe\train_file\56.txt,"Còn đối với dữ liệu, thông thường ban đầu dữ liệu sẽ ở dạng thô, lộn xộn, chứa dữ liệu sai hoặc không liên quan."
4201,E:\DATN\dataframe\train_file\56.txt,"Ngoài ra, ngay cả với dữ liệu có liên quan, thông tin đôi khi sẽ bị thiếu."
4202,E:\DATN\dataframe\train_file\56.txt,"Trong giai đoạn tiền xử lý, bạn xác định các thuộc tính không liên quan của dữ liệu và loại bỏ các thuộc tính đó."
4203,E:\DATN\dataframe\train_file\56.txt,"Đồng thời, việc xác định các điểm bất thường của tập dữ liệu và gắn cờ chúng là rất cần thiết."
4204,E:\DATN\dataframe\train_file\56.txt,"Ví dụ, lỗi của con người có thể dẫn đến vô tình hợp nhất hoặc phân tích không chính xác thông tin giữa các cột."
4205,E:\DATN\dataframe\train_file\56.txt,Vì vậy dữ liệu phải được kiểm tra để đảm bảo tính toàn vẹn.
4206,E:\DATN\dataframe\train_file\56.txt,"Cuối cùng, bạn phải phát triển một phương pháp để xử lý dữ liệu bị thiếu và xác định xem dữ liệu bị thiếu ngẫu nhiên hay có hệ thống hay không."
4207,E:\DATN\dataframe\train_file\56.txt,"Nếu dữ liệu bị thiếu ngẫu nhiên, một bộ giải pháp đơn giản có thể sẽ đáp ứng được."
4208,E:\DATN\dataframe\train_file\56.txt,"Tuy nhiên, khi dữ liệu bị thiếu một cách có hệ thống, bạn phải xác định tác động nào khiến dữ liệu bị thiếu."
4209,E:\DATN\dataframe\train_file\56.txt,"Ví dụ, một lượng lớn data khách hàng của bạn bị thiếu thông tin về thu nhập, có thể họ đã từ chối tiết lộ thu nhập."
4210,E:\DATN\dataframe\train_file\56.txt,Vì vậy những phân tích dựa trên thu nhập có thể sẽ không còn khách quan vì bộ dữ liệu về thu nhập là không đầy đủ.
4211,E:\DATN\dataframe\train_file\56.txt,"Do đó, bạn phải xem xét kỹ dữ liệu và cân nhắc loại bỏ thay vì nhắm mắt nhắm mũi đem hết chúng vào phân tích"
4212,E:\DATN\dataframe\train_file\56.txt,Biến đổi (transform) dữ liệu
4213,E:\DATN\dataframe\train_file\56.txt,"Sau khi đã tiền xử lý dữ liệu, bước tiếp theo là xác định định dạng thích hợp để lưu trữ dữ liệu."
4214,E:\DATN\dataframe\train_file\56.txt,Một lưu ý trong Data mining là chúng ta cần giảm số lượng thuộc tính cần thiết xuống mức tối thiểu mà không làm mất đi những thông tin cần thiết để giải thích các hiện tượng.
4215,E:\DATN\dataframe\train_file\56.txt,"Tức là chúng ta sẽ chuyển đổi dữ liệu thông qua các thuật toán giảm dữ liệu, chẳng hạn như Principal Component Analysis (mọi người có thể research thêm)."
4216,E:\DATN\dataframe\train_file\56.txt,"Ngoài ra, các biến có thể cần phải được chuyển đổi để giúp giải thích hiện tượng đang được nghiên cứu."
4217,E:\DATN\dataframe\train_file\56.txt,"Ví dụ, thu nhập của một cá nhân có thể được ghi lại trong bộ dữ liệu dưới dạng nhiều nguồn như:"
4218,E:\DATN\dataframe\train_file\56.txt,Thu nhập tiền lương
4219,E:\DATN\dataframe\train_file\56.txt,Thu nhập từ tài sản cho thuê
4220,E:\DATN\dataframe\train_file\56.txt,Hỗ trợ các khoản thanh toán từ chính phủ
4221,E:\DATN\dataframe\train_file\56.txt,"Thu nhập khác,.... Tổng hợp thu nhập từ tất cả các nguồn này chúng ta sẽ gom thành một thuộc tính với chỉ số đại diện cho tổng thu nhập cá nhân."
4222,E:\DATN\dataframe\train_file\56.txt,Thông thường bạn cần phải chuyển đổi các biến từ loại này sang loại khác.
4223,E:\DATN\dataframe\train_file\56.txt,"Có thể thận trọng khi chuyển đổi biến liên tục cho thu nhập thành một biến phân loại trong đó mỗi bản ghi trong cơ sở dữ liệu được xác định là cá nhân có thu nhập thấp, trung bình và cao."
4224,E:\DATN\dataframe\train_file\56.txt,Điều này có thể giúp nắm bắt các phi tuyến tính trong các hành vi cơ bản.
4225,E:\DATN\dataframe\train_file\56.txt,Lưu trữ dữ liệu
4226,E:\DATN\dataframe\train_file\56.txt,Dữ liệu đã được chuyển đổi phải được lưu trữ ở định dạng dễ dàng cho việc Data mining.
4227,E:\DATN\dataframe\train_file\56.txt,Dữ liệu phải được lưu trữ ở định dạng cung cấp các quyền đọc và ghi ngay lập tức và không hạn chế cho các Data Scientist.
4228,E:\DATN\dataframe\train_file\56.txt,"Trong quá trình Data mining, các biến mới được tạo ra, được ghi lại vào cơ sở dữ liệu ban đầu, đó là lý do tại sao sơ đồ lưu trữ dữ liệu sẽ tạo điều kiện đọc và ghi hiệu quả vào cơ sở dữ liệu."
4229,E:\DATN\dataframe\train_file\56.txt,Nó cũng quan trọng để lưu trữ dữ liệu trên các máy chủ hoặc phương tiện lưu trữ giữ cho dữ liệu an toàn và cũng ngăn chặn thuật toán Data mining không cần thiết tìm khi kiếm các mảnh dữ liệu nằm rải rác trên các máy chủ hoặc phương tiện lưu trữ khác nhau.
4230,E:\DATN\dataframe\train_file\56.txt,"An toàn và quyền riêng tư, bảo mậtr dữ liệu nên là mối quan tâm hàng đầu khi lưu trữ dữ liệu."
4231,E:\DATN\dataframe\train_file\56.txt,Data mining
4232,E:\DATN\dataframe\train_file\56.txt,"Sau khi dữ liệu được xử lý, chuyển đổi và lưu trữ một cách thích hợp, nó sẽ được mining."
4233,E:\DATN\dataframe\train_file\56.txt,"Bước này bao gồm các phương pháp phân tích dữ liệu, bao gồm các phương pháp tham số và không tham số, và các thuật toán Machine Learning."
4234,E:\DATN\dataframe\train_file\56.txt,"Chúng ta nên bắt đầu giai đoạn này bằng việc trực quan hóa dữ liệu, nó giúp chúng ta có góc nhìn đa chiều, xu hướng ấn,... về dữ liệu nhờ vào việc tận dụng khả năng vẽ đồ thị hiện đại của các phần mềm Data mining."
4235,E:\DATN\dataframe\train_file\56.txt,Đánh giá kết quả
4236,E:\DATN\dataframe\train_file\56.txt,"Sau khi kết quả đã được trích xuất từ Data mining, chúng ta cần thực hiện đánh kết quả."
4237,E:\DATN\dataframe\train_file\56.txt,Đánh giá có thể bao gồm kiểm tra khả năng dự đoán của các mô hình trên dữ liệu quan sát được để xem các thuật toán đã hiệu quả chưa và hiệu quả như thế nào trong việc tái tạo dữ liệu.
4238,E:\DATN\dataframe\train_file\56.txt,"Điều này được gọi là ""dự báo trong mẫu""."
4239,E:\DATN\dataframe\train_file\56.txt,"Ngoài ra, kết quả được chia sẻ với các bên liên quan (stake holder) để phản hồi, sau đó được kết hợp trong các lần lặp lại sau này của Data mining để tiếp tục cải thiện quy trình."
4240,E:\DATN\dataframe\train_file\56.txt,"Data mining và đánh giá kết quả trở thành một quá trình lặp đi lặp lại để các Analyst, Data Scientist sử dụng các thuật toán tốt hơn và cải thiện chất lượng kết quả được tạo ra theo phản hồi nhận được từ các bên liên quan."
4241,E:\DATN\dataframe\train_file\56.txt,Tham khảo từ quyển Getting Started with Data Science của IBM
4242,E:\DATN\dataframe\train_file\57.txt,Prunning model với Tensorflow API
4243,E:\DATN\dataframe\train_file\57.txt,"Tiếp nối chuỗi Series nâng cao kiến thức bản thân về ML, DL, bài viết này mình xin phép chia sẻ một bài viết thuộc chủ để Pruning."
4244,E:\DATN\dataframe\train_file\57.txt,"Vẫn với lí do lướt Towards Data Science, Medium thì thấy bài viết hay quá nên chia sẻ cùng mọi người"
4245,E:\DATN\dataframe\train_file\57.txt,"Cùng với việc phát triển mạnh mẽ của công nghệ và dữ liệu đã thúc đẩy Deep Learning ngày càng lớn mạnh với những thành tựu đánh kinh nể, có những bài toán có độ chính xác vượt xa cả con người."
4246,E:\DATN\dataframe\train_file\57.txt,"Các mô hình ngày càng lớn mạnh, đi kèm với việc tiêu tốn tài nguyên."
4247,E:\DATN\dataframe\train_file\57.txt,"Không nói gì xa, hiện tại khi muốn triển khai Deep Learning cho khách hàng, bên cạnh độ chính xác thì luôn phải cân nhắc tới việc tiêu tốn tài nguyên."
4248,E:\DATN\dataframe\train_file\57.txt,Làm sao để giải quyết các bài toán lớn những phải phù hợp với tài nguyên hiện tại.
4249,E:\DATN\dataframe\train_file\57.txt,Một trong các giải pháp giải quyết vấn đề này phải kể tới kỹ thuật Prunning.
4250,E:\DATN\dataframe\train_file\57.txt,Pruning là gì?
4251,E:\DATN\dataframe\train_file\57.txt,"Nói một cách khai quát, Prunning là một trong những phương pháp đáp ứng việc Inference một cách hiệu quả đối với các mô hình có kích thước nhỏ hơn, tiết kiệm bộ nhớ hơn, suy luận nhanh hơn với độ chính xác giảm ít nhất có thể so với mô hình gốc ban đầu."
4252,E:\DATN\dataframe\train_file\57.txt,"Trong Decision tree, Pruning là 1 kỹ thuật regularization để tránh Overfitting, trong đó, các leaf node có chung một non-leaf node sẽ được cắt tỉa và non-leaf node đó sẽ trở thành 1 leaf node, với class tương ứng là class chiếm đa số trong số mọi điểm được phân vào node đó"
4253,E:\DATN\dataframe\train_file\57.txt,"Ý tưởng cắt tỉa mạng neural network được lấy cảm hứng từ chính sự cắt tỉa liên kết neural trong não người, nơi các liên kết thần kinh giữa các neural(axon) bị phân rã hoàn toàn và chết đi xảy ra giữa thời thơ ấu và sự sự khởi đầu của dậy thì."
4254,E:\DATN\dataframe\train_file\57.txt,Pruning trong Neural network chính là loại bỏ các kết nối dư thừa trong kiến trúc mạng.
4255,E:\DATN\dataframe\train_file\57.txt,"Việc cắt bỏ này thực chất là đưa các giá trị trọng số gần 0 về 0 để loại bỏ những kết nối không cần thiết, việc cắt tỉa này sẽ không gây ảnh hường nhiều đến quá trình Inference"
4256,E:\DATN\dataframe\train_file\57.txt,Có nhiều cách khác nhau để Pruning model.
4257,E:\DATN\dataframe\train_file\57.txt,"Có thể cắt tỉa ngày từ đầu một số trọng số ngẫu nhiên, hoặc cũng có thể cắt tỉa khi kết thúc quá trinhg đào tạo để đơn giản hóa mô hình."
4258,E:\DATN\dataframe\train_file\57.txt,Chắc hẳn sẽ có bạn thắc mắc rằng tại sao một mô hình lại nên được cắt bớt thay vì được khởi tạo với ít tham số hơn từ lúc bắt đầu.
4259,E:\DATN\dataframe\train_file\57.txt,"Câu trả lời cho câu hỏi này là về bản chất bạn muốn giữa một kiến trúc mô hình tương đối phức tạp để đạo tạo, bao quát được dữ liệu."
4260,E:\DATN\dataframe\train_file\57.txt,"Đồng thời việc tinh chỉnh các lớp, giảm hay tăng kích thước các tính năng là một công việc không đem lại hiệu quả cao."
4261,E:\DATN\dataframe\train_file\57.txt,So với đó thì việc Pruning model đơn giản mà mang lại hiệu quả hơn nhiều.
4262,E:\DATN\dataframe\train_file\57.txt,Prunning cùng Tensorflow
4263,E:\DATN\dataframe\train_file\57.txt,Giới thiệu tfmot
4264,E:\DATN\dataframe\train_file\57.txt,"Tfmot là một công cụ với mục tiêu loại bỏ những weights yếu nhất vào cuối mỗi bước huấn luyện, đồng thời nó cho phép lập trình viên xác định một lịch trình cắt tỉa sẽ tự động xử lý việc loại bỏ các weights."
4265,E:\DATN\dataframe\train_file\57.txt,Bộ lập lịch này tuân theo một lịch trịch phân rã đa thức (polynomial decay schedule).
4266,E:\DATN\dataframe\train_file\57.txt,Cần truyền vào cho công cụ các tham số như:
4267,E:\DATN\dataframe\train_file\57.txt,Độ thưa ban đầu (initial sparsity)
4268,E:\DATN\dataframe\train_file\57.txt,Độ thưa cuối cùng (final sparsity)
4269,E:\DATN\dataframe\train_file\57.txt,Bước bắt đầu cắt tỉa
4270,E:\DATN\dataframe\train_file\57.txt,Bước kết thúc cắt tỉa
4271,E:\DATN\dataframe\train_file\57.txt,"Số mũ của phép phân rã (exponent ò the polynomial decay) Tại mỗi bước, bộ công cụ sẽ loại bỏ đủ weights sao cho độ thưa thớt đạt được là:"
4272,E:\DATN\dataframe\train_file\57.txt,S = ( S _ { e } - S _ { 0 } ) ( \frac { t - t _ { 0 } } { t _ { e } - t _ { 0 } } ) ^ { \alpha }
4273,E:\DATN\dataframe\train_file\57.txt,−S
4274,E:\DATN\dataframe\train_file\57.txt,−t
4275,E:\DATN\dataframe\train_file\57.txt,t−t
4276,E:\DATN\dataframe\train_file\57.txt,Trong đó
4277,E:\DATN\dataframe\train_file\57.txt,S là độ thưa thớt
4278,E:\DATN\dataframe\train_file\57.txt, là độ thưa thớt cuối cùng
4279,E:\DATN\dataframe\train_file\57.txt, là độ thưa thớt ban đầu
4280,E:\DATN\dataframe\train_file\57.txt,t là time step hiện tại
4281,E:\DATN\dataframe\train_file\57.txt, là time steop bắt đầu
4282,E:\DATN\dataframe\train_file\57.txt,α là số mũ (mặc định là 3)
4283,E:\DATN\dataframe\train_file\57.txt,Ngoài a ra thì các siêu tham số khác cần thay đổi để tìm ra giá trị tối ưu.
4284,E:\DATN\dataframe\train_file\57.txt,"Theo lời khuyên của tác giả, cần cắt tỉa từ từ, chút một để mô hình “thích nghi” với việc giảm weights, cũng giống như cắt cây, cắt một lèo thì còn gì đâu =))"
4285,E:\DATN\dataframe\train_file\57.txt,Triển khai pruning cùng tfmot với ví dụ đơn giản
4286,E:\DATN\dataframe\train_file\57.txt,"Để có thể hình dung và dễ sử dụng tfmot hơn, mình sẽ làm một thí nghiệm nhỏ vừa để hiểu cách sử dụng tfmot, vừa để so sánh việc cắt tỉa và không xem hiệu suất mô hình thay đổi như thế nào"
4287,E:\DATN\dataframe\train_file\57.txt,"Ở đây mình sử dụng sklearn để tạo dataset, đồng thời sử dụng một kiến trúc mạng MLP tương đối đơn giản để so sánh"
4288,E:\DATN\dataframe\train_file\57.txt,Tạo dataset
4289,E:\DATN\dataframe\train_file\57.txt,import pandas as pd
4290,E:\DATN\dataframe\train_file\57.txt,import numpy as np
4291,E:\DATN\dataframe\train_file\57.txt,from sklearn.model_selection import train_test_split
4292,E:\DATN\dataframe\train_file\57.txt,from sklearn.datasets import make_regression
4293,E:\DATN\dataframe\train_file\57.txt,# Parameters of the data-set
4294,E:\DATN\dataframe\train_file\57.txt,n_samples = 10000
4295,E:\DATN\dataframe\train_file\57.txt,n_features = 1000
4296,E:\DATN\dataframe\train_file\57.txt,n_informative = 500
4297,E:\DATN\dataframe\train_file\57.txt,noise = 3
4298,E:\DATN\dataframe\train_file\57.txt,# Create dataset and preprocess it
4299,E:\DATN\dataframe\train_file\57.txt,"x, y = make_regression(n_samples=n_samples, n_features=n_features, n_informative=n_informative, noise=noise)"
4300,E:\DATN\dataframe\train_file\57.txt,x = x / abs(x).max(axis=0)
4301,E:\DATN\dataframe\train_file\57.txt,y = y / abs(y).max()
4302,E:\DATN\dataframe\train_file\57.txt,"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
4303,E:\DATN\dataframe\train_file\57.txt,Tạo mô hình
4304,E:\DATN\dataframe\train_file\57.txt,import tensorflow as tf
4305,E:\DATN\dataframe\train_file\57.txt,from tensorflow.keras.models import Sequential
4306,E:\DATN\dataframe\train_file\57.txt,"from tensorflow.keras.layers import Dense, ReLU"
4307,E:\DATN\dataframe\train_file\57.txt,model = tf.keras.Sequential()
4308,E:\DATN\dataframe\train_file\57.txt,"model.add(Dense(1024, kernel_initializer=""he_normal"", input_dim=n_features))"
4309,E:\DATN\dataframe\train_file\57.txt,Summary mô hình
4310,E:\DATN\dataframe\train_file\57.txt,"Với kiến trúc mạng đơn giản như vậy tuy nhiên tổng số lượng params cũng đã lên tới hơn 2 triệu, nói gì là các kiến trúc mạng phức tạp."
4311,E:\DATN\dataframe\train_file\57.txt,"Vì vậy, mình thử nghiệm việc đào tạo mô hình không Pruning và có Pruning xem có thay đổi đáng kể hiệu suất mô hình hay không"
4312,E:\DATN\dataframe\train_file\57.txt,Training mô hình không sử dụng Pruning
4313,E:\DATN\dataframe\train_file\57.txt,history = model.fit(
4314,E:\DATN\dataframe\train_file\57.txt,"    validation_data = (x_val, y_val),"
4315,E:\DATN\dataframe\train_file\57.txt,Training mô hình sử dụng Pruning với công cụ tfmot
4316,E:\DATN\dataframe\train_file\57.txt,import tensorflow_model_optimization as tfmot
4317,E:\DATN\dataframe\train_file\57.txt,initial_sparsity = 0.0
4318,E:\DATN\dataframe\train_file\57.txt,final_sparsity = 0.75
4319,E:\DATN\dataframe\train_file\57.txt,begin_step = 1000
4320,E:\DATN\dataframe\train_file\57.txt,end_step = 5000
4321,E:\DATN\dataframe\train_file\57.txt,        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(
4322,E:\DATN\dataframe\train_file\57.txt,"model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)"
4323,E:\DATN\dataframe\train_file\57.txt,pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()
4324,E:\DATN\dataframe\train_file\57.txt,"Ở đây sử dụng tfmot như 1 callback, giống learning rate scheduler và early stopping"
4325,E:\DATN\dataframe\train_file\57.txt,history = model.fit(
4326,E:\DATN\dataframe\train_file\57.txt,"    validation_data = (x_val, y_val),"
4327,E:\DATN\dataframe\train_file\57.txt,"    callbacks= pruning_callback,"
4328,E:\DATN\dataframe\train_file\57.txt,"Đã có sự chênh lệch tuy nhiên khi sử dụng Pruning thì độ chính xác giảm đi không nhiều, val_loss vẫn ở mức chấp nhận được"
4329,E:\DATN\dataframe\train_file\57.txt,Với cá nhân mình thấy Pruning là mọt phương pháp đang khá được để tâm tới do tính hữu dụng của nó trong việc “làm nhẹ” mô hình.
4330,E:\DATN\dataframe\train_file\57.txt,MÌnh đã thử nghiệm một vài bái toán cùng team và nghe một vài buổi seminar nới về Pruning thì thấy kết quả của các tác giả thử nghiệm đem lại hiệu quả tương đối bất ngờ.
4331,E:\DATN\dataframe\train_file\57.txt,"Song song với việc phát triển phần cứng thì chúng ta cũng cần có nhwung phương pháp xoa dịu mô hình nhẹ xuống để phần cứng hay tài chính, thời gian còn theo kịp =)))"
4332,E:\DATN\dataframe\train_file\57.txt,Tài liệu tham khảo
4333,E:\DATN\dataframe\train_file\58.txt,Design Patterns - Visitor
4334,E:\DATN\dataframe\train_file\58.txt,📜 Mục đích
4335,E:\DATN\dataframe\train_file\58.txt,Visitor là một design pattern thuộc nhóm behavioral giúp bạn tách các thuật toán khỏi đối tượng mà chúng đang hoạt động trên đó.
4336,E:\DATN\dataframe\train_file\58.txt,😟 Vấn đề
4337,E:\DATN\dataframe\train_file\58.txt,Tưởng tượng team bạn đang phát triển một ứng dụng làm việc với thông tin địa lý được cấu trúc dưới dạng một đồ thị khổng lồ.
4338,E:\DATN\dataframe\train_file\58.txt,"Mỗi nút trong đồ thị có thể biểu diễn một thực thể phức tạp như một thành phố, nhưng chi tiết hơn như các nhà máy, khu tham quan,... Các nút được kết nối với nhau nếu có một con đường giữa các đối tượng thực mà nó biểu diễn."
4339,E:\DATN\dataframe\train_file\58.txt,"Hiểu sâu hơn, mỗi loại nút được biểu diễn bởi lớp riêng của nó, trong khi mỗi nút cụ thể là một đối tượng."
4340,E:\DATN\dataframe\train_file\58.txt,"Tại một thời điểm nào đó, bạn có nhiệm vụ xuất đồ thị sang định dạng XML."
4341,E:\DATN\dataframe\train_file\58.txt,"Lúc đầu, công việc có vẻ khá đơn giản."
4342,E:\DATN\dataframe\train_file\58.txt,"Bạn đã lên kế hoạch thêm một phương thức xuất vào từng lớp nút và sau đó tận dụng đệ quy để đi qua từng nút của đồ thị, thực hiện phương thức xuất."
4343,E:\DATN\dataframe\train_file\58.txt,"Giải pháp rất đơn giản và gọn gàng: nhờ tính đa hình, bạn không phải ghép đoạn code phương thức xuất với các lớp nút cụ thể."
4344,E:\DATN\dataframe\train_file\58.txt,"Thật không may, kỹ sư hệ thống đã từ chối cho phép bạn thay đổi các lớp nút hiện có."
4345,E:\DATN\dataframe\train_file\58.txt,Anh ấy nói rằng code đã được tạo và anh ấy không muốn mạo hiểm phá vỡ nó vì một lỗi tiềm ẩn trong các thay đổi của bạn.
4346,E:\DATN\dataframe\train_file\58.txt,"Bên cạnh đó, anh ấy đặt câu hỏi liệu có hợp lý khi có code xuất XML trong các lớp nút hay không."
4347,E:\DATN\dataframe\train_file\58.txt,Công việc chính của các lớp này là làm việc với dữ liệu địa lý.
4348,E:\DATN\dataframe\train_file\58.txt,Hành vi xuất XML sẽ có vẻ không phù hợp ở đó.
4349,E:\DATN\dataframe\train_file\58.txt,Có một lý do khác cho việc từ chối.
4350,E:\DATN\dataframe\train_file\58.txt,"Rất có thể sau khi tính năng này được triển khai, một người nào đó từ bộ phận tiếp thị sẽ yêu cầu bạn cung cấp khả năng xuất sang một định dạng khác hoặc yêu cầu một số thứ kỳ lạ khác."
4351,E:\DATN\dataframe\train_file\58.txt,Điều này sẽ buộc bạn phải thay đổi những lớp này một lần nữa.
4352,E:\DATN\dataframe\train_file\58.txt,😊 Giải pháp
4353,E:\DATN\dataframe\train_file\58.txt,"Pattern Visitor gợi ý rằng bạn nên đặt hành vi mới vào một lớp riêng biệt được gọi là visitor, thay vì cố gắng tích hợp nó vào các lớp hiện có."
4354,E:\DATN\dataframe\train_file\58.txt,"Đối tượng gốc phải thực hiện hành vi bây giờ được chuyển cho một trong những phương thức của visitor dưới dạng tham số, cung cấp cho phương thức này quyền truy cập vào tất cả dữ liệu cần thiết có trong đối tượng."
4355,E:\DATN\dataframe\train_file\58.txt,"Bây giờ, điều gì sẽ xảy ra nếu hành vi đó có thể được thực thi trên các đối tượng của các lớp khác nhau?"
4356,E:\DATN\dataframe\train_file\58.txt,"Ví dụ, trong trường hợp này là xuất XML, việc triển khai thực tế có thể sẽ khác một chút trên các lớp nút khác nhau."
4357,E:\DATN\dataframe\train_file\58.txt,"Do đó, lớp visitor phải xác định không phải một, mà là một tập hợp các phương thức, mỗi phương thức có thể nhận các tham số thuộc các kiểu khác nhau, như thế này:"
4358,E:\DATN\dataframe\train_file\58.txt,class ExportVisitor implements Visitor is
4359,E:\DATN\dataframe\train_file\58.txt,    method doForCity(City c) { ... }
4360,E:\DATN\dataframe\train_file\58.txt,    method doForIndustry(Industry f) { ... }
4361,E:\DATN\dataframe\train_file\58.txt,    method doForSightSeeing(SightSeeing ss) { ... }
4362,E:\DATN\dataframe\train_file\58.txt,"Nhưng chính xác thì chúng ta sẽ gọi những phương pháp này như thế nào, đặc biệt là khi xử lý toàn bộ đồ thị?"
4363,E:\DATN\dataframe\train_file\58.txt,"Các phương pháp này có các signature khác nhau, vì vậy ta không thể sử dụng tính đa hình."
4364,E:\DATN\dataframe\train_file\58.txt,"Để chọn một phương thức visitor thích hợp có thể xử lý một đối tượng nhất định, ta cần kiểm tra lớp của nó."
4365,E:\DATN\dataframe\train_file\58.txt,foreach (Node node in graph)
4366,E:\DATN\dataframe\train_file\58.txt,    if (node instanceof City)
4367,E:\DATN\dataframe\train_file\58.txt,        exportVisitor.doForCity((City) node)
4368,E:\DATN\dataframe\train_file\58.txt,    if (node instanceof Industry)
4369,E:\DATN\dataframe\train_file\58.txt,        exportVisitor.doForIndustry((Industry) node)
4370,E:\DATN\dataframe\train_file\58.txt,"Bạn có thể hỏi, tại sao chúng ta không sử dụng phương thức overloading - nạp chồng?"
4371,E:\DATN\dataframe\train_file\58.txt,"Overloading là khi bạn đặt cùng một tên cho tất cả các phương thức, ngay cả khi chúng có các tham số khác nhau."
4372,E:\DATN\dataframe\train_file\58.txt,"Thật không may, ngay cả trong trường hợp ngôn ngữ lập trình của ta hỗ trợ overloading (như Java và C #), thì nó cũng không giúp ích được gì cả."
4373,E:\DATN\dataframe\train_file\58.txt,"Vì lớp chính xác của đối tượng nút không được biết trước, cơ chế overloading sẽ không thể xác định phương thức chính xác để thực thi."
4374,E:\DATN\dataframe\train_file\58.txt,Nó sẽ mặc định là phương thức nhận một đối tượng của lớp Node cơ sở.
4375,E:\DATN\dataframe\train_file\58.txt,"Tuy nhiên, pattern visitor giải quyết vấn đề này."
4376,E:\DATN\dataframe\train_file\58.txt,"Nó sử dụng một kỹ thuật gọi là , giúp thực thi phương thức thích hợp trên một đối tượng mà không cần các điều kiện rườm rà."
4377,E:\DATN\dataframe\train_file\58.txt,"Và thay vì cho phép client chọn một phiên bản thích hợp của phương thức để gọi, tại sao ta không ủy thác lựa chọn này cho các đối tượng mà chúng ta đang chuyển cho visitor làm tham số ?"
4378,E:\DATN\dataframe\train_file\58.txt,"Vì các đối tượng biết các lớp riêng của chúng, chúng có thể chọn một phương pháp thích hợp cho visitor một cách ít lúng túng hơn."
4379,E:\DATN\dataframe\train_file\58.txt,"Chúng ""accept"" một visitor và cho visitor đó biết phương thức truy cập nào nên được thực thi."
4380,E:\DATN\dataframe\train_file\58.txt,// Client code
4381,E:\DATN\dataframe\train_file\58.txt,foreach (Node node in graph)
4382,E:\DATN\dataframe\train_file\58.txt,class City is
4383,E:\DATN\dataframe\train_file\58.txt,    method accept(Visitor v) is
4384,E:\DATN\dataframe\train_file\58.txt,class Industry is
4385,E:\DATN\dataframe\train_file\58.txt,    method accept(Visitor v) is
4386,E:\DATN\dataframe\train_file\58.txt,Rốt cuộc thì ta cũng phải thay đổi các lớp nút.
4387,E:\DATN\dataframe\train_file\58.txt,Nhưng ít nhất sự thay đổi là nhỏ và nó cho phép ta thêm các hành vi khác mà không phải thay đổi code một lần nữa.
4388,E:\DATN\dataframe\train_file\58.txt,"Bây giờ, nếu ta trích xuất một interface chung cho tất cả visitor, thì tất cả các nút hiện có có thể hoạt động với bất kỳ visitor nào mà bạn thêm vào ứng dụng."
4389,E:\DATN\dataframe\train_file\58.txt,"Nếu bạn thấy mình đang thêm một hành vi mới liên quan đến các nút, tất cả những gì bạn phải làm là triển khai một lớp visitor mới."
4390,E:\DATN\dataframe\train_file\58.txt,Thế Giới Thực
4391,E:\DATN\dataframe\train_file\58.txt,Hãy tưởng tượng một đại lý bảo hiểm dày dạn kinh nghiệm đang mong muốn có được khách hàng mới.
4392,E:\DATN\dataframe\train_file\58.txt,"Anh ta có thể đến thăm mọi tòa nhà trong khu phố, cố gắng bán bảo hiểm cho mọi người anh ta gặp."
4393,E:\DATN\dataframe\train_file\58.txt,"Tùy thuộc vào loại hình tổ chức chiếm giữ tòa nhà, anh ta có thể đưa ra các chính sách bảo hiểm chuyên biệt:"
4394,E:\DATN\dataframe\train_file\58.txt,"Nếu đó là một tòa nhà dân cư, anh ta bán bảo hiểm y tế."
4395,E:\DATN\dataframe\train_file\58.txt,"Nếu đó là một ngân hàng, anh ta bán bảo hiểm trộm cắp."
4396,E:\DATN\dataframe\train_file\58.txt,"Nếu đó là một quán cà phê, anh ấy bán bảo hiểm cháy nổ và thiên tai."
4397,E:\DATN\dataframe\train_file\58.txt,Visitor là interface khai báo một tập hợp các phương thức truy cập có thể lấy các concrete element của cấu trúc đối tượng làm tham số.
4398,E:\DATN\dataframe\train_file\58.txt,"Các phương thức này có thể trùng tên nếu chương trình được viết bằng ngôn ngữ hỗ trợ overloading, nhưng kiểu tham số của chúng phải khác nhau."
4399,E:\DATN\dataframe\train_file\58.txt,"Concrete Visitor thực hiện một số phiên bản của các hành vi giống nhau, được điều chỉnh cho các lớp concrete element khác nhau."
4400,E:\DATN\dataframe\train_file\58.txt,"Element là interface khai báo một phương thức để ""accept"" visitor."
4401,E:\DATN\dataframe\train_file\58.txt,Phương thức này phải có một tham số được khai báo với kiểu interface visitor.
4402,E:\DATN\dataframe\train_file\58.txt,Concrete Element thực hiện phương pháp nghiệm thu.
4403,E:\DATN\dataframe\train_file\58.txt,Mục đích của phương thức này là chuyển hướng lệnh gọi đến phương thức của visitor thích hợp tương ứng với lớp element hiện tại.
4404,E:\DATN\dataframe\train_file\58.txt,"Cần biết rằng ngay cả khi một lớp element cơ sở triển khai phương thức này, tất cả các lớp con vẫn phải ghi đè phương thức này trong các lớp của chính chúng và gọi phương thức thích hợp trên đối tượng visitor."
4405,E:\DATN\dataframe\train_file\58.txt,"Client thường đại diện cho một tập hợp hoặc một số đối tượng phức tạp khác (ví dụ, một cây tổng hợp)."
4406,E:\DATN\dataframe\train_file\58.txt,"Thông thường, client không biết tất cả các lớp concrete element vì chúng làm việc với các đối tượng từ tập hợp đó thông qua một số interface trừu tượng"
4407,E:\DATN\dataframe\train_file\58.txt,Mã giả
4408,E:\DATN\dataframe\train_file\58.txt,"Trong ví dụ này, Visitor thêm hỗ trợ xuất XML vào hệ thống phân cấp lớp của các hình dạng hình học."
4409,E:\DATN\dataframe\train_file\58.txt,Xuất nhiều loại đối tượng khác nhau sang định dạng XML thông qua đối tượng visitor.
4410,E:\DATN\dataframe\train_file\58.txt,// Interface element khai báo phương thức `accept` để
4411,E:\DATN\dataframe\train_file\58.txt,// nhận interface visitor cơ sở như là tham số.
4412,E:\DATN\dataframe\train_file\58.txt,interface Shape is
4413,E:\DATN\dataframe\train_file\58.txt,"    method move(x, y)"
4414,E:\DATN\dataframe\train_file\58.txt,    method draw()
4415,E:\DATN\dataframe\train_file\58.txt,    method accept(v: Visitor)
4416,E:\DATN\dataframe\train_file\58.txt,// Mỗi lớp concrete element phải triển khai phương
4417,E:\DATN\dataframe\train_file\58.txt,// thức `accept` theo một cách như gọi phương thức
4418,E:\DATN\dataframe\train_file\58.txt,// của visitor phù hợp với lớp của element.
4419,E:\DATN\dataframe\train_file\58.txt,class Dot implements Shape is
4420,E:\DATN\dataframe\train_file\58.txt,"    // Lưu ý ta gọi `visitDot`, tương ứng với tên lớp hiện"
4421,E:\DATN\dataframe\train_file\58.txt,Cách này giúp visitor biết lớp của element
4422,E:\DATN\dataframe\train_file\58.txt,    // đang làm việc với nó.
4423,E:\DATN\dataframe\train_file\58.txt,    method accept(v: Visitor) is
4424,E:\DATN\dataframe\train_file\58.txt,class Circle implements Shape is
4425,E:\DATN\dataframe\train_file\58.txt,    method accept(v: Visitor) is
4426,E:\DATN\dataframe\train_file\58.txt,class Rectangle implements Shape is
4427,E:\DATN\dataframe\train_file\58.txt,    method accept(v: Visitor) is
4428,E:\DATN\dataframe\train_file\58.txt,class CompoundShape implements Shape is
4429,E:\DATN\dataframe\train_file\58.txt,    method accept(v: Visitor) is
4430,E:\DATN\dataframe\train_file\58.txt,// Interface visitor khai báo một tập hợp phương thức đi qua
4431,E:\DATN\dataframe\train_file\58.txt,// tương ứng với các lớp element.
4432,E:\DATN\dataframe\train_file\58.txt,Ký hiệu của phương thức
4433,E:\DATN\dataframe\train_file\58.txt,// đi qua giúp visitior xác định chính xác lớp của element
4434,E:\DATN\dataframe\train_file\58.txt,// đang xử lý nó.
4435,E:\DATN\dataframe\train_file\58.txt,interface Visitor is
4436,E:\DATN\dataframe\train_file\58.txt,    method visitDot(d: Dot)
4437,E:\DATN\dataframe\train_file\58.txt,    method visitCircle(c: Circle)
4438,E:\DATN\dataframe\train_file\58.txt,    method visitRectangle(r: Rectangle)
4439,E:\DATN\dataframe\train_file\58.txt,    method visitCompoundShape(cs: CompoundShape)
4440,E:\DATN\dataframe\train_file\58.txt,// Concrete visitor triển khai nhiều phiên bản thuật toán
4441,E:\DATN\dataframe\train_file\58.txt,"// giống nhau, thứ làm việc với tất cả lớp concrete element."
4442,E:\DATN\dataframe\train_file\58.txt,// Bạn có thể có nhiều lợi ích từ làm việc với pattern Visitor
4443,E:\DATN\dataframe\train_file\58.txt,// khi sử dụng nó với đối tượng có cấu trúc phức tạp như cây
4444,E:\DATN\dataframe\train_file\58.txt,"Trong trường hợp này, nó sẽ hữu ích để lưu trữ"
4445,E:\DATN\dataframe\train_file\58.txt,// một vài trạng thái trung gian của thuật toán trong khi thực
4446,E:\DATN\dataframe\train_file\58.txt,// thi phương thức của visitor qua các đối tượng khác nhau của
4447,E:\DATN\dataframe\train_file\58.txt,class XMLExportVisitor implements Visitor is
4448,E:\DATN\dataframe\train_file\58.txt,    method visitDot(d: Dot) is
4449,E:\DATN\dataframe\train_file\58.txt,        // Xuất ID của dấu chấm và hệ toạ độ trung tâm.
4450,E:\DATN\dataframe\train_file\58.txt,    method visitCircle(c: Circle) is
4451,E:\DATN\dataframe\train_file\58.txt,"        // Xuất ID của vòng tròn, toạ độ trung tâm và bán kính."
4452,E:\DATN\dataframe\train_file\58.txt,    method visitRectangle(r: Rectangle) is
4453,E:\DATN\dataframe\train_file\58.txt,"        // Xuất ID của hình chữ nhật, toạ độ trên-trái,"
4454,E:\DATN\dataframe\train_file\58.txt,        // chiều dài và chiều rộng.
4455,E:\DATN\dataframe\train_file\58.txt,    method visitCompoundShape(cs: CompoundShape) is
4456,E:\DATN\dataframe\train_file\58.txt,        // Xuất ID của hình dạng cũng như danh sách con của ID.
4457,E:\DATN\dataframe\train_file\58.txt,// Code client chạy thao tác visitor qua bất kỳ tập hợp element
4458,E:\DATN\dataframe\train_file\58.txt,// mà không cần biết lớp cụ thể của nó.
4459,E:\DATN\dataframe\train_file\58.txt,Thao tá accept trực tiếp
4460,E:\DATN\dataframe\train_file\58.txt,// gọi đến thao tác thích hợp ở đối tượng visitor.
4461,E:\DATN\dataframe\train_file\58.txt,class Application is
4462,E:\DATN\dataframe\train_file\58.txt,    field allShapes: array of Shapes
4463,E:\DATN\dataframe\train_file\58.txt,    method export() is
4464,E:\DATN\dataframe\train_file\58.txt,        exportVisitor = new XMLExportVisitor()
4465,E:\DATN\dataframe\train_file\58.txt,        foreach (shape in allShapes) do
4466,E:\DATN\dataframe\train_file\58.txt,💡 Ứng dụng
4467,E:\DATN\dataframe\train_file\58.txt,🐞 Sử dụng Visitor khi bạn cần thực hiện thao tác trên tất cả các phần tử của cấu trúc đối tượng phức tạp (ví dụ: cây đối tượng).
4468,E:\DATN\dataframe\train_file\58.txt,"⚡ Pattern Visitor cho phép bạn thực hiện một thao tác trên một tập hợp các đối tượng có các lớp khác nhau bằng cách để một đối tượng visitor triển khai một số biến thể của cùng một thao tác, tương ứng với tất cả các lớp mục tiêu."
4469,E:\DATN\dataframe\train_file\58.txt,🐞 Sử dụng Visitor để làm sạch logic nghiệp vụ của các hành vi phụ trợ.
4470,E:\DATN\dataframe\train_file\58.txt,⚡ Visitor cho phép bạn làm cho các lớp chính của ứng dụng tập trung hơn vào công việc chính của chúng bằng cách trích xuất tất cả các hành vi khác vào một tập hợp các lớp visitor.
4471,E:\DATN\dataframe\train_file\58.txt,"🐞 Sử dụng Visitor khi một hành vi chỉ có ý nghĩa trong một số lớp của hệ thống phân cấp lớp, nhưng không có ý nghĩa trong các lớp khác."
4472,E:\DATN\dataframe\train_file\58.txt,"⚡ Bạn có thể trích xuất hành vi này thành một lớp visitor riêng biệt và chỉ triển khai những phương thức truy cập chấp nhận các đối tượng của các lớp có liên quan, để trống phần còn lại."
4473,E:\DATN\dataframe\train_file\58.txt,"Khai báo interface visitor với một tập hợp các phương thức “ghé thăm”, một phương thức cho mỗi lớp phần tử cụ thể tồn tại trong chương trình."
4474,E:\DATN\dataframe\train_file\58.txt,Khai báo interface phần tử.
4475,E:\DATN\dataframe\train_file\58.txt,"Nếu bạn đang làm việc với hệ thống phân cấp lớp phần tử hiện có, hãy thêm phương thức trừu tượng ""accept"" vào lớp cơ sở của hệ thống phân cấp."
4476,E:\DATN\dataframe\train_file\58.txt,Phương thức này phải chấp nhận một đối tượng visitor làm tham số.
4477,E:\DATN\dataframe\train_file\58.txt,Thực hiện các phương pháp chấp nhận trong tất cả các lớp phần tử cụ thể.
4478,E:\DATN\dataframe\train_file\58.txt,Các phương thức này chỉ phải chuyển hướng cuộc gọi đến một phương thức thăm trên đối tượng visitor đến phù hợp với lớp của phần tử hiện tại.
4479,E:\DATN\dataframe\train_file\58.txt,Các lớp phần tử chỉ nên hoạt động với visitor thông qua interface visitor.
4480,E:\DATN\dataframe\train_file\58.txt,"Tuy nhiên, visitor phải biết tất cả các lớp phần tử cụ thể, được tham chiếu như các kiểu tham số của các phương thức truy cập."
4481,E:\DATN\dataframe\train_file\58.txt,"Đối với mỗi hành vi không thể được triển khai bên trong phân cấp phần tử, hãy tạo một lớp visitor cụ thể mới và triển khai tất cả các phương pháp truy cập."
4482,E:\DATN\dataframe\train_file\58.txt,Bạn có thể gặp phải tình huống trong đó visitor sẽ cần quyền truy cập vào một số thành viên riêng tư của lớp phần tử.
4483,E:\DATN\dataframe\train_file\58.txt,"Trong trường hợp này, bạn có thể đặt các trường hoặc phương thức này ở chế độ công khai, vi phạm tính đóng gói của phần tử hoặc lồng lớp visitor vào lớp phần tử."
4484,E:\DATN\dataframe\train_file\58.txt,Điều sau chỉ có thể thực hiện được nếu bạn may mắn làm việc với ngôn ngữ lập trình hỗ trợ các lớp lồng nhau.
4485,E:\DATN\dataframe\train_file\58.txt,"Client phải tạo các đối tượng visitor và chuyển chúng vào các phần tử thông qua các phương thức ""accept""."
4486,E:\DATN\dataframe\train_file\58.txt,⚖️ Ưu nhược điểm
4487,E:\DATN\dataframe\train_file\58.txt,✔️ Open/Closed Principle.
4488,E:\DATN\dataframe\train_file\58.txt,Bạn có thể thêm một hành vi mới có thể hoạt động với các đối tượng của các lớp khác nhau mà không cần thay đổi các lớp này.
4489,E:\DATN\dataframe\train_file\58.txt,✔️ Single Responsibility Principle.
4490,E:\DATN\dataframe\train_file\58.txt,Bạn có thể chuyển nhiều phiên bản của cùng một hành vi vào cùng một lớp.
4491,E:\DATN\dataframe\train_file\58.txt,✔️ Một đối tượng visitor có thể tích lũy một số thông tin hữu ích khi làm việc với nhiều đối tượng khác nhau.
4492,E:\DATN\dataframe\train_file\58.txt,"Điều này có thể hữu ích khi bạn muốn duyệt qua một số cấu trúc đối tượng phức tạp, chẳng hạn như cây đối tượng và áp dụng visitor vào từng đối tượng của cấu trúc này."
4493,E:\DATN\dataframe\train_file\58.txt,❌ Bạn cần cập nhật tất cả visitor mỗi khi một lớp được thêm vào hoặc xóa khỏi hệ thống phân cấp phần tử.
4494,E:\DATN\dataframe\train_file\58.txt,❌ Visitor có thể thiếu quyền truy cập cần thiết vào các trường riêng tư và phương pháp của các phần tử mà họ phải làm việc với.
4495,E:\DATN\dataframe\train_file\58.txt,🔁 Quan hệ với các pattern khác
4496,E:\DATN\dataframe\train_file\58.txt,Bạn có thể coi Visitor như một phiên bản mạnh mẽ của Command.
4497,E:\DATN\dataframe\train_file\58.txt,Các đối tượng của nó có thể thực thi các hoạt động trên các đối tượng khác nhau của các lớp khác nhau.
4498,E:\DATN\dataframe\train_file\58.txt,"Bạn có thể sử dụng Visitor cùng với Iterator để duyệt qua một cấu trúc dữ liệu phức tạp và thực hiện một số thao tác trên các phần tử của nó, ngay cả khi tất cả chúng đều có các lớp khác nhau"
4499,E:\DATN\dataframe\train_file\58.txt,Bạn có thể sử dụng Visitor để thực hiện một thao tác trên toàn bộ cây Composite.
4500,E:\DATN\dataframe\train_file\59.txt,Design Patterns - Strategy
4501,E:\DATN\dataframe\train_file\59.txt,📜 Mục đích
4502,E:\DATN\dataframe\train_file\59.txt,"Strategy là một design pattern thuộc nhóm behavioral giúp bạn xác định một nhóm thuật toán, đặt chúng vào một lớp riêng biệt và làm cho các đối tượng của chúng có thể hoán đổi lẫn nhau."
4503,E:\DATN\dataframe\train_file\59.txt,😟 Vấn đề
4504,E:\DATN\dataframe\train_file\59.txt,"Vào một ngày đẹp trời, bạn định tạo một ứng dụng chỉ đường cho các khách du lịch."
4505,E:\DATN\dataframe\train_file\59.txt,Ứng dụng xoay quanh các bản đồ đẹp mắt giúp người dùng dễ dàng đi đến bất cứ thành phố nào.
4506,E:\DATN\dataframe\train_file\59.txt,Phần lớn chức năng yêu cầu của ứng dụng là tự thiết lập lộ trình đường đi.
4507,E:\DATN\dataframe\train_file\59.txt,Người dùng sẽ nhập vào địa chỉ hiện tại của họ và thấy con đường nhanh nhất để đến đích trên bản đồ.
4508,E:\DATN\dataframe\train_file\59.txt,Phiên bản đầu tiên của ứng dụng chỉ tập trung vào những đại lộ.
4509,E:\DATN\dataframe\train_file\59.txt,Những người du lịch bằng xe sẽ cảm thấy vui sướng vì điều này.
4510,E:\DATN\dataframe\train_file\59.txt,"Nhưng mà rõ ràng là, không phải tất cả mọi người đều du lịch bằng xe."
4511,E:\DATN\dataframe\train_file\59.txt,"Thế nên ở bản cập nhật tiếp theo, bạn thêm tính năng chức năng cho người đi bộ."
4512,E:\DATN\dataframe\train_file\59.txt,"Ngay sau đó, bạn thêm các lựa chọn khác cho những phương tiện công cộng(bus, tàu điện ngầm,..) trên tuyến đường của họ."
4513,E:\DATN\dataframe\train_file\59.txt,"Tuy nhiên, mọi thứ vẫn chưa dừng lại."
4514,E:\DATN\dataframe\train_file\59.txt,"Sau đó bạn định thêm lộ trình cho người đi xe đạp, hay là về sau này bạn sẽ thêm các lựa chọn khác cho xây dựng các lộ trình qua tất cả điểm tham quan trong thành phố."
4515,E:\DATN\dataframe\train_file\59.txt,"Từ quan điểm kinh doanh, ứng dụng của bạn đã thành công, nhưng ở khía cạnh kỹ thuật bạn sẽ gặp nhiều vấn đề đau đầu."
4516,E:\DATN\dataframe\train_file\59.txt,"Mỗi lần bạn thêm một thuật toán chỉ đường mới, lớp chính của bộ chỉ đường sẽ gấp đôi kích thước."
4517,E:\DATN\dataframe\train_file\59.txt,"Và đến một thời điểm nào đó, nó sẽ như là một con quái vật, cực kỳ khó cho việc bảo trì."
4518,E:\DATN\dataframe\train_file\59.txt,"Bất kỳ một thuật toán nào thay đổi, cho dù chỉ là fix lỗi đơn giản hay một chút điều chỉnh lên các con đường nó cũng ảnh hưởng đến toàn bộ lớp, làm tăng nguy cơ sinh lỗi ở các đoạn code đã hoạt động."
4519,E:\DATN\dataframe\train_file\59.txt,"Bên cạnh đó, teamwork cũng bất tiện hơn."
4520,E:\DATN\dataframe\train_file\59.txt,"Các đồng nghiệp của bạn, những người gia nhập sau khi phiên bản đầu tiên phát hành sẽ than phiền rằng họ mất quá nhiều thời gian cho giải quyết các xung đột khi hợp nhất."
4521,E:\DATN\dataframe\train_file\59.txt,"Triển khai tính năng mới yêu cầu thay đổi cùng một lớp khổng lồ, xung đột với code được viết bởi những người khác."
4522,E:\DATN\dataframe\train_file\59.txt,😊 Giải pháp
4523,E:\DATN\dataframe\train_file\59.txt,Strategy đề xuất giải pháp là bạn nên chọn một lớp làm điều gì đó cụ thể theo nhiều cách khác nhau và trích xuất tất cả thuật toán vào các lớp riêng biệt đấy gọi là strategy.
4524,E:\DATN\dataframe\train_file\59.txt,"Lớp gốc gọi là context, phải có một trường lưu trữ tham chiếu đến một trong các stategy."
4525,E:\DATN\dataframe\train_file\59.txt,Context uỷ thác công việc cho đối tượng strategy được liên kết thay vì tự thực hiện nó.
4526,E:\DATN\dataframe\train_file\59.txt,Context không có trách nhiệm chọn thuật toán phù hợp cho công việc.
4527,E:\DATN\dataframe\train_file\59.txt,"Thay vào đó, client truyền strategy mong muốn đến context."
4528,E:\DATN\dataframe\train_file\59.txt,"Thực tế, context không biết gì về strategy."
4529,E:\DATN\dataframe\train_file\59.txt,"Nó làm việc với mọi strategy thông qua interface chung, nó chỉ để lộ một phương thức duy nhất cho kích hoạt thuật toán đã đóng gói trong stategy được chọn."
4530,E:\DATN\dataframe\train_file\59.txt,"Với cách này, context trở nên độc lập với các strategy cụ thể, bạn có thể thêm hay chỉnh sửa thuật toán mà không ảnh hưởng gì đến code của context hay các strategy khác."
4531,E:\DATN\dataframe\train_file\59.txt,"Trở lại với ứng dụng chỉ đường, mội thuật toán định tuyến có thể được trích xuất vào lớp của chúng với phương thức buildRoute duy nhất."
4532,E:\DATN\dataframe\train_file\59.txt,"Phương thức nhận vào điểm đầu và đích đến, và trả về một tập hợp các trạm dừng của lộ trình."
4533,E:\DATN\dataframe\train_file\59.txt,"Mặc dùng cho cùng một tham số, mỗi lớp định tuyến sẽ có tạo một lộ trình khác nhau, lớp chính của ứng dụng không thực sự quan tâm thuật toán được chọn vì công việc chính của nó chỉ là hiển thị các trạm dừng trên bản đồ."
4534,E:\DATN\dataframe\train_file\59.txt,"Lớp có phương thức chuyển đổi các lịch trình đang hoạt động, thế nên người dùng với các button ở giao diện người dùng, có thể thay thế hành vi được chọn hiện tại với cái khác."
4535,E:\DATN\dataframe\train_file\59.txt,🚗 Thế Giới Thực
4536,E:\DATN\dataframe\train_file\59.txt,Tưởng tượng để đi đến sân bay.
4537,E:\DATN\dataframe\train_file\59.txt,"Bạn có thể bắt xe bus, gọi taxi hay đi xe đập."
4538,E:\DATN\dataframe\train_file\59.txt,Các phương tiện của bạn là strategy.
4539,E:\DATN\dataframe\train_file\59.txt,Bạn có thể chọn một trong các strategy dựa vào các nhân tố như ví tiền hay thời gian.
4540,E:\DATN\dataframe\train_file\59.txt,🏢 Cấu trúc
4541,E:\DATN\dataframe\train_file\59.txt,Context duy trì một tham chiếu đến một trong các strategy cụ thể và giao tiếp với các đối tượng này thông qua interface strategy.
4542,E:\DATN\dataframe\train_file\59.txt,Strategy là interface chung cho tất cả strategy cụ thể.
4543,E:\DATN\dataframe\train_file\59.txt,Nó khai báo một phương thức duy nhất cho context sử dụng để thực thi.
4544,E:\DATN\dataframe\train_file\59.txt,Concrete Strategies triển khai khác nhau của thuật toán mà context sử dụng.
4545,E:\DATN\dataframe\train_file\59.txt,Context gọi phương thức thực thi đến đối tượng strategy được liên kết mỗi lần nó cần chạy thuật toán.
4546,E:\DATN\dataframe\train_file\59.txt,Context không cần biết chính xác kiểu strategy nào đang làm việc và thuật toán được thực thi thế nào.
4547,E:\DATN\dataframe\train_file\59.txt,Client tạo đối tượng strategy cụ thể và truyền nó vào context.
4548,E:\DATN\dataframe\train_file\59.txt,Context để lộ một setter cho client thay thế với strategy được liên kết với context khi đang chạy.
4549,E:\DATN\dataframe\train_file\59.txt,👨‍💻 Mã giả
4550,E:\DATN\dataframe\train_file\59.txt,"Trong ví dụ này, context sử dụng nhiều strategy để thực hiện các phép toán khác nhau."
4551,E:\DATN\dataframe\train_file\59.txt,// Interface strategy khai báo các phép toán chung cho tất cả
4552,E:\DATN\dataframe\train_file\59.txt,// phiên bản hỗ trợ của một vài thuật toán.
4553,E:\DATN\dataframe\train_file\59.txt,Context sử dụng
4554,E:\DATN\dataframe\train_file\59.txt,// interface này để gọi thuật toán đã xác định bởi concrete
4555,E:\DATN\dataframe\train_file\59.txt,interface Strategy is
4556,E:\DATN\dataframe\train_file\59.txt,"    method execute(a, b)"
4557,E:\DATN\dataframe\train_file\59.txt,// Concrete strategies triển khai thuật toán khi đang theo
4558,E:\DATN\dataframe\train_file\59.txt,// interface strategy cơ sở.
4559,E:\DATN\dataframe\train_file\59.txt,Interface hoán đổi chúng với
4560,E:\DATN\dataframe\train_file\59.txt,// nhau trong context.
4561,E:\DATN\dataframe\train_file\59.txt,class ConcreteStrategyAdd implements Strategy is
4562,E:\DATN\dataframe\train_file\59.txt,"    method execute(a, b) is"
4563,E:\DATN\dataframe\train_file\59.txt,        return a + b
4564,E:\DATN\dataframe\train_file\59.txt,class ConcreteStrategySubtract implements Strategy is
4565,E:\DATN\dataframe\train_file\59.txt,"    method execute(a, b) is"
4566,E:\DATN\dataframe\train_file\59.txt,        return a - b
4567,E:\DATN\dataframe\train_file\59.txt,class ConcreteStrategyMultiply implements Strategy is
4568,E:\DATN\dataframe\train_file\59.txt,"    method execute(a, b) is"
4569,E:\DATN\dataframe\train_file\59.txt,        return a * b
4570,E:\DATN\dataframe\train_file\59.txt,// Context xác định interface mà client mong muốn.
4571,E:\DATN\dataframe\train_file\59.txt,class Context is
4572,E:\DATN\dataframe\train_file\59.txt,    // Context duy trì một tham chiếu đến một trong các đối tượng
4573,E:\DATN\dataframe\train_file\59.txt,Context không biết rõ lớp cụ thể của strategy.
4574,E:\DATN\dataframe\train_file\59.txt,    // Nó làm việc với mọi strategy thông qua interface strategy.
4575,E:\DATN\dataframe\train_file\59.txt,    private strategy: Strategy
4576,E:\DATN\dataframe\train_file\59.txt,"    // Thông thường, context nhận strategy thông qua hàm khởi"
4577,E:\DATN\dataframe\train_file\59.txt,    // tạo và cung cập một setter cho strategy có thể chuyển
4578,E:\DATN\dataframe\train_file\59.txt,    // đổi khi đang chạy.
4579,E:\DATN\dataframe\train_file\59.txt,    method setStrategy(Strategy strategy) is
4580,E:\DATN\dataframe\train_file\59.txt,        this.strategy = strategy
4581,E:\DATN\dataframe\train_file\59.txt,    // Context uỷ thác công việc cho đối tượng strategy thay
4582,E:\DATN\dataframe\train_file\59.txt,    // vì triển khai nhiều phiên bản thuật toán của chính nó.
4583,E:\DATN\dataframe\train_file\59.txt,"    method executeStrategy(int a, int b) is"
4584,E:\DATN\dataframe\train_file\59.txt,"        return strategy.execute(a, b)"
4585,E:\DATN\dataframe\train_file\59.txt,// Code client chọn một concrete strategy và truyền nó vào
4586,E:\DATN\dataframe\train_file\59.txt,Client nên nhận thức được sự khác nhau giữa
4587,E:\DATN\dataframe\train_file\59.txt,// các strategy theo trật tự để chọn đúng.
4588,E:\DATN\dataframe\train_file\59.txt,class ExampleApplication is
4589,E:\DATN\dataframe\train_file\59.txt,    method main() is
4590,E:\DATN\dataframe\train_file\59.txt,        Create context object.
4591,E:\DATN\dataframe\train_file\59.txt,        Read first number.
4592,E:\DATN\dataframe\train_file\59.txt,        Read last number.
4593,E:\DATN\dataframe\train_file\59.txt,        Read the desired action from user input.
4594,E:\DATN\dataframe\train_file\59.txt,        if (action == addition) then
4595,E:\DATN\dataframe\train_file\59.txt,            context.setStrategy(new ConcreteStrategyAdd())
4596,E:\DATN\dataframe\train_file\59.txt,        if (action == subtraction) then
4597,E:\DATN\dataframe\train_file\59.txt,            context.setStrategy(new ConcreteStrategySubtract())
4598,E:\DATN\dataframe\train_file\59.txt,        if (action == multiplication) then
4599,E:\DATN\dataframe\train_file\59.txt,            context.setStrategy(new ConcreteStrategyMultiply())
4600,E:\DATN\dataframe\train_file\59.txt,"        result = context.executeStrategy(First number, Second number)"
4601,E:\DATN\dataframe\train_file\59.txt,        Print result.
4602,E:\DATN\dataframe\train_file\59.txt,💡 Ứng dụng
4603,E:\DATN\dataframe\train_file\59.txt,🐞 Sử dụng Strategy khi bạn muốn dùng các biến thể thuật toán khác nhau trong một đối tượng cho phép chuyển đổi từ thuật toán này sang thuật toán khác khi đang chạy.
4604,E:\DATN\dataframe\train_file\59.txt,⚡ Strategy giúp bạn gián tiếp chỉnh sửa hành vi của đối tượng khi đang chạy bằng liên kết với các đối tượng con khác để thực hiện hành vi cụ thể theo các cách khác nhau.
4605,E:\DATN\dataframe\train_file\59.txt,🐞 Sử dụng Strategy khi bạn có nhiều lớp giống nhau chỉ khác nhau cách chúng thực hiện một vài hành vi
4606,E:\DATN\dataframe\train_file\59.txt,"⚡ Strategy giúp bạn trích xuất các hành vi khác nhau vào một hệ thống phân cấp lớp và kết hợp với lớp gốc thành một, bằng cách này sẽ làm giảm code trùng lặp."
4607,E:\DATN\dataframe\train_file\59.txt,"🐞 Sử dụng Strategy để cô lập logic nghiệp vụ của một lớp khỏi triển khai chi tiết của thuật toán, thứ không mấy quan trọng trong ngữ cảnh của logic đó."
4608,E:\DATN\dataframe\train_file\59.txt,"⚡ Strategy giúp bạn cô lập code, dữ liệu bên trong và các phụ thuộc vào thuật toán với phần code còn lại."
4609,E:\DATN\dataframe\train_file\59.txt,Các client khác nhau nhận về một interface đơn giản để thực thi thuật toán và chuyển đổi chúng khi đang chạy.
4610,E:\DATN\dataframe\train_file\59.txt,🐞 Sử dụng Strategy khi lớp của bạn có một lượng điều kiện khổng lồ để chuyển đổi các biến thể khác nhau với cùng thuật toán.
4611,E:\DATN\dataframe\train_file\59.txt,⚡ Strategy giúp bạn bỏ đi các điều kiện bằng cách trích xuất tất cả thuật toán vào các lớp riêng biệt.
4612,E:\DATN\dataframe\train_file\59.txt,Toàn bộ triển khai cùng interface.
4613,E:\DATN\dataframe\train_file\59.txt,Đối tượng gốc uỷ thác thực thi cho một trong các đối tượng trên thay vì triển khai tất cả biến thể của thuật toán.
4614,E:\DATN\dataframe\train_file\59.txt,📋 Triển khai
4615,E:\DATN\dataframe\train_file\59.txt,"Trong lớp context, xác định thuật toán dễ thay đổi."
4616,E:\DATN\dataframe\train_file\59.txt,Nó còn có thể có một lượng lớn điều kiện để chọn và thực thi một biến thể của cùng một thuật toán khi đang chạy
4617,E:\DATN\dataframe\train_file\59.txt,Khai báo interface strategy chung cho tất cả biến thể của thuật toán.
4618,E:\DATN\dataframe\train_file\59.txt,"Từng cái một, trích xuất tất cả thuật toán vào các lớp của nó."
4619,E:\DATN\dataframe\train_file\59.txt,Chúng nên triển khai tất cả trên interface strategy.
4620,E:\DATN\dataframe\train_file\59.txt,"Trong lớp context, thêm một trường cho lưu trữ tham chiếu đến đối tượng strategy."
4621,E:\DATN\dataframe\train_file\59.txt,Cung cấp một setter cho thay thế giá trị của trường này.
4622,E:\DATN\dataframe\train_file\59.txt,Context nên làm việc với đối tượng strategy thông qua interface strategy.
4623,E:\DATN\dataframe\train_file\59.txt,Context có thể định nghĩa một interface để cho phép strategy truy cập dữ liệu của nó.
4624,E:\DATN\dataframe\train_file\59.txt,Client của context phải liên kết nó với strategy phù hợp để ứng với cách chúng mong đợi context thực hiện hành vi chính.
4625,E:\DATN\dataframe\train_file\59.txt,⚖️ Ưu nhược điểm
4626,E:\DATN\dataframe\train_file\59.txt,✔️ Bạn có thể chuyển đổi thuật toán bên trong đối tượng khi đang chạy.
4627,E:\DATN\dataframe\train_file\59.txt,✔️ Bạn có thể cô lập triển khai chi tiết của thuật toán khỏi code sử dụng nó.
4628,E:\DATN\dataframe\train_file\59.txt,✔️ Bạn có thể thay thế kế thừa với hỗn hợp.
4629,E:\DATN\dataframe\train_file\59.txt,✔️ Open/Closed Principle.
4630,E:\DATN\dataframe\train_file\59.txt,Bạn có thể thêm strategy mới mà không ảnh hưởng đến context.
4631,E:\DATN\dataframe\train_file\59.txt,"❌ Nếu bạn chỉ có một vài thuật toán và chúng hiếm khi thay đổi, thì không có lý do thực sự nào để làm phức tạp chương trình quá mức với các lớp và interface mới đi kèm với pattern."
4632,E:\DATN\dataframe\train_file\59.txt,❌ Client phải nhận thức được các strategy khác nhau để có thể chọn cái phù hợp.
4633,E:\DATN\dataframe\train_file\59.txt,❌ Rất nhiều ngôn ngữ lập trình hiện đại có hỗ trợ kiểu hàm cho phép bạn triển khai các phiên bản khác nhau của thuật toán bên trong một tập hợp các hàm ẩn danh.
4634,E:\DATN\dataframe\train_file\59.txt,"Sau đó, bạn có thể sử dụng các chức năng này chính xác như khi bạn đã sử dụng các đối tượng strategy, nhưng không làm tăng code của bạn với các lớp và giao diện bổ sung."
4635,E:\DATN\dataframe\train_file\59.txt,🔁 Quan hệ với các pattern khác
4636,E:\DATN\dataframe\train_file\59.txt,"Bridge, State, Strategy (và ở một mức độ nào đó là Adapter) có cấu trúc rất giống nhau."
4637,E:\DATN\dataframe\train_file\59.txt,"Thật vậy, tất cả các pattern này đều dựa trên nguyên tắc là ủy thác công việc cho các đối tượng khác."
4638,E:\DATN\dataframe\train_file\59.txt,"Tuy nhiên, chúng giải quyết các vấn đề khác nhau."
4639,E:\DATN\dataframe\train_file\59.txt,Một pattern không chỉ là một công thức để cấu trúc code của bạn theo một cách cụ thể.
4640,E:\DATN\dataframe\train_file\59.txt,Nó còn có thể truyền đạt đến các dev khác về vấn đề mà pattern giải quyết.
4641,E:\DATN\dataframe\train_file\59.txt,Command và Strategy có thể trông giống nhau vì bạn có thể sử dụng cả hai để tham số hóa một đối tượng bằng một số hành động.
4642,E:\DATN\dataframe\train_file\59.txt,"Tuy nhiên, chúng có mục đích rất khác nhau."
4643,E:\DATN\dataframe\train_file\59.txt,Bạn có thể sử dụng Command để chuyển đổi bất kỳ thao tác nào thành một đối tượng.
4644,E:\DATN\dataframe\train_file\59.txt,Các tham số của thao tác trở thành các trường của đối tượng đó.
4645,E:\DATN\dataframe\train_file\59.txt,"Việc chuyển đổi cho phép bạn trì hoãn việc thực hiện thao tác, xếp hàng đợi, lưu trữ lịch sử lệnh, gửi lệnh đến các dịch vụ từ xa, v.v."
4646,E:\DATN\dataframe\train_file\59.txt,"Mặt khác, Strategy thường mô tả các cách khác nhau để thực hiện cùng một việc, cho phép bạn hoán đổi các thuật toán này trong một lớp ngữ cảnh duy nhất."
4647,E:\DATN\dataframe\train_file\59.txt,"Decorator cho phép bạn thay đổi vẻ ngoài của một đối tượng, trong khi Strategy cho phép bạn thay đổi ruột."
4648,E:\DATN\dataframe\train_file\59.txt,Template Method dựa trên sự kế thừa: nó cho phép bạn thay đổi các phần của một thuật toán bằng cách mở rộng các phần đó trong các lớp con.
4649,E:\DATN\dataframe\train_file\59.txt,Strategy dựa trên cấu tạo: bạn có thể thay đổi các phần trong hành vi của đối tượng bằng cách cung cấp cho đối tượng các strategy khác nhau tương ứng với hành vi đó.
4650,E:\DATN\dataframe\train_file\59.txt,"Template Method hoạt động ở cấp độ lớp, vì vậy nó là tĩnh."
4651,E:\DATN\dataframe\train_file\59.txt,"Strategy hoạt động ở cấp độ đối tượng, cho phép bạn chuyển đổi hành vi trong thời gian chạy."
4652,E:\DATN\dataframe\train_file\59.txt,State có thể được coi là một phần mở rộng của Strategy.
4653,E:\DATN\dataframe\train_file\59.txt,Cả hai pattern đều dựa trên kết hợp: chúng thay đổi hành vi của ngữ cảnh bằng cách ủy quyền một số công việc cho các đối tượng trợ giúp.
4654,E:\DATN\dataframe\train_file\59.txt,Strategy làm cho các đối tượng này hoàn toàn độc lập và không biết về nhau.
4655,E:\DATN\dataframe\train_file\59.txt,"Tuy nhiên, State không hạn chế sự phụ thuộc giữa các trạng thái cụ thể, cho phép chúng thay đổi trạng thái của ngữ cảnh theo ý muốn."
4656,E:\DATN\dataframe\train_file\6.txt,Cải thiện Tìm kiếm trong Database Full-text search
4657,E:\DATN\dataframe\train_file\6.txt,Mục tiêu: Cải thiện tìm kiếm trong database (DB) hay nói cách khác là làm sao để tìm kiếm trong database cho nó thông minh hơn.
4658,E:\DATN\dataframe\train_file\6.txt,Ghi chú: Mình sử dụng postgresql 12 cho bài viết này.
4659,E:\DATN\dataframe\train_file\6.txt,Với các loại Structured Query Language(SQL) DB khác mình nghĩ sẽ tương tự.
4660,E:\DATN\dataframe\train_file\6.txt,Các bạn có thể chạy example trên loại DB khác để test.
4661,E:\DATN\dataframe\train_file\6.txt,"Đa số nói đến tìm kiếm trong DB thì mọi nguời sẽ sử dụng từ khoá LIKE để so sánh giữa hai chuỗi (string), nhưng nếu để ý kĩ hơn thì có nhiều vấn đề mà cách thông thương này không giải quyết được."
4662,E:\DATN\dataframe\train_file\6.txt,Mình sẽ đưa ra từng vấn đề và cách mình đang xử lý chúng.
4663,E:\DATN\dataframe\train_file\6.txt,"Tất nhiên sẽ có nhiều cách khác nhau, các bạn comment giúp mình nhé ~."
4664,E:\DATN\dataframe\train_file\6.txt,Mình sẽ đưa ra ví dụ dựa trên dữ liệu sản phẩm của một trang website bán hàng.
4665,E:\DATN\dataframe\train_file\6.txt,Bảng dữ liệu gồm có 2 cột ID và Tittle .
4666,E:\DATN\dataframe\train_file\6.txt,Mình cũng sẽ thêm 1 ít dữ liệu để cho trực quan hơn.
4667,E:\DATN\dataframe\train_file\6.txt,CREATE TABLE product (
4668,E:\DATN\dataframe\train_file\6.txt,"	id serial NOT NULL,"
4669,E:\DATN\dataframe\train_file\6.txt,"	title TEXT NOT NULL,"
4670,E:\DATN\dataframe\train_file\6.txt,	CONSTRAINT product_pkey PRIMARY KEY (id)
4671,E:\DATN\dataframe\train_file\6.txt,INSERT INTO product (title)
4672,E:\DATN\dataframe\train_file\6.txt,"	('Main B360 Msi B360-F Pro LGA1151'),"
4673,E:\DATN\dataframe\train_file\6.txt,"	('Main B360 Msi B360 A Pro LGA1151'),"
4674,E:\DATN\dataframe\train_file\6.txt,"	('Mainboard B360M Pro VH LGA1151 2*DDR4'),"
4675,E:\DATN\dataframe\train_file\6.txt,"	('Mainboard B360M MORTAR TITANIUM LGA1151 4*DDR4'),"
4676,E:\DATN\dataframe\train_file\6.txt,"	('Main Msi B360M Mortar LGA1151 4*DDR4'),"
4677,E:\DATN\dataframe\train_file\6.txt,"	('Main B360-F Pro LGA1151 2*DDR4'),"
4678,E:\DATN\dataframe\train_file\6.txt,"	('Mainboard Msi B360 A Pro LGA1151 4*DDR4'),"
4679,E:\DATN\dataframe\train_file\6.txt,"	('Mainboard Msi B360M Mortar LGA1151 4*DDR4'),"
4680,E:\DATN\dataframe\train_file\6.txt,"	('Mainboard B360M Bazooka LGA1151 4*DDR4'),"
4681,E:\DATN\dataframe\train_file\6.txt,	('Mainboard Msi B360M PRO-VD LGA1151 4*DDR4');
4682,E:\DATN\dataframe\train_file\6.txt,Tìm kiếm bằng So sánh 2 chuỗi
4683,E:\DATN\dataframe\train_file\6.txt,Cách đơn giản nhất để tìm kiếm là SELECT column_name FROM table WHERE column_name LIKE 'key_word'.
4684,E:\DATN\dataframe\train_file\6.txt,Bạn cũng có thể cải thiện thêm phạm vi tìm kiếm bằng cách thêm các kí tự đặc biệt như:
4685,E:\DATN\dataframe\train_file\6.txt,Main% : để tìm tất cả các ký nào bắt đầu bằng chữ Main.
4686,E:\DATN\dataframe\train_file\6.txt,Hoặc %board% bất kì giá trị nào có chữ board.
4687,E:\DATN\dataframe\train_file\6.txt,Ví dụ: SELECT * FROM product WHERE title LIKE '%board%';
4688,E:\DATN\dataframe\train_file\6.txt,_xy: để tìm giá trị bắt đầu với ít nhất 1 ký tự bất kì.
4689,E:\DATN\dataframe\train_file\6.txt,"Ví dụ: axy, $xy, xy."
4690,E:\DATN\dataframe\train_file\6.txt,"Các giá trị không hợp lệ như: xy, a xy, bxyz."
4691,E:\DATN\dataframe\train_file\6.txt,Nếu là __xy thì sẽ đúng với các giá trị với 2 kí từ đầu bất kì.
4692,E:\DATN\dataframe\train_file\6.txt,ILIKE: giống như LIKE nhưng sẽ bỏ qua kiểm tra giá trị hoa hay thường.
4693,E:\DATN\dataframe\train_file\6.txt,Về cơ bản thì bạn cũng có thể bao phủ các trường hợp mà cần tìm kiếm rồi.
4694,E:\DATN\dataframe\train_file\6.txt,Nhưng với người dùng không rõ mình cần tìm kiếm cái gì thì với các trường hợp sau bạn sẽ xử lý như thế nào:
4695,E:\DATN\dataframe\train_file\6.txt,Tìm kiếm: main msi thay vì phải ghi đầy đủ ra mainboard msi.
4696,E:\DATN\dataframe\train_file\6.txt,Mình xử lý trường hợp này như sau: SELECT * FROM product WHERE title ILIKE '%main%msi%'; Bằng cách tìm kiếm trên sẽ ra đầy đủ các sản phẩm mình cần tìm kiếm.
4697,E:\DATN\dataframe\train_file\6.txt,Có vẻ cũng khá thông mình đó!
4698,E:\DATN\dataframe\train_file\6.txt,Thế còn từ khóa khoá như: msi main.
4699,E:\DATN\dataframe\train_file\6.txt,Như này thì vị trí các từ khoá đã bị thay đổi rồi nên DB sẽ không trả về kết quả nào.
4700,E:\DATN\dataframe\train_file\6.txt,"Các bạn có thể suy nghĩ hoán vị các từ khoá, nhưng nếu như có hơn 10 từ khác nhau với DB hơn 10 triệu dòng thì quả thật không gian tìm kiếm quá lớn."
4701,E:\DATN\dataframe\train_file\6.txt,Hoặc các bạn có thể tách từng từ ra tìm kiếm.
4702,E:\DATN\dataframe\train_file\6.txt,Như vậy DB vẫn phải tìm kiếm toàn bộ các dòng điều này dẫn tới tốc độ tìm kiếm chậm và server cũng phải xử lý nhiều.
4703,E:\DATN\dataframe\train_file\6.txt,"Bạn còn muốn tìm kiếm trên các cột dữ liệu khác như mã code sản phẩm, nội dung sản phẩm hay các tags mà sản phẩm có, thì bạn cũng phải viết các câu SQL tìm kiếm trên tất cả các thuộc tính này."
4704,E:\DATN\dataframe\train_file\6.txt,"Nó chậm, phức tạp và dài dòng code 🙃."
4705,E:\DATN\dataframe\train_file\6.txt,Mình là mình lười á 🫢.
4706,E:\DATN\dataframe\train_file\6.txt,"Chính vì vậy nhiều DB đã hỗ trợ full-text search, nó nhanh và linh hoạt hơn so với cách tìm kiếm thông thường."
4707,E:\DATN\dataframe\train_file\6.txt,Full-text search
4708,E:\DATN\dataframe\train_file\6.txt,"Đầu tiên, full-text search là gì?"
4709,E:\DATN\dataframe\train_file\6.txt,"Theo mình hiểu một cách đơn giản, full-text search là một kỹ thuật tìm kiếm các từ khoá nằm trong dữ liệu văn bản của database."
4710,E:\DATN\dataframe\train_file\6.txt,Dữ liệu văn bản có thể là một thuộc tính (1 cột) hoặc kết hợp nhiều thuộc tính với nhau như tên sản phẩm+mã code+nội dung sản phẩm.
4711,E:\DATN\dataframe\train_file\6.txt,Kết quả trả về sẽ chứa một vài từ khoá hoặc tất cả từ khoá cần tìm kiếm tuỳ thuộc vào cách ta tìm kiếm.
4712,E:\DATN\dataframe\train_file\6.txt,Chúng ta bắt đầu nhé:
4713,E:\DATN\dataframe\train_file\6.txt,1. tsvector
4714,E:\DATN\dataframe\train_file\6.txt,"tsvector là một kiểu dữ liệu trong DB dùng để lưu các từ khoá (ts nghĩa text search), giống như các kiểu dữ liệu như text, integer, hay char."
4715,E:\DATN\dataframe\train_file\6.txt,to_tsvector là hàm dùng để chuyển đổi văn bản sang các token.
4716,E:\DATN\dataframe\train_file\6.txt,Ví dụ như: SELECT to_tsvector('The quick brown fox jumped over the lazy dog.
4717,E:\DATN\dataframe\train_file\6.txt,'); Kết quả trả về: 'brown':3 'dog':9 'fox':4 'jump':5 'lazi':8 'quick':2
4718,E:\DATN\dataframe\train_file\6.txt,Các từ như jumped hoặc jumping sẽ được tự động chuyển về dạng nguyên mẫu jump .
4719,E:\DATN\dataframe\train_file\6.txt,"Nhưng nó chỉ hoạt động trong một số ngôn ngữ như Tiếng Anh, chứ Tiếng Việt mình chưa thấy có."
4720,E:\DATN\dataframe\train_file\6.txt,2. tsquery
4721,E:\DATN\dataframe\train_file\6.txt,to_tsquery là hàm dùng để chuyển các từ khoá thành các token và kiểm tra xem có đúng (matching) với ts_vector được tạo từ to_tsvector hay không.
4722,E:\DATN\dataframe\train_file\6.txt,Để làm được điều này thì sử dụng toán tử @@ cho nhiệm vụ kiểm tra (matching).
4723,E:\DATN\dataframe\train_file\6.txt,Với từ khoá jumping thì giá trị trả về True
4724,E:\DATN\dataframe\train_file\6.txt,Nhưng với từ khoá juping thì trả về False.
4725,E:\DATN\dataframe\train_file\6.txt,Ví nó không có trong các token được tạo ra từ to_tsvector.
4726,E:\DATN\dataframe\train_file\6.txt,"Nói nhiều dài, áp dụng vô dữ liệu mình có nào:"
4727,E:\DATN\dataframe\train_file\6.txt,SELECT * FROM product
4728,E:\DATN\dataframe\train_file\6.txt,WHERE to_tsvector(title) @@ to_tsquery('msi');
4729,E:\DATN\dataframe\train_file\6.txt,Các phép toán tử
4730,E:\DATN\dataframe\train_file\6.txt,"Nhưng với 2 từ khóa trở lên sẽ lỗi, nên từ 2 từ khoá trở lên mới thể hiện được thế mạnh của full-text search!"
4731,E:\DATN\dataframe\train_file\6.txt,AND - &: cần xuất hiện cùng lúc tất cả từ khoá trong các token từ to_tsvector và không quan tâm thứ tự.
4732,E:\DATN\dataframe\train_file\6.txt,SELECT * FROM product
4733,E:\DATN\dataframe\train_file\6.txt,WHERE to_tsvector(title) @@ to_tsquery('msi & main');
4734,E:\DATN\dataframe\train_file\6.txt,"Đảo ngược vị trí main và msi lại, tìm kiếm thông thường không tìm kiếm được nhé!"
4735,E:\DATN\dataframe\train_file\6.txt,OR - |: xuất hiện ít nhất một từ khoá trong văn bản.
4736,E:\DATN\dataframe\train_file\6.txt,SELECT * FROM product
4737,E:\DATN\dataframe\train_file\6.txt,WHERE to_tsvector(title) @@ to_tsquery('msi | main');
4738,E:\DATN\dataframe\train_file\6.txt,: kiểm tra văn bản không có từ khoá cần tìm.
4739,E:\DATN\dataframe\train_file\6.txt,Có thể kết hợp tất cả các toán tử trong 1 câu lệnh SQL.
4740,E:\DATN\dataframe\train_file\6.txt,VD: to_tsquery('fox & (dog | clown) & !queen');
4741,E:\DATN\dataframe\train_file\6.txt,4.Tìm kiếm theo cụm từ
4742,E:\DATN\dataframe\train_file\6.txt,"Để tìm kiếm theo chính xác theo cụm từ ví dụ như: ""Chó Mèo"" thì chắc bạn không muốn kết quả có ""con Chó cắn con Mèo"" (sorry vì ví dụ hơi nhạt nhẽo 🤢 )."
4743,E:\DATN\dataframe\train_file\6.txt,"Nếu sử dụng toán tử thông thường AND & thì vị trí của các từ khoá sẽ không được phân biệt, vậy nên có ta có toán từ Proximity-<-> (Xấp xỉ)"
4744,E:\DATN\dataframe\train_file\6.txt,<->: từ thứ 2 phải xuất hiện ngay sau từ thứ nhất.
4745,E:\DATN\dataframe\train_file\6.txt,"VD: vẫn là từ khóa chó mèo, thì ""Nhà nuôi chó mèo"" là hợp lý."
4746,E:\DATN\dataframe\train_file\6.txt,"Nhưng ""con Chó cắn con Mèo"" là không đúng."
4747,E:\DATN\dataframe\train_file\6.txt,Vì vị trí từ mèo cách từ chó là 3.
4748,E:\DATN\dataframe\train_file\6.txt,<3>: từ thứ 2 phải xuất hiện đứng thứ 3 so với từ thứ nhất.
4749,E:\DATN\dataframe\train_file\6.txt,"Vì vậy ""con Chó cắn con Mèo"" sẽ đúng trong trường hợp này."
4750,E:\DATN\dataframe\train_file\6.txt,Tìm kiếm theo cụm từ sẽ không có đối xứng.
4751,E:\DATN\dataframe\train_file\6.txt,"Trong Postgresql, to_tsquery('chó <3> mèo') là tương đương với tsquery_phrase('chó', 'mèo', 3)."
4752,E:\DATN\dataframe\train_file\6.txt,"Một vài tính năng khác mình chưa đề cập tới như: tìm kiếm theo từ điển (1 từ có nhiều nghĩa nên bạn có thể search theo các từ đồng nghĩa), cấu hình lại tsvector (cho phép các từ tìm kiếm sai chính tả hay các từ teen code),"
4753,E:\DATN\dataframe\train_file\6.txt,Trên là mình đã trình cách sử dụng full-text search như thế nào trong DB cùng các ví dụ.
4754,E:\DATN\dataframe\train_file\6.txt,Về cơ bản các bạn có thể áp dụng vào dự án của các bạn.
4755,E:\DATN\dataframe\train_file\6.txt,Có một vài vấn đề mà mình chưa viết hết trong bài này nếu các bạn cần thì hãy nói cho mình biết để viết chi tiết thêm.
4756,E:\DATN\dataframe\train_file\6.txt,Các vấn đề có thể xảy ra là:
4757,E:\DATN\dataframe\train_file\6.txt,Chưa có Tiếng Việt.
4758,E:\DATN\dataframe\train_file\6.txt,Mình xử lý bằng cách chuyển hết về các ký tự ASCII.
4759,E:\DATN\dataframe\train_file\6.txt,Vd như: 'â' -> 'a'.
4760,E:\DATN\dataframe\train_file\6.txt,Tối ưu kết quả tính toán to_tsvector bằng cách lưu vào thành một thuộc tính mới của bảng.
4761,E:\DATN\dataframe\train_file\6.txt,Tiết kiệm thời gian tính toán và cải thiện thời gian tìm kiếm.
4762,E:\DATN\dataframe\train_file\6.txt,"Nếu lưu thêm 1 thuộc tính tsvector thì cần phải cập nhập lại giá trị khi Tên sản phẩm, mã code, nội dung thay đổi chẳng hạn."
4763,E:\DATN\dataframe\train_file\6.txt,Viết các function và trigger trong DB.
4764,E:\DATN\dataframe\train_file\6.txt,"Đánh trọng số và ưu tiên (setweight() và ts_rank()) các thuộc tính, từ khoá mà muốn được ưu tiên."
4765,E:\DATN\dataframe\train_file\6.txt,Ví dụ sẽ ưu tiên từ khoá có trong Tên sản phẩm hơn rồi mới tới từ khoá có trong Nội dung.
4766,E:\DATN\dataframe\train_file\6.txt,Và cảm ơn các bạn đã đọc tới đây ~ .~ Happy time with me
4767,E:\DATN\dataframe\train_file\60.txt,Design Patterns - State
4768,E:\DATN\dataframe\train_file\60.txt,📜 Mục đích
4769,E:\DATN\dataframe\train_file\60.txt,State là một design pattern thuộc nhóm behavoiral giúp chỉnh sửa hành vi của một đối tượng khi trạng thái bên trong nó thay đổi.
4770,E:\DATN\dataframe\train_file\60.txt,Nó xảy ra nếu như một đối tượng thay đổi lớp của nó.
4771,E:\DATN\dataframe\train_file\60.txt,😟 Vấn đề
4772,E:\DATN\dataframe\train_file\60.txt,Pattern State có mối quan hệ gần gũi với khái niệm  (gọi tắt là máy trạng thái)
4773,E:\DATN\dataframe\train_file\60.txt,"Ý tưởng chính là như thế này, tại bất kỳ thời điểm nào cũng có một hữu hạn trạng thái mà chương trình có thể có."
4774,E:\DATN\dataframe\train_file\60.txt,"Với từng trạng thái đơn nhất, chương trình sẽ có hành vi khác nhau và chương trình còn có thể chuyển từ trạng thái này sang trạng thái khác ngay lập tức."
4775,E:\DATN\dataframe\train_file\60.txt,"Tuy nhiên, điều này phụ thuộc vào trạng thái hiện tại, mà chương trình có thể chuyển hoặc không thể chuyển sang trạng thái khác."
4776,E:\DATN\dataframe\train_file\60.txt,"Quy luật chuyển đổi này gọi là transitions, nó hữu hạn và có thể định trước."
4777,E:\DATN\dataframe\train_file\60.txt,Bạn có thể áp dụng cách tiếp cận này lên các đối tượng.
4778,E:\DATN\dataframe\train_file\60.txt,Ví dụ bạn có lớp Document.
4779,E:\DATN\dataframe\train_file\60.txt,"Một tài liệu có thể có 3 trạng thái: Draft(nháp), Moderation (chờ duyệt) và Published (đã công khai)."
4780,E:\DATN\dataframe\train_file\60.txt,Phương thức public của tài liệu làm việc với từng trạng thái sẽ có vài khác biệt nhỏ:
4781,E:\DATN\dataframe\train_file\60.txt,"Ở Draft, nó chuyển tài liệu lên chờ duyệt."
4782,E:\DATN\dataframe\train_file\60.txt,"Ở Moderation, nó làm cho tài liệu công khai, nhưng chỉ khi người dùng hiện tại là admin."
4783,E:\DATN\dataframe\train_file\60.txt,Ở Publushed nó không phải làm gì cả.
4784,E:\DATN\dataframe\train_file\60.txt,Máy trạng thái thường được triển khai với nhiều điều kiện hành động (if hoặc switch) để lựa chọn hành vi thích hợp dựa trên trạng thái hiện tại của đối tượng.
4785,E:\DATN\dataframe\train_file\60.txt,"Thông thường, ""trạng thái"" này chỉ là một tập hợp trường giá trị của đối tượng."
4786,E:\DATN\dataframe\train_file\60.txt,"Nếu bạn đã từng nghe về Máy trạng thái hữu hạn trước đây, thì bạn có lẽ đã triển khai nó ít nhất một lần."
4787,E:\DATN\dataframe\train_file\60.txt,Ví dụ như nhìn đoạn code dưới đây bạn có thấy quen quen không?
4788,E:\DATN\dataframe\train_file\60.txt,class Document is
4789,E:\DATN\dataframe\train_file\60.txt,    field state: string
4790,E:\DATN\dataframe\train_file\60.txt,    method publish() is
4791,E:\DATN\dataframe\train_file\60.txt,        switch (state)
4792,E:\DATN\dataframe\train_file\60.txt,"                state = ""moderation"""
4793,E:\DATN\dataframe\train_file\60.txt,                if (currentUser.role == 'admin')
4794,E:\DATN\dataframe\train_file\60.txt,"                    state = ""published"""
4795,E:\DATN\dataframe\train_file\60.txt,                // Do nothing.
4796,E:\DATN\dataframe\train_file\60.txt,Điểm yếu lớn nhất của máy trạng thái nằm ở việc các điều kiện tự để lộ chúng khi ta thêm quá nhiều trạng thái và các hành vi phụ thuộc trạng thái vào lớp Document.
4797,E:\DATN\dataframe\train_file\60.txt,"Phần lớn phương thức sẽ chứa các điều kiện quái dị, để chọn hành vi phù hợp của phương thức theo trạng thái hiện tại."
4798,E:\DATN\dataframe\train_file\60.txt,Điều này làm cho code trở nên khó bảo trì vì bất kỳ thay đổi nào đến logic transition sẽ đòi hỏi thay đổi điều kiện trạng thái ở toàn bộ phương thức.
4799,E:\DATN\dataframe\train_file\60.txt,Vấn đề có xu hướng trở nên lớn hơn khi dự án phát triển.
4800,E:\DATN\dataframe\train_file\60.txt,Khá là khó khăn để có thể dự đoán tất cả trạng thái và transition xảy ra ở giai đoạn thiết kế.
4801,E:\DATN\dataframe\train_file\60.txt,"Do đó, một máy trạng thái tinh gọn được xây dựng với một tập hợp điều kiện giới hạn có thể phát triển thành một mớ hỗn độn theo thời gian."
4802,E:\DATN\dataframe\train_file\60.txt,😊 Giải pháp
4803,E:\DATN\dataframe\train_file\60.txt,State đề xuất giải pháp là tạo một lớp mới cho tất cả trạng thái của một đối tượng và trích xuất tất cả hành vi dựa trên trạng thái cụ thể vào lớp đó.
4804,E:\DATN\dataframe\train_file\60.txt,"Thay vì triển khai tất cả hành vi của nó, đối tượng gốc bây giờ gọi là context sẽ lưu tham chiếu đến một trong những đối tượng trạng thái, để biểu diễn trạng thái hiện tại của nó và uỷ thác mọi công việc liên quan đến trạng thái cho đối tượng này."
4805,E:\DATN\dataframe\train_file\60.txt,"Để chuyển context sang trạng thái khác, ta sẽ thay thế đối tượng trạng thái đang hoạt động với một đối tượng khác để có trạng thái mới."
4806,E:\DATN\dataframe\train_file\60.txt,Điều này chỉ khả thi khi tất cả lớp trạng thái theo cùng một interface và context làm việc với các đối tượng đó thông qua interface này.
4807,E:\DATN\dataframe\train_file\60.txt,"Cấu trúc này trông giống Strategy, nhưng có một điểm khác biệt."
4808,E:\DATN\dataframe\train_file\60.txt,"Ở State, các trạng thái cụ thể có thể biết về nhau và bắt đầu chuyển đổi từ trạng thái này sang trạng thái khác, trong khi các Stategy hầu như không bao giờ biết về nhau"
4809,E:\DATN\dataframe\train_file\60.txt,🚗 Thế Giới Thực
4810,E:\DATN\dataframe\train_file\60.txt,Các button và switch trong điện thoại thông minh của bạn hoạt động khác nhau tùy thuộc vào trạng thái hiện tại của thiết bị:
4811,E:\DATN\dataframe\train_file\60.txt,"Khi điện thoại được mở khóa, việc nhấn các button dẫn đến việc thực hiện các chức năng khác nhau."
4812,E:\DATN\dataframe\train_file\60.txt,"Khi điện thoại bị khóa, nhấn bất kỳ button nào sẽ dẫn đến màn hình mở khóa."
4813,E:\DATN\dataframe\train_file\60.txt,"Khi điện thoại gần hết pin, nhấn bất kỳ button nào sẽ hiển thị màn hình sạc."
4814,E:\DATN\dataframe\train_file\60.txt,🏢 Cấu trúc
4815,E:\DATN\dataframe\train_file\60.txt,Context lưu trữ một tham chiếu đến một trong các đối tượng concrete state và uỷ thác cho nó tất cả công việc cụ thể liên quan đến trạng thái.
4816,E:\DATN\dataframe\train_file\60.txt,Context giao tiếp với đối tượng state thông qua interface state.
4817,E:\DATN\dataframe\train_file\60.txt,Context để lộ một setter nhằm truyền vào nó một đối tượng state mới.
4818,E:\DATN\dataframe\train_file\60.txt,State là interface khai báo phương thức cụ thể liên quan đến trạng thái.
4819,E:\DATN\dataframe\train_file\60.txt,Phương thức này nên có nghĩa với tất cả concrete state vì bạn không muốn các trạng thái của bạn có một phương thức vô dụng không bao giờ dùng đến.
4820,E:\DATN\dataframe\train_file\60.txt,Concrete State cung cấp triển khai của nó cho phương thức cụ thể liên quan đến trạng thái.
4821,E:\DATN\dataframe\train_file\60.txt,"Để tránh trùng lặp với code trên nhiều state, bạn nên cung cấp lớp trừu tượng trung gian cho đóng gói các hành vi dùng chung."
4822,E:\DATN\dataframe\train_file\60.txt,Đối tượng state có thể lưu trữ một tham chiếu trở lại (backreference) đến đối tượng context.
4823,E:\DATN\dataframe\train_file\60.txt,"Thông qua tham chiếu này, state có thể tìm nạp thông tin cần thiết từ đối tượng context, cũng như bắt đầu chuyển trạng thái."
4824,E:\DATN\dataframe\train_file\60.txt,Cả context và concrete state có thể thiết lập trạng thái tiếp theo cho context và thực hiện chuyển đổi trạng thái thực bằng cách thay thế đối tượng state được liên kết với context.
4825,E:\DATN\dataframe\train_file\60.txt,👨‍💻 Mã giả
4826,E:\DATN\dataframe\train_file\60.txt,"Trong ví dụ này, State sẽ làm cho cùng một bộ điều chỉnh nhạc có các hành vi khác nhau phụ thuộc vào trạng thái phát hiện tại."
4827,E:\DATN\dataframe\train_file\60.txt,"Đối tượng chính của bộ phát nhạc có liên kết đến một đối tượng state, thứ thực hiện phần lớn công việc thực."
4828,E:\DATN\dataframe\train_file\60.txt,"Các hành động thay thế đối tượng state hiện tại của bộ phát nhạc bằng đối tượng khác, để thay đổi cách mà bộ phát nhạc phản ứng với tương tác của người dùng."
4829,E:\DATN\dataframe\train_file\60.txt,// Lớp AudioPlayer hành động như một context.
4830,E:\DATN\dataframe\train_file\60.txt,Nó luôn
4831,E:\DATN\dataframe\train_file\60.txt,// duy trì tham chiếu đến một trong số các lớp state
4832,E:\DATN\dataframe\train_file\60.txt,// để biểu diễn trạng thái hiện tại của bộ phát nhạc.
4833,E:\DATN\dataframe\train_file\60.txt,class AudioPlayer is
4834,E:\DATN\dataframe\train_file\60.txt,    field state: State
4835,E:\DATN\dataframe\train_file\60.txt,"    field UI, volume, playlist, currentSong"
4836,E:\DATN\dataframe\train_file\60.txt,    constructor AudioPlayer() is
4837,E:\DATN\dataframe\train_file\60.txt,        this.state = new ReadyState(this)
4838,E:\DATN\dataframe\train_file\60.txt,        // Context uỷ thác việc xử lý đầu vào của người dùng
4839,E:\DATN\dataframe\train_file\60.txt,        // cho đối tượng state.
4840,E:\DATN\dataframe\train_file\60.txt,Kết quả dựa trên trạng thái
4841,E:\DATN\dataframe\train_file\60.txt,"        // hiện tại đang hoạt động, vì ở mỗi trạng thái sẽ xử"
4842,E:\DATN\dataframe\train_file\60.txt,        // lý đầu vào khác nhau.
4843,E:\DATN\dataframe\train_file\60.txt,        UI = new UserInterface()
4844,E:\DATN\dataframe\train_file\60.txt,    // Đối tượng khác có thể chuyển trạng thái hoạt động
4845,E:\DATN\dataframe\train_file\60.txt,    // của bộ phát nhạc.
4846,E:\DATN\dataframe\train_file\60.txt,    method changeState(state: State) is
4847,E:\DATN\dataframe\train_file\60.txt,        this.state = state
4848,E:\DATN\dataframe\train_file\60.txt,    // Các phương thức UI uỷ thác thực thi cho trạng thái
4849,E:\DATN\dataframe\train_file\60.txt,    // đang hoạt động.
4850,E:\DATN\dataframe\train_file\60.txt,    method clickLock() is
4851,E:\DATN\dataframe\train_file\60.txt,    method clickPlay() is
4852,E:\DATN\dataframe\train_file\60.txt,    method clickNext() is
4853,E:\DATN\dataframe\train_file\60.txt,    method clickPrevious() is
4854,E:\DATN\dataframe\train_file\60.txt,    // State có thể gọi các phương thức dịch vụ có
4855,E:\DATN\dataframe\train_file\60.txt,    // trên context
4856,E:\DATN\dataframe\train_file\60.txt,    method startPlayback() is
4857,E:\DATN\dataframe\train_file\60.txt,    method stopPlayback() is
4858,E:\DATN\dataframe\train_file\60.txt,    method nextSong() is
4859,E:\DATN\dataframe\train_file\60.txt,    method previousSong() is
4860,E:\DATN\dataframe\train_file\60.txt,    method fastForward(time) is
4861,E:\DATN\dataframe\train_file\60.txt,    method rewind(time) is
4862,E:\DATN\dataframe\train_file\60.txt,// Lớp state cơ sở khai báo các phương thức cho tất cả concrete
4863,E:\DATN\dataframe\train_file\60.txt,// state triển khai và cung cấp một tham chiếu trở về đối tượng
4864,E:\DATN\dataframe\train_file\60.txt,// context được liên kết với state.
4865,E:\DATN\dataframe\train_file\60.txt,Các state có thể dùng tham chiếu
4866,E:\DATN\dataframe\train_file\60.txt,// đó để chuyển đổi trạng thái.
4867,E:\DATN\dataframe\train_file\60.txt,abstract class State is
4868,E:\DATN\dataframe\train_file\60.txt,    protected field player: AudioPlayer
4869,E:\DATN\dataframe\train_file\60.txt,    // Context truyền chính nó qua hàm khởi tạo của state.
4870,E:\DATN\dataframe\train_file\60.txt,    // này giúp state lấy được dữ liệu hữu ích khi cần.
4871,E:\DATN\dataframe\train_file\60.txt,    constructor State(player) is
4872,E:\DATN\dataframe\train_file\60.txt,        this.player = player
4873,E:\DATN\dataframe\train_file\60.txt,    abstract method clickLock()
4874,E:\DATN\dataframe\train_file\60.txt,    abstract method clickPlay()
4875,E:\DATN\dataframe\train_file\60.txt,    abstract method clickNext()
4876,E:\DATN\dataframe\train_file\60.txt,    abstract method clickPrevious()
4877,E:\DATN\dataframe\train_file\60.txt,// Các concrete state triển khai các hành vi khác nhau được
4878,E:\DATN\dataframe\train_file\60.txt,// liên kết với state của context.
4879,E:\DATN\dataframe\train_file\60.txt,class LockedState extends State is
4880,E:\DATN\dataframe\train_file\60.txt,"    // Khi bạn mở khoá một bộ phát nhạc bị khoá,"
4881,E:\DATN\dataframe\train_file\60.txt,    // nó có thể có một trong hai trạng thái.
4882,E:\DATN\dataframe\train_file\60.txt,    method clickLock() is
4883,E:\DATN\dataframe\train_file\60.txt,        if (player.playing)
4884,E:\DATN\dataframe\train_file\60.txt,            player.changeState(new PlayingState(player))
4885,E:\DATN\dataframe\train_file\60.txt,            player.changeState(new ReadyState(player))
4886,E:\DATN\dataframe\train_file\60.txt,    method clickPlay() is
4887,E:\DATN\dataframe\train_file\60.txt,"        // Bị khoá, nên không làm gì cả."
4888,E:\DATN\dataframe\train_file\60.txt,    method clickNext() is
4889,E:\DATN\dataframe\train_file\60.txt,"        // Bị khoá, nên không làm gì cả."
4890,E:\DATN\dataframe\train_file\60.txt,    method clickPrevious() is
4891,E:\DATN\dataframe\train_file\60.txt,"        // Bị khoá, nên không làm gì cả."
4892,E:\DATN\dataframe\train_file\60.txt,// Chúng cũng có thể kích hoạt chuyển đổi trạng thái context.
4893,E:\DATN\dataframe\train_file\60.txt,class ReadyState extends State is
4894,E:\DATN\dataframe\train_file\60.txt,    method clickLock() is
4895,E:\DATN\dataframe\train_file\60.txt,        player.changeState(new LockedState(player))
4896,E:\DATN\dataframe\train_file\60.txt,    method clickPlay() is
4897,E:\DATN\dataframe\train_file\60.txt,        player.changeState(new PlayingState(player))
4898,E:\DATN\dataframe\train_file\60.txt,    method clickNext() is
4899,E:\DATN\dataframe\train_file\60.txt,    method clickPrevious() is
4900,E:\DATN\dataframe\train_file\60.txt,class PlayingState extends State is
4901,E:\DATN\dataframe\train_file\60.txt,    method clickLock() is
4902,E:\DATN\dataframe\train_file\60.txt,        player.changeState(new LockedState(player))
4903,E:\DATN\dataframe\train_file\60.txt,    method clickPlay() is
4904,E:\DATN\dataframe\train_file\60.txt,        player.changeState(new ReadyState(player))
4905,E:\DATN\dataframe\train_file\60.txt,    method clickNext() is
4906,E:\DATN\dataframe\train_file\60.txt,        if (event.doubleclick)
4907,E:\DATN\dataframe\train_file\60.txt,    method clickPrevious() is
4908,E:\DATN\dataframe\train_file\60.txt,        if (event.doubleclick)
4909,E:\DATN\dataframe\train_file\60.txt,💡 Ứng dụng
4910,E:\DATN\dataframe\train_file\60.txt,"🐞 Sử dụng State khi bạn có một đối tượng có các hành vi khác nhau phụ thuộc vào trạng thái hiện tại, số lượng trạng thái là rất lớn và code của trạng thái cụ thể thường xuyên thay đổi."
4911,E:\DATN\dataframe\train_file\60.txt,⚡ Pattern đề nghị việc trích xuất tất cả code trạng thái cụ thể vào một tập hợp lớp riêng biệt.
4912,E:\DATN\dataframe\train_file\60.txt,"Kết quả là bạn có thể thêm trạng thái mới hoặc thay đổi cái đã có độc lập với nhau, giảm thiểu chi phí bảo trì."
4913,E:\DATN\dataframe\train_file\60.txt,🐞 Sử dụng State khi bạn có một lớp với số lượng điều kiện không lồ để thay đổi hành vi lớp đó theo giá trị hiện tại của các trường trong lớp đó.
4914,E:\DATN\dataframe\train_file\60.txt,⚡ State giúp bạn trích xuất các nhánh của các điều kiện này thành các phương thức của các lớp trạng thái tương ứng.
4915,E:\DATN\dataframe\train_file\60.txt,Đồng thời bạn còn có thể làm sạch các trường tạm thời và các phương thức trợ giúp liên quan đến code trạng thái cụ thể khỏi lớp chính của bạn.
4916,E:\DATN\dataframe\train_file\60.txt,🐞 Sử dụng State khi bạn có một lượng lớn code trùng lặp các trạng thái và chuyển đổi tương tự của máy trạng thái dựa trên điều kiện.
4917,E:\DATN\dataframe\train_file\60.txt,⚡ State giúp bạn soạn các hệ thống phân cấp của các lớp trạng thái và làm giảm sự trùng lặp bằng cách trích xuất code chung vào lớp cơ sở trừu tượng.
4918,E:\DATN\dataframe\train_file\60.txt,📋 Triển khai
4919,E:\DATN\dataframe\train_file\60.txt,Xác định lớp nào sẽ hành động như context.
4920,E:\DATN\dataframe\train_file\60.txt,"Nó có thể là một lớp đã có sẵn hoặc một lớp mới, nếu code trạng thái cụ thể được phân phối trên nhiều lớp."
4921,E:\DATN\dataframe\train_file\60.txt,"Với tất cả trạng thái thực, tạo một lớp dẫn xuất từ interface state."
4922,E:\DATN\dataframe\train_file\60.txt,"Sau đó đi qua tất cả phương thức của context, trích xuất mọi code liên quan đến trạng thái vào lớp mới vừa tạo."
4923,E:\DATN\dataframe\train_file\60.txt,"Trong khi chuyển code vào lớp trạng thái, bạn sẽ gặp trường hợp là nó phụ thuộc vào thành phần riêng tư của context."
4924,E:\DATN\dataframe\train_file\60.txt,Có một vài cách giải quyết là:
4925,E:\DATN\dataframe\train_file\60.txt,Làm cho trường hay phương thức đó công khai.
4926,E:\DATN\dataframe\train_file\60.txt,Chuyển hành vi bạn đang trích xuất vào phương thức công khai trong context và gọi nó từ lớp state.
4927,E:\DATN\dataframe\train_file\60.txt,Cách này khá tệ nhưng nhanh bạn có thể sửa lại sau.
4928,E:\DATN\dataframe\train_file\60.txt,"Lồng lớp state vào lớp context, nhưng chỉ khi ngôn ngữ lập trình của bạn hỗ trợ lớp lồng nhau."
4929,E:\DATN\dataframe\train_file\60.txt,"Trong lớp context, thêm trường tham chiếu của kiểu interface state và một setter công khai cho phép ghi đè giá trị lên trường."
4930,E:\DATN\dataframe\train_file\60.txt,Đi qua phương thức của context lần nữa và thay thế điều kiện trạng thái trống với lệnh gọi đến phương thức phù hợp của đối tượng state.
4931,E:\DATN\dataframe\train_file\60.txt,"Để chuyển đổi trạng thái context, tạo một trong những lớp state và truyền nó vào context."
4932,E:\DATN\dataframe\train_file\60.txt,"Bạn có thể làm điều này bên trong context hoặc các state khác, hoặc ở client."
4933,E:\DATN\dataframe\train_file\60.txt,"Bất cứ khi nào thực hiện xong, lớp sẽ trở nên phụ thuộc vào lớp concrete state mà nó khởi tạo."
4934,E:\DATN\dataframe\train_file\60.txt,⚖️ Ưu nhược điểm
4935,E:\DATN\dataframe\train_file\60.txt,✔️ Single Responsibility Principle.
4936,E:\DATN\dataframe\train_file\60.txt,Tổ chức code liên kết với trạng thái cụ thể trong lớp riêng biệt.
4937,E:\DATN\dataframe\train_file\60.txt,✔️ Open/Closed Principle.
4938,E:\DATN\dataframe\train_file\60.txt,Thêm trạng thái mới mà không ảnh hưởng đến lớp trạng thái hiện có hay ngữ cảnh.
4939,E:\DATN\dataframe\train_file\60.txt,✔️ Đơn giản hoá code context bằng loại bỏ các điều kiện máy trạng thái cồng kềnh.
4940,E:\DATN\dataframe\train_file\60.txt,❌ Việc áp dụng pattern có thể quá mức cần thiết nếu máy trạng thái chỉ có một vài trạng thái hoặc hiếm khi thay đổi.
4941,E:\DATN\dataframe\train_file\60.txt,🔁 Quan hệ với các pattern khác
4942,E:\DATN\dataframe\train_file\60.txt,"Bridge, State, Strategy (và ở một mức độ nào đó là Adapter) có cấu trúc rất giống nhau."
4943,E:\DATN\dataframe\train_file\60.txt,"Thật vậy, tất cả các pattern này đều dựa trên nguyên tắc là ủy thác công việc cho các đối tượng khác."
4944,E:\DATN\dataframe\train_file\60.txt,"Tuy nhiên, chúng giải quyết các vấn đề khác nhau."
4945,E:\DATN\dataframe\train_file\60.txt,Một pattern không chỉ là một công thức để cấu trúc code của bạn theo một cách cụ thể.
4946,E:\DATN\dataframe\train_file\60.txt,Nó còn có thể truyền đạt đến các dev khác về vấn đề mà pattern giải quyết.
4947,E:\DATN\dataframe\train_file\60.txt,State có thể được coi là một phần mở rộng của Strategy.
4948,E:\DATN\dataframe\train_file\60.txt,Cả hai pattern đều dựa trên kết hợp: chúng thay đổi hành vi của ngữ cảnh bằng cách ủy quyền một số công việc cho các đối tượng trợ giúp.
4949,E:\DATN\dataframe\train_file\60.txt,Strategy làm cho các đối tượng này hoàn toàn độc lập và không biết về nhau.
4950,E:\DATN\dataframe\train_file\60.txt,"Tuy nhiên, State không hạn chế sự phụ thuộc giữa các trạng thái cụ thể, cho phép chúng thay đổi trạng thái của ngữ cảnh theo ý muốn."
4951,E:\DATN\dataframe\train_file\61.txt,Design Patterns - State
4952,E:\DATN\dataframe\train_file\61.txt,📜 Mục đích
4953,E:\DATN\dataframe\train_file\61.txt,State là một design pattern thuộc nhóm behavoiral giúp chỉnh sửa hành vi của một đối tượng khi trạng thái bên trong nó thay đổi.
4954,E:\DATN\dataframe\train_file\61.txt,Nó xảy ra nếu như một đối tượng thay đổi lớp của nó.
4955,E:\DATN\dataframe\train_file\61.txt,😟 Vấn đề
4956,E:\DATN\dataframe\train_file\61.txt,Pattern State có mối quan hệ gần gũi với khái niệm  (gọi tắt là máy trạng thái)
4957,E:\DATN\dataframe\train_file\61.txt,"Ý tưởng chính là như thế này, tại bất kỳ thời điểm nào cũng có một hữu hạn trạng thái mà chương trình có thể có."
4958,E:\DATN\dataframe\train_file\61.txt,"Với từng trạng thái đơn nhất, chương trình sẽ có hành vi khác nhau và chương trình còn có thể chuyển từ trạng thái này sang trạng thái khác ngay lập tức."
4959,E:\DATN\dataframe\train_file\61.txt,"Tuy nhiên, điều này phụ thuộc vào trạng thái hiện tại, mà chương trình có thể chuyển hoặc không thể chuyển sang trạng thái khác."
4960,E:\DATN\dataframe\train_file\61.txt,"Quy luật chuyển đổi này gọi là transitions, nó hữu hạn và có thể định trước."
4961,E:\DATN\dataframe\train_file\61.txt,Bạn có thể áp dụng cách tiếp cận này lên các đối tượng.
4962,E:\DATN\dataframe\train_file\61.txt,Ví dụ bạn có lớp Document.
4963,E:\DATN\dataframe\train_file\61.txt,"Một tài liệu có thể có 3 trạng thái: Draft(nháp), Moderation (chờ duyệt) và Published (đã công khai)."
4964,E:\DATN\dataframe\train_file\61.txt,Phương thức public của tài liệu làm việc với từng trạng thái sẽ có vài khác biệt nhỏ:
4965,E:\DATN\dataframe\train_file\61.txt,"Ở Draft, nó chuyển tài liệu lên chờ duyệt."
4966,E:\DATN\dataframe\train_file\61.txt,"Ở Moderation, nó làm cho tài liệu công khai, nhưng chỉ khi người dùng hiện tại là admin."
4967,E:\DATN\dataframe\train_file\61.txt,Ở Publushed nó không phải làm gì cả.
4968,E:\DATN\dataframe\train_file\61.txt,Máy trạng thái thường được triển khai với nhiều điều kiện hành động (if hoặc switch) để lựa chọn hành vi thích hợp dựa trên trạng thái hiện tại của đối tượng.
4969,E:\DATN\dataframe\train_file\61.txt,"Thông thường, ""trạng thái"" này chỉ là một tập hợp trường giá trị của đối tượng."
4970,E:\DATN\dataframe\train_file\61.txt,"Nếu bạn đã từng nghe về Máy trạng thái hữu hạn trước đây, thì bạn có lẽ đã triển khai nó ít nhất một lần."
4971,E:\DATN\dataframe\train_file\61.txt,Ví dụ như nhìn đoạn code dưới đây bạn có thấy quen quen không?
4972,E:\DATN\dataframe\train_file\61.txt,class Document is
4973,E:\DATN\dataframe\train_file\61.txt,    field state: string
4974,E:\DATN\dataframe\train_file\61.txt,    method publish() is
4975,E:\DATN\dataframe\train_file\61.txt,        switch (state)
4976,E:\DATN\dataframe\train_file\61.txt,"                state = ""moderation"""
4977,E:\DATN\dataframe\train_file\61.txt,                if (currentUser.role == 'admin')
4978,E:\DATN\dataframe\train_file\61.txt,"                    state = ""published"""
4979,E:\DATN\dataframe\train_file\61.txt,                // Do nothing.
4980,E:\DATN\dataframe\train_file\61.txt,Điểm yếu lớn nhất của máy trạng thái nằm ở việc các điều kiện tự để lộ chúng khi ta thêm quá nhiều trạng thái và các hành vi phụ thuộc trạng thái vào lớp Document.
4981,E:\DATN\dataframe\train_file\61.txt,"Phần lớn phương thức sẽ chứa các điều kiện quái dị, để chọn hành vi phù hợp của phương thức theo trạng thái hiện tại."
4982,E:\DATN\dataframe\train_file\61.txt,Điều này làm cho code trở nên khó bảo trì vì bất kỳ thay đổi nào đến logic transition sẽ đòi hỏi thay đổi điều kiện trạng thái ở toàn bộ phương thức.
4983,E:\DATN\dataframe\train_file\61.txt,Vấn đề có xu hướng trở nên lớn hơn khi dự án phát triển.
4984,E:\DATN\dataframe\train_file\61.txt,Khá là khó khăn để có thể dự đoán tất cả trạng thái và transition xảy ra ở giai đoạn thiết kế.
4985,E:\DATN\dataframe\train_file\61.txt,"Do đó, một máy trạng thái tinh gọn được xây dựng với một tập hợp điều kiện giới hạn có thể phát triển thành một mớ hỗn độn theo thời gian."
4986,E:\DATN\dataframe\train_file\61.txt,😊 Giải pháp
4987,E:\DATN\dataframe\train_file\61.txt,State đề xuất giải pháp là tạo một lớp mới cho tất cả trạng thái của một đối tượng và trích xuất tất cả hành vi dựa trên trạng thái cụ thể vào lớp đó.
4988,E:\DATN\dataframe\train_file\61.txt,"Thay vì triển khai tất cả hành vi của nó, đối tượng gốc bây giờ gọi là context sẽ lưu tham chiếu đến một trong những đối tượng trạng thái, để biểu diễn trạng thái hiện tại của nó và uỷ thác mọi công việc liên quan đến trạng thái cho đối tượng này."
4989,E:\DATN\dataframe\train_file\61.txt,"Để chuyển context sang trạng thái khác, ta sẽ thay thế đối tượng trạng thái đang hoạt động với một đối tượng khác để có trạng thái mới."
4990,E:\DATN\dataframe\train_file\61.txt,Điều này chỉ khả thi khi tất cả lớp trạng thái theo cùng một interface và context làm việc với các đối tượng đó thông qua interface này.
4991,E:\DATN\dataframe\train_file\61.txt,"Cấu trúc này trông giống Strategy, nhưng có một điểm khác biệt."
4992,E:\DATN\dataframe\train_file\61.txt,"Ở State, các trạng thái cụ thể có thể biết về nhau và bắt đầu chuyển đổi từ trạng thái này sang trạng thái khác, trong khi các Stategy hầu như không bao giờ biết về nhau"
4993,E:\DATN\dataframe\train_file\61.txt,🚗 Thế Giới Thực
4994,E:\DATN\dataframe\train_file\61.txt,Các button và switch trong điện thoại thông minh của bạn hoạt động khác nhau tùy thuộc vào trạng thái hiện tại của thiết bị:
4995,E:\DATN\dataframe\train_file\61.txt,"Khi điện thoại được mở khóa, việc nhấn các button dẫn đến việc thực hiện các chức năng khác nhau."
4996,E:\DATN\dataframe\train_file\61.txt,"Khi điện thoại bị khóa, nhấn bất kỳ button nào sẽ dẫn đến màn hình mở khóa."
4997,E:\DATN\dataframe\train_file\61.txt,"Khi điện thoại gần hết pin, nhấn bất kỳ button nào sẽ hiển thị màn hình sạc."
4998,E:\DATN\dataframe\train_file\61.txt,🏢 Cấu trúc
4999,E:\DATN\dataframe\train_file\61.txt,Context lưu trữ một tham chiếu đến một trong các đối tượng concrete state và uỷ thác cho nó tất cả công việc cụ thể liên quan đến trạng thái.
5000,E:\DATN\dataframe\train_file\61.txt,Context giao tiếp với đối tượng state thông qua interface state.
5001,E:\DATN\dataframe\train_file\61.txt,Context để lộ một setter nhằm truyền vào nó một đối tượng state mới.
5002,E:\DATN\dataframe\train_file\61.txt,State là interface khai báo phương thức cụ thể liên quan đến trạng thái.
5003,E:\DATN\dataframe\train_file\61.txt,Phương thức này nên có nghĩa với tất cả concrete state vì bạn không muốn các trạng thái của bạn có một phương thức vô dụng không bao giờ dùng đến.
5004,E:\DATN\dataframe\train_file\61.txt,Concrete State cung cấp triển khai của nó cho phương thức cụ thể liên quan đến trạng thái.
5005,E:\DATN\dataframe\train_file\61.txt,"Để tránh trùng lặp với code trên nhiều state, bạn nên cung cấp lớp trừu tượng trung gian cho đóng gói các hành vi dùng chung."
5006,E:\DATN\dataframe\train_file\61.txt,Đối tượng state có thể lưu trữ một tham chiếu trở lại (backreference) đến đối tượng context.
5007,E:\DATN\dataframe\train_file\61.txt,"Thông qua tham chiếu này, state có thể tìm nạp thông tin cần thiết từ đối tượng context, cũng như bắt đầu chuyển trạng thái."
5008,E:\DATN\dataframe\train_file\61.txt,Cả context và concrete state có thể thiết lập trạng thái tiếp theo cho context và thực hiện chuyển đổi trạng thái thực bằng cách thay thế đối tượng state được liên kết với context.
5009,E:\DATN\dataframe\train_file\61.txt,👨‍💻 Mã giả
5010,E:\DATN\dataframe\train_file\61.txt,"Trong ví dụ này, State sẽ làm cho cùng một bộ điều chỉnh nhạc có các hành vi khác nhau phụ thuộc vào trạng thái phát hiện tại."
5011,E:\DATN\dataframe\train_file\61.txt,"Đối tượng chính của bộ phát nhạc có liên kết đến một đối tượng state, thứ thực hiện phần lớn công việc thực."
5012,E:\DATN\dataframe\train_file\61.txt,"Các hành động thay thế đối tượng state hiện tại của bộ phát nhạc bằng đối tượng khác, để thay đổi cách mà bộ phát nhạc phản ứng với tương tác của người dùng."
5013,E:\DATN\dataframe\train_file\61.txt,// Lớp AudioPlayer hành động như một context.
5014,E:\DATN\dataframe\train_file\61.txt,Nó luôn
5015,E:\DATN\dataframe\train_file\61.txt,// duy trì tham chiếu đến một trong số các lớp state
5016,E:\DATN\dataframe\train_file\61.txt,// để biểu diễn trạng thái hiện tại của bộ phát nhạc.
5017,E:\DATN\dataframe\train_file\61.txt,class AudioPlayer is
5018,E:\DATN\dataframe\train_file\61.txt,    field state: State
5019,E:\DATN\dataframe\train_file\61.txt,"    field UI, volume, playlist, currentSong"
5020,E:\DATN\dataframe\train_file\61.txt,    constructor AudioPlayer() is
5021,E:\DATN\dataframe\train_file\61.txt,        this.state = new ReadyState(this)
5022,E:\DATN\dataframe\train_file\61.txt,        // Context uỷ thác việc xử lý đầu vào của người dùng
5023,E:\DATN\dataframe\train_file\61.txt,        // cho đối tượng state.
5024,E:\DATN\dataframe\train_file\61.txt,Kết quả dựa trên trạng thái
5025,E:\DATN\dataframe\train_file\61.txt,"        // hiện tại đang hoạt động, vì ở mỗi trạng thái sẽ xử"
5026,E:\DATN\dataframe\train_file\61.txt,        // lý đầu vào khác nhau.
5027,E:\DATN\dataframe\train_file\61.txt,        UI = new UserInterface()
5028,E:\DATN\dataframe\train_file\61.txt,    // Đối tượng khác có thể chuyển trạng thái hoạt động
5029,E:\DATN\dataframe\train_file\61.txt,    // của bộ phát nhạc.
5030,E:\DATN\dataframe\train_file\61.txt,    method changeState(state: State) is
5031,E:\DATN\dataframe\train_file\61.txt,        this.state = state
5032,E:\DATN\dataframe\train_file\61.txt,    // Các phương thức UI uỷ thác thực thi cho trạng thái
5033,E:\DATN\dataframe\train_file\61.txt,    // đang hoạt động.
5034,E:\DATN\dataframe\train_file\61.txt,    method clickLock() is
5035,E:\DATN\dataframe\train_file\61.txt,    method clickPlay() is
5036,E:\DATN\dataframe\train_file\61.txt,    method clickNext() is
5037,E:\DATN\dataframe\train_file\61.txt,    method clickPrevious() is
5038,E:\DATN\dataframe\train_file\61.txt,    // State có thể gọi các phương thức dịch vụ có
5039,E:\DATN\dataframe\train_file\61.txt,    // trên context
5040,E:\DATN\dataframe\train_file\61.txt,    method startPlayback() is
5041,E:\DATN\dataframe\train_file\61.txt,    method stopPlayback() is
5042,E:\DATN\dataframe\train_file\61.txt,    method nextSong() is
5043,E:\DATN\dataframe\train_file\61.txt,    method previousSong() is
5044,E:\DATN\dataframe\train_file\61.txt,    method fastForward(time) is
5045,E:\DATN\dataframe\train_file\61.txt,    method rewind(time) is
5046,E:\DATN\dataframe\train_file\61.txt,// Lớp state cơ sở khai báo các phương thức cho tất cả concrete
5047,E:\DATN\dataframe\train_file\61.txt,// state triển khai và cung cấp một tham chiếu trở về đối tượng
5048,E:\DATN\dataframe\train_file\61.txt,// context được liên kết với state.
5049,E:\DATN\dataframe\train_file\61.txt,Các state có thể dùng tham chiếu
5050,E:\DATN\dataframe\train_file\61.txt,// đó để chuyển đổi trạng thái.
5051,E:\DATN\dataframe\train_file\61.txt,abstract class State is
5052,E:\DATN\dataframe\train_file\61.txt,    protected field player: AudioPlayer
5053,E:\DATN\dataframe\train_file\61.txt,    // Context truyền chính nó qua hàm khởi tạo của state.
5054,E:\DATN\dataframe\train_file\61.txt,    // này giúp state lấy được dữ liệu hữu ích khi cần.
5055,E:\DATN\dataframe\train_file\61.txt,    constructor State(player) is
5056,E:\DATN\dataframe\train_file\61.txt,        this.player = player
5057,E:\DATN\dataframe\train_file\61.txt,    abstract method clickLock()
5058,E:\DATN\dataframe\train_file\61.txt,    abstract method clickPlay()
5059,E:\DATN\dataframe\train_file\61.txt,    abstract method clickNext()
5060,E:\DATN\dataframe\train_file\61.txt,    abstract method clickPrevious()
5061,E:\DATN\dataframe\train_file\61.txt,// Các concrete state triển khai các hành vi khác nhau được
5062,E:\DATN\dataframe\train_file\61.txt,// liên kết với state của context.
5063,E:\DATN\dataframe\train_file\61.txt,class LockedState extends State is
5064,E:\DATN\dataframe\train_file\61.txt,"    // Khi bạn mở khoá một bộ phát nhạc bị khoá,"
5065,E:\DATN\dataframe\train_file\61.txt,    // nó có thể có một trong hai trạng thái.
5066,E:\DATN\dataframe\train_file\61.txt,    method clickLock() is
5067,E:\DATN\dataframe\train_file\61.txt,        if (player.playing)
5068,E:\DATN\dataframe\train_file\61.txt,            player.changeState(new PlayingState(player))
5069,E:\DATN\dataframe\train_file\61.txt,            player.changeState(new ReadyState(player))
5070,E:\DATN\dataframe\train_file\61.txt,    method clickPlay() is
5071,E:\DATN\dataframe\train_file\61.txt,"        // Bị khoá, nên không làm gì cả."
5072,E:\DATN\dataframe\train_file\61.txt,    method clickNext() is
5073,E:\DATN\dataframe\train_file\61.txt,"        // Bị khoá, nên không làm gì cả."
5074,E:\DATN\dataframe\train_file\61.txt,    method clickPrevious() is
5075,E:\DATN\dataframe\train_file\61.txt,"        // Bị khoá, nên không làm gì cả."
5076,E:\DATN\dataframe\train_file\61.txt,// Chúng cũng có thể kích hoạt chuyển đổi trạng thái context.
5077,E:\DATN\dataframe\train_file\61.txt,class ReadyState extends State is
5078,E:\DATN\dataframe\train_file\61.txt,    method clickLock() is
5079,E:\DATN\dataframe\train_file\61.txt,        player.changeState(new LockedState(player))
5080,E:\DATN\dataframe\train_file\61.txt,    method clickPlay() is
5081,E:\DATN\dataframe\train_file\61.txt,        player.changeState(new PlayingState(player))
5082,E:\DATN\dataframe\train_file\61.txt,    method clickNext() is
5083,E:\DATN\dataframe\train_file\61.txt,    method clickPrevious() is
5084,E:\DATN\dataframe\train_file\61.txt,class PlayingState extends State is
5085,E:\DATN\dataframe\train_file\61.txt,    method clickLock() is
5086,E:\DATN\dataframe\train_file\61.txt,        player.changeState(new LockedState(player))
5087,E:\DATN\dataframe\train_file\61.txt,    method clickPlay() is
5088,E:\DATN\dataframe\train_file\61.txt,        player.changeState(new ReadyState(player))
5089,E:\DATN\dataframe\train_file\61.txt,    method clickNext() is
5090,E:\DATN\dataframe\train_file\61.txt,        if (event.doubleclick)
5091,E:\DATN\dataframe\train_file\61.txt,    method clickPrevious() is
5092,E:\DATN\dataframe\train_file\61.txt,        if (event.doubleclick)
5093,E:\DATN\dataframe\train_file\61.txt,💡 Ứng dụng
5094,E:\DATN\dataframe\train_file\61.txt,"🐞 Sử dụng State khi bạn có một đối tượng có các hành vi khác nhau phụ thuộc vào trạng thái hiện tại, số lượng trạng thái là rất lớn và code của trạng thái cụ thể thường xuyên thay đổi."
5095,E:\DATN\dataframe\train_file\61.txt,⚡ Pattern đề nghị việc trích xuất tất cả code trạng thái cụ thể vào một tập hợp lớp riêng biệt.
5096,E:\DATN\dataframe\train_file\61.txt,"Kết quả là bạn có thể thêm trạng thái mới hoặc thay đổi cái đã có độc lập với nhau, giảm thiểu chi phí bảo trì."
5097,E:\DATN\dataframe\train_file\61.txt,🐞 Sử dụng State khi bạn có một lớp với số lượng điều kiện không lồ để thay đổi hành vi lớp đó theo giá trị hiện tại của các trường trong lớp đó.
5098,E:\DATN\dataframe\train_file\61.txt,⚡ State giúp bạn trích xuất các nhánh của các điều kiện này thành các phương thức của các lớp trạng thái tương ứng.
5099,E:\DATN\dataframe\train_file\61.txt,Đồng thời bạn còn có thể làm sạch các trường tạm thời và các phương thức trợ giúp liên quan đến code trạng thái cụ thể khỏi lớp chính của bạn.
5100,E:\DATN\dataframe\train_file\61.txt,🐞 Sử dụng State khi bạn có một lượng lớn code trùng lặp các trạng thái và chuyển đổi tương tự của máy trạng thái dựa trên điều kiện.
5101,E:\DATN\dataframe\train_file\61.txt,⚡ State giúp bạn soạn các hệ thống phân cấp của các lớp trạng thái và làm giảm sự trùng lặp bằng cách trích xuất code chung vào lớp cơ sở trừu tượng.
5102,E:\DATN\dataframe\train_file\61.txt,📋 Triển khai
5103,E:\DATN\dataframe\train_file\61.txt,Xác định lớp nào sẽ hành động như context.
5104,E:\DATN\dataframe\train_file\61.txt,"Nó có thể là một lớp đã có sẵn hoặc một lớp mới, nếu code trạng thái cụ thể được phân phối trên nhiều lớp."
5105,E:\DATN\dataframe\train_file\61.txt,"Với tất cả trạng thái thực, tạo một lớp dẫn xuất từ interface state."
5106,E:\DATN\dataframe\train_file\61.txt,"Sau đó đi qua tất cả phương thức của context, trích xuất mọi code liên quan đến trạng thái vào lớp mới vừa tạo."
5107,E:\DATN\dataframe\train_file\61.txt,"Trong khi chuyển code vào lớp trạng thái, bạn sẽ gặp trường hợp là nó phụ thuộc vào thành phần riêng tư của context."
5108,E:\DATN\dataframe\train_file\61.txt,Có một vài cách giải quyết là:
5109,E:\DATN\dataframe\train_file\61.txt,Làm cho trường hay phương thức đó công khai.
5110,E:\DATN\dataframe\train_file\61.txt,Chuyển hành vi bạn đang trích xuất vào phương thức công khai trong context và gọi nó từ lớp state.
5111,E:\DATN\dataframe\train_file\61.txt,Cách này khá tệ nhưng nhanh bạn có thể sửa lại sau.
5112,E:\DATN\dataframe\train_file\61.txt,"Lồng lớp state vào lớp context, nhưng chỉ khi ngôn ngữ lập trình của bạn hỗ trợ lớp lồng nhau."
5113,E:\DATN\dataframe\train_file\61.txt,"Trong lớp context, thêm trường tham chiếu của kiểu interface state và một setter công khai cho phép ghi đè giá trị lên trường."
5114,E:\DATN\dataframe\train_file\61.txt,Đi qua phương thức của context lần nữa và thay thế điều kiện trạng thái trống với lệnh gọi đến phương thức phù hợp của đối tượng state.
5115,E:\DATN\dataframe\train_file\61.txt,"Để chuyển đổi trạng thái context, tạo một trong những lớp state và truyền nó vào context."
5116,E:\DATN\dataframe\train_file\61.txt,"Bạn có thể làm điều này bên trong context hoặc các state khác, hoặc ở client."
5117,E:\DATN\dataframe\train_file\61.txt,"Bất cứ khi nào thực hiện xong, lớp sẽ trở nên phụ thuộc vào lớp concrete state mà nó khởi tạo."
5118,E:\DATN\dataframe\train_file\61.txt,⚖️ Ưu nhược điểm
5119,E:\DATN\dataframe\train_file\61.txt,✔️ Single Responsibility Principle.
5120,E:\DATN\dataframe\train_file\61.txt,Tổ chức code liên kết với trạng thái cụ thể trong lớp riêng biệt.
5121,E:\DATN\dataframe\train_file\61.txt,✔️ Open/Closed Principle.
5122,E:\DATN\dataframe\train_file\61.txt,Thêm trạng thái mới mà không ảnh hưởng đến lớp trạng thái hiện có hay ngữ cảnh.
5123,E:\DATN\dataframe\train_file\61.txt,✔️ Đơn giản hoá code context bằng loại bỏ các điều kiện máy trạng thái cồng kềnh.
5124,E:\DATN\dataframe\train_file\61.txt,❌ Việc áp dụng pattern có thể quá mức cần thiết nếu máy trạng thái chỉ có một vài trạng thái hoặc hiếm khi thay đổi.
5125,E:\DATN\dataframe\train_file\61.txt,🔁 Quan hệ với các pattern khác
5126,E:\DATN\dataframe\train_file\61.txt,"Bridge, State, Strategy (và ở một mức độ nào đó là Adapter) có cấu trúc rất giống nhau."
5127,E:\DATN\dataframe\train_file\61.txt,"Thật vậy, tất cả các pattern này đều dựa trên nguyên tắc là ủy thác công việc cho các đối tượng khác."
5128,E:\DATN\dataframe\train_file\61.txt,"Tuy nhiên, chúng giải quyết các vấn đề khác nhau."
5129,E:\DATN\dataframe\train_file\61.txt,Một pattern không chỉ là một công thức để cấu trúc code của bạn theo một cách cụ thể.
5130,E:\DATN\dataframe\train_file\61.txt,Nó còn có thể truyền đạt đến các dev khác về vấn đề mà pattern giải quyết.
5131,E:\DATN\dataframe\train_file\61.txt,State có thể được coi là một phần mở rộng của Strategy.
5132,E:\DATN\dataframe\train_file\61.txt,Cả hai pattern đều dựa trên kết hợp: chúng thay đổi hành vi của ngữ cảnh bằng cách ủy quyền một số công việc cho các đối tượng trợ giúp.
5133,E:\DATN\dataframe\train_file\61.txt,Strategy làm cho các đối tượng này hoàn toàn độc lập và không biết về nhau.
5134,E:\DATN\dataframe\train_file\61.txt,"Tuy nhiên, State không hạn chế sự phụ thuộc giữa các trạng thái cụ thể, cho phép chúng thay đổi trạng thái của ngữ cảnh theo ý muốn."
5135,E:\DATN\dataframe\train_file\62.txt,Bạn đã biết về Zero-shot Learning chưa?
5136,E:\DATN\dataframe\train_file\62.txt,"Trong các bài toán về Face Recognition, chắc hẳn các bạn đã nghe hoặc nên nghe về 1 khái niệm One-shot learning."
5137,E:\DATN\dataframe\train_file\62.txt,"Mình cũng đã từng làm đồ án môn học về phương pháp này, tương đối hay."
5138,E:\DATN\dataframe\train_file\62.txt,"Lại là lúc lượn lờ linh tinh, bắt gặp một khai niệm Zero-shot learning."
5139,E:\DATN\dataframe\train_file\62.txt,"Ủa, tiền thân của One-shot learning hay gì?"
5140,E:\DATN\dataframe\train_file\62.txt,"Vì vậy, song song với việc tìm hiểu xem nó là gì, mình cũng mong muốn chia sẻ cho mọi người thêm một chút kiến thức mới cho những ai chưa biết."
5141,E:\DATN\dataframe\train_file\62.txt,"Còn Two-shot, Three-shot gì đấy thì để sau nhé"
5142,E:\DATN\dataframe\train_file\62.txt,Chúc các bạn có thời gian đọc bài viết vui vẻ!
5143,E:\DATN\dataframe\train_file\62.txt,Zero-shot learning là gì?
5144,E:\DATN\dataframe\train_file\62.txt,"Theo các nguồn mình đọc, có thể khái quát One-shot learning như sau: One-shot learning là một phương pháp xác định các danh mục chưa được quan sát thấy trong quá trình đào tạo."
5145,E:\DATN\dataframe\train_file\62.txt,"Ví dụ dễ hiểu, sẽ không có gì khó khăn khi bạn nhận ra một con ngựa vằn khi bạn đọc được nó chỉ khác con ngựa thường ở chỗ có thêm vằn, mặc dù bạn chưa thấy lần nào nhưng chắc chắn bạn sẽ nhận ra ngày lần đầu nhìn thấy nó."
5146,E:\DATN\dataframe\train_file\62.txt,"Với các phương pháp học tập có giám sát hay không có giám sát truyền thống, việc dự đoán nhãn cho một đầu vào đều dựa vào những nhãn đã có, đã biết."
5147,E:\DATN\dataframe\train_file\62.txt,"Đối với One-shot learning, ý tưởng chính là dựa trên việc chuyển ngữ nghĩa từ các nhãn được quan sát (đã có) sang nhãn mới."
5148,E:\DATN\dataframe\train_file\62.txt,"Về cơ bản, Zero-shot hoạt động bằng cách kết hợp các mục quan sát/nhìn thấy với các mục không quan sát/nhìn thấy thông qua một số loại thông tin bổ trợ, mã hóa các thuộc tính phân biệt có thể quan sát của các đối tượng."
5149,E:\DATN\dataframe\train_file\62.txt,Ví dụ mô hình đào tạo phân loại động vật đã được huấn luyện để nhận dạng được con ngựa.
5150,E:\DATN\dataframe\train_file\62.txt,"Mô hình này có thể xác định được ngựa vằn nếu nó có các thông tin bổ trợ, thông tin bổ trợ ở đây có thể bao gồm các thuộc tính, mô tả dạng văn bản hoặc vector đặc trưng."
5151,E:\DATN\dataframe\train_file\62.txt,Chìa khóa của việc chuyển giao ngữ nghĩa là mã hóa các danh mục dưới dạng vector trong một không gian ngữ nghĩa.
5152,E:\DATN\dataframe\train_file\62.txt,Danh mục ở đây là gì?
5153,E:\DATN\dataframe\train_file\62.txt,"Ví dụ một con mèo có đặc điểm 4 chân, có đuôi, có lông, … các tính năng này sẽ được mã hóa thành các vector danh mục."
5154,E:\DATN\dataframe\train_file\62.txt,"Zero-shot cũng bao gồm 2 giai đoạn, tuy nhiên có hơi khác một chút:"
5155,E:\DATN\dataframe\train_file\62.txt,Training: Huấn luyện mô hình với các thuộc tính đã biết
5156,E:\DATN\dataframe\train_file\62.txt,Inference: Mô hình sau khi huấn luyện được sử dụng để phân loại các cá thể trong một tập hợp các lớp mới
5157,E:\DATN\dataframe\train_file\62.txt,Cách thức hoạt động của Zero-shot learning
5158,E:\DATN\dataframe\train_file\62.txt,Có 2 cách tiếp cận phổ biến được sử dụng các vấn đề về các bài toán nhận dạng ảnh
5159,E:\DATN\dataframe\train_file\62.txt,Tiếp cận dựa trên nhúng
5160,E:\DATN\dataframe\train_file\62.txt,"Mục tiêu chính là ánh xạ các đặc điểm, danh mục, các thuộc tính ngữ nghĩa vào 1 không gian nhúng bằng một hàm ánh xạ y=f(x), trong đó hàm này sẽ được học."
5161,E:\DATN\dataframe\train_file\62.txt,Cùng tìm hiểu cách thức hoạt động của phương pháp này thông qua hình vẽ trên nhé Đối với quá trình Training:
5162,E:\DATN\dataframe\train_file\62.txt,"Các thuộc tính, danh mục sẽ được vector hóa để làm nhãn cũng như thuật tiện cho việc mô hình so sánh với dự đoán để điều chỉnh lại mô hình."
5163,E:\DATN\dataframe\train_file\62.txt,"Giả sử có các danh mục như: 4 chân, có đuôi, ăn cá, giả sử dùng kỹ thuật encoding đơn giản nhất đó là thuộc tính nào positive thì để là 1, negative để là 0 thì ta sẽ có attribute vector đối với con chim là [0,1, 1]."
5164,E:\DATN\dataframe\train_file\62.txt,"Đây là mình chỉ ví dụ vì có rất nhiều cách khác nhau encoding các thuộc tính, tuy nhiên bài viết gốc thì lại lấy vị dụ về văn bản, dễ dàng hơn."
5165,E:\DATN\dataframe\train_file\62.txt,Đối với mỗi bức ảnh đầu vào sẽ được đưa qua một mạng Deep Neural network để trích xuất ra vector đặc trưng của ảnh.
5166,E:\DATN\dataframe\train_file\62.txt,Giả sử vector đặc trưng này có số chiều là N. Trong khi dữ liệu có D thuộc tính cần quan tâm.
5167,E:\DATN\dataframe\train_file\62.txt,"Lúc này ta sẽ sử dụng một mạng ANN bao gồm các lớp Fully connected để giảm số chiều từ N xuống D, đồng thời tính toán vector biểu thị ra xác suất của các đặc trưng (có số chiều D)."
5168,E:\DATN\dataframe\train_file\62.txt,Đầu ra của mô hình sẽ được so sánh với vector thuộc tính đã nêu trên bằng 1 hàm Loss để điều chỉnh mô hình sao cho bức ảnh đầu vào trả ra đặc tính sát nhất với đặc tính đúng của nó.
5169,E:\DATN\dataframe\train_file\62.txt,Đối với quá trình Inferences:
5170,E:\DATN\dataframe\train_file\62.txt,"Khi mô hình đã học được việc trả ra các đặc trưng, danh mục của ảnh đầu vào, khi đưa một bức ảnh mới chưa có trong các nhóm quan sát được vào, mô hình sẽ trả ra các đặc trưng ngữ nghĩa của bức ảnh đó dưới dạng vector (Đó là lý do tại sao gọi là tiếp cận dựa trên nhúng)."
5171,E:\DATN\dataframe\train_file\62.txt,"Lại ví dụ với với con ngựa cho dễ hiểu nhé :v, giả sử có các đặc trưng như sau: 4 chân, ăn cá, ăn cỏ, có vằn, có đuôi, giả sử vector thuộc tính của con ngựa sẽ là [1, 0, 1, 0, 1]."
5172,E:\DATN\dataframe\train_file\62.txt,"Với giả sử mô hình đủ tốt để nhận diện ra các đặc tính cảu bức ảnh, ta đưa đầu vào là bức ảnh con ngựa vằn vào, mô hình trả ra cho ta vector thuộc tính dạng như con ngựa nhưng ở thuộc tính có vằn thì lại có trong khi con ngựa thì không."
5173,E:\DATN\dataframe\train_file\62.txt,"Chính việc tạo ra các vector thuộc tính này sẽ giúp chúng ta trong việc truy vấn về sau, kiểu như mô hình mình chỉ nhận dạng được con ngựa, tuy nhiên mình chỉ cần tìm các hình ảnh nào dự đoán là con ngựa và có thêm thuộc tính có vằn thì đó sẽ là con ngựa vằn =))"
5174,E:\DATN\dataframe\train_file\62.txt,Đơn giản phải không nào?
5175,E:\DATN\dataframe\train_file\62.txt,Tuy nhiên hạn chế cựa phương pháp này là hiện tượng thiên vị và dịch chuyển miền.
5176,E:\DATN\dataframe\train_file\62.txt,"Tức là việc học này chỉ dựa trên những gì mô hình nhìn thấy (Giả sử có những ảnh ngựa nó không ăn cỏ mà nó đang phi trên bờ biển chẳng hạn thì đặc tính ăn cỏ sẽ bị lu mờ do mô hình không nhận thấy), do vậy mô hình sẽ thiên về phía các đặc tính nhìn thấy được trong dữ liệu."
5177,E:\DATN\dataframe\train_file\62.txt,"Để khắc phục được yếu điểm này, mợi các bạn đọc tiếp cách tiếp cận thứ 2"
5178,E:\DATN\dataframe\train_file\62.txt,Tiếp cận dựa trên mô hình sinh
5179,E:\DATN\dataframe\train_file\62.txt,"Trước tiên, chúng ta cùng tìm hiểu pipeline của cách tiếp cận này."
5180,E:\DATN\dataframe\train_file\62.txt,"Nhìn vào hình vẽ, trước hết , ảnh đầu vào vẫn được trích xuất ra vector đặc trưng thông qua một mạng DNN như ở cách tiếp cận nhúng."
5181,E:\DATN\dataframe\train_file\62.txt,"Còn về phía vector thuộc tính, thay vì được đối chiếu trực tiếp với đặc trưng của ảnh đầu vào, chúng sẽ được đưa vào một mô hình sinh (Generative Model)."
5182,E:\DATN\dataframe\train_file\62.txt,"Đảo qua một chút kiến thức cơ bản về mạng GAN (Generative Adversarial Networks), GAN cấu tạo gồm 2 mạng là Generator và Discriminator."
5183,E:\DATN\dataframe\train_file\62.txt,Trong khi Generator sinh ra các dữ liệu giống như thật thì Discriminator cố gắng phân biệt đâu là dữ liệu được sinh ra từ Generator và đâu là dữ liệu thật (Nghĩa là coi dữ liệu sinh ra từ Generator là dữ liệu giả).
5184,E:\DATN\dataframe\train_file\62.txt,"Quay lại kiến trúc mô hình bên trên, Vector thuộc tính thay vị được so sánh trực tiếp với vector đặc trưng thì chúng được đưa qua khối Generator để điều chỉnh vector thuộc tính sao cho giống với vector đặc trưng nhất có thể."
5185,E:\DATN\dataframe\train_file\62.txt,"Như vậy, khác với cách tiếp cận ban đầu, thay vì cố gắng biến đổi vector đặc trưng sao cho sát nhất với vector thuộc tính, ở cách tiếp cận này, cả 2 vector đều phải biến đổi sao cho giống nhau, khó phân biệt."
5186,E:\DATN\dataframe\train_file\62.txt,"Chắc hẳn sẽ có 1 số bạn giống mình, đến đây chưa hiểu cái kiến trúc trên lắm."
5187,E:\DATN\dataframe\train_file\62.txt,Vậy các bạn cùng tìm hiểu lại về mạng GAN nhé.
5188,E:\DATN\dataframe\train_file\62.txt,Còn để mình nói đơn giản thế này cho dễ hiểu 2 khối Generator và Discriminator này hoạt động như thế nào.
5189,E:\DATN\dataframe\train_file\62.txt,"Trong khi khối Generator cố gắng học ông Fake cho giống ông Real, thì ông Discriminator cố gắng phân biệt ông Real với ông Fake."
5190,E:\DATN\dataframe\train_file\62.txt,"2 ông này học kiểu ngược nhau, và mục tiêu là ông Generator phải thắng, qua mặt được ông Discriminator."
5191,E:\DATN\dataframe\train_file\62.txt,"Sau khi mô hình sinh đã được huấn luyện, lúc này trong quá trình Inference, Ảnh đầu vào sẽ dược đưa vào mô hình, đi kèm với đó là các lớp nhìn thấy (có trong dataset train) và các lớp không nhìn thấy (mới) được đưa vào khối Generator, tiếp tục sử dụng khối Discriminative để phân biệt, trong đó việc phân biệt vector đặc trưng với đầu ra của khối Generator của thuộc tính nhìn thấy được phân biệt với trọng số cao hơn so với thuộc tính không nhìn thấy."
5192,E:\DATN\dataframe\train_file\62.txt,"Đơn giản vì với dữ liệu mới, nguyên lý là chủ yếu dựa trên các thuộc tính nhìn thấy, còn các thuộc tính mới là bổ sung nên trọng số phụ thuộc sẽ thấp hơn."
5193,E:\DATN\dataframe\train_file\62.txt,"Cuối cùng trả ra Classification score, từ đó có thể trả ra các kết quả mong muốn."
5194,E:\DATN\dataframe\train_file\62.txt,"Theo bài viết gốc còn phần đánh giá cho phương pháp Zẻo-shot learning nữa nhưng cá nhân mình thấy tương đối sơ sài, vì vậy chưa đưa vào bài viết của mình, đồng thời mình thấy bài viết cũng đã tương đối nhiều chữ."
5195,E:\DATN\dataframe\train_file\62.txt,Trên đây là những kiến thức mình tham khảo đồng thời kết hợp việc tìm hiểu của mình để diễn giải cho dễ hiểu hơn.
5196,E:\DATN\dataframe\train_file\62.txt,"Mình thấy đây là một chủ đề tương đối hay, ngoài ra còn có phương pháp Few-shot learning, mình sẽ trình bày vào các bài viết sau."
5197,E:\DATN\dataframe\train_file\62.txt,Cảm ơn các bạn đã đọc đến cuối cùng.
5198,E:\DATN\dataframe\train_file\62.txt,Mong mọi người ủng hộ để mình có động lực chia sẻ nhiều hơn.
5199,E:\DATN\dataframe\train_file\62.txt,"[1] Chauhan, N. S. (2021)."
5200,E:\DATN\dataframe\train_file\62.txt,Zero-Shot Learning: Can you classify an object without seeing it before?
5201,E:\DATN\dataframe\train_file\62.txt,"[2] N. (2021, February 16)."
5202,E:\DATN\dataframe\train_file\62.txt,Bài 1: Giới thiệu về GAN.
5203,E:\DATN\dataframe\train_file\62.txt,Deep Learning Cơ Bản.
5204,E:\DATN\dataframe\train_file\62.txt,"[3] Sinha, S. (2018, June 18)."
5205,E:\DATN\dataframe\train_file\62.txt,What Is Zero-Shot Learning?
5206,E:\DATN\dataframe\train_file\62.txt,Analytics India Magazine.
5207,E:\DATN\dataframe\train_file\62.txt,"[4] Xian, Y."
5208,E:\DATN\dataframe\train_file\62.txt,"(2017, July 3)."
5209,E:\DATN\dataframe\train_file\62.txt,"Zero-Shot Learning -- A Comprehensive Evaluation of the Good, the."
5210,E:\DATN\dataframe\train_file\63.txt,Learning rate - Những điều có thể bạn đã bỏ qua
5211,E:\DATN\dataframe\train_file\63.txt,Ngồi chơi lượn lờ Facebook một hồi tự dưng đập vào mắt 1 bài viết về Learning rate của page  khiến mình tò mò đọc thử.
5212,E:\DATN\dataframe\train_file\63.txt,"Thử kiểu gì mà đọc hết sạch, lại thấy tương đối hay và muốn chia sẻ cho mọi người cũng như lưu giữ lại cho cá nhân."
5213,E:\DATN\dataframe\train_file\63.txt,"Bài viết của mình dựa trên các kiến thức của các tác giả và một chút kinh nghiệm cá nhân, mong các bạn đón đọc và đừng hiểu lầm, trách mình đi copy paste, tội mình lắm"
5214,E:\DATN\dataframe\train_file\63.txt,"Không dài dòng nữa, chúng ta cùng đi sâu vào tìm hiểu về Learning rate, tầm quan trọng và một vài cách điều chỉnh của nó ở thời điểm hiện tại nhé!"
5215,E:\DATN\dataframe\train_file\63.txt,Model hyperparameter (siêu tham số mô hình) là một cấu hình nằm ngoài mô hình và giá trị của nó không thể được ước tính từ dữ liệu (không phụ thuộc vào tập dữ liệu huấn luyện).
5216,E:\DATN\dataframe\train_file\63.txt,Nôm na dễ hiểu hơn:
5217,E:\DATN\dataframe\train_file\63.txt,Chúng thường được sử dụng trong các quy trình để giúp ước tính các tham số của mô hình
5218,E:\DATN\dataframe\train_file\63.txt,Chúng thường được lựa chọn thủ công bởi người tham gia vào quá trình huấn luyện mô hình
5219,E:\DATN\dataframe\train_file\63.txt,Nó có thể được định nghĩa bởi một vài chiến lược heuristics
5220,E:\DATN\dataframe\train_file\63.txt,"Các bạn có thể sẽ bị nhầm lẫn giữa 2 khái niệm Model Parameters và Model hyperparameters, vì vậy mình khuyên các bạn nên dành chút thời gian đọc qua sự khác nhau giữa 2 khái niệm này, có thể google search hoặc xem tại  của anh Phạm Văn Toàn"
5221,E:\DATN\dataframe\train_file\63.txt,"Đối với Model hyperparameters, chúng ta không thể đoán được đâu là giá trị tốt nhất cho các bài toán cụ thể."
5222,E:\DATN\dataframe\train_file\63.txt,"Bởi vậy chỉ có thể sử dụng các quy tắc chung, các kỹ thuật ước lượng hoặc các thử nghiệm thực tế"
5223,E:\DATN\dataframe\train_file\63.txt,Một vài ví dụ về model hyperparameter mà các bạn đã từng ít nhất 1 lần bắt gặp
5224,E:\DATN\dataframe\train_file\63.txt,Learning rate
5225,E:\DATN\dataframe\train_file\63.txt,Tham số k trong k-nearest neighbors
5226,E:\DATN\dataframe\train_file\63.txt,Tham số C và sigma khi training Suport Vector Machine (SVM)
5227,E:\DATN\dataframe\train_file\63.txt,Learning rate là gì?
5228,E:\DATN\dataframe\train_file\63.txt,Learning rate là một trong số những siêu tham số quan trọng nhất của mô hình.
5229,E:\DATN\dataframe\train_file\63.txt,"Có thể sẽ có các siêu tham số các bạn chưa nghe bao giờ hoặc chưa dùng bao giờ, nhưng learning rate, batch size, epochs, … là các tham số các bạn bắt gặp hầu như trong hầu hết các bài toán Deep Learning trong quá trình huấn luyện."
5230,E:\DATN\dataframe\train_file\63.txt,Learning rate được hiểu là một phần tỷ lệ của một bước dịch chuyển trọng số mô hình được cập nhật theo các mini-batch truyền vào.
5231,E:\DATN\dataframe\train_file\63.txt,Độ lớn của learning rate sẽ ảnh hưởng trực tiếp tới tốc độ hội tụ của hàm loss tới điểm cực trị toàn cục.
5232,E:\DATN\dataframe\train_file\63.txt,Cùng mình hiểu rõ hơn tầm ảnh hưởng của Learning rate qua hình vẽ dưới đây
5233,E:\DATN\dataframe\train_file\63.txt,"Ở hình bên trái, với trường hợp Learning rate quá nhỏ dẫn đến các cập nhật đối với trọng số là nhỏ, điều này sẽ giúp tìm tới điểm cực tiểu được chuẩn xác hơn vì bước nhảy là rất nhỏ."
5234,E:\DATN\dataframe\train_file\63.txt,"Tuy nhiên điều này sẽ khiến mất rất nhiều thời gian để hội tụ, hoặc nếu các bạn biết tới khái niệm cực tiểu cục bộ, thì với learning rate quá nhỏ này có thể dẫn tới việc bị kẹt trong cực tiểu cục bộ không mong muốn"
5235,E:\DATN\dataframe\train_file\63.txt,"Trái với hình bên trái, hãy nhìn hình bên phải với trường hợp Learning rate quá lớn, thuật toán sẽ học nhanh, nhưng có thể thấy thuật toán bị dao động xung quanh hoặc thậm chí nhảy qua điểm cực tiểu."
5236,E:\DATN\dataframe\train_file\63.txt,"Sau cùng, hình ở giữa là việc chọn Learning rate phù hợp, nó sẽ hài hòa được giữa tốc độ hội tụ của thuật toán cũng như việc tìm ra điểm cực tiểu."
5237,E:\DATN\dataframe\train_file\63.txt,"Không quá nhỏ cũng không quá lớn, đúng là cái gì quá cũng không tốt =)))"
5238,E:\DATN\dataframe\train_file\63.txt,"Lý thuyết là thế, tuy nhiên mỗi bài toán cụ thể sẽ có các cách khác nhau để tìm ra Learning rate phù hợp"
5239,E:\DATN\dataframe\train_file\63.txt,Phương pháp tìm kiếm với Learning rate
5240,E:\DATN\dataframe\train_file\63.txt,Tìm kiếm từ thô tới tinh
5241,E:\DATN\dataframe\train_file\63.txt,Ý tưởng của phương pháp này là lựa chọn ngẫu nhiên trong một không gian siêu tham số và tìm ra một miền mà tại đó tập trung các giá trị của siêu tham số khiến cho loss function thấp.
5242,E:\DATN\dataframe\train_file\63.txt,Tiếp tục lặp lại quá trình trên đối với vùng nhỏ vừa tìm được để tìm ra vùng nhỏ hơn
5243,E:\DATN\dataframe\train_file\63.txt,Tìm kiếm trên không gian scale logarithm
5244,E:\DATN\dataframe\train_file\63.txt,"Khi sử dụng phân phối đều trên khoảng [0, 1] để lựa chọn ngẫu nhiên learning rate, 10% sẽ rơi vào [0, 0.1] và 90% sẽ rơi vào [0.1, 1], nhưng trên thực tế, learning rate gần như không bao giờ rơi vào [0.1, 1]."
5245,E:\DATN\dataframe\train_file\63.txt,Learning rate bởi vậy thông thường không tuân theo phân bố đều.
5246,E:\DATN\dataframe\train_file\63.txt,"Do đó, ý tưởng của phương pháp là lấy logarithm cơ số 10 của learning rate và thực hiện tìm kiếm trên miền không gian lúc này, chẳng hạn chọn [-5, 0], thì lúc này learning rate phân bố đều trên các miền giá trị nhỏ [0.00001, 0.0001], [0.0001, 0.001], [0.001, 0.01], [0.01, 0.1], [0.1, 1]"
5247,E:\DATN\dataframe\train_file\63.txt,Tuning learning rate theo loss function
5248,E:\DATN\dataframe\train_file\63.txt,Ý tưởng của phương pháp là tăng dần learning rate theo batch iteration và theo dõi loss function trên từng batch iteration.
5249,E:\DATN\dataframe\train_file\63.txt,Có 3 trường hợp xảy ra:
5250,E:\DATN\dataframe\train_file\63.txt,Những vị trí mà learning rate nhỏ sẽ khiến cho đường biểu diễn giá loss gần như nằm ngang
5251,E:\DATN\dataframe\train_file\63.txt,Những vị trí có learning rate phù hợp sẽ biểu thị đường biểu diễn giá trị loss đi xuống cho thấy loss function đang hội tụ dần
5252,E:\DATN\dataframe\train_file\63.txt,"Những vị trí có learning rate cao sẽ khiến cho hàm loss biến đổi thất thường, tăng, giảm hoặc dao động ngẫu nhiên như hình dưới"
5253,E:\DATN\dataframe\train_file\63.txt,Khi đó ta sẽ lấy learning rate ở điểm chính giữa đường hạ dốc của loss function (điểm màu đỏ như hình dưới)
5254,E:\DATN\dataframe\train_file\63.txt,Vấn đề Plateus
5255,E:\DATN\dataframe\train_file\63.txt,Plateaus là hiện tượng miền giá trị của hàm loss function rơi vào một vùng mặt phẳng có đạo hàm gần bằng 0 và đồ thị của loss function đường như nằm trên một mặt phẳng nằm ngang có độ lớn không đổi.
5256,E:\DATN\dataframe\train_file\63.txt,Một trong những nguyên nhân quen thuộc đó chính là mô hình bị nghẽn ở điểm cực tiểu cục bộ (chấm đỏ ở hình dưới).
5257,E:\DATN\dataframe\train_file\63.txt,Mặc dù là điểm cực tiểu nhưng không phải là vị trí ta mong muốn cho mô hình tốt nhất (cực tiểu toàn cục)
5258,E:\DATN\dataframe\train_file\63.txt,Đối với vấn đề này có thể sử dụng những thuật toán như momentum hay adam để vượt qua vùng Plateus dễ dàng.
5259,E:\DATN\dataframe\train_file\63.txt,"Momentum có thể hiểu như bạn truyền cho con lắc một vận tốc ban đầu, từ đó nó có thêm động lực để vượt qua được cực tiểu cục bộ"
5260,E:\DATN\dataframe\train_file\63.txt,Sử dụng Learning rate decay
5261,E:\DATN\dataframe\train_file\63.txt,Learning rate decay là hệ số giúp triệt tiêu độ lớn của learning rate theo thời gian huấn luyện nhằm tránh giá trị của chúng quá cao ở những giai đoạn trọng số mô hình đã đi vào hội tụ.
5262,E:\DATN\dataframe\train_file\63.txt,"Càng về các epochs sau, khi mô hình tương đối gần điểm cực tiểu, bạn sẽ quan sát thấy giá trị loss function gần như không đổi hoặc thay đổi rất nhỏ, lúc này việc sử dụng learning rate decay là rất cần thiết, 1 mặt tránh cho việc bị nhảy qua điểm cực trị, 1 mặt khi giảm learning rate, loss function sẽ hội tụ tốt hơn."
5263,E:\DATN\dataframe\train_file\63.txt,Một số phương pháp decay:
5264,E:\DATN\dataframe\train_file\63.txt,Linear learning rate decay: lr = lr/(1+decay_rate*epoch_num)
5265,E:\DATN\dataframe\train_file\63.txt,Exponential learning rate decay: lr = 0.99^epoch_num*lr
5266,E:\DATN\dataframe\train_file\63.txt,Các công thức khác:
5267,E:\DATN\dataframe\train_file\63.txt,r = k/sqrt(epoch_num) * lr
5268,E:\DATN\dataframe\train_file\63.txt,lr = k/sqrt(mini_batch_num)*lr
5269,E:\DATN\dataframe\train_file\63.txt,lr = lr*
5270,E:\DATN\dataframe\train_file\63.txt,−1
5271,E:\DATN\dataframe\train_file\63.txt, (kể từ epoch thứ n) (Đây là công thức mình dùng gần nhất cho một paper môn tin sinh học)
5272,E:\DATN\dataframe\train_file\63.txt,"Hiện tại learning rate decay được tích hợp kèm các module schedule learning rate như: ReduceLROnPlateau, ExponentialLR, LinearLR trên pytorch, bạn đọc có thể xem thêm"
5273,E:\DATN\dataframe\train_file\63.txt,"Ngoài ra trên tensorflow cũng hỗ trợ với module LearningRateScheduler, bạn đọc có thể tham khảo tại"
5274,E:\DATN\dataframe\train_file\63.txt,"Ngoài ra còn một số chiến lược huấn luyện Learning rate, tuy nhiên mình chưa có thời gian tìm hiểu kỹ nên cũng chưa chia sẻ được thêm."
5275,E:\DATN\dataframe\train_file\63.txt,Thời gian tới mình sẽ cố gắng chăm chỉ hơn để có thể cùng chia sẻ với các bạn và cả với bản thân những kiến thức mới.
5276,E:\DATN\dataframe\train_file\63.txt,Mong rằng bài viết của mình sẽ giúp các bạn hiểu hơn vể Learning rate cũng như phần nào vận dụng được sức mạnh của nó trong việc huấn luyện mô hình của mình.
5277,E:\DATN\dataframe\train_file\63.txt,"Thật sự là trước đó mình chỉ biết fix cứng Learning rate theo paper hoặc theo số đông thôi (0.001, 0.01)."
5278,E:\DATN\dataframe\train_file\63.txt,"[1] Barreto, S. (2021, November 26)."
5279,E:\DATN\dataframe\train_file\63.txt,Choosing a Learning Rate.
5280,E:\DATN\dataframe\train_file\63.txt,Baeldung on Computer Science.
5281,E:\DATN\dataframe\train_file\63.txt,"[2] Lau, S. (2018, June 20)."
5282,E:\DATN\dataframe\train_file\63.txt,Learning Rate Schedules and Adaptive Learning Rate Methods for Deep Learning.
5283,E:\DATN\dataframe\train_file\63.txt,"[3] Lendave, V. (2021, September 17)."
5284,E:\DATN\dataframe\train_file\63.txt,What is the Plateau Problem in Neural Networks and How to Fix it?
5285,E:\DATN\dataframe\train_file\63.txt,Analytics India Magazine.
5286,E:\DATN\dataframe\train_file\63.txt,"[4] Li, K. (2021, October 13)."
5287,E:\DATN\dataframe\train_file\63.txt,How to Choose a Learning Rate Scheduler for Neural Networks.
5288,E:\DATN\dataframe\train_file\63.txt,"[5] Surmenok, P. (2021, April 19)."
5289,E:\DATN\dataframe\train_file\63.txt,Estimating an Optimal Learning Rate For a Deep Neural Network.
5290,E:\DATN\dataframe\train_file\64.txt,Đoán trọng âm tiếng Anh với machine learning - Tại sao không?
5291,E:\DATN\dataframe\train_file\64.txt,"Chào các bạn, không biết hồi trước khi học tiếng Anh các bạn có từng ""phát điên lên"" với bài trọng âm không?"
5292,E:\DATN\dataframe\train_file\64.txt,"Mình thì có, tuy ở trường có được học một số quy tắc đánh trọng âm, nhưng đau lòng thay, tiếng Anh, như mọi loại ngôn ngữ khác, luôn luôn có ngoại lệ."
5293,E:\DATN\dataframe\train_file\64.txt,"Tính mình thì không thích những thứ không suy ra được bằng logic nên tuy yêu thương môn tiếng Anh thắm thiết nhưng khi ôn thi đại học gần như mình luôn liệt bài trọng âm vào dạng ""câu 10 điểm"" và không bao giờ cố để làm những câu này cả."
5294,E:\DATN\dataframe\train_file\64.txt,"Hôm trước khi ngồi dạy thêm cho đứa em thì mình bỗng ngồi nghĩ là, liệu các quy tắc trọng âm trong tiếng Anh có phải là thứ mà một model machine learning có thể học được hay không?"
5295,E:\DATN\dataframe\train_file\64.txt,Vậy thì chúng mình cùng tìm hiểu qua bài viết này nhé!
5296,E:\DATN\dataframe\train_file\64.txt,Vì đang học tensorflow nên trong bài này mình sẽ sử dụng các thư viện của tensorflow để thử xem.
5297,E:\DATN\dataframe\train_file\64.txt,Trong bài này mình sử dụng bộ data The CMU Pronouncing Dictionary của Carnegie Mellon University.
5298,E:\DATN\dataframe\train_file\64.txt,"Đây là một bộ từ điển phát âm cho tiếng Anh Mỹ, bao gồm trên 134,000 từ và phát âm của chúng theo ARPAbet phoneme set, thường được sử dụng cho nhận diện và tổng hợp giọng nói (speech recognition and synthesis)."
5299,E:\DATN\dataframe\train_file\64.txt,Dưới đây một số ví dụ về cách phiên âm của CMU Pronouncing Dictionary
5300,E:\DATN\dataframe\train_file\64.txt,ACCOUNT  => AH0 K AW1 N T
5301,E:\DATN\dataframe\train_file\64.txt,LIQUIDITY  => L IH0 K W IH1 D AH0 T IY0
5302,E:\DATN\dataframe\train_file\64.txt,TELESCOPE  => T EH1 L AH0 S K OW2 P
5303,E:\DATN\dataframe\train_file\64.txt,Như vậy qua cách phiên âm của 1 từ chúng ta sẽ biết được số âm tiết của từ đó (qua số nguyên âm) và trọng âm của từ nằm ở đâu (những nguyên âm được đánh số 1 đằng sau - primary stress)
5304,E:\DATN\dataframe\train_file\64.txt,"vowels = ['AA ', 'AE ', 'AH ', 'AO ', 'AW ', 'AY ', 'EH ', 'ER ', 'EY ', 'IH ', 'IY ', 'OW ', 'OY ', 'UH ', 'UW ']"
5305,E:\DATN\dataframe\train_file\64.txt,Chi tiết các bạn có thể tham khảo thêm tại link:
5306,E:\DATN\dataframe\train_file\64.txt,Như vậy đầu vào trong mô hình của mình sẽ là một từ bất kỳ trong tiếng Anh và output là trọng âm của từ nằm ở âm tiết thứ mấy.
5307,E:\DATN\dataframe\train_file\64.txt,Do không tìm được bộ data nào khác nên model của mình sẽ chỉ học trên thứ tự sắp xếp các chữ cái của từ thôi thay vì cả từ loại như ngày xưa chúng mình học theo quy tắc đánh trọng âm.
5308,E:\DATN\dataframe\train_file\64.txt,Chuẩn bị dataset
5309,E:\DATN\dataframe\train_file\64.txt,Trong bài này mình sẽ sử dụng tf.data - một API của tensorlfow dùng để xây dựng một input pipepline cho model machine learning.
5310,E:\DATN\dataframe\train_file\64.txt,"tf.data giúp hỗ trợ xử lý lượng lớn dữ liệu, đọc dữ liệu từ các data formats khác nhau và thực hiện các bước chuyển đổi (transform) dữ liệu phức tạp."
5311,E:\DATN\dataframe\train_file\64.txt,"API này bao gồm một abstraction là tf.data.Dataset đại diện cho một chuỗi các phần tử, thường là mỗi phần tử tương ứng với một training example ~ một cặp tensor: input - label."
5312,E:\DATN\dataframe\train_file\64.txt,"Điểm tiện lợi hơn nữa là từ tensorflow 2.0, chúng ta có thể trực tiếp dùng tf.data.Dataset như một input khi dùng model.fit trong Keras."
5313,E:\DATN\dataframe\train_file\64.txt,Argument của method fit trong tf.keras.Model
5314,E:\DATN\dataframe\train_file\64.txt,"Input của mình được đọc từ file text, ngoài ra có thể tạo dataset từ một list python (tf.data.Dataset.from_tensor_slices), từ các bản ghi dưới dạng TFRecord (tf.data.TFRecordDataset), hoặc từ một list file (tf.data.Dataset.list_files)"
5315,E:\DATN\dataframe\train_file\64.txt,"dataset = tf.data.TextLineDataset([""/content/drive/My Drive/eng.txt""])"
5316,E:\DATN\dataframe\train_file\64.txt,Mỗi phần tử trong dataset của mình là một string tensor có dạng như sau:
5317,E:\DATN\dataframe\train_file\64.txt,"> tf.Tensor(b'ABANDON  AH0 B AE1 N D AH0 N', shape=(), dtype=string)"
5318,E:\DATN\dataframe\train_file\64.txt,"Để có thể pass dataset này vào trong model.fit, mình cần biến đổi mỗi phần tử trong dataset về dạng tuple gồm một cặp (input, target)."
5319,E:\DATN\dataframe\train_file\64.txt,"> ('ABANDON', 2)"
5320,E:\DATN\dataframe\train_file\64.txt,Rất may là tf.data API có cung cấp rất nhiều method giúp mình làm điều này.
5321,E:\DATN\dataframe\train_file\64.txt,"Để cho đơn giản, trước hết mình sẽ lọc bớt các từ có chứa các ký tự đặc biệt ví dụ như dấu nháy, gạch ngang, vv."
5322,E:\DATN\dataframe\train_file\64.txt,Chúng ta có thể dùng dataset.filter(predicate) với predicate là một function nhằm map một phần tử trong dataset với một kết quả True hoặc False.
5323,E:\DATN\dataframe\train_file\64.txt,Ví dụ muốn lọc các phần tử nhỏ hơn 3 trong dataset ta có thể làm như sau:
5324,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.filter(lambda x: x < 3)
5325,E:\DATN\dataframe\train_file\64.txt,def filter_fn(x):
5326,E:\DATN\dataframe\train_file\64.txt,"  return tf.math.equal(x, 1)"
5327,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.filter(filter_fn)
5328,E:\DATN\dataframe\train_file\64.txt,"Tuy nhiên do hàm filter_fn của mình có sử dụng những biểu thức, hàm mà không phải là một Tensorflow operation nên mình không thể trực tiếp truyền vào như trên mà phải thông qua một hàm tf.py_function nữa nhằm ""đóng gói"" function Python thành một Tensorflow operation để tính toán trên TensorFlow graph."
5329,E:\DATN\dataframe\train_file\64.txt,# filter: elminate lines that contain special characters
5330,E:\DATN\dataframe\train_file\64.txt,def filter_fn(x):
5331,E:\DATN\dataframe\train_file\64.txt,  s = x.numpy().decode('utf-8')
5332,E:\DATN\dataframe\train_file\64.txt,  pos = s.find(' ')
5333,E:\DATN\dataframe\train_file\64.txt,  s1 = s[0:pos]
5334,E:\DATN\dataframe\train_file\64.txt,"  return re.match(""^[A-Z]+$"", s1) != None # => trả ra True nếu trong từ tiếng Anh không có ký tự đặc biệt"
5335,E:\DATN\dataframe\train_file\64.txt,def tf_filter(x):
5336,E:\DATN\dataframe\train_file\64.txt,"  return tf.py_function(filter_fn, [x], tf.bool) # => áp dụng hàm filter_fn lên một list Tensor object, kết quả trả về là tf.bool"
5337,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.filter(tf_filter)
5338,E:\DATN\dataframe\train_file\64.txt,Tiếp theo mình sẽ thực hiện tách string ban đầu lấy từ file ra thành một tuple gồm 1 từ tiếng Anh và trọng âm tương ứng của nó dùng method map.
5339,E:\DATN\dataframe\train_file\64.txt,"Tương tự như filter , method này sẽ apply hàm map_fn vào từng phần tử trong dataset, và trả về một dataset mới bao gồm các phần tử đã được transform theo đúng thứ tự."
5340,E:\DATN\dataframe\train_file\64.txt,map_fn có thể dùng để thay đổi cả value cũng như cấu trúc của một phần tử trong dataset.
5341,E:\DATN\dataframe\train_file\64.txt,# map1: return a tuple of input word as a string and its corresponding stress
5342,E:\DATN\dataframe\train_file\64.txt,"vowels = ['AA ', 'AE ', 'AH ', 'AO ', 'AW ', 'AY ', 'EH ', 'ER ', 'EY ', 'IH ', 'IY ', 'OW ', 'OY ', 'UH ', 'UW ', 'AA0', 'AE0', 'AH0', 'AO0', 'AW0', 'AY0', 'EH0', 'ER0', 'EY0', 'IH0', 'IY0', 'OW0', 'OY0', 'UH0', 'UW0', 'AA1', 'AE1', 'AH1', 'AO1', 'AW1', 'AY1', 'EH1', 'ER1', 'EY1', 'IH1', 'IY1', 'OW1', 'OY1', 'UH1', 'UW1', 'AA2', 'AE2', 'AH2', 'AO2', 'AW2', 'AY2', 'EH2', 'ER2', 'EY2', 'IH2', 'IY2', 'OW2', 'OY2', 'UH2', 'UW2']"
5343,E:\DATN\dataframe\train_file\64.txt,"vowels_with_stress = ['AA1', 'AE1', 'AH1', 'AO1', 'AW1', 'AY1', 'EH1', 'ER1', 'EY1', 'IH1', 'IY1', 'OW1', 'OY1', 'UH1', 'UW1']"
5344,E:\DATN\dataframe\train_file\64.txt,def map_fn(x):
5345,E:\DATN\dataframe\train_file\64.txt,  s = x.numpy().decode('utf-8')
5346,E:\DATN\dataframe\train_file\64.txt,  pos = s.find(' ')
5347,E:\DATN\dataframe\train_file\64.txt,  s1 = s[0:pos]
5348,E:\DATN\dataframe\train_file\64.txt,  s2 = s[pos+2: len(s)]
5349,E:\DATN\dataframe\train_file\64.txt,  l = len(s2)
5350,E:\DATN\dataframe\train_file\64.txt,"  for j in range(0,l-2):"
5351,E:\DATN\dataframe\train_file\64.txt,"      for k in range(2,l):"
5352,E:\DATN\dataframe\train_file\64.txt,          s3 = s2[j:k+1]
5353,E:\DATN\dataframe\train_file\64.txt,          if s3 in vowels_with_stress:
5354,E:\DATN\dataframe\train_file\64.txt,              mark += 'S'
5355,E:\DATN\dataframe\train_file\64.txt,          elif s3 in vowels:
5356,E:\DATN\dataframe\train_file\64.txt,              mark += 's'
5357,E:\DATN\dataframe\train_file\64.txt,  stress = mark.find('S') + 1
5358,E:\DATN\dataframe\train_file\64.txt,"  return (s1, stress)"
5359,E:\DATN\dataframe\train_file\64.txt,def tf_map(x):
5360,E:\DATN\dataframe\train_file\64.txt,"  return tf.py_function(map_fn, [x], (tf.string, tf.int64))"
5361,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.map(tf_map)
5362,E:\DATN\dataframe\train_file\64.txt,"Kết quả, phần tử mới được transform có dạng như sau:"
5363,E:\DATN\dataframe\train_file\64.txt,"> (<tf.Tensor: shape=(), dtype=string, numpy=b'ABANDON'>, <tf.Tensor: shape=(), dtype=int64, numpy=2>)"
5364,E:\DATN\dataframe\train_file\64.txt,>> Từ:  ABANDON; trọng âm nằm ở âm tiết thứ 2
5365,E:\DATN\dataframe\train_file\64.txt,"Tiếp theo, để thực hiện encode input và xây dựng output layer cho mô hình, mình cần phải tìm xem từ dài nhất có trong bộ từ điển là từ nào và có tất cả bao nhiêu trọng âm."
5366,E:\DATN\dataframe\train_file\64.txt,Do vậy mình sẽ phải duyệt qua tất cả các phần tử trong dataset một lượt dù thủ tục này khá tốn thời gian.
5367,E:\DATN\dataframe\train_file\64.txt,"Nhân tiện mình cũng sẽ ""tranh thủ"" đếm luôn số phần tử có trong dataset do tf.data.TextLineDataset sẽ trả về unknown shape, tức là chỉ khi toàn bộ dataset được chạy qua hết một lần, chúng ta mới biết được nó có bao nhiêu phần tử."
5368,E:\DATN\dataframe\train_file\64.txt,"# calculate total length of dataset, maximum length of the input examples, number of stress available"
5369,E:\DATN\dataframe\train_file\64.txt,max_len = 0
5370,E:\DATN\dataframe\train_file\64.txt,output_labels = 0
5371,E:\DATN\dataframe\train_file\64.txt,dataset_len = 0
5372,E:\DATN\dataframe\train_file\64.txt,for element in dataset.as_numpy_iterator():
5373,E:\DATN\dataframe\train_file\64.txt,  word = element[0].decode('utf-8')
5374,E:\DATN\dataframe\train_file\64.txt,  stress = element[1]
5375,E:\DATN\dataframe\train_file\64.txt,  if len(word) > max_len:
5376,E:\DATN\dataframe\train_file\64.txt,    max_len = len(word)
5377,E:\DATN\dataframe\train_file\64.txt,  if output_labels < stress:
5378,E:\DATN\dataframe\train_file\64.txt,    output_labels+= 1
5379,E:\DATN\dataframe\train_file\64.txt,  dataset_len += 1
5380,E:\DATN\dataframe\train_file\64.txt,"print(dataset_len, max_len, output_labels)"
5381,E:\DATN\dataframe\train_file\64.txt,> dataset_len: 200632
5382,E:\DATN\dataframe\train_file\64.txt,>> max_len: 34
5383,E:\DATN\dataframe\train_file\64.txt,>>> output_labels: 8
5384,E:\DATN\dataframe\train_file\64.txt,Sau đó mình sẽ thực hiện one-hot encoding với input và label: Từ dài nhất trong từ điển của mình có 34 ký tự và bộ từ điển có các trọng âm nằm ở vị trí từ 1 đến 8.
5385,E:\DATN\dataframe\train_file\64.txt,"Như vậy một từ input sẽ được encode thành một vector có 34x26 = 884 phần tử với mỗi chữ cái tương ứng với một one hot vector 26 phần tử, nếu số chữ cái của từ nhỏ hơn 34 thì toàn bộ phần còn lại sẽ là 0."
5386,E:\DATN\dataframe\train_file\64.txt,Tương tự thì mỗi labels thể hiện trọng âm của từ tương ứng sẽ trở thành một one hot vector có 8 phần tử.
5387,E:\DATN\dataframe\train_file\64.txt,# one-hot encode for inputs
5388,E:\DATN\dataframe\train_file\64.txt,"alphabet = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ"""
5389,E:\DATN\dataframe\train_file\64.txt,for i in alphabet:
5390,E:\DATN\dataframe\train_file\64.txt,"  temp = np.zeros([26,], dtype = np.float32)"
5391,E:\DATN\dataframe\train_file\64.txt,  temp[alphabet.find(i)] = 1
5392,E:\DATN\dataframe\train_file\64.txt,  abcdict[i] = temp
5393,E:\DATN\dataframe\train_file\64.txt,def encodex(word):
5394,E:\DATN\dataframe\train_file\64.txt,  w = word.numpy().decode('utf-8').upper()
5395,E:\DATN\dataframe\train_file\64.txt,"  res = np.array([], dtype = int)"
5396,E:\DATN\dataframe\train_file\64.txt,"  temp = np.zeros([(max_len - len(w))*26,], dtype = np.float32)"
5397,E:\DATN\dataframe\train_file\64.txt,  for i in w:
5398,E:\DATN\dataframe\train_file\64.txt,"    res = np.append(res, np.array(abcdict[i]))"
5399,E:\DATN\dataframe\train_file\64.txt,"  res = np.append(res, temp)"
5400,E:\DATN\dataframe\train_file\64.txt,  res = tf.convert_to_tensor(res)
5401,E:\DATN\dataframe\train_file\64.txt,# one-hot encode for labels
5402,E:\DATN\dataframe\train_file\64.txt,"for i in range(0, output_labels):"
5403,E:\DATN\dataframe\train_file\64.txt,"encodey = tf.one_hot(stress_list, len(stress_list), on_value = 1, dtype = tf.int32)"
5404,E:\DATN\dataframe\train_file\64.txt,"Theo hướng dẫn để đạt performance tốt hơn với tf.data API trên trang chủ của Tensorflow (), mình thêm một bước cache dataset vào sau bước map cuối cùng."
5405,E:\DATN\dataframe\train_file\64.txt,"Khi lưu một dataset vào bộ nhớ cache, những bước transformation trước khi cache (mở file, đọc dữ liệu) sẽ chỉ phải thực hiện một lần duy nhất trong epoch đầu tiên."
5406,E:\DATN\dataframe\train_file\64.txt,Nhưng epoch tiếp theo sẽ sử dụng lại dữ liệu đã được cached.
5407,E:\DATN\dataframe\train_file\64.txt,"def enc_fn(a, b):"
5408,E:\DATN\dataframe\train_file\64.txt,"  return (encodex(a), encodey[b-1])"
5409,E:\DATN\dataframe\train_file\64.txt,"def tf_enc(a, b):"
5410,E:\DATN\dataframe\train_file\64.txt,"  return tf.py_function(enc_fn, (a, b), (tf.int64, tf.int64))"
5411,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.map(tf_enc)
5412,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.cache()
5413,E:\DATN\dataframe\train_file\64.txt,"Như đã nói ở trên, dataset được đọc từ tf.data.TextLineDataset sẽ trả về unknown shape and rank, do vậy để đưa được vào mô hình, mình cần phải set lại shape cho nó."
5414,E:\DATN\dataframe\train_file\64.txt,Đồng thời mình sẽ tạo batch dữ liệu và thực hiện bước prefetching.
5415,E:\DATN\dataframe\train_file\64.txt,"Hiểu đơn giản thì prefetching giúp thực hiện song song hai quá trình, training và load dữ liệu."
5416,E:\DATN\dataframe\train_file\64.txt,Ví dụ khi model đang thực hiện bước training thứ n thì input pipeline sẽ thực hiện đọc data cho bước thứ n+1.
5417,E:\DATN\dataframe\train_file\64.txt,"Nhờ vậy chúng ta có thể giảm thiểu thời gian training cũng như tối ưu hóa được hiệu suất cho GPU (trong khi GPU training thì CPU load dữ liệu, thay vì train xong một bước thì GPU lại phải đợi CPU xử lý xong)"
5418,E:\DATN\dataframe\train_file\64.txt,Các bạn có thể đọc chi tiết hơn về prefetch tại .
5419,E:\DATN\dataframe\train_file\64.txt,Ngoài ra trên viblo cũng có một bài viết giải thích khá chi tiết:
5420,E:\DATN\dataframe\train_file\64.txt,"def set_shapes(a, b):"
5421,E:\DATN\dataframe\train_file\64.txt,"    a = tf.reshape(a, (-1, max_len*26, 1))"
5422,E:\DATN\dataframe\train_file\64.txt,"    b = tf.reshape(b, (-1, 8))"
5423,E:\DATN\dataframe\train_file\64.txt,"    return a, b"
5424,E:\DATN\dataframe\train_file\64.txt,BATCH_SIZE = 32
5425,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.batch(BATCH_SIZE)
5426,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.map(set_shapes)
5427,E:\DATN\dataframe\train_file\64.txt,dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
5428,E:\DATN\dataframe\train_file\64.txt,Chia tập train/ val/ test
5429,E:\DATN\dataframe\train_file\64.txt,"Do đặc thù của bộ Dataset mình dùng là ở dạng từ điển, xếp theo thứ tự alphabet và có nhiều từ được lặp lại chỉ thay đổi một phần theo loại từ (ví dụ PRODUCE - PRODUCT - PRODUCTS - PRODUCTION, vv.)"
5430,E:\DATN\dataframe\train_file\64.txt,nên mình sẽ không shuffle trước mà chia ra tập train/ validation/ test rồi mới shuffle tập train để tránh việc mô hình chỉ ghi nhớ những từ có sẵn.
5431,E:\DATN\dataframe\train_file\64.txt,API tf.data có hỗ trợ shuffling.
5432,E:\DATN\dataframe\train_file\64.txt,Lưu ý là để shuffle hiệu quả nhất thì buffer_size cần lớn hơn hoặc bằng size của dataset.
5433,E:\DATN\dataframe\train_file\64.txt,Ngoài ra bạn có thể thêm argument reshuffle_each_iteration=True để thực hiện shuffle lại sau mỗi epoch.
5434,E:\DATN\dataframe\train_file\64.txt,"(đây là tính năng mới kể từ TF 2.0, trước đó nếu muốn thứ tự shuffle thay đổi thì phải dùng bước repeat)"
5435,E:\DATN\dataframe\train_file\64.txt,# train/ val/ test splitting
5436,E:\DATN\dataframe\train_file\64.txt,"def split_dataset(dataset: tf.data.Dataset, validation_data_fraction: float, test_data_fraction: float):"
5437,E:\DATN\dataframe\train_file\64.txt,    a = round(dataset_len/BATCH_SIZE*(1-validation_data_fraction - test_data_fraction))
5438,E:\DATN\dataframe\train_file\64.txt,    b = round(dataset_len/BATCH_SIZE*(1 - test_data_fraction))
5439,E:\DATN\dataframe\train_file\64.txt,    dataset = dataset.enumerate()
5440,E:\DATN\dataframe\train_file\64.txt,"    train_dataset = dataset.filter(lambda f, data: f <= a)"
5441,E:\DATN\dataframe\train_file\64.txt,"    validation_dataset = dataset.filter(lambda f, data: (f > a and f <= b))"
5442,E:\DATN\dataframe\train_file\64.txt,"    test_dataset = dataset.filter(lambda f, data: f > b)"
5443,E:\DATN\dataframe\train_file\64.txt,    # remove enumeration
5444,E:\DATN\dataframe\train_file\64.txt,"    train_dataset = train_dataset.map(lambda f, data: data)"
5445,E:\DATN\dataframe\train_file\64.txt,"    validation_dataset = validation_dataset.map(lambda f, data: data)"
5446,E:\DATN\dataframe\train_file\64.txt,"    test_dataset = test_dataset.map(lambda f, data: data)"
5447,E:\DATN\dataframe\train_file\64.txt,"    return train_dataset, validation_dataset, test_dataset"
5448,E:\DATN\dataframe\train_file\64.txt,"train_ds, val_ds, test_ds = split_dataset(dataset, 0.2, 0.1)"
5449,E:\DATN\dataframe\train_file\64.txt,"train_ds = train_ds.shuffle(round(dataset_len/batch_size*0.7), reshuffle_each_iteration=True)"
5450,E:\DATN\dataframe\train_file\64.txt,Trong bài này mình sẽ dùng một mạng neural network đơn giản gồm 2 hidden layer.
5451,E:\DATN\dataframe\train_file\64.txt,Input là một one-hot vector gồm 884 phần tử đại diện cho từ tiếng Anh.
5452,E:\DATN\dataframe\train_file\64.txt,Output là một vector 8 phần tử tương ứng với xác suất trọng âm của từ đó nằm ở từng vị trí từ 1-8.
5453,E:\DATN\dataframe\train_file\64.txt,Do vector input của mình là một sparse vector nên mình thêm một lớp convolutional layer 1D rồi flatten nó ra để kết nối với lớp dense.
5454,E:\DATN\dataframe\train_file\64.txt,Cụ thể như sau:
5455,E:\DATN\dataframe\train_file\64.txt,model = Sequential()
5456,E:\DATN\dataframe\train_file\64.txt,"model.add(Conv1D(filters=7, kernel_size=5, input_shape=(884, 1), activation=activations.relu))"
5457,E:\DATN\dataframe\train_file\64.txt,"model.add(LayerNormalization(axis=1 , center=True , scale=True))"
5458,E:\DATN\dataframe\train_file\64.txt,"model.add(Dense(512, activation=activations.relu))"
5459,E:\DATN\dataframe\train_file\64.txt,"model.add(Dense(256, activation=activations.relu))"
5460,E:\DATN\dataframe\train_file\64.txt,"model.add(Dense(output_labels, activation=activations.softmax))"
5461,E:\DATN\dataframe\train_file\64.txt,Ngoài ra mình cũng kết hợp với một số Callbacks API của Keras khi training để tối ưu thời gian và tránh overfitting:
5462,E:\DATN\dataframe\train_file\64.txt,early_stopping = keras.callbacks.EarlyStopping(patience=20)
5463,E:\DATN\dataframe\train_file\64.txt,model_checkpoint = keras.callbacks.ModelCheckpoint(
5464,E:\DATN\dataframe\train_file\64.txt,"    ""my_checkpoint"", save_best_only=True)"
5465,E:\DATN\dataframe\train_file\64.txt,Chạy thử nào
5466,E:\DATN\dataframe\train_file\64.txt,"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
5467,E:\DATN\dataframe\train_file\64.txt,"history = model.fit(train_ds, epochs=100, validation_data= val_ds, callbacks=[model_checkpoint, early_stopping])"
5468,E:\DATN\dataframe\train_file\64.txt,best_model_accuracy = history.history['acc'][np.argmin(history.history['loss'])]
5469,E:\DATN\dataframe\train_file\64.txt,"Sau 32 epochs, mô hình của mình đạt accuracy là 92.7% trên tập train và 91.8% trên tập validation."
5470,E:\DATN\dataframe\train_file\64.txt,Accuracy cao nhất đạt được trên tập train là 94.5%
5471,E:\DATN\dataframe\train_file\64.txt,Evaluate trên tập test:
5472,E:\DATN\dataframe\train_file\64.txt,"model1 = keras.models.load_model(""my_checkpoint"")"
5473,E:\DATN\dataframe\train_file\64.txt,Kết quả: 86.9% trên tập test
5474,E:\DATN\dataframe\train_file\64.txt,Mình sẽ thử lấy ra một vài kết quả để trông cho trực quan:
5475,E:\DATN\dataframe\train_file\64.txt,prediction = model1.predict(test_ds)
5476,E:\DATN\dataframe\train_file\64.txt,test_ds1 = test_ds.unbatch()
5477,E:\DATN\dataframe\train_file\64.txt,"for key, value in abcdict.items():"
5478,E:\DATN\dataframe\train_file\64.txt,  abcdict2[np.array_str(value)] = key
5479,E:\DATN\dataframe\train_file\64.txt,def decodex (x : tf.Tensor):
5480,E:\DATN\dataframe\train_file\64.txt,"  x = tf.reshape(x, (-1, 26)).numpy()"
5481,E:\DATN\dataframe\train_file\64.txt,"  for i in range(0, np.size(x, 0)):"
5482,E:\DATN\dataframe\train_file\64.txt,    if np.array_str(x[i]) in abcdict2.keys():
5483,E:\DATN\dataframe\train_file\64.txt,      res += abcdict2[np.array_str(x[i])]
5484,E:\DATN\dataframe\train_file\64.txt,  return res
5485,E:\DATN\dataframe\train_file\64.txt,i = 0
5486,E:\DATN\dataframe\train_file\64.txt,for element in test_ds1:
5487,E:\DATN\dataframe\train_file\64.txt,  res_comp = 'RIGHT'
5488,E:\DATN\dataframe\train_file\64.txt,  if np.argmax(element[1])+1 != np.argmax(prediction[i])+1:
5489,E:\DATN\dataframe\train_file\64.txt,    res_comp = 'WRONG'
5490,E:\DATN\dataframe\train_file\64.txt,"  print(decodex(element[0]), np.argmax(element[1])+1, np.argmax(prediction[i])+1, res_comp)"
5491,E:\DATN\dataframe\train_file\64.txt,"Một vài ""đáp án"":"
5492,E:\DATN\dataframe\train_file\64.txt,WHODUNITS 2 2 RIGHT
5493,E:\DATN\dataframe\train_file\64.txt,WESTERNIZATION 4 4 RIGHT
5494,E:\DATN\dataframe\train_file\64.txt,YESTERDAY 1 1 RIGHT
5495,E:\DATN\dataframe\train_file\64.txt,XENOPHOBIA 3 3 RIGHT
5496,E:\DATN\dataframe\train_file\64.txt,WOLVERINE 3 1 WRONG
5497,E:\DATN\dataframe\train_file\64.txt,WHATSOEVER 3 1 WRONG
5498,E:\DATN\dataframe\train_file\64.txt,WHITECOTTON 1 3 WRONG
5499,E:\DATN\dataframe\train_file\64.txt,WIDEN 1 2 WRONG
5500,E:\DATN\dataframe\train_file\64.txt,Như vậy trong bài viết này mình đã dùng API tf.data của Tensorflow để xây dựng một input pipeline và đưa vào mô hình machine learning dùng Keras để đoán trọng âm của một từ tiếng Anh.
5501,E:\DATN\dataframe\train_file\64.txt,"Kết quả đạt được là gần 87% trên tập test, con số tuy không cao nhưng đủ để mình đưa ra kết luận là dùng machine learning có thể ""học"" được một phần nào đó các quy tắc trọng âm tiếng Anh chỉ dựa trên phân phối các chữ cái trong từ."
5502,E:\DATN\dataframe\train_file\64.txt,"Nếu kết hợp với loại từ thì mình nghĩ sẽ có được độ chính xác cao hơn, tuy nhiên phần đó chắc phải để lại cho tương lai nếu có dịp."
5503,E:\DATN\dataframe\train_file\64.txt,"Mình cũng chỉ mới bắt đầu với machine learning nói chung và tensorflow nói riêng chưa lâu lắm, nên nếu có sai sót rất mong nhận được góp ý từ các bạn."
5504,E:\DATN\dataframe\train_file\65.txt,Xây dựng mô hình dịch máy cho cặp ngôn ngữ Nhật - Việt
5505,E:\DATN\dataframe\train_file\65.txt,"Dịch tự động hay còn gọi là dịch máy (tiếng Anh: machine translation) là một nhánh của xử lý ngôn ngữ tự nhiên thuộc phân ngành trí tuệ nhân tạo, nó là sự kết hợp giữa ngôn ngữ, dịch thuật và khoa học máy tính."
5506,E:\DATN\dataframe\train_file\65.txt,"Như tên gọi, dịch tự động thực hiện dịch một ngôn ngữ này (gọi là ngôn ngữ nguồn) sang một hoặc nhiều ngôn ngữ khác (gọi là ngôn ngữ đích) một cách tự động, không có sự can thiệp của con người trong quá trình dịch."
5507,E:\DATN\dataframe\train_file\65.txt,Lịch sử một số phương pháp dịch máy:
5508,E:\DATN\dataframe\train_file\65.txt,"Rule-based Machine Translation (RBMT): Tập trung vào các quy tắc giúp chuyển đổi văn bản trong ngôn ngữ nguồn (source) sang ngôn ngữ đích (target) trên các cấp độ: từ vựng, cú pháp hoặc ngữ nghĩa."
5509,E:\DATN\dataframe\train_file\65.txt,Các quy tắc thường do nhà ngôn ngữ học phát triển.
5510,E:\DATN\dataframe\train_file\65.txt,"Do vậy hạn chế chính của phương pháp này là nó đòi hỏi rất nhiều nguồn lực về chuyên môn/ chuyên gia (có thể rất tốn kém) để xây dựng rất rất nhiều quy tắc và ngoại lệ, đồng thời nó không khái quát được cho những ngôn ngữ khác."
5511,E:\DATN\dataframe\train_file\65.txt,Statistical machine translation (SMT): sử dụng các mô hình thống kê (statistical model) học cách dịch văn bản từ ngôn ngữ nguồn sang ngôn ngữ đích dựa trên một bộ ngữ liệu (corpus) lớn.
5512,E:\DATN\dataframe\train_file\65.txt,Ý tưởng đằng sau dịch máy thống kê đến từ lý thuyết thông tin.
5513,E:\DATN\dataframe\train_file\65.txt,Tài liệu được dịch theo phân bố xác suất
5514,E:\DATN\dataframe\train_file\65.txt,p(e∣f) trong đó
5515,E:\DATN\dataframe\train_file\65.txt,"e là ngôn ngữ đích (ví dụ, Tiếng Việt) dịch từ"
5516,E:\DATN\dataframe\train_file\65.txt,"f là ngôn ngữ nguồn (ví dụ, Tiếng Nhật)."
5517,E:\DATN\dataframe\train_file\65.txt,Các vấn đề của mô hình phân phối xác suất
5518,E:\DATN\dataframe\train_file\65.txt,p ( e | f )
5519,E:\DATN\dataframe\train_file\65.txt,p(e∣f) được tiếp cận theo một số cách.
5520,E:\DATN\dataframe\train_file\65.txt,"Một cách tiếp cận trực quan là áp dụng định lý Bayes, đó là"
5521,E:\DATN\dataframe\train_file\65.txt,p ( e | f ) ∝ p ( f | e ) p ( e )
5522,E:\DATN\dataframe\train_file\65.txt,"p(e∣f)∝p(f∣e)p(e), trong đó"
5523,E:\DATN\dataframe\train_file\65.txt,p ( f | e )
5524,E:\DATN\dataframe\train_file\65.txt,p(f∣e) là xác suất để chuỗi nguồn
5525,E:\DATN\dataframe\train_file\65.txt,f là bản dịch của chuỗi đích
5526,E:\DATN\dataframe\train_file\65.txt,"e, xác suất này gọi là mô hình dịch, và"
5527,E:\DATN\dataframe\train_file\65.txt,p ( e )
5528,E:\DATN\dataframe\train_file\65.txt,"p(e) là xác suất chuỗi e thực sự xuất hiện trong ngôn ngữ đích, xác suất này gọi là mô hình ngôn ngữ."
5529,E:\DATN\dataframe\train_file\65.txt,Phân tích này giúp tách các vấn đề thành hai bài toán con.
5530,E:\DATN\dataframe\train_file\65.txt,Bản dịch tốt nhất
5531,E:\DATN\dataframe\train_file\65.txt, được tìm bằng cách chọn ra bản có xác suất cao nhất:
5532,E:\DATN\dataframe\train_file\65.txt,"Để áp dụng phương pháp này một cách đầy đủ, cần thực hiện việc tìm kiếm trên tất cả các chuỗi"
5533,E:\DATN\dataframe\train_file\65.txt, của ngôn ngữ đích.
5534,E:\DATN\dataframe\train_file\65.txt,"Khối lượng tìm kiếm này rất lớn, và nhiệm vụ thực hiện tìm kiếm hiệu quả là công việc của một bộ giải mã dịch máy, sử dụng nhiều kỹ thuật để hạn chế không gian tìm kiếm nhưng vẫn giữ chất lượng dịch thuật chấp nhận được."
5535,E:\DATN\dataframe\train_file\65.txt,"Mặc dù hiệu quả, phương pháp này tập trung chủ yếu vào các cụm từ mà bỏ qua hàm nghĩa rộng hơn của văn bản."
5536,E:\DATN\dataframe\train_file\65.txt,Đồng thời việc tiếp cận theo hướng dữ liệu (data-driven) cũng có nghĩa là mô hình có khả năng đã bỏ qua những đặc điểm về cú pháp trong ngôn ngữ.
5537,E:\DATN\dataframe\train_file\65.txt,Neural machine translation (NMT): sử dụng các mô hình neural network để học một mô hình thống kê cho quá trình dịch máy.
5538,E:\DATN\dataframe\train_file\65.txt,"Với phương pháp này, người ta chỉ cần huấn luyện một hệ thống duy nhất trên tập văn bản nguồn và văn bản đích (end-to-end system), không cần phải xây dựng một pipeline gồm các hệt thống chuyên biệt giống như SMT, không cần phải có nhiều kiến thức chuyên môn về ngôn ngữ, nhờ vậy mà có thể áp dụng cho các cặp ngôn ngữ khác nhau khá dễ dàng."
5539,E:\DATN\dataframe\train_file\65.txt,Trong bài này mình sẽ xây dựng một chương trình dịch máy NMT từ tiếng Nhật sang tiếng Việt sử dụng mô hình Encoder-Decoder cơ bản.
5540,E:\DATN\dataframe\train_file\65.txt,Machine translation là một bài toán sequence-to-sequence (seq2seq) điển hình do nó có đầu vào là một chuỗi (sequence) và đầu ra cũng là một chuỗi.
5541,E:\DATN\dataframe\train_file\65.txt,Một thách thức của bài toán này là độ dài của chuỗi đầu vào và chuỗi đầu ra biến đổi liên tục và không giống nhau.
5542,E:\DATN\dataframe\train_file\65.txt,Một trong những cách tiếp cận hiệu quả đó là Encoder-Decoder LSTM.
5543,E:\DATN\dataframe\train_file\65.txt,Hệ thống này bao gồm 2 model:
5544,E:\DATN\dataframe\train_file\65.txt,"Model thứ nhất được gọi là Encoder, chịu trách nhiệm nhận chuỗi đầu vào (input sequence) và mã hóa (encode) nó thành một vector có độ dài cố định"
5545,E:\DATN\dataframe\train_file\65.txt,Model thứ hai là Decoder có nhiệm vụ giải mã (decode) vector trên và dự đoán chuỗi đầu ra.
5546,E:\DATN\dataframe\train_file\65.txt,Trong bài này mình sử dụng bộ data: Tatoeba corpus from OPUS project gồm hơn 2000 cặp câu Nhật - Việt.
5547,E:\DATN\dataframe\train_file\65.txt,"Ngoài ra trong repo này có khá nhiều bộ dataset nữa được tổng hợp và chỉnh lý từ các nguồn khác nhau, các bạn có thể tham khảo thêm:"
5548,E:\DATN\dataframe\train_file\65.txt,# read data
5549,E:\DATN\dataframe\train_file\65.txt,import string
5550,E:\DATN\dataframe\train_file\65.txt,"with open(f""{path}vi_data.txt"") as f:"
5551,E:\DATN\dataframe\train_file\65.txt,  for line in f:
5552,E:\DATN\dataframe\train_file\65.txt,"    line = line.replace('  ', ' ').lower()"
5553,E:\DATN\dataframe\train_file\65.txt,"with open(f""{path}ja_data.txt"") as f:"
5554,E:\DATN\dataframe\train_file\65.txt,  for line in f:
5555,E:\DATN\dataframe\train_file\65.txt,"for i in zip(ja_input[:5], vi_input[:5]):"
5556,E:\DATN\dataframe\train_file\65.txt,"('私は眠らなければなりません。', 'tôi phải đi ngủ .')"
5557,E:\DATN\dataframe\train_file\65.txt,"('何してるの？', 'bạn đang làm gì đây ?')"
5558,E:\DATN\dataframe\train_file\65.txt,"('今日は６月１８日で、ムーリエルの誕生日です！', 'hôm nay là ngày 18 tháng sáu , và cũng là ngày sinh nhật của muiriel !')"
5559,E:\DATN\dataframe\train_file\65.txt,"('お誕生日おめでとうムーリエル！', 'chúc mừng sinh nhật , muiriel !')"
5560,E:\DATN\dataframe\train_file\65.txt,"('ムーリエルは２０歳になりました。', 'bây giờ muiriel được 20 tuổi .')"
5561,E:\DATN\dataframe\train_file\65.txt,Data Preprocessing
5562,E:\DATN\dataframe\train_file\65.txt,"Giống như những bài toán về NLP khác, các bước tiền xử lý dữ liệu cần thực hiện là:"
5563,E:\DATN\dataframe\train_file\65.txt,Tokenization: tách câu thành các từ có nghĩa.
5564,E:\DATN\dataframe\train_file\65.txt,"Do đặc thù của tiếng Việt là một từ có thể được cấu tạo bởi nhiều tiếng, còn tiếng Nhật lại không có dấu cách giữa các chữ nên mình không thể tokenize giống tiếng Anh bằng cách dựa vào khoảng trắng giữa các chữ được."
5565,E:\DATN\dataframe\train_file\65.txt,Hiện đã có rất nhiều bộ tokenizer dành riêng cho hai thứ tiếng.
5566,E:\DATN\dataframe\train_file\65.txt,Trong bài này mình sẽ sử dụng thư viện pyvi cho tiếng Việt và spacy cho tiếng Nhật.
5567,E:\DATN\dataframe\train_file\65.txt,!pip install pyvi
5568,E:\DATN\dataframe\train_file\65.txt,!pip install -U pip setuptools wheel
5569,E:\DATN\dataframe\train_file\65.txt,!pip install -U spacy
5570,E:\DATN\dataframe\train_file\65.txt,!python -m spacy download ja_core_news_sm
5571,E:\DATN\dataframe\train_file\65.txt,(Nếu dùng Colab thì khi cài đặt xong các bạn nhớ restart runtime để chạy nhé ^^;)
5572,E:\DATN\dataframe\train_file\65.txt,# Thêm token đánh dấu điểm bắt đầu và kết thúc của câu vào mỗi câu trong ngôn ngữ đích
5573,E:\DATN\dataframe\train_file\65.txt,eos = '<eos>'
5574,E:\DATN\dataframe\train_file\65.txt,bos = '<bos>'
5575,E:\DATN\dataframe\train_file\65.txt,from pyvi import ViTokenizer
5576,E:\DATN\dataframe\train_file\65.txt,vi_input_tokenize = [ViTokenizer.tokenize(i).split() for i in vi_input]
5577,E:\DATN\dataframe\train_file\65.txt,for i in range(len(vi_input_tokenize)):
5578,E:\DATN\dataframe\train_file\65.txt,"  vi_input_tokenize[i].insert(0, bos)"
5579,E:\DATN\dataframe\train_file\65.txt,"  vi_input_tokenize[i].insert(len(vi_input_tokenize[i]), eos)"
5580,E:\DATN\dataframe\train_file\65.txt,import spacy
5581,E:\DATN\dataframe\train_file\65.txt,"nlp = spacy.load(""ja_core_news_sm"")"
5582,E:\DATN\dataframe\train_file\65.txt,ja_input_tokenize = [[] for i in range(len(ja_input))]
5583,E:\DATN\dataframe\train_file\65.txt,for i in range(len(ja_input)):
5584,E:\DATN\dataframe\train_file\65.txt,  doc = nlp(ja_input[i])
5585,E:\DATN\dataframe\train_file\65.txt,  for token in doc:
5586,E:\DATN\dataframe\train_file\65.txt,"Tạo một bộ từ vựng cho các từ có trong corpus, trong đó mỗi từ sẽ có một index tương ứng."
5587,E:\DATN\dataframe\train_file\65.txt,Ở bước này mình dùng class Tokenizer của TF Keras.
5588,E:\DATN\dataframe\train_file\65.txt,from tensorflow.keras.preprocessing.text import Tokenizer
5589,E:\DATN\dataframe\train_file\65.txt,ja_tokenizer = Tokenizer(oov_token = '<oov>')
5590,E:\DATN\dataframe\train_file\65.txt,ja_vocabulary = ja_tokenizer.word_index
5591,E:\DATN\dataframe\train_file\65.txt,ja_size = len(ja_vocabulary)
5592,E:\DATN\dataframe\train_file\65.txt,print(ja_size) # number of words in the vocabulary
5593,E:\DATN\dataframe\train_file\65.txt,vi_tokenizer = Tokenizer()
5594,E:\DATN\dataframe\train_file\65.txt,vi_vocabulary = vi_tokenizer.word_index
5595,E:\DATN\dataframe\train_file\65.txt,vi_size = len(vi_vocabulary)
5596,E:\DATN\dataframe\train_file\65.txt,"{'<oov>': 1, '。': 2, 'は': 3, 'の': 4, 'に': 5, 'た': 6, 'を': 7, ..., '資金': 1994, '広く': 1995, '投資': 1996}"
5597,E:\DATN\dataframe\train_file\65.txt,"{'<bos>': 1, '<eos>': 2, '."
5598,E:\DATN\dataframe\train_file\65.txt,"': 3, 'tôi': 4, 'không': 5, 'anh': 6, '?"
5599,E:\DATN\dataframe\train_file\65.txt,"': 7, 'bạn': 8, ..., 'kêu_gọi': 1632, 'đầu_tư': 1633, 'kinh_phí': 1634}"
5600,E:\DATN\dataframe\train_file\65.txt,Tạo một bộ từ vựng để tra ngược lại (từ index -> từ):
5601,E:\DATN\dataframe\train_file\65.txt,"for key, value in ja_tokenizer.word_index.items():"
5602,E:\DATN\dataframe\train_file\65.txt,  ja_vocabulary_reverse[value] = key
5603,E:\DATN\dataframe\train_file\65.txt,"for key, value in vi_tokenizer.word_index.items():"
5604,E:\DATN\dataframe\train_file\65.txt,  vi_vocabulary_reverse[value] = key
5605,E:\DATN\dataframe\train_file\65.txt,"{1: '<oov>', 2: '。', 3: 'は', 4: 'の', 5: 'に', 6: 'た', 7: 'を', ...}"
5606,E:\DATN\dataframe\train_file\65.txt,"{1: '<bos>', 2: '<eos>', 3: '."
5607,E:\DATN\dataframe\train_file\65.txt,"', 4: 'tôi', 5: 'không', 6: 'anh', 7: '?"
5608,E:\DATN\dataframe\train_file\65.txt,"', 8: 'bạn', ...}"
5609,E:\DATN\dataframe\train_file\65.txt,"Mã hóa các câu đầu vào thành các chuỗi dựa trên index của bộ từ vựng vừa tạo, thực hiện padding để có các chuỗi độ dài bằng nhau."
5610,E:\DATN\dataframe\train_file\65.txt,from tensorflow.keras.preprocessing.sequence import pad_sequences
5611,E:\DATN\dataframe\train_file\65.txt,ja_sequence = ja_tokenizer.texts_to_sequences(ja_input_tokenize)
5612,E:\DATN\dataframe\train_file\65.txt,jamaxlen = max([len(i) for i in ja_sequence])
5613,E:\DATN\dataframe\train_file\65.txt,"ja_sequence = pad_sequences(ja_sequence, maxlen = jamaxlen, padding = 'post')"
5614,E:\DATN\dataframe\train_file\65.txt,vi_sequence = vi_tokenizer.texts_to_sequences(vi_input_tokenize)
5615,E:\DATN\dataframe\train_file\65.txt,vimaxlen = max([len(i) for i in vi_sequence])
5616,E:\DATN\dataframe\train_file\65.txt,"vi_sequence = pad_sequences(vi_sequence, maxlen = vimaxlen, padding = 'post')"
5617,E:\DATN\dataframe\train_file\65.txt,[ 10   3 780  98  62  84  43  28   2   0   0   0   0   0   0   0   0   0
5618,E:\DATN\dataframe\train_file\65.txt,   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
5619,E:\DATN\dataframe\train_file\65.txt,   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
5620,E:\DATN\dataframe\train_file\65.txt,   0   0   0   0   0   0   0   0   0]
5621,E:\DATN\dataframe\train_file\65.txt,[  1   4  29  21 133   3   2   0   0   0   0   0   0   0   0   0   0   0
5622,E:\DATN\dataframe\train_file\65.txt,   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
5623,E:\DATN\dataframe\train_file\65.txt,   0   0   0   0   0   0   0   0   0]
5624,E:\DATN\dataframe\train_file\65.txt,"Train/ test split, Generate batch"
5625,E:\DATN\dataframe\train_file\65.txt,split_ratio = 0.9
5626,E:\DATN\dataframe\train_file\65.txt,split = round(len(vi_sequence)* split_ratio)
5627,E:\DATN\dataframe\train_file\65.txt,trainX = ja_sequence[:split]
5628,E:\DATN\dataframe\train_file\65.txt,testX = ja_sequence[split:]
5629,E:\DATN\dataframe\train_file\65.txt,trainY = vi_sequence[:split]
5630,E:\DATN\dataframe\train_file\65.txt,testY = vi_sequence[split:]
5631,E:\DATN\dataframe\train_file\65.txt,train_samples = len(trainX)
5632,E:\DATN\dataframe\train_file\65.txt,val_samples = len(testX)
5633,E:\DATN\dataframe\train_file\65.txt,batch_size = 128
5634,E:\DATN\dataframe\train_file\65.txt,epochs = 200
5635,E:\DATN\dataframe\train_file\65.txt,Tạo data để đưa vào mô hình encoder-decoder:
5636,E:\DATN\dataframe\train_file\65.txt,"Do lượng dữ liệu khá lớn để có thể load toàn bộ vào trong bộ nhớ, ta sẽ tạo một hàm generate các batch dữ liệu để pass vào mô hình bằng fit_generator()"
5637,E:\DATN\dataframe\train_file\65.txt,"def generate_batch(X, y, batch_size):"
5638,E:\DATN\dataframe\train_file\65.txt,  while True:
5639,E:\DATN\dataframe\train_file\65.txt,"    for j in range(0, len(X), batch_size):"
5640,E:\DATN\dataframe\train_file\65.txt,"      for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):"
5641,E:\DATN\dataframe\train_file\65.txt,"        decodertargetdata = to_categorical(target_text, num_classes=vi_size+1)[1:]"
5642,E:\DATN\dataframe\train_file\65.txt,"        decoder_target_data.append(np.concatenate((np.array(decodertargetdata), np.zeros((1, vi_size+1))), axis = 0))"
5643,E:\DATN\dataframe\train_file\65.txt,      encoder_input_data = np.array(encoder_input_data)
5644,E:\DATN\dataframe\train_file\65.txt,      decoder_input_data = np.array(decoder_input_data)
5645,E:\DATN\dataframe\train_file\65.txt,      decoder_target_data = np.array(decoder_target_data)
5646,E:\DATN\dataframe\train_file\65.txt,"      yield([encoder_input_data, decoder_input_data], decoder_target_data)"
5647,E:\DATN\dataframe\train_file\65.txt,"Để train mô hình encoder - decoder sequence to sequence, ta cần 3 mảng np.array như sau:"
5648,E:\DATN\dataframe\train_file\65.txt,"encoder inputs: sequence của câu tiếng Nhật, đầu vào cho encoder, shape: (batch_size, jamaxlen)"
5649,E:\DATN\dataframe\train_file\65.txt,"decoder inputs: sequence của câu tiếng Việt, đầu vào cho decoder, shape: (batch_size, vimaxlen)"
5650,E:\DATN\dataframe\train_file\65.txt,"decoder outputs: decoder inputs sau khi đã onehot encoded, shape: (batch_size, vimaxlen, vi_size + 1) (+1 do chuỗi đã được zero-padded -> có thêm số 0)."
5651,E:\DATN\dataframe\train_file\65.txt,"Lưu ý, với mỗi câu, decoder output sẽ sớm hơn 1 bước timestep so với decoder input."
5652,E:\DATN\dataframe\train_file\65.txt,"Tức là, nếu input là token ở vị trí thứ t thì output predict ra phải là token tiếp theo của nó, tức là t+1."
5653,E:\DATN\dataframe\train_file\65.txt,Xây dựng model
5654,E:\DATN\dataframe\train_file\65.txt,Encoder làm nhiệm vụ mã hóa chuỗi đầu vào thành một vector có độ dài cố định.
5655,E:\DATN\dataframe\train_file\65.txt,Bao gồm các layer sau:
5656,E:\DATN\dataframe\train_file\65.txt,Input layer: encode_input_data
5657,E:\DATN\dataframe\train_file\65.txt,Embedding layer: đưa các sparse vector về dạng dense vector với số chiều thấp hơn.
5658,E:\DATN\dataframe\train_file\65.txt,"Các parameter: số từ trong bộ từ vựng, số chiều của vector sau khi embedded, mask_zero = True để mask out - bỏ qua phần zero padding trong input"
5659,E:\DATN\dataframe\train_file\65.txt,LSTM layer: set return_state = True để lấy hidden state và cell state của encoder.
5660,E:\DATN\dataframe\train_file\65.txt,Các state này sau đó sẽ được pass vào decoder.
5661,E:\DATN\dataframe\train_file\65.txt,# Define an input sequence and process it.
5662,E:\DATN\dataframe\train_file\65.txt,"encoder_inputs = Input(shape=(None,))"
5663,E:\DATN\dataframe\train_file\65.txt,"enc_emb =  Embedding(ja_size+1, latent_dim, mask_zero = True)(encoder_inputs)"
5664,E:\DATN\dataframe\train_file\65.txt,"encoder_lstm = LSTM(latent_dim, return_state=True)"
5665,E:\DATN\dataframe\train_file\65.txt,"encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
5666,E:\DATN\dataframe\train_file\65.txt,# We discard `encoder_outputs` and only keep the states.
5667,E:\DATN\dataframe\train_file\65.txt,"encoder_states = [state_h, state_c]"
5668,E:\DATN\dataframe\train_file\65.txt,Gồm các layer:
5669,E:\DATN\dataframe\train_file\65.txt,Input layer: decoder_input_data
5670,E:\DATN\dataframe\train_file\65.txt,Embedding layer
5671,E:\DATN\dataframe\train_file\65.txt,LSTM layer: nhận đầu vào từ embedding layer và encoder states.
5672,E:\DATN\dataframe\train_file\65.txt,Set return_seq=True vì ta cần decoder output sau mỗi timestep để predict token tiếp theo.
5673,E:\DATN\dataframe\train_file\65.txt,Set return_state=True để lấy internal state dùng khi inference.
5674,E:\DATN\dataframe\train_file\65.txt,"Dense layer: số node là số lượng từ vựng trong ngôn ngữ đích, hàm kích hoạt là softmax để predict ra token tiếp theo sau mỗi timestep."
5675,E:\DATN\dataframe\train_file\65.txt,"# Set up the decoder, using `encoder_states` as initial state."
5676,E:\DATN\dataframe\train_file\65.txt,"decoder_inputs = Input(shape=(None,))"
5677,E:\DATN\dataframe\train_file\65.txt,"dec_emb_layer = Embedding(vi_size+1, latent_dim, mask_zero = True)"
5678,E:\DATN\dataframe\train_file\65.txt,dec_emb = dec_emb_layer(decoder_inputs)
5679,E:\DATN\dataframe\train_file\65.txt,"# We set up our decoder to return full output sequences,"
5680,E:\DATN\dataframe\train_file\65.txt,# and to return internal states as well.
5681,E:\DATN\dataframe\train_file\65.txt,We don't use the
5682,E:\DATN\dataframe\train_file\65.txt,"# return states in the training model, but we will use them in inference."
5683,E:\DATN\dataframe\train_file\65.txt,"decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)"
5684,E:\DATN\dataframe\train_file\65.txt,"decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)"
5685,E:\DATN\dataframe\train_file\65.txt,"decoder_dense = Dense(vi_size+1, activation='softmax')"
5686,E:\DATN\dataframe\train_file\65.txt,decoder_outputs = decoder_dense(decoder_outputs)
5687,E:\DATN\dataframe\train_file\65.txt,Compile và run model:
5688,E:\DATN\dataframe\train_file\65.txt,"model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
5689,E:\DATN\dataframe\train_file\65.txt,"model.fit_generator(generator = generate_batch(trainX, trainY, batch_size = batch_size),"
5690,E:\DATN\dataframe\train_file\65.txt,"                    steps_per_epoch = train_samples//batch_size,"
5691,E:\DATN\dataframe\train_file\65.txt,"                    validation_data = generate_batch(testX, testY, batch_size = batch_size),"
5692,E:\DATN\dataframe\train_file\65.txt,"                    validation_steps = val_samples//batch_size,"
5693,E:\DATN\dataframe\train_file\65.txt,Epoch 200/200
5694,E:\DATN\dataframe\train_file\65.txt,14/14 [==============================] - 11s 819ms/step - loss: 0.0049 - acc: 0.9980 - val_loss: 0.4400 - val_acc: 0.7955
5695,E:\DATN\dataframe\train_file\65.txt,Các bước inference:
5696,E:\DATN\dataframe\train_file\65.txt,Truyền chuỗi đầu vào vào mô hình encoder để lấy ra hidden state và cell state của mạng LSTM
5697,E:\DATN\dataframe\train_file\65.txt,Mô hình decoder sẽ predict ra từng token một.
5698,E:\DATN\dataframe\train_file\65.txt,Input trong bước đầu tiên của decoder là hidden state + cell state của encoder (hay còn gọi là context vector) và token bắt đầu câu <bos>
5699,E:\DATN\dataframe\train_file\65.txt,Token output của decoder sẽ được truyền vào như input của decoder trong time step tiếp theo.
5700,E:\DATN\dataframe\train_file\65.txt,"Trong mỗi time step, decoder sẽ trả ra một one-hot encoded vector."
5701,E:\DATN\dataframe\train_file\65.txt,Ta áp dụng hàm np.argmax để lấy ra chỉ số của token và convert ngược lại về từ trong ngôn ngữ đích.
5702,E:\DATN\dataframe\train_file\65.txt,Lặp lại đến khi gặp token kết thúc câu <eos> hoặc vượt quá số lượng từ.
5703,E:\DATN\dataframe\train_file\65.txt,Define inference model
5704,E:\DATN\dataframe\train_file\65.txt,"# Encode the input sequence to get the ""Context vectors"""
5705,E:\DATN\dataframe\train_file\65.txt,"encoder_model = Model(encoder_inputs, encoder_states)"
5706,E:\DATN\dataframe\train_file\65.txt,# Decoder setup
5707,E:\DATN\dataframe\train_file\65.txt,# Below tensors will hold the states of the previous time step
5708,E:\DATN\dataframe\train_file\65.txt,"decoder_state_input_h = Input(shape=(latent_dim,))"
5709,E:\DATN\dataframe\train_file\65.txt,"decoder_state_input_c = Input(shape=(latent_dim,))"
5710,E:\DATN\dataframe\train_file\65.txt,"decoder_state_input = [decoder_state_input_h, decoder_state_input_c]"
5711,E:\DATN\dataframe\train_file\65.txt,# Get the embeddings of the decoder sequence
5712,E:\DATN\dataframe\train_file\65.txt,dec_emb2= dec_emb_layer(decoder_inputs)
5713,E:\DATN\dataframe\train_file\65.txt,"# To predict the next word in the sequence, set the initial states to the states from the previous time step"
5714,E:\DATN\dataframe\train_file\65.txt,"decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_input)"
5715,E:\DATN\dataframe\train_file\65.txt,"decoder_states2 = [state_h2, state_c2]"
5716,E:\DATN\dataframe\train_file\65.txt,# A dense softmax layer to generate prob dist.
5717,E:\DATN\dataframe\train_file\65.txt,over the target vocabulary
5718,E:\DATN\dataframe\train_file\65.txt,decoder_outputs2 = decoder_dense(decoder_outputs2)
5719,E:\DATN\dataframe\train_file\65.txt,# Final decoder model
5720,E:\DATN\dataframe\train_file\65.txt,decoder_model = Model(
5721,E:\DATN\dataframe\train_file\65.txt,"    [decoder_inputs] + decoder_state_input,"
5722,E:\DATN\dataframe\train_file\65.txt,    [decoder_outputs2] + decoder_states2)
5723,E:\DATN\dataframe\train_file\65.txt,Inference lookup
5724,E:\DATN\dataframe\train_file\65.txt,def decode_sequence(input_seq):
5725,E:\DATN\dataframe\train_file\65.txt,    # Encode the input as state vectors.
5726,E:\DATN\dataframe\train_file\65.txt,    states_value = encoder_model.predict(input_seq)
5727,E:\DATN\dataframe\train_file\65.txt,    # Generate empty target sequence of length 1.
5728,E:\DATN\dataframe\train_file\65.txt,"    target_seq = np.zeros((1,1))"
5729,E:\DATN\dataframe\train_file\65.txt,    # Populate the first character of target sequence with the start character.
5730,E:\DATN\dataframe\train_file\65.txt,"    target_seq[0, 0] = vi_vocabulary[bos]"
5731,E:\DATN\dataframe\train_file\65.txt,"    # Sampling loop for a batch of sequences (to simplify, here we assume a batch of size 1)."
5732,E:\DATN\dataframe\train_file\65.txt,    stop_condition = False
5733,E:\DATN\dataframe\train_file\65.txt,    # greedy search
5734,E:\DATN\dataframe\train_file\65.txt,    while not stop_condition:
5735,E:\DATN\dataframe\train_file\65.txt,"        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)"
5736,E:\DATN\dataframe\train_file\65.txt,        # Sample a token
5737,E:\DATN\dataframe\train_file\65.txt,"        sampled_token_index = np.argmax(output_tokens[0, -1, :])"
5738,E:\DATN\dataframe\train_file\65.txt,        sampled_word =vi_vocabulary_reverse[sampled_token_index]
5739,E:\DATN\dataframe\train_file\65.txt,        decoded_sentence += ' '+ sampled_word
5740,E:\DATN\dataframe\train_file\65.txt,        # Exit condition: either hit max length or find stop character.
5741,E:\DATN\dataframe\train_file\65.txt,        if (sampled_word == eos or
5742,E:\DATN\dataframe\train_file\65.txt,           len(decoded_sentence) > 100):
5743,E:\DATN\dataframe\train_file\65.txt,            stop_condition = True
5744,E:\DATN\dataframe\train_file\65.txt,        # Update the target sequence (of length 1).
5745,E:\DATN\dataframe\train_file\65.txt,"        target_seq = np.zeros((1,1))"
5746,E:\DATN\dataframe\train_file\65.txt,"        target_seq[0, 0] = sampled_token_index"
5747,E:\DATN\dataframe\train_file\65.txt,        # Update states
5748,E:\DATN\dataframe\train_file\65.txt,"        states_value = [h, c]"
5749,E:\DATN\dataframe\train_file\65.txt,    return decoded_sentence
5750,E:\DATN\dataframe\train_file\65.txt,Thử in ra một vài kết quả trong tập test nào:
5751,E:\DATN\dataframe\train_file\65.txt,"test_gen = generate_batch(testX, testY, batch_size = 1)"
5752,E:\DATN\dataframe\train_file\65.txt,"(input_seq, actual_output), _ = next(test_gen)"
5753,E:\DATN\dataframe\train_file\65.txt,decoded_sentence = decode_sequence(input_seq)
5754,E:\DATN\dataframe\train_file\65.txt,"print('Input Source sentence:', ''.join([ja_vocabulary_reverse[i] for i in input_seq[0]]))"
5755,E:\DATN\dataframe\train_file\65.txt,"print('Actual Target Translation:', ' '.join([vi_vocabulary_reverse[i] for i in actual_output[0]]))"
5756,E:\DATN\dataframe\train_file\65.txt,"print('Predicted Target Translation:', decoded_sentence)"
5757,E:\DATN\dataframe\train_file\65.txt,Input Source sentence: あなたはいつからラテン語を勉強しましたか。
5758,E:\DATN\dataframe\train_file\65.txt,Actual Target Translation: <bos> anh học tiếng la - tinh từ bao_giờ ?
5759,E:\DATN\dataframe\train_file\65.txt,Predicted Target Translation:  anh học tiếng la - tinh từ bao_giờ ?
5760,E:\DATN\dataframe\train_file\65.txt,Input Source sentence: 私は彼の威嚇をぜんぜん怖くない。
5761,E:\DATN\dataframe\train_file\65.txt,Actual Target Translation: <bos> tôi hoàn_toàn không sợ những sự đe_dọa của hắn .
5762,E:\DATN\dataframe\train_file\65.txt,Predicted Target Translation:  tôi hoàn_toàn không sợ những sự đe_dọa của hắn .
5763,E:\DATN\dataframe\train_file\65.txt,Input Source sentence: 私の弟は上手にギターを弾けます。
5764,E:\DATN\dataframe\train_file\65.txt,Actual Target Translation: <bos> em_trai tôi chơi ghi - ta rất giỏi .
5765,E:\DATN\dataframe\train_file\65.txt,Predicted Target Translation:  em_trai tôi chơi ghi - ta rất giỏi .
5766,E:\DATN\dataframe\train_file\65.txt,Input Source sentence: 豚は小屋にいない。
5767,E:\DATN\dataframe\train_file\65.txt,Actual Target Translation: <bos> lợn không có ở trong chuồng .
5768,E:\DATN\dataframe\train_file\65.txt,Predicted Target Translation:  tôi không nghĩ như_vậy .
5769,E:\DATN\dataframe\train_file\65.txt,Input Source sentence: 彼は彼女にチョコレートを買ってあげた。
5770,E:\DATN\dataframe\train_file\65.txt,Actual Target Translation: <bos> anh ta đã mua cho cô ấy sô cô la .
5771,E:\DATN\dataframe\train_file\65.txt,Predicted Target Translation:  anh ấy đã thổ_lộ là thích tôi .
5772,E:\DATN\dataframe\train_file\65.txt,Input Source sentence: 私は彼が野球をするのを見た。
5773,E:\DATN\dataframe\train_file\65.txt,Actual Target Translation: <bos> tôi đã xem anh ấy chơi bóng_chày .
5774,E:\DATN\dataframe\train_file\65.txt,Predicted Target Translation:  tôi đã xem anh ấy chơi bóng_chày .
5775,E:\DATN\dataframe\train_file\65.txt,Input Source sentence: 遅れてごめん。
5776,E:\DATN\dataframe\train_file\65.txt,Actual Target Translation: <bos> xin_lỗi tôi đến trễ .
5777,E:\DATN\dataframe\train_file\65.txt,Predicted Target Translation:  xin_lỗi tôi đến trễ .
5778,E:\DATN\dataframe\train_file\65.txt,Từ một số kết quả in ra ở trên có thể thấy mô hình của chúng ta đã dự đoán khá ổn cho phần lớn các câu.
5779,E:\DATN\dataframe\train_file\65.txt,Kể cả với những câu dự đoán sai thì câu output cũng có ý nghĩa.
5780,E:\DATN\dataframe\train_file\65.txt,Như vậy trong bài này mình đã giới thiệu các bước để xây dựng một mô hình dịch máy cơ bản cho tiếng Nhật -> tiếng Việt.
5781,E:\DATN\dataframe\train_file\65.txt,Ở bài tiếp theo mình sẽ tiếp tục cải thiện mô hình này.
5782,E:\DATN\dataframe\train_file\65.txt,"Cảm ơn các bạn đã đọc và nếu có góp ý, câu hỏi gì các bạn có thể trao đổi thêm ở comment nhé!"
5783,E:\DATN\dataframe\train_file\66.txt,Tìm hiểu về Autoencoder
5784,E:\DATN\dataframe\train_file\66.txt,"Làm về xử lý ảnh, chắc hẳn các bạn sẽ bắt gặp 1 số bài toán như tái tạo ảnh, giảm nhiễu ảnh, làm sáng ảnh, hay bài toàn giảm chiều dữ liệu, … Gặp các bài toán này thì cũng có khá nhiều phương pháp để xử lý, với cá nhân mình thì mình nghỉ ngày tới kỹ thuật Autoencoder."
5785,E:\DATN\dataframe\train_file\66.txt,"Lướt một vòng google search thì mình chỉ tìm thấy các bài viết nước ngoài hoặc 1 số blog của các anh Việt Nam, còn Viblo thì chưa thấy, nên mình quyết định góp chút sức để làm phòng phú thêm cộng đồng Viblo"
5786,E:\DATN\dataframe\train_file\66.txt,Cùng tìm hiểu về Autoencoder nào!
5787,E:\DATN\dataframe\train_file\66.txt,Autoencoder là gì?
5788,E:\DATN\dataframe\train_file\66.txt,“An autoencoder is a type of artificial neural network used to learn data encodings in an unsupervised manner.”
5789,E:\DATN\dataframe\train_file\66.txt,"Autoencoder là mạng ANN có khả năng học hiệu quả các biểu diễn của dữ liệu đầu vào mà không cần nhãn, nói cách khác, giả sử từ một hình ảnh có thể tái tạo ra một bức ảnh có liên quan chặt chẽ với bức ảnh đầu vào đó."
5790,E:\DATN\dataframe\train_file\66.txt,"Đầu vào loại mạng neural này không có nhãn, tức là mạng có khả năng học không giám sát (Unsupervised Learning)"
5791,E:\DATN\dataframe\train_file\66.txt,"Đầu vào được mạng mã hóa để chỉ tập trung vào các đặc trưng quan trọng nhất, tùy vào bài toán cụ thể."
5792,E:\DATN\dataframe\train_file\66.txt,"Các biểu diễn (coding) thường có chiều nhỏ hơn so với input của Autoencoder, đó là lý do Autoencoder có thể dùng trong các bài toán giảm chiều dữ liệu hoặc trích xuất đặc trưng."
5793,E:\DATN\dataframe\train_file\66.txt,"Bên cạnh đó, Autoencoder còn có thể được sử dụng để tạo ra các mô hình học tập trung (Generative learning models), ví dụ như huấn luyện một tập hợp các khuôn mặt để tạo ra các khuôn mặt mới"
5794,E:\DATN\dataframe\train_file\66.txt,"Tham khảo một số bài viết, mình có thấy các tác giả nói rằng mục đích của Autoencoder là cố gắng học vào tạo ra ouput giống với input nhất có thể dựa vào việc tập trung vào các đặc trưng cần thiết."
5795,E:\DATN\dataframe\train_file\66.txt,"Tuy nhiên các bạn cẩn thận kẻo nhầm, tùy các bài toán cụ thể, ví dự như làm nét ảnh, làm mờ ảnh, hay kéo sáng ảnh mà đầu ra và đầu vào sẽ giống về nội dung chứ giá trị thì không hẳn."
5796,E:\DATN\dataframe\train_file\66.txt,"Chứ không phải là ảnh đầu ra và đầu vào phải giống hệt nhau cho mọi bài toán được, thế thì copy paste cho lành chứ Autoencoder với Deep Learning làm gì cho khổ?"
5797,E:\DATN\dataframe\train_file\66.txt,Kiến trúc của Autoencoder
5798,E:\DATN\dataframe\train_file\66.txt,Autoencoder bao gồm 3 phần chính
5799,E:\DATN\dataframe\train_file\66.txt,"Encoder: Module có nhiệm vụ nén dữ liệu đầu vòa thành một biễu diễn được mã hóa (coding), thường nhỏ hơn một vài bậc so với dữ liệu đầu vào"
5800,E:\DATN\dataframe\train_file\66.txt,"Bottleneck: Module chứa các biểu diễn tri thức được nén (chính là output của Encoder), đây là phần quan trọng nhất của mạng bới nó mang đặc trưng của đầu vào, có thể dùng để tái tạo ảnh, lấy đặc trưng của ảnh, …."
5801,E:\DATN\dataframe\train_file\66.txt,"Decoder: Module giúp mạng giải nén các biểu diễn tri thức và tái cấu trúc lại dữ liệu từ dạng mã hóa của nó, mô hình học dựa trên việc so sánh đầu ra của Decoder với đầu vào ban đầu (Input của Encoder)"
5802,E:\DATN\dataframe\train_file\66.txt,Autoencoder hoạt động như thế nào?
5803,E:\DATN\dataframe\train_file\66.txt,"Để tìm hiểu về cách thức hoạt động của Autoencoder, trước hết chúng ta sẽ cùng tìm hiểu về mối liên quan giữa các khối Encoder, Bottleneck và Decoder"
5804,E:\DATN\dataframe\train_file\66.txt,"Bao gồm một tập gợp các convolutional blocks, theo sau là các polling modules giúp cho việc nén đầu vào của mô hình thành một phần nhỏ gọn hơn, được gọi là Bottleneck."
5805,E:\DATN\dataframe\train_file\66.txt,Ở đây thì ngoài việc sử dụng các Convolutional + Pooling thì có thể chỉ cần sử dụng các khối fully connected tùy vào đầu vào và bài toán yêu cầu.
5806,E:\DATN\dataframe\train_file\66.txt,"Ví dụ bài toán làm mờ chữ số viết tay, thì chỉ cần một vài lớp Fully connected cũng đã làm rất tốt nhiệm vụ của mình rồi Tiếp đến, với đầu ra là Bottleneck, bộ Decoder sẽ giải mã bằng một loạt các module Upsampling (hoặc Fully Connected) để đưa đặc trưng nén về dạng hình ảnh."
5807,E:\DATN\dataframe\train_file\66.txt,"Trong các bài toán đơn giản thì đầu ra được mong đợi là giống với đầu vào (nhiễu hơn hoặc nét hơn, …) Tuy nhiên với các bài toán cao hơn thì ảnh đầu ra mong muốn là một ảnh hoàn toàn mới, mang một mối liên hệ chặt chẽ với ảnh đầu vào, được hình thành từ đặc trưng của ảnh đầu vào đã cung cấp"
5808,E:\DATN\dataframe\train_file\66.txt,"Phần quan trọng nhất cảu Autoencoder, cũng là phần mang kích thước nhỏ nhất Bởi Bottleneck được thiết kế từ việc mã hóa tối đa thông tin của ảnh đầu vào, vậy nên có thể nói rằng bottleneck mang đặc trưng, chi thức của ảnh đầu vào Với cấu trúc mã hóa – giải mã, mô hình trích xuất được đặc trưng của ảnh dưới dạng dữ liệu và thiết lập được mối tương quan giữa input và output của mạng Với việc Bottleneck có kichc thước nhỏ hơn ảnh đầu vào cũng như mang nhiều thông tin đặc trưng giúp ngăn cản mạng ghi nhớ quá nhiều."
5809,E:\DATN\dataframe\train_file\66.txt,"Bottle neck càng nhỏ, tủi ro overfitting càng thấp, tuy nhiên nếu kích thước Bottleneck quá nhỏ sẽ hạn chế khả năng lưu trữ thông tin của ảnh đầu vào, gây khó khăn cho việc giải mã ở khối Decoder"
5810,E:\DATN\dataframe\train_file\66.txt,"Khối cuối cùng, mang nhiệp vụ giải mã từ Bottleneck để tái tạo lại hình ảnh đầu vào dựa vào các đặc trưng “tiềm ẩn” bên trong Bottleneck"
5811,E:\DATN\dataframe\train_file\66.txt,Một số Hyper-parameter quan trong trong Autoencoder
5812,E:\DATN\dataframe\train_file\66.txt,Các bạn cần phân biệt Hyperparameter và parameter nhé.
5813,E:\DATN\dataframe\train_file\66.txt,Một bài viết về các hiểu nhầm trong Machien Learning mình để để các bạn tham khảo
5814,E:\DATN\dataframe\train_file\66.txt,Có 4 hyperparameters cần quan tâm trước khi training một mô hình Autoencoder:
5815,E:\DATN\dataframe\train_file\66.txt,Code size: kích thước của Bottleneck là 1 hyperparameter rất quan trọng được sử dụng mà chúng ta cần lưu ý. Kích thước Bottleneck quyết định lượng thông tin được nén.
5816,E:\DATN\dataframe\train_file\66.txt,“Nhiều quá không tốt mà ít quá cũng không ổn”
5817,E:\DATN\dataframe\train_file\66.txt,"Number of layers: giống với hầu hết các mạng neural, một hyperparameter quan trọng để điều chỉnh độ sâu của encoder và decoder trong Autoencoder, càng sâu thì mô hình càng phức tạp, nhưng càng nông thì mô hình chạy càng nhanh, càng light weights"
5818,E:\DATN\dataframe\train_file\66.txt,Number of nodes per layer: Số lượng nodes trên 1 layer quyết định số weights ra sẽ sử dụng trên từng layer.
5819,E:\DATN\dataframe\train_file\66.txt,"Thông thường, số lượng nút này giảm dần theo mỗi lớp tiếp theo bởi đầu vào của lớp này là đầu ra của lớp trước đó, và đầu vào này thì dần trở nên nhỏ hơn trên các lớp"
5820,E:\DATN\dataframe\train_file\66.txt,Reconstruction Loss: Loss function là một thức không thể thiếu trong mạng neural.
5821,E:\DATN\dataframe\train_file\66.txt,Hàm loss này sẽ phụ thuộc vào kiểu input và oupt của mô hình chúng ta muốn đáp ứng.
5822,E:\DATN\dataframe\train_file\66.txt,"Ví dụ với việc xử lý ảnh, các hàm loss thông thường được ưa chuộng là Mean Square Error (MSE) và L1 Loss."
5823,E:\DATN\dataframe\train_file\66.txt,"Còn với một số trường hợp ảnh nhị phân (MNIST), chúng ta có thể sử dụng Binary Cross Entropy sẽ tốt hơn."
5824,E:\DATN\dataframe\train_file\66.txt,"Như vậy, trong khuôn khổ bài viết đã khá là nhiều chữ và code tutorial thì chả thầy đâu thì mình nghỉ đọc vậy đã đủ rồi."
5825,E:\DATN\dataframe\train_file\66.txt,Bài viết này mình mong muốn mang tới một cái nhìn tổng quan về Autoencoder cho người mới để hiểu hơn về nó mà biết vận dụng cho bài toán của mình.
5826,E:\DATN\dataframe\train_file\66.txt,"Code tutorial thì trên mạng có nhiều lắm, các bạn có thể tham khảo."
5827,E:\DATN\dataframe\train_file\66.txt,"Trong bài viết tới mình sẽ tìm hiểu tiếp về 5 kiểu Autoencoder, mong cách bạn sẽ ủng hộ."
5828,E:\DATN\dataframe\train_file\67.txt,Một số kiến thức cơ bản về Text2Speech
5829,E:\DATN\dataframe\train_file\67.txt,Hello mọi người.
5830,E:\DATN\dataframe\train_file\67.txt,"Trước hết, mình xin cảm ơn mọi người vì đã theo dõi những bài viết của mình trong suốt hai năm vừa qua."
5831,E:\DATN\dataframe\train_file\67.txt,"Nhân dịp đầu xuân năm mới, mình chúc mọi người một năm mới tiền, tài, sức khỏe phát triển mạnh mẽ như em Dần."
5832,E:\DATN\dataframe\train_file\67.txt,"Chả là thế này từ ngày bắt đầu hành trình học tập và làm việc với bộ môn ML (viết tắt của Machine Learning mọi người nhé  ) đến nay cũng khoảng 2 năm rưỡi có lẻ, mình hầu hết học kiến thức về mảng thị giác máy tính."
5833,E:\DATN\dataframe\train_file\67.txt,"Mình nghĩ đến lúc bản thân cần một cái gì đó mới mẻ nên nhân dịp đầu xuân năm mới, mình thử tập tành về lĩnh vực Xử lý tiếng nói cụ thể hơn trong bài viết này là Text2Speech."
5834,E:\DATN\dataframe\train_file\67.txt,"Lĩnh vực mới, kiến thức mới nên có thể có những sai xót nhưng với mục đích chia sẻ, trao đổi kiến thức, hy vọng các bạn đọc góp ý để mình có các bài viết về chủ đề này hoàn thiện hơn."
5835,E:\DATN\dataframe\train_file\67.txt,Text to Speech và ứng dụng.
5836,E:\DATN\dataframe\train_file\67.txt,Text to speech là công nghệ chuyển đổi văn bản thành giọng nói.
5837,E:\DATN\dataframe\train_file\67.txt,Công nghệ này đã được sử dụng trong nhiều ứng dụng trong đời hằng ngày:
5838,E:\DATN\dataframe\train_file\67.txt,Sách nói cho người khiếm thị
5839,E:\DATN\dataframe\train_file\67.txt,"Đọc ngoại ngữ như google translate, ..."
5840,E:\DATN\dataframe\train_file\67.txt,Tổng đài tự động
5841,E:\DATN\dataframe\train_file\67.txt,"Text2Speech có lẽ đã không còn mới và đã có nhiều nghiên cứu, giải pháp được đề cập."
5842,E:\DATN\dataframe\train_file\67.txt,Và chắc chắn không thể không nhắc đến hai kiến trúc Tacotron và Tacotron2.
5843,E:\DATN\dataframe\train_file\67.txt,Hai kiến trúc này là một trong những kiến trúc nền tảng phát triển công nghệ Text2Speech sau này.
5844,E:\DATN\dataframe\train_file\67.txt,"Trong series này, mình sẽ cùng đi xem qua tổng quan hai em này nhé."
5845,E:\DATN\dataframe\train_file\67.txt,Một số kiến thức cơ bản
5846,E:\DATN\dataframe\train_file\67.txt,"Trước khi đi vào nội dung của bài nghiên cứu các kiến trúc cụ thể, mình cùng các bạn tìm hiểu một số kiến thức cơ bản liên quan nhé."
5847,E:\DATN\dataframe\train_file\67.txt,Human Speech
5848,E:\DATN\dataframe\train_file\67.txt,Cách tạo ra âm thanh của con người.
5849,E:\DATN\dataframe\train_file\67.txt,Giọng nói được tạo ra bởi các sóng âm thanh được tạo ra bởi một loại các bộ phận trong cơ thể thể con người được miêu tả như hình dưới đây:
5850,E:\DATN\dataframe\train_file\67.txt,Âm thanh được tạo ra bởi con người được chia ra làm hai âm:
5851,E:\DATN\dataframe\train_file\67.txt,Âm hữu thanh
5852,E:\DATN\dataframe\train_file\67.txt,Âm vô thanh
5853,E:\DATN\dataframe\train_file\67.txt,Đặc điểm chung cách tạo hai âm thanh này là đều do không khí được đẩy từ phổi (lung) đi qua khí quản (trachea) lên thanh hầu (larynx).
5854,E:\DATN\dataframe\train_file\67.txt,Bên trong thanh hầu có các dây thanh (vocal fold/cords).
5855,E:\DATN\dataframe\train_file\67.txt,Tuỳ vào vị trạng thái dây thanh khép hay mở sẽ tạo ra âm hữu thanh hoặc âm vô thanh:
5856,E:\DATN\dataframe\train_file\67.txt,"Âm hữu thanh: Khi các dây thanh khép lại, không khí được đẩy từ phổi sẽ tách các dây thanh quản dãn ra liên tục tạo ra hiệu ứng rung động tạo nên âm hữu thanh."
5857,E:\DATN\dataframe\train_file\67.txt,"Âm vô thanh: Khi các dây thanh quản mở ra, không khí từ phổi đẩy đi qua dây thanh quản không bị cản tạo nên âm vô thanh."
5858,E:\DATN\dataframe\train_file\67.txt,Âm vị (Phonemes)
5859,E:\DATN\dataframe\train_file\67.txt,Đơn vị cơ bản nhất của âm thanh.
5860,E:\DATN\dataframe\train_file\67.txt,"Nếu thay đổi âm vị, nghĩa của từ cũng sẽ thay đổi."
5861,E:\DATN\dataframe\train_file\67.txt,"""pat"" -> ""bat"""
5862,E:\DATN\dataframe\train_file\67.txt,"""pat"" -> ""pam"""
5863,E:\DATN\dataframe\train_file\67.txt,"Formant là các tần số cộng hưởng của tuyến phát âm liên quan trực tiếp đến hình dạng, kích thước của cơ quan phát âm nên cung cấp nhiều thông tin đến người nói."
5864,E:\DATN\dataframe\train_file\67.txt,Đặc tính của âm thanh
5865,E:\DATN\dataframe\train_file\67.txt,Âm thanh có 4 đặc tính:
5866,E:\DATN\dataframe\train_file\67.txt,Cao độ (pitch)
5867,E:\DATN\dataframe\train_file\67.txt,Trường độ (duration)
5868,E:\DATN\dataframe\train_file\67.txt,Cường độ (amplitude)
5869,E:\DATN\dataframe\train_file\67.txt,"Âm sắc (timbre, tone color)"
5870,E:\DATN\dataframe\train_file\67.txt,Cao độ: đặc trưng độ trầm hoặc bổng của âm thanh.
5871,E:\DATN\dataframe\train_file\67.txt,Nốt nhạc thấp cao là kí hiệu biễu diễn cao độ của âm thanh
5872,E:\DATN\dataframe\train_file\67.txt,Trường độ: Một âm thanh có thể ngân dài hoặc ngắn.
5873,E:\DATN\dataframe\train_file\67.txt,Người ta dùng hình nốt khác nhau để định trường độ của âm.
5874,E:\DATN\dataframe\train_file\67.txt,Cường độ: đặc trưng cho tính mạnh hoặc yếu của âm thanh.
5875,E:\DATN\dataframe\train_file\67.txt,"Âm sắc Mỗi giọng hát, mỗi loại đàn có âm sắc riêng biệt (sáng - tối, trong - đục)."
5876,E:\DATN\dataframe\train_file\67.txt,Đặc trưng cho tính chất đó người ta gọi là âm sắc.
5877,E:\DATN\dataframe\train_file\67.txt,Tín hiệu là một đại lượng vật lý biếu diễn thông tin.
5878,E:\DATN\dataframe\train_file\67.txt,Ví dụ: Tín hiệu audio là do âm thanh phát ra gây thay đổi áp suất không khí khi đến tai chúng ta.
5879,E:\DATN\dataframe\train_file\67.txt,"Khi chúng ta thực hiện lấy mẫu với tần số 44.1kHZ tức khoảng 44100 lần / s, ta sẽ thu được sóng (waveform) biễu diễn sự thay đổi của tín hiệu."
5880,E:\DATN\dataframe\train_file\67.txt,"Chúng ta có thể sửa đổi, phân tích thông tin tín hiệu qua sóng nay bằng máy tính."
5881,E:\DATN\dataframe\train_file\67.txt,Tín hiệu sẽ được phân loại như sau:
5882,E:\DATN\dataframe\train_file\67.txt,Tín hiệu liên tục có biến độc lập của biễu diễn toán học của một tín hiệu là liên tục
5883,E:\DATN\dataframe\train_file\67.txt,Tín hiệu tương tự có biên độ của tín hiệu liên tục là liên tục.
5884,E:\DATN\dataframe\train_file\67.txt,Tín hiệu lượng tử hóa có biên độ của tín hiệu liên tục là rời rạc.
5885,E:\DATN\dataframe\train_file\67.txt,Tín hiệu rời rạc có biến độc lập của biễu diễn toán học của một tín hiệu là rời rạc
5886,E:\DATN\dataframe\train_file\67.txt,Tín hiệu lấy mẫu có biên độ của tín hiệu rời rạc là liên tục và không bị lượng tử hóa.
5887,E:\DATN\dataframe\train_file\67.txt,Tín hiệu số có biên độ của tín hiệu rời rạc là rời rạc.
5888,E:\DATN\dataframe\train_file\67.txt,Fourier Transform
5889,E:\DATN\dataframe\train_file\67.txt,Fourier Transform là một công cụ giúp chuyển đổi tín hiệu từ miền thời gian về một dạng biểu diễn được gọi là spectrum ở miền tần số.
5890,E:\DATN\dataframe\train_file\67.txt,Miền thời gian hay miền tần số đều là các cách biểu diễn của tín hiệu.
5891,E:\DATN\dataframe\train_file\67.txt,Và Fourier Transform là cầu nối trung gian giữa hai biểu diễn này.
5892,E:\DATN\dataframe\train_file\67.txt,Một sự thay đổi của tín hiệu ở miền kia cũng sẽ ảnh hưởng tín hiệu ở miền khác.
5893,E:\DATN\dataframe\train_file\67.txt,Ví dụ chúng ta có một sóng có chu kì T được biếu diễn như dưới đây:
5894,E:\DATN\dataframe\train_file\67.txt,Nguồn: https://www.thefouriertransform.com/series/fourier.php
5895,E:\DATN\dataframe\train_file\67.txt,Công thức Fourier biếu diễn chuỗi này như sau:
5896,E:\DATN\dataframe\train_file\67.txt,g(t) - = \sum _ { m = 0 } ^ { \infty } a _ { m } \cos ( \frac { 2 \pi m t } { T } ) + \sum _ { n = 1 } ^ { \infty } b _ { n } \sin ( \frac { 2 \pi n t } { T } )
5897,E:\DATN\dataframe\train_file\67.txt,g(t)−=
5898,E:\DATN\dataframe\train_file\67.txt,2πmt
5899,E:\DATN\dataframe\train_file\67.txt,2πnt
5900,E:\DATN\dataframe\train_file\67.txt,trong đó:
5901,E:\DATN\dataframe\train_file\67.txt,"a_m, b_n"
5902,E:\DATN\dataframe\train_file\67.txt, là hệ số của chuỗi Fourier.
5903,E:\DATN\dataframe\train_file\67.txt,Discrete Time Fourier Transform
5904,E:\DATN\dataframe\train_file\67.txt,Discrete Time Fourier Transform (DTFT) là phương thức biến đổi giống như Fourier Transform nhưng để giải quyết trong xử lý tín hiệu số.
5905,E:\DATN\dataframe\train_file\67.txt,Ở đây chúng ta sẽ thắc mắc rằng Tại sao chúng ta là sử dụng tín hiệu số thay vì tín hiệu liên tục ?
5906,E:\DATN\dataframe\train_file\67.txt,Vì máy tính chúng ta không thể làm việc với tín hiệu liên tục do đó chúng ta cần phải lấy một số lượng mẫu nhất định thay vì dùng tín hiệu gốc.
5907,E:\DATN\dataframe\train_file\67.txt,Số lượng mẫu này phải biếu diễn được đặc trưng của tín hiệu
5908,E:\DATN\dataframe\train_file\67.txt,Ví dụ ta có một tín hiệu liên tục được biểu diễn ở đồ thị dưới đây.
5909,E:\DATN\dataframe\train_file\67.txt,Chúng ta thực hiện số lần lấy mẫu L = 8 và tốc đốc lấy mẫu r = 8000 mẫu / giây.
5910,E:\DATN\dataframe\train_file\67.txt,Nguồn: https://www.allaboutcircuits.com/technical-articles/an-introduction-to-the-discrete-fourier-transform/
5911,E:\DATN\dataframe\train_file\67.txt,Sau đó chúng ta thực hiện chuẩn hóa
5912,E:\DATN\dataframe\train_file\67.txt,T_s = \frac{1}{f_{s}}
5913,E:\DATN\dataframe\train_file\67.txt,", chúng ta sẽ thu được một chuỗi giá trị rời rạc x(n) biếu diễn cho tín hiệu liên tục x(t):"
5914,E:\DATN\dataframe\train_file\67.txt,Các giá trị bên trên là rời rạc.
5915,E:\DATN\dataframe\train_file\67.txt,Đó chính là lý do chúng ta cần sử DTFT.
5916,E:\DATN\dataframe\train_file\67.txt,Công thức DTFT gồm có hai chiều:
5917,E:\DATN\dataframe\train_file\67.txt,Chiều thuận:
5918,E:\DATN\dataframe\train_file\67.txt,Chiều ngược:
5919,E:\DATN\dataframe\train_file\67.txt,Giải thích toán học.
5920,E:\DATN\dataframe\train_file\67.txt,"Giống như Fourier Transform, chúng ta mong muốn biến đổi chuỗi tín hiệu rời rạc x(n) đại diện cho các tín hiêu liên tục x(t) thành một tập hợp các sóng sin, cos. Hay nói cách khác từ chuỗi tín hiệu rời rạc đầu vào, ta sẽ tìm các hàm sóng biểu diễn cho các giá trị ấy."
5921,E:\DATN\dataframe\train_file\67.txt,) là hàm tuần hoàn với tần số
5922,E:\DATN\dataframe\train_file\67.txt,2\pi
5923,E:\DATN\dataframe\train_file\67.txt,2π.
5924,E:\DATN\dataframe\train_file\67.txt,"Nếu ta lấy N mẫu ở mỗi chu kỳ, khoảng cách giữa hai điểm tần số lấy mẫu là"
5925,E:\DATN\dataframe\train_file\67.txt,2π
5926,E:\DATN\dataframe\train_file\67.txt,"Như vậy tần số của các hàm sin, cos chúng ta mong đợi sẽ có dạng biếu diễn là"
5927,E:\DATN\dataframe\train_file\67.txt,\frac{2\pi}{N} \times k
5928,E:\DATN\dataframe\train_file\67.txt,2π
5929,E:\DATN\dataframe\train_file\67.txt,×k trong đó
5930,E:\DATN\dataframe\train_file\67.txt,"k = 0, 1, ..., N - 1"
5931,E:\DATN\dataframe\train_file\67.txt,"k=0,1,...,N−1."
5932,E:\DATN\dataframe\train_file\67.txt,Ta có biếu diễn tín hiệu x(n) dưới dạng số phức như dưới đây.
5933,E:\DATN\dataframe\train_file\67.txt,"Nếu các bạn chưa rõ về biếu diễn chuỗi Fourier với số phức, các bạn có thể tìm hiểu tại bài ."
5934,E:\DATN\dataframe\train_file\67.txt,"Với các giá trị L, N và chuỗi giá trị x(n) đã được biết trước, chúng ta có thể giải N giá trị X' bằng hệ phương trình sau:"
5935,E:\DATN\dataframe\train_file\67.txt,"Sử dụng ngay chuỗi giá trị x(n) rời rạc được trình bày ở phần 3.1 Khái niệm, ta sẽ tính được các giá trị X'(k) như sau:"
5936,E:\DATN\dataframe\train_file\67.txt,"Thay các giá trị X'(k) vào, cuối cùng ta tìm được biểu diễn tín hiệu x(n) như sau:"
5937,E:\DATN\dataframe\train_file\67.txt,x ( n ) = s i n ( \frac { 2 \pi } { 8 } n ) + 0 .
5938,E:\DATN\dataframe\train_file\67.txt,1 2 5 s i n ( \frac { 4 \pi } { 8 } n ) + 0 .
5939,E:\DATN\dataframe\train_file\67.txt,2 1 6 6 c o s ( \frac { 4 \pi } { 8 } n ) = s i n ( \frac { 4 \pi } { 8 } n ) = s i n ( \frac { 4 \pi } { 8 } n + 3\frac{\pi}{3})
5940,E:\DATN\dataframe\train_file\67.txt,2π
5941,E:\DATN\dataframe\train_file\67.txt,4π
5942,E:\DATN\dataframe\train_file\67.txt,4π
5943,E:\DATN\dataframe\train_file\67.txt,4π
5944,E:\DATN\dataframe\train_file\67.txt,4π
5945,E:\DATN\dataframe\train_file\67.txt,"Như vậy thông qua biến đổi DTFT, tín hiệu rời rạc ban đầu có thể biễu diễn ở dạng spectrum ở miền tần số."
5946,E:\DATN\dataframe\train_file\67.txt,Phần này mình đọc tài liệu và tham khảo tại bài viết .
5947,E:\DATN\dataframe\train_file\67.txt,Các bạn muốn xem chi tiết hơn thì tham khảo bài trên nhé.
5948,E:\DATN\dataframe\train_file\67.txt,Fast Fourier Transform
5949,E:\DATN\dataframe\train_file\67.txt,Fast Fourier Transform (FFT) chức năng giống như DTFT.
5950,E:\DATN\dataframe\train_file\67.txt,"Tuy nhiên, hiệu quả và nhanh hơn nhiều do giảm được chi phí cho các phép tính toán."
5951,E:\DATN\dataframe\train_file\67.txt,"Theo như bài viết , để thực hiện một phép tính với N giá trị lấy mẫu ta cần"
5952,E:\DATN\dataframe\train_file\67.txt, phép nhân và
5953,E:\DATN\dataframe\train_file\67.txt,N(4N - 2)
5954,E:\DATN\dataframe\train_file\67.txt,N(4N−2) phép cộng.
5955,E:\DATN\dataframe\train_file\67.txt,Có thể thấy chi phí tính toán này tỉ lệ thuận với
5956,E:\DATN\dataframe\train_file\67.txt, nên khi giá trị N tăng thì chi phí tính toán sẽ bị tăng lên rất nhiều.
5957,E:\DATN\dataframe\train_file\67.txt,Nguồn: https://www.allaboutcircuits.com/technical-articles/an-introduction-to-the-fast-fourier-transform/
5958,E:\DATN\dataframe\train_file\67.txt,Đó chính là lý do FFT được ra đời.
5959,E:\DATN\dataframe\train_file\67.txt,FFT phân tách N-point DFT thành các DFT có số điểm ít hơn.
5960,E:\DATN\dataframe\train_file\67.txt,"Ví dụ thực hiện phân tách 1024-point DFT thành 2 512-point DFT, qua đó giảm số phép nhân từ 4,194,304 xuống 2,097,152."
5961,E:\DATN\dataframe\train_file\67.txt,"Tìm hiểu thêm về FFT, các bạn có thể tham khảo bài viết này nhé."
5962,E:\DATN\dataframe\train_file\67.txt,Hầu hết các tín hiệu hay gặp đều không tuần hoàn ví dụ như tín hiệu âm thanh hoặc tiếng nói trong khi Fourier Transform chỉ xử lý cho tín hiệu tuần hoàn.
5963,E:\DATN\dataframe\train_file\67.txt,Và từ đây ý tưởng dùng FFT cho từng đoạn nhỏ hơn được ra đời.
5964,E:\DATN\dataframe\train_file\67.txt,Ở đây mình có một số khái niệm như sau:
5965,E:\DATN\dataframe\train_file\67.txt,Window length: Chiều dài cố định các khoảng mà FFT chia tín hiệu.
5966,E:\DATN\dataframe\train_file\67.txt,Hop length: Chiều dài phần không giao nhau giữa hai window.
5967,E:\DATN\dataframe\train_file\67.txt,Overlap length: Chiều dài của phần giao nhau giữa hai window.
5968,E:\DATN\dataframe\train_file\67.txt,"Để biểu diễn kết quả tính của FFT, ta dùng một khái niệm gọi là Spectrogram."
5969,E:\DATN\dataframe\train_file\67.txt,Spectrogram là biễu diễn kết quả của nhiều FFT trên phần window length.
5970,E:\DATN\dataframe\train_file\67.txt,Mỗi đơn vị trên trục y tương ứng với tần số ở log scale và mỗi đơn vị ở giá trị x tương ứng với window length được dùng để tính FFT.
5971,E:\DATN\dataframe\train_file\67.txt,"Mỗi giá trị (x, y) biểu diễn cường độ tín hiệu ở dB scale tương ứng với window length và tần số."
5972,E:\DATN\dataframe\train_file\67.txt,Mel Scale
5973,E:\DATN\dataframe\train_file\67.txt,Các nghiên cứu đã chỉ ra rằng tai người dễ dàng phân biệt các âm thanh ở tần số 500-1000 Hz.
5974,E:\DATN\dataframe\train_file\67.txt,Tuy nhiên khó phân biệt các âm thanh ở tần số 7500-8000 Hz hoặc nói cách khác là tai người nghe các âm ở vùng tần số này giống nhau.
5975,E:\DATN\dataframe\train_file\67.txt,"Để biếu diễn thang đo phù hợp tai người, chúng ta dùng một thang đo được gọi Mel Scale."
5976,E:\DATN\dataframe\train_file\67.txt,Công thức chuyển đổi từ Hz scale sang Mel scale như sau:
5977,E:\DATN\dataframe\train_file\67.txt,m = 2 5 9 5 \log _ { 1 0 } \left( 1 + { \frac { f } { 7 0 0 } } \right)
5978,E:\DATN\dataframe\train_file\67.txt,Mel Spectrogram
5979,E:\DATN\dataframe\train_file\67.txt,Mel Spectrogram về cơ bản giống như Spectrogram tuy nhiên trục tần số tức là trục x không ở Hz scale mà ở Mel scale để phù hợp với khả năng nghe của con người.
5980,E:\DATN\dataframe\train_file\67.txt,Lời kết.
5981,E:\DATN\dataframe\train_file\67.txt,"Trong bài này, mình đã giới thiệu qua một số kiến thức nền tảng về chủ đề Xử lý giọng nói."
5982,E:\DATN\dataframe\train_file\67.txt,"Việc nắm chắc các kiến thức cơ bản giúp các bạn hiểu rõ hơn cách tạo ra giọng nói, kiến trúc của những thuật toán sau này."
5983,E:\DATN\dataframe\train_file\67.txt,"Ở các bài sau, mình sẽ đi sâu vào phần các thuật toán Text2Speech."
5984,E:\DATN\dataframe\train_file\67.txt,Nếu các bạn thấy bài viết hay thì hãy cho mình một upvote nhé.
5985,E:\DATN\dataframe\train_file\67.txt,😁 Gặp lại các bạn trong các bài về chủ đề này tiếp theo.
5986,E:\DATN\dataframe\train_file\67.txt,Tài liệu tham khảo
5987,E:\DATN\dataframe\train_file\68.txt,[Paper Explain] Reading Race: AI Recognises Patient's Racial Identity In Medical Images
5988,E:\DATN\dataframe\train_file\68.txt,"Trong bài báo  nhóm tác gả đã chỉ ra rằng các mô hình AI có thể học cách phát hiện chủng tộc của ai đó từ nhiều phương thức xử lý hình ảnh khác nhau (bao gồm cả chụp X-quang ngực trắng và đen) và điều này thật kỳ lạ, bởi vì ngay cả những bác sĩ chuyên môn cũng không thể làm được điều này."
5989,E:\DATN\dataframe\train_file\68.txt,"Để tìm hiểu về điều đó, nhóm tác giả đã thực hiện một lượng lớn các thứ thí nghiệm trước khi rút ra kết luận cuối cùng và trong bài viết này, chúng ta sẽ tìm hiểu xem vấn đề ở đây thực sự là gì và nhóm tác giả đã thực hiện các thí nghiệm như thế nào để rút ra kết luận trên."
5990,E:\DATN\dataframe\train_file\68.txt,Giới thiệu chung
5991,E:\DATN\dataframe\train_file\68.txt,Thành kiến và phân biệt đối xử về chủng tộc có nhiều trong ảnh y tế và có thể sẽ ảnh hưởng đến hiệu suất mô hình.
5992,E:\DATN\dataframe\train_file\68.txt,Điều đã được chứng minh thông qua nhiều nghiên cứu nhưng chưa có nghiên cứu nào nói về có dấu hiệu sinh học hình ảnh y tế đáng tin cậy nào được biết đến tương quan với nhận dạng chủng tộc.
5993,E:\DATN\dataframe\train_file\68.txt,"Nói cách khác, trong khi có thể quan sát các dấu hiệu nhận dạng chủng tộc trong các bức ảnh và video, các chuyên gia lâm sàng không thể dễ dàng xác định chủng tộc của bệnh nhân từ các hình ảnh y tế."
5994,E:\DATN\dataframe\train_file\68.txt,"Với khả năng gây hại do phân biệt đối xử trong một hệ thống được cho là bất khả tri khi xét đến thông tin chủng tộc, và việc hiểu rõ chủng tộc đóng vai trò như thế nào trong các mô hình hình ảnh y tế thường có tầm quan trọng cao."
5995,E:\DATN\dataframe\train_file\68.txt,"Câu hỏi này đặc biệt đúng lúc vì các thuật toán y tế đang được FDA và các cơ quan quản lý khác thường sử dụng hình ảnh y tế (chẳng hạn như phim X-quang, chụp CT, v.v.)"
5996,E:\DATN\dataframe\train_file\68.txt,làm đầu vào chính.
5997,E:\DATN\dataframe\train_file\68.txt,"Các cơ quan quản lý này đã đưa ra các khuyến nghị để báo cáo các nghiên cứu về AI, nhưng các tài liệu quản lý công khai của các công ty được FDA chấp thuận không cho thấy kết quả trên các phân nhóm nhân khẩu học và lâm sàng có liên quan."
5998,E:\DATN\dataframe\train_file\68.txt,"Chủng tộc và bản dạng chủng tộc có thể là những thuộc tính khó định lượng và nghiên cứu trong nghiên cứu chăm sóc sức khỏe, và thường bị nhầm lẫn với các khái niệm sinh học như tổ tiên di truyền."
5999,E:\DATN\dataframe\train_file\68.txt,"Trong công trình này, ta định nghĩa bản sắc chủng tộc là một cấu trúc xã hội, chính trị và luật pháp có liên quan đến sự tương tác giữa nhận thức bên ngoài (tức là “làm thế nào để người khác nhìn thấy tôi?”) và nhận dạng bản thân, và đặc biệt tận dụng chủng tộc tự báo cáo của bệnh nhân trong tất cả các thí nghiệm."
6000,E:\DATN\dataframe\train_file\68.txt,"Trong khi các nghiên cứu trước đây đã chứng minh sự tồn tại của khả năng xác định chủng tộc, cơ chế của những khác biệt này trong hình ảnh y tế vẫn chưa được khám phá."
6001,E:\DATN\dataframe\train_file\68.txt,"Một nghiên cứu trước đó đã lưu ý rằng một mô hình AI được thiết kế để dự đoán mức độ nghiêm trọng của viêm xương khớp bằng cách sử dụng tia X đầu gối không thể xác định chủng tộc của bệnh nhân, trong khi một đánh giá khác về chụp X-quang ngực cho thấy các thuật toán AI có thể dự đoán giới tính, phân biệt giữa bệnh nhân người lớn và bệnh nhi và phân biệt giữa bệnh nhân Mỹ và Trung Quốc."
6002,E:\DATN\dataframe\train_file\68.txt,"Trong nhãn khoa, hình ảnh quét võng mạc đã được sử dụng để dự đoán giới tính, tuổi tác và các dấu hiệu tim mạch như tăng huyết áp và tình trạng hút thuốc."
6003,E:\DATN\dataframe\train_file\68.txt,"Điều này tạo ra rủi ro lớn cho tất cả các triển khai mô hình trong hình ảnh y tế: nếu một mô hình AI sử dụng khả năng phát hiện danh tính chủng tộc làm một yếu tố để đưa ra các quyết định y tế, nhưng khi làm như vậy đã phân loại sai tất cả bệnh nhân thuộc một chủng tộc nào đó, bác sĩ X quang lâm sàng (những người thường không có quyền truy cập chủng tộc thông tin nhân khẩu học) sẽ không thể phát hiện và điều chỉnh nhãn dữ liệu để chính xác hơn."
6004,E:\DATN\dataframe\train_file\68.txt,Đóng góp của nhóm tác giả
6005,E:\DATN\dataframe\train_file\68.txt,"Trên cơ sở trình bày vấn đề như trên, bằng việc huấn luyện các mô hình phân loại dựa trên CNN với cả tập dữ liệu, kịch bản và kĩ thuật khác nhau, nhóm tác giả đã có những đóng góp như sau:"
6006,E:\DATN\dataframe\train_file\68.txt,"Sử dụng các phương pháp học sâu tiêu chuẩn cho từng thí nghiệm phân tích hình ảnh, đào tạo nhiều mô hình phổ biến phù hợp với các tác vụ để chứng minh rằng các mô hình AI có thể dự đoán chủng tộc qua nhiều phương thức hình ảnh, nhiều bộ dữ liệu khác nhau và các nhiệm vụ lâm sàng đa dạng."
6007,E:\DATN\dataframe\train_file\68.txt,"Mức hiệu suất cao vẫn tồn tại trong quá trình xác nhận bên ngoài của các mô hình này trên một loạt các trung tâm học thuật và quần thể bệnh nhân ở Hoa Kỳ, cũng như khi các mô hình được tối ưu hóa để thực hiện các tác vụ có động cơ lâm sàng."
6008,E:\DATN\dataframe\train_file\68.txt,"Thực hiện cắt bỏ để chứng minh rằng việc phát hiện này không phải do các proxy tầm thường, chẳng hạn như thói quen cơ thể, tuổi tác, mật độ mô hoặc các yếu tố gây nhiễu hình ảnh tiềm năng khác cho chủng tộc chẳng hạn như phân bố bệnh cơ bản trong dân số."
6009,E:\DATN\dataframe\train_file\68.txt,"Chỉ ra rằng các đặc điểm đã học có vẻ liên quan đến tất cả các vùng của phổ tần số và hình ảnh, cho thấy rằng các nỗ lực giảm thiểu sẽ gặp nhiều thách thức."
6010,E:\DATN\dataframe\train_file\68.txt,"Nhấn mạnh rằng bản thân khả năng dự đoán danh tính chủng tộc của AI không phải là vấn đề quan trọng, mà vấn đề là khả năng này được học thông thường và do đó có khả năng xuất hiện trong nhiều mô hình phân tích hình ảnh y tế, cung cấp véc tơ trực tiếp cho việc tái tạo hoặc trầm trọng thêm sự khác biệt về chủng tộc đã tồn tại trong thực hành y tế."
6011,E:\DATN\dataframe\train_file\68.txt,"Nguy cơ này còn tăng thêm do các chuyên gia về con người không thể xác định tương tự danh tính chủng tộc từ các hình ảnh y tế, có nghĩa là sự giám sát của con người đối với các mô hình AI chỉ được sử dụng hạn chế để nhận ra và giảm thiểu vấn đề này."
6012,E:\DATN\dataframe\train_file\68.txt,Cách thức thực hiện
6013,E:\DATN\dataframe\train_file\68.txt,"Để chứng minh cho luận điểm của mình, nhóm tác giả đã thực hiện các nhóm một số các bộ dữ liệu hình ảnh y khoa phổ biến và dữ liệu về chủng tộc được sử dụng dựa trên các bộ dữ liệu không công khai đi kèm được liệt kê ở hình dưới đâ1y."
6014,E:\DATN\dataframe\train_file\68.txt,"Để điều tra nguyên nhân của sự chênh lệch hiệu suất được thiết lập trước đây theo chủng tộc bệnh nhân,nhóm tác giả đã nghiên cứu một số giả thuyết và thực hiện ba nhóm thử nghiệm như sau:"
6015,E:\DATN\dataframe\train_file\68.txt,Khả năng phát hiện chủng tộc của các mô hình học sâu
6016,E:\DATN\dataframe\train_file\68.txt,"Để khảo sát khả năng của hệ thống học sâu trong việc khám phá chủng tộc từ hình ảnh X quang, nhóm đã tiến hành các thí nghiệm sau:"
6017,E:\DATN\dataframe\train_file\68.txt,Phát triển các mô hình để phát hiện danh tính chủng tộc trên ba tập dữ liệu X quang lớn với xác thực tập dữ liệu bên ngoài để thiết lập hiệu suất cơ bản của hệ thống AI cho nhiệm vụ phát hiện chủng tộc.
6018,E:\DATN\dataframe\train_file\68.txt,Đào tạo các mô hình phát hiện danh tính chủng tộc cho các hình ảnh không phải ảnh X quang từ nhiều vị trí cơ thể để đánh giá xem hiệu suất của mô hình có bị giới hạn ở dữ liệu chụp X quang phổi hay không
6019,E:\DATN\dataframe\train_file\68.txt,Đào tạo các mô hình phát hiện bệnh lý và xác định lại bệnh nhân và đánh giá hiệu suất dự đoán chủng tộc của họ để xác định xem các mô hình học sâu có thể học cách xác định danh tính chủng tộc khi được đào tạo để thực hiện các nhiệm vụ khác hay không
6020,E:\DATN\dataframe\train_file\68.txt,"Kết quả cho thấy rằng các mô hình học sâu đều thể hiện mức hiệu suất cao trong nhiệm vụ phát hiện chủng tộc trên chụp X-quang ngực, với hiệu suất cao được duy trì trên các phương thức khác và các bộ validations across datasets như được thể hiện ở ảnh dưới đây"
6021,E:\DATN\dataframe\train_file\68.txt,Thí nghiệm về các yếu tố gây nhiễu giải phẫu và kiểu hình
6022,E:\DATN\dataframe\train_file\68.txt,"Sau khi thiết lập mô hình học sâu dung lượng cao (CNN) có thể xác định chủng tộc của bệnh nhân trong dữ liệu hình ảnh y tế, nhóm tác giả đã tạo ra một loạt các giả thuyết cạnh tranh để giải thích điều này có thể xảy ra như thế nào:"
6023,E:\DATN\dataframe\train_file\68.txt,"Sự khác biệt về đặc điểm thể chất giữa các bệnh nhân thuộc các nhóm chủng tộc khác nhau, ví dụ, thói quen cơ thể hoặc mật độ vú."
6024,E:\DATN\dataframe\train_file\68.txt,"Sự khác biệt về phân bố bệnh tật giữa các bệnh nhân thuộc các nhóm chủng tộc khác nhau, ví dụ, bệnh nhân da đen có tỷ lệ mắc một số bệnh như tiểu đường, bệnh thận và bệnh tim cao hơn"
6025,E:\DATN\dataframe\train_file\68.txt,"Sự khác biệt về kiểu hình hoặc giải phẫu theo vị trí cụ thể hoặc mô cụ thể, ví dụ: người da đen có mật độ khoáng xương được điều chỉnh cao hơn người da trắng và tốc độ suy giảm mật độ khoáng xương hàng năm được điều chỉnh theo độ tuổi chậm hơn"
6026,E:\DATN\dataframe\train_file\68.txt,"Tác động tích lũy của thành kiến xã hội và căng thẳng môi trường, ví dụ, sức khỏe của bệnh nhân da đen nói chung là tồi tệ hơn"
6027,E:\DATN\dataframe\train_file\68.txt,Kết quả thu được cho thấy rằng khả năng phát hiện chủng tộc không bị ảnh hưởng bởi các yếu tố giải phẫu và kiểu hình khi mà hiệu suất của các mô hình được đào tạo dựa trên các thông tin này kém hơn rất nhiều khi so sánh với kết quả được đề cập ở trên.
6028,E:\DATN\dataframe\train_file\68.txt,Kết quả chi tiết vui lòng đọc thêm tại bài báo.
6029,E:\DATN\dataframe\train_file\68.txt,Điều tra về các cơ chế cơ bản mà các mô hình AI có thể nhận ra chủng tộc
6030,E:\DATN\dataframe\train_file\68.txt,Nhóm tác giả điều tra các cơ chế cơ bản mà các mô hình AI có thể nhận ra chủng tộc bằng cách:
6031,E:\DATN\dataframe\train_file\68.txt,Điều tra những đóng góp tương đối của các đặc điểm cấu trúc quy mô lớn và các đặc điểm cấu trúc nhỏ bằng cách thực hiện đào tạo và thử nghiệm trên bộ dữ liệu được thay đổi bằng cách lọc phổ tần số của hình ảnh trong MXR.
6032,E:\DATN\dataframe\train_file\68.txt,"Điều này đã được bằng cách áp dụng lọc thông thấp (LPF), lọc thông cao (HPF), lọc thông dải (BF) và lọc rãnh (NF) sau đó áp dụng phép biến đổi Fourier ngược trên phổ được lọc để thu được phiên bản đã thay đổi của hình ảnh gốc và sau đó đào tạo các mô hình trên các tập dữ liệu bị xáo trộn này để quan sát ảnh hưởng đến khả năng dự đoán chủng tộc của mô hình."
6033,E:\DATN\dataframe\train_file\68.txt,Thay đổi kích thước hình ảnh MXR thành nhiều độ phân giải khác nhau và đào tạo mô hình Resnet34.
6034,E:\DATN\dataframe\train_file\68.txt,"Để kiểm tra xem nhiễu ảnh có ảnh hưởng đến việc phát hiện chủng tộc hay không, nhóm tác giả đã làm cho ảnh thử nghiệm trong tập dữ liệu MXR bị nhiễu và bị mờ bằng cách thêm nhiễu Gauss (trung bình = 0, phương sai = 0,1) và áp dụng bộ lọc gaussian cho chúng."
6035,E:\DATN\dataframe\train_file\68.txt,Điều tra xem liệu thông tin chủng tộc có thể được bản địa hóa cho một khu vực hoặc mô giải phẫu cụ thể hay không bằng cách tạo saliency map cho các trường hợp ngẫu nhiên cho mỗi nhiệm vụ bằng phương pháp Grad-Cam và các vùng này sẽ được đánh giá bởi các chuyên gia y khoa.
6036,E:\DATN\dataframe\train_file\68.txt,"Tiếp đó, nhóm tác giả đánh giá thêm ý nghĩa của các vùng quan tâm như được chỉ ra bởi saliency map cách che vùng RoI trong mỗi ảnh X quang và sử dụng chúng để kiểm tra với mô hình được đào tạo trên ảnh MXR gốc."
6037,E:\DATN\dataframe\train_file\68.txt,Điều tra xem liệu thông tin chủng tộc có thể được tách biệt thành các phần cụ cụ thể trong ảnh chụp x-quang ngực hay không bằng cách chia mỗi hình ảnh thành chín ô vuông 3x3 có kích thước bằng nhau và thử nghiệm với việc đào tạo mô hình dự đoán chủng tộc bằng hai cách tiếp cận khác nhau
6038,E:\DATN\dataframe\train_file\68.txt,Chọn một trong chín bản vá và xóa hoàn toàn tất cả thông tin khỏi bản vá bằng cách đặt tất cả các pixel trong bản vá thành 0
6039,E:\DATN\dataframe\train_file\68.txt,"Chọn một trong các chín bản vá, chia tỷ lệ nó trở lại kích thước của hình ảnh gốc và chỉ sử dụng bản vá này để huấn luyện mô hình"
6040,E:\DATN\dataframe\train_file\68.txt,"Sau khi thực hiện thí nghiệm, nhóm tác giả thu được kết quả như sau:"
6041,E:\DATN\dataframe\train_file\68.txt,"Thông tin về chủng tộc được chứa trên miền tần số : Trong hình dưới đây ta có thể quan sát thấy rằng bộ lọc thông thấp dẫn đến hiệu suất bị suy giảm đáng kể ở khoảng đường kính 10, tương ứng với mức độ mà hình ảnh bị suy giảm đáng kể về mặt trực quan."
6042,E:\DATN\dataframe\train_file\68.txt,"bộ lọc thông cao duy trì hiệu suất cao lên đến đường kính 100, điều này đáng chú ý là không có các đặc điểm giải phẫu rõ ràng trực quan trong hình ảnh mẫu ngay cả ở các mức bán kính thấp hơn (nghĩa là hiệu suất được duy trì mặc dù hình ảnh bị suy giảm nghiêm trọng về mặt trực quan)."
6043,E:\DATN\dataframe\train_file\68.txt,"Thông tin về chủng tộc vẫn tồn tại ở độ phân giải hình ảnh bị suy giảm và chất lượng hình ảnh thấp: Hình dưới đây cho thấy AUC của các độ phân giải hình ảnh khác nhau từ độ phân giải 4x4 đến hình ảnh 512x512, cho thấy AUC> 0,95 đối với hình ảnh ở độ phân giải 160 X 160 hoặc lớn hơn."
6044,E:\DATN\dataframe\train_file\68.txt,Ta có thể ghi nhận sự sụt giảm hiệu suất đối với hình ảnh dưới độ phân giải này nhưng chứng minh rằng thông tin chủng tộc vẫn tồn tại nhiều hơn cơ hội ngẫu nhiên ngay cả ở độ phân giải nhỏ như 4x4.
6045,E:\DATN\dataframe\train_file\68.txt,Kết quả tương tự cũng được quan sát đối với hình ảnh nhiễu
6046,E:\DATN\dataframe\train_file\68.txt,"Thông tin về chủng tộc không được bản địa hóa cho một khu vực giải phẫu cụ thể hoặc phân đoạn cơ thể: Sau khi thực hiện thí nghiệm, nhóm nhận thấy rằng không có đóng góp rõ ràng nào từ một phân đoạn giải phẫu cụ thể bằng cách sử dụng nhiều thí nghiệm."
6047,E:\DATN\dataframe\train_file\68.txt,"Ta có hiệu suất cao của các mô hình được thử nghiệm trên các phân đoạn không phải phổi (so với phân đoạn phổi), nhưng các dự đoán phân đoạn thấp hơn so với dự đoán hình ảnh ban đầu."
6048,E:\DATN\dataframe\train_file\68.txt,Và do đó thông tin về chủng tộc có thể là sự kết hợp thông tin từ tất cả các phân đoạn hình ảnh phổi và không phổi.
6049,E:\DATN\dataframe\train_file\68.txt,"Kết quả tương tự được quan sát từ phân tích lát cắt CT trong đó hiệu suất theo từng lát của mô hình là tương tự trong suốt các lát ở trên cùng, giữa và dưới ngực."
6050,E:\DATN\dataframe\train_file\68.txt,"Kết quả mà các mô hình học sâu có thể dự đoán chủng tộc tự báo cáo của bệnh nhân chỉ từ các hình ảnh y tế là đáng ngạc nhiên, đặc biệt là nhiệm vụ này không thể thực hiện đối với các chuyên gia về con người."
6051,E:\DATN\dataframe\train_file\68.txt,"Bằng cách thực hiện các thí nghiệm của mình trên nhiều môi trường lâm sàng khác nhau, phương thức hình ảnh y tế và quần thể bệnh nhân, nhóm tác giả xác nhận cho thấy rằng các mô hình này không dựa vào các biến số của quy trình bệnh viện hoặc sự khác biệt đặc trưng của địa phương trong cách thực hiện các nghiên cứu hình ảnh cho bệnh nhân bản sắc chủng tộc khác nhau."
6052,E:\DATN\dataframe\train_file\68.txt,Có một số cuộc tranh luận về ý nghĩa của điều này.
6053,E:\DATN\dataframe\train_file\68.txt,"Một trong những tác giả của bài báo: Luke Oakden-Rayner tin rằng khả năng phát hiện chủng tộc quá dễ dàng của AI là rất tệ và có thể dẫn đến sự thiên vị tuy nhiên một số khác cho rằng không thấy khả năng này là đáng báo động, thông tin chi tiết có thể xem tại :"
6054,E:\DATN\dataframe\train_file\68.txt,Bài viết này giới thiệu về báo  cũng như trình bày một cách ngắn gọn nhất các nội dung được trình bày trong các paper đó.
6055,E:\DATN\dataframe\train_file\68.txt,Cảm ơn các bạn đã dành thời gian đọc và hi vọng rằng bài viết này sẽ cung cấp cho các bạn các thông tin hữu ích cho mọi người.
6056,E:\DATN\dataframe\train_file\68.txt,Một số từ viết tắt các thứ :v
6057,E:\DATN\dataframe\train_file\68.txt,Chủng tộc/dân tộc tự báo cáo (self-reported race/ethnicity): thường được sử dụng trong các nghiên cứu dịch tễ học để đánh giá nguồn gốc xuất thân của một cá nhân.
6058,E:\DATN\dataframe\train_file\68.txt,"Thông thường, những người tham gia ở Hoa Kỳ được yêu cầu chỉ định một chủng tộc / nhóm dân tộc duy nhất dựa trên sáu loại: Da trắng, Da đen, Da đen gốc Tây Ban Nha, Da trắng Tây Ban Nha, Châu Á hoặc khác"
6059,E:\DATN\dataframe\train_file\68.txt,FDA (U.S. Food and Drug Administration): Cục quản lý Thực phẩm và Dược phẩm Hoa Kỳ
6060,E:\DATN\dataframe\train_file\68.txt,CXR: X quang ngực
6061,E:\DATN\dataframe\train_file\7.txt,Thuật ngữ trong Frontend - Optimization
6062,E:\DATN\dataframe\train_file\7.txt,Tại sao nên đọc bài này?
6063,E:\DATN\dataframe\train_file\7.txt,Dành cho các bạn mới tiếp cận và thấy quá nhiều thuật ngữ mới
6064,E:\DATN\dataframe\train_file\7.txt,Dành cho các bạn có thể đã làm FE một thời gian rồi nhưng đôi khi vẫn không biết có một thứ như vậy tồn tại trên đời
6065,E:\DATN\dataframe\train_file\7.txt,Có vài keyword để tối ưu performance cho website
6066,E:\DATN\dataframe\train_file\7.txt,Các thuật ngữ phổ biến
6067,E:\DATN\dataframe\train_file\7.txt,Trong bài này mình sẽ nói về các thuật ngữ liên quan tới optimization nhé!
6068,E:\DATN\dataframe\train_file\7.txt,Code split
6069,E:\DATN\dataframe\train_file\7.txt,"Hiểu một cách đơn giản thì bạn có một file code rất to, bạn chia file to đó ra thành nhiều file nhỏ thì gọi là code split"
6070,E:\DATN\dataframe\train_file\7.txt,"Hoặc một ví dụ khác là bạn có một trang web build bằng React, trong đó bao gồm Header, body và Footer."
6071,E:\DATN\dataframe\train_file\7.txt,"Thì bạn có thể build thành một file bundle.js bao gồm cả 3 component trên hoặc cũng có thể chia cái bundle đó thành 3 file, mỗi file chứa một component"
6072,E:\DATN\dataframe\train_file\7.txt,😼 Hãy nghĩ đơn giản code split như là bạn cắt một miếng bánh to thành nhiều miếng nhỏ
6073,E:\DATN\dataframe\train_file\7.txt,Lazy load
6074,E:\DATN\dataframe\train_file\7.txt,Lazy load nghĩa là một cách để delay việc load một resource gì đó cho tới khi thật sự cần thiết
6075,E:\DATN\dataframe\train_file\7.txt,"Như trong Video ở trên, sẽ khá tốn resource nếu chúng ta load hình mà user chưa thực sự cần xem đúng không."
6076,E:\DATN\dataframe\train_file\7.txt,"Do đó, nó apply lazy load để khi nào ta gần scroll tới cái hình đó thì mới load hình về."
6077,E:\DATN\dataframe\train_file\7.txt,"Vừa đỡ tốn CPU cho máy user, cùng vừa đỡ tốn 3g cho người ta"
6078,E:\DATN\dataframe\train_file\7.txt,Resource ở đây bạn có thể define là mọi thứ như là
6079,E:\DATN\dataframe\train_file\7.txt,Một file code
6080,E:\DATN\dataframe\train_file\7.txt,Một cái thẻ img
6081,E:\DATN\dataframe\train_file\7.txt,Một thư viện
6082,E:\DATN\dataframe\train_file\7.txt,Một response từ API
6083,E:\DATN\dataframe\train_file\7.txt,Khi nghĩ về lazy load thì bạn cần suy nghĩ: Cái gì có thể lazy và cái gì không thể lazy.
6084,E:\DATN\dataframe\train_file\7.txt,"Việc chia ra những resource nào lazy load được, cái gì không thể lazy load giúp bạn có chiến thuật quản lý resource tốt hơn."
6085,E:\DATN\dataframe\train_file\7.txt,Back lại cái thuật ngữ bên trên Split code làm ví dụ nhé.
6086,E:\DATN\dataframe\train_file\7.txt,Câu hỏi của bạn là cắt cái bundle bự thành nhiều bundle nhỏ để làm gì?
6087,E:\DATN\dataframe\train_file\7.txt,Câu trả lời thường là bạn cắt nó ra thành hai phần: Phần có thể lazy load được và phần không thể lazy load được.
6088,E:\DATN\dataframe\train_file\7.txt,Do đó bạn sẽ thấy khái niệm lazy load thường đi chung với split code vì lazy load cái resource code thì cần cắt nó thành nhiều chunk nhỏ hơn để hiện thực lazy load
6089,E:\DATN\dataframe\train_file\7.txt,"😼 Về mặt lý thuyết, tất cả các resource liên quan tới interaction của user (Scroll, click, hover, press,…) đều có thể lazy load được"
6090,E:\DATN\dataframe\train_file\7.txt,"Prefetch nghĩa là bạn nói với Browser “Tao có một cái resource này nè, khi nào mày rảnh thì load trước giúp tao nhé”"
6091,E:\DATN\dataframe\train_file\7.txt,"Preload nghĩa là bạn nói với Browser “Load trước đống resource này cho tao nhé, rảnh hay không thì cũng load 😈”"
6092,E:\DATN\dataframe\train_file\7.txt,Okey vậy khi nào thì nên dùng prefetch hay preload?
6093,E:\DATN\dataframe\train_file\7.txt,Prefetch hữu dụng khi bạn tin là user sẽ cần một số resource này trong tương lai.
6094,E:\DATN\dataframe\train_file\7.txt,"Mình ví dụ khi user hover vào một link nào đó, mình cũng không chắc là user sẽ thật sự click vào link này hay không, nhưng khả năng cao là có."
6095,E:\DATN\dataframe\train_file\7.txt,"Vì vậy nếu mình prefetch trước cái link này thì nếu user bấm thật thì nó đã được load sẵn cmnr, nên sẽ thấy trang này load nhanh vklllllllllll ⚡"
6096,E:\DATN\dataframe\train_file\7.txt,Preload hữu dụng khi bạn cần những resource cực kì quan trọng cho bước render đầu tiên.
6097,E:\DATN\dataframe\train_file\7.txt,"Ví dụ dễ thấy nhất là Font, việc preload trước font giúp trang web của bạn render lần đầu tiên thì visual cũng ok luôn."
6098,E:\DATN\dataframe\train_file\7.txt,"Thay vì nếu render ra trang web mà font chưa có, sau đó load font rồi phải render lại một lần nữa."
6099,E:\DATN\dataframe\train_file\7.txt,Việc thay font như vậy dễ khiến cho layout bị flick và với góc nhìn của user thì thấy nó cũng khá là bad
6100,E:\DATN\dataframe\train_file\7.txt,Tree Shaking
6101,E:\DATN\dataframe\train_file\7.txt,Bạn tưởng tượng đống code/module của bạn như một cái cây nha.
6102,E:\DATN\dataframe\train_file\7.txt,"Bây giờ bạn cầm cái cây đó rung mạnh thật mạnh, cái gì sẽ xảy ra?"
6103,E:\DATN\dataframe\train_file\7.txt,"Những thành phần yếu ớt trên cái cây đó sẽ bị rơi ra như là già, cành khô, tổ chym,…"
6104,E:\DATN\dataframe\train_file\7.txt,"Tree shaking trong code cũng tương đương vậy, bạn loại bỏ những thứ không cần thiết trong code (dead code) một cách tự động."
6105,E:\DATN\dataframe\train_file\7.txt,"Cái này giống như việc giảm “mỡ” cho bundle của các bạn, sẽ giúp load web nhanh hơn, không tốn thời gian cho những thứ không cần thiết"
6106,E:\DATN\dataframe\train_file\7.txt,Viết tắt của cụm từ Search Engine Optimization - Tối ưu hóa cho công cụ tìm kiếm.
6107,E:\DATN\dataframe\train_file\7.txt,"Hiểu đơn giản là có vô vàn website trên internet đúng không, và khi bạn search Google thì nó sẽ trả về cho bạn vào trăm hay vài triệu kết quả đó."
6108,E:\DATN\dataframe\train_file\7.txt,Vậy làm sao để trang web của mình nằm ở vị trí cao hơn trong danh sách đó để nhiều user biết tới hơn?
6109,E:\DATN\dataframe\train_file\7.txt,"Vậy SEO là cách để tối ưu trang web giúp nó có thứ hạng cao hơn ở các công cụ tìm kiếm như Google, Bing"
6110,E:\DATN\dataframe\train_file\7.txt,"Tụi Google sẽ có nhiều tiêu chí để quyết định trang web của bạn có phù hợp với user hay không như là Content, keyword, hình ảnh, tốc độ load trang, ngôn ngữ,… Do đó khi nói làm SEO nghĩa là bạn làm đủ kiểu để các tiêu chí đó tốt hơn, phù hợp với user hơn (đường nhiên là theo tiêu chí của tụi Google rồi)"
6111,E:\DATN\dataframe\train_file\7.txt,Google Page Speed
6112,E:\DATN\dataframe\train_file\7.txt,Nó là cái trang này nè
6113,E:\DATN\dataframe\train_file\7.txt,Google build ra một cài tool để đo lường tốc độ website của bạn và cho ra thang điểm từ 0 tới 100.
6114,E:\DATN\dataframe\train_file\7.txt,Điểm càng cao thì chứng tỏ website của bạn “ra dẻ” load càng nhanh
6115,E:\DATN\dataframe\train_file\7.txt,Thường cái này là một tiêu chí mà ai cũng dùng để xem coi website của bạn có đuỷnh hay không.
6116,E:\DATN\dataframe\train_file\7.txt,Mình thì thấy nó cũng tương đối tuy nhiên mọi người lại dựa vào nó quá nhiều để đánh giá một website
6117,E:\DATN\dataframe\train_file\7.txt,The fold
6118,E:\DATN\dataframe\train_file\7.txt,"The fold hiểu là bạn cắt cái trang web theo chiều ngang, bên trên the fold là những gì đập vào mặt user ngay lập tức khi họ mở trang web của bạn."
6119,E:\DATN\dataframe\train_file\7.txt,Những gì ở dưới thì người ta phải scroll xuống mới thấy được.
6120,E:\DATN\dataframe\train_file\7.txt,Và vì định nghĩa là những gì đập vào mặt user ngay lập tức nên khái niệm này khá là … tương đối.
6121,E:\DATN\dataframe\train_file\7.txt,"Vì users có thể dùng device khác nhau, to nhỏ khác nhau."
6122,E:\DATN\dataframe\train_file\7.txt,Có thể đập vào mặt ở màn hình MateView 4k 27inch với màn hình Dell FullHD 24 inch nó khác nhau nên do đó the fold ở hai màn hình đó cũng khác nhau.
6123,E:\DATN\dataframe\train_file\7.txt,Tại sao cần phải phân biệt the fold?
6124,E:\DATN\dataframe\train_file\7.txt,Nó giúp bạn tối ưu hơn cho user kiểu như
6125,E:\DATN\dataframe\train_file\7.txt,Ở trên the fold thì load càng nhanh càng tốt vì nó là thứ xuất hiện ngay lập tức khi user mở website
6126,E:\DATN\dataframe\train_file\7.txt,Ở dưới the fold thì có thể apply lazy load vì user phải scroll xuống mới thấy được phải không nào
6127,E:\DATN\dataframe\train_file\7.txt,CSS critical
6128,E:\DATN\dataframe\train_file\7.txt,Là một cách để trích xuất những CSS Above the fold ra riêng để tối ưu tốc độc load.
6129,E:\DATN\dataframe\train_file\7.txt,"Nhớ vụ mình nói ở trên là optimize tối đa cho những thứ Above the fold không, thì cái này là một cách để tối ưu Above the fold."
6130,E:\DATN\dataframe\train_file\7.txt,Tuy idea về việc chỉ inject CSS above the fold ra gắn vào khá là đỉnh nhưng thực tế rất rất khó làm cái này.
6131,E:\DATN\dataframe\train_file\7.txt,Nên mình thấy nghe cho vui thì được )
6132,E:\DATN\dataframe\train_file\7.txt,CSS in JS
6133,E:\DATN\dataframe\train_file\7.txt,Cái tên nó lên tất cả: Viết CSS ở JavaScript.
6134,E:\DATN\dataframe\train_file\7.txt,Mà tại sao lại không viết trong file css nhỉ?
6135,E:\DATN\dataframe\train_file\7.txt,"Khi dùng css đồng thời kết hợp với các library, hay framework gần đầy thì nó sẽ gặp một vài vấn đề"
6136,E:\DATN\dataframe\train_file\7.txt,"CSS là global, trong khi mình muốn component của là isolated và không bị, hoặc tạo những style lên các thành phần khác"
6137,E:\DATN\dataframe\train_file\7.txt,Lỡ code JS hết rồi nên thôi code luôn JS hết 😅
6138,E:\DATN\dataframe\train_file\7.txt,"Vì nó viết bằng CSS nên sẽ dễ hơn khi bạn muốn làm một số thứ advance hơn với CSS như CSS extraction, critical,…"
6139,E:\DATN\dataframe\train_file\7.txt,Service worker
6140,E:\DATN\dataframe\train_file\7.txt,"Là một đoạn script chạy ở background, nó có thể intercept vào request và response giữa web của bạn và server, và làm một vài thứ hay ho khác (Notification, cache, sync data,…)"
6141,E:\DATN\dataframe\train_file\7.txt,"Vì nó đứng ở giữa nên các bạn tưởng tượng nó như proxy cũng được, có thể thay đổi data gửi đi hay data nhận về luôn."
6142,E:\DATN\dataframe\train_file\7.txt,"Nên cách dùng của service worker cũng khá là sáng tạo, có thể là"
6143,E:\DATN\dataframe\train_file\7.txt,Mock proxy server
6144,E:\DATN\dataframe\train_file\7.txt,Cache lại response để biến web của các bạn trở thành offline web
6145,E:\DATN\dataframe\train_file\7.txt,Precache những resource cần thiết
6146,E:\DATN\dataframe\train_file\7.txt,Một key quan trọng khi nói tới Service worker là vì nó chạy dưới background nên bạn có thể làm vài thứ hay ho mà không khiến cho web của các bạn chậm đi
6147,E:\DATN\dataframe\train_file\7.txt,Web worker
6148,E:\DATN\dataframe\train_file\7.txt,"Trước đây thì web chỉ có một luồng thực thi thôi, được gọi là Main thread."
6149,E:\DATN\dataframe\train_file\7.txt,"Và vì chỉ có một luồng thực thì nên nó đẻ ra một vấn đề: Khi bạn đang thực hiện một tác vụ (task) gì đó, thì các tương tác khác phải chờ cho task đó chạy xong mới chạy được."
6150,E:\DATN\dataframe\train_file\7.txt,"Case thử tế là ví dụ bạn code một trang web tính lương cho nhân viên, khi có một task tính toán lương đang chạy ở dưới và nếu nó khá nặng thì lúc này user có click vào đâu thì trang web của các bạn cũng không phản hồi được (vì đang bận tính lương chết mọe rồi mà, còn bắt tao làm cái khác nữa hả????)"
6151,E:\DATN\dataframe\train_file\7.txt,Do đó Web worker đẻ ra để giải quyết vấn đề trên.
6152,E:\DATN\dataframe\train_file\7.txt,"Nói đơn giản là cái gì tính toán nặng thì đẩy ra một thread khác, để cái thằng Main thread rảnh rỗi còn handle interaction từ user"
6153,E:\DATN\dataframe\train_file\7.txt,Cái từ này hơi hiếm gặp nhưng khác là quan trọng và gặp phải ở hầu hết các lib support SSR.
6154,E:\DATN\dataframe\train_file\7.txt,Hydration là quá trình gắn các event listener và các node tương ứng đã được generate từ quá trình SSR
6155,E:\DATN\dataframe\train_file\7.txt,Mình có một bài viết lan quyên tới cái này ở đây
6156,E:\DATN\dataframe\train_file\7.txt,List virtualization
6157,E:\DATN\dataframe\train_file\7.txt,Bạn tưởng tượng là cái web của mình là một cuộn giấy siêu dài và mình dang nhìn nò thông qua một cửa sổ nhỏ (Window).
6158,E:\DATN\dataframe\train_file\7.txt,"Nghĩa là mình đang nhìn một phần rất nhỏ trong cuộn giấy đó, và để nhìn hết thì các bạn phải scroll."
6159,E:\DATN\dataframe\train_file\7.txt,"List virtualization là kĩ thuật chỉ render cái DOM node nằm trong cửa sổ (Window) của bạn, các thứ nằm ngoài thì bỏ nó ra khỏi DOM luôn để trình duyệt không tốn resource để take care những thứ không quan trọng."
6160,E:\DATN\dataframe\train_file\7.txt,"Bạn sẽ thấy cái này rất quan trọng khi apply cho những trang web có list cực kì dài và phức tạp như là New feed của Facebook, Twitter,…"
6161,E:\DATN\dataframe\train_file\7.txt,"Tới đây thấy cũng khá dài rồi, kiều càng viết nó càng có thêm á 😅, nên mình cũng không biết là còn thiếu gì quan trọng không."
6162,E:\DATN\dataframe\train_file\7.txt,"Ngoài ra bạn còn muốn tìm hiểu về thuật ngữ ở mảng nào nữa (Layout, CSS, state management, …)?"
6163,E:\DATN\dataframe\train_file\7.txt,Comment bên dưới nhé!
6164,E:\DATN\dataframe\train_file\70.txt,Imbalance Problem in Object Detection
6165,E:\DATN\dataframe\train_file\70.txt,Trong lĩnh vực thị giác máy tính bài toán về nhận diện vật thể - Object Detection đóng vai trò quan trọng vì nó mang lại nhiều ứng dụng to lớn.
6166,E:\DATN\dataframe\train_file\70.txt,"Nhiều năm trở lại đây, các mạng học sâu đã liên tục ra đời cho bài toán này."
6167,E:\DATN\dataframe\train_file\70.txt,"Như chúng ta đã biết thì trong các bài toán ML, DL nói chung imbalance problem có ảnh hưởng xấu đến chất lượng mô hình như thế này."
6168,E:\DATN\dataframe\train_file\70.txt,Vì thế các vấn đề về sự mất cân bằng - imbalance problem trong bài toán Object Detection nhận được rất nhiều sự quan tâm và nghiên cứu.
6169,E:\DATN\dataframe\train_file\70.txt,Trong bài này mình sẽ tổng hợp lại các imblance problem đã được nghiên cứu trong bài toán nhận diện vật thể.
6170,E:\DATN\dataframe\train_file\70.txt,Imbalance Problem
6171,E:\DATN\dataframe\train_file\70.txt,Có thể nhóm các loại imbalance problem thành 4 nhóm sau:
6172,E:\DATN\dataframe\train_file\70.txt,Class imbalance: xảy ra khi có sự mất cân bằng giữa các class cần nhận diện trong bài toàn object detection.
6173,E:\DATN\dataframe\train_file\70.txt,Scale imbalance: xảy ra khi các vật thể (object) có sự mất cân bằng về các kích thước
6174,E:\DATN\dataframe\train_file\70.txt,Spatial imbalance: liên quan đến các yếu tố về vị trí của bbox
6175,E:\DATN\dataframe\train_file\70.txt,Objective imbalance: liên quan đến việc mô hình phải tối ưu nhiều hàm loss (cụ thể classification và regression loss)
6176,E:\DATN\dataframe\train_file\70.txt,Dưới đây là pineline của một mạng detection cơ bản và các loại imbalance problem kể trên có thể xảy ra ở các phase nào.
6177,E:\DATN\dataframe\train_file\70.txt,Tiếp theo ta sẽ cùng đi vào tìm hiểu từng cụ thể hơn từng loại Imbalance Problem trong bài toán Object Detection!
6178,E:\DATN\dataframe\train_file\70.txt,Class Imbalance
6179,E:\DATN\dataframe\train_file\70.txt,Foreground-Background class imbalance
6180,E:\DATN\dataframe\train_file\70.txt,Một số định nghĩa:
6181,E:\DATN\dataframe\train_file\70.txt,Over-represented class: là class mà xuất hiện quá trình nhiều bộ dữ liệu hoặc trong các minibatch ở quá trình training
6182,E:\DATN\dataframe\train_file\70.txt,"Under-represented class: ngược lại, là class xuất hiện quá ít trong bộ dữ liệu hoặc trong các minibatch ở quá trình training"
6183,E:\DATN\dataframe\train_file\70.txt,Foreground class: IoU của anchor với ground-truth bounding box mà cho kết quả lớn hơn 1 ngưỡng thì coi đó là foreground class.
6184,E:\DATN\dataframe\train_file\70.txt,Đây sẽ là vùng mang nhiều thông tin nhưng mà tần suất xuất hiện trong ảnh sẽ ít.
6185,E:\DATN\dataframe\train_file\70.txt,Background class: ngược lại nếu IoU của anchor với ground-truth bounding box mà nhỏ hơn ngưỡng thì gọi đó là background class.
6186,E:\DATN\dataframe\train_file\70.txt,"Vùng này xuất hiện rất nhiều và mang những thông tin không quan trọng, vô nghĩa."
6187,E:\DATN\dataframe\train_file\70.txt,"Như vậy, foreground-background class imbalance là khi foreground class là under-represented class còn background class là over-represented class."
6188,E:\DATN\dataframe\train_file\70.txt,"Nhìn chung, vấn đề này là không thể tránh khỏi vì hầu hết bounding box sẽ được đánh dấu là background."
6189,E:\DATN\dataframe\train_file\70.txt,Vấn đề này nhận được nhiều sự quan tâm vì thế đã có nhiều nghiên cứu về giải pháp được đề xuất và có thể chia thành các nhóm:
6190,E:\DATN\dataframe\train_file\70.txt,"Hard sampling methods: Đơn giản nhất là random sampling đã được sử dụng trong R-CNN, là phương pháp phổ biến được dùng giúp loại bỏ imbalance problem."
6191,E:\DATN\dataframe\train_file\70.txt,Cụ thể trong một tập các bounding box thì ta sẽ chọn ra các tập nhỏ positive example và negative example với số lượng bằng nhau và sử dụng để cho quá trình training.
6192,E:\DATN\dataframe\train_file\70.txt,Khi đó đóng góp vào hàm loss của các positive và negative example là như nhau.
6193,E:\DATN\dataframe\train_file\70.txt,Tiếp theo là các phương pháp hard-example mining methods lựa chọn ra các hard example (các case khó với giá trị loss cao) để training (SSD có áp dụng phương pháp này).
6194,E:\DATN\dataframe\train_file\70.txt,Soft sampling methods: Thay vì chọn xem nên lấy hay loại như Hard sampling methods thì phương pháp này đặt hệ số cho foreground và background class.
6195,E:\DATN\dataframe\train_file\70.txt,Thông thường thì các background class sẽ có hệ số nhỏ hơn và do đó đóng góp ít hơn vào hàm loss.
6196,E:\DATN\dataframe\train_file\70.txt,Các giá trị trọng số này cũng được đặt theo nhiều tiêu chí khác nhau.
6197,E:\DATN\dataframe\train_file\70.txt,YOLO có sử dụng phương pháp này.
6198,E:\DATN\dataframe\train_file\70.txt,Generative methods: Thay vì phải lựa chọn các hard example thì phương pháp này ứng dụng các mô hình sinh như GAN để sinh ra các hard example.
6199,E:\DATN\dataframe\train_file\70.txt,"Ngoài ra, có thể tạo ra các ảnh mới bằng các phương pháp augmentation."
6200,E:\DATN\dataframe\train_file\70.txt,Foreground-Foreground class imbalance
6201,E:\DATN\dataframe\train_file\70.txt,Theo định nghĩa trong trường hợp này thì cả over-represented class và under-represented class đều là foreground class.
6202,E:\DATN\dataframe\train_file\70.txt,"Ví dụ như bài toán nhận diện các không đeo khẩu trang (class 0), người đeo khẩu trang (class 1) và đeo khẩu trang không đúng cách (class 2) trong challange của Datacomp thì class 1 có số lượng rất lớn trong khi class 2 thì rất ít."
6203,E:\DATN\dataframe\train_file\70.txt,Cụ thể hơn thì foreground-foreground class imbalance được chia thành 2 mức: dataset-level và batch-level
6204,E:\DATN\dataframe\train_file\70.txt,"Dataset-level: trong tự nhiên, các object sẽ xuất hiện với tuần suất khác nhau vì vậy sự mất cân bằng giữa các class trong dataset là không tránh khỏi."
6205,E:\DATN\dataframe\train_file\70.txt,Hình dưới là thông kế số lượng các object class trên các tập dataset khác nhau.
6206,E:\DATN\dataframe\train_file\70.txt,Như vậy có thể thấy rằng hiện tượng overfit đối với các over-represented class là khó tránh khỏi.
6207,E:\DATN\dataframe\train_file\70.txt,"Batch-level: trong quá trình training thì phân phối các object class trong 1 batch có thể không đồng đều, đặc biệt khi kích thước của batch nhỏ."
6208,E:\DATN\dataframe\train_file\70.txt,"Trong trường hợp này, một over-represented class ở dataset-level cũng có thể trở thành under-represented level khi trong 1 batch."
6209,E:\DATN\dataframe\train_file\70.txt,Kể cả khi các class ở dataset có phân phối đồng đều thì hiện tượng này vẫn xảy ra trong quá trình training.
6210,E:\DATN\dataframe\train_file\70.txt,Như hình dưới a) là phân phối của class person và parking meter trong dataset nhưng khi trong một batch thì trường hợp như b) có thể xảy ra.
6211,E:\DATN\dataframe\train_file\70.txt,"Đối với dataset-level có thể áp dụng các mô hình sinh để tạo ra ảnh mới hoặc bounding box mới, ngoài ra cũng có thể tập trung augment thêm các under-represented class."
6212,E:\DATN\dataframe\train_file\70.txt,Đối với batch-level có một phương pháp là  sẽ chọn các bounding box cho 1 batch theo xác suất sao cho phân phối của các class trong một batch là uniform.
6213,E:\DATN\dataframe\train_file\70.txt,"Một số cách khác là sử dụng phương pháp under-sampling cho các over-represented class, over-sampling cho các under-represented class hoặc là dùng 1 hàm loss riêng để giải quyết vấn đề mất cân bằng giữa các foreground class."
6214,E:\DATN\dataframe\train_file\70.txt,Scale Imbalance
6215,E:\DATN\dataframe\train_file\70.txt,Object/Box-Level Scale Imbalance
6216,E:\DATN\dataframe\train_file\70.txt,"Vấn đề này được định nghĩa là là các object hay các ground-truth bounding boxes trong dataset có các kích thước khác nhau, trong đó một vài kích thước rơi vào trường hợp over-represented."
6217,E:\DATN\dataframe\train_file\70.txt,"Hình dưới đã thể hiện sự mất cân bằng về chiều cao, chiều rộng và diện tích của object trong các bộ dataset khác nhau."
6218,E:\DATN\dataframe\train_file\70.txt,"Có thể giải quyết bằng việc sử dụng các feature tại các ""level"" khác nhau để dự đoán."
6219,E:\DATN\dataframe\train_file\70.txt,Cụ thể như hình dưới a) là chỉ dự đoán bằng feature cuối cùng của backbone (chưa áp dụng phương pháp để giải quyết hiện tượng trên).
6220,E:\DATN\dataframe\train_file\70.txt,Hình b) thì sử dụng feature ở các level khác nhau để dự đoán.
6221,E:\DATN\dataframe\train_file\70.txt,Hình c) kết hợp các feature tại các level khác nhau để dự đoán.
6222,E:\DATN\dataframe\train_file\70.txt,Hình d) và e)cho các ảnh với độ phân giải khác nhau để thu được các feature khác nhau và dùng chúng để dự đoán.
6223,E:\DATN\dataframe\train_file\70.txt,Trừ hình a) thì các hình còn lại đều giúp giảm thiểu ảnh hưởng của scale imbalance problem.
6224,E:\DATN\dataframe\train_file\70.txt,Feature-level Imbalance
6225,E:\DATN\dataframe\train_file\70.txt,Khi áp dụng các phương pháp để giảm thiểu ảnh hưởng của Object/Box-Level Scale Imbalance đặc biêt là phương pháp kết hợp các feature tại các level khác nhau và dùng chúng để dự đoán vô tình gây ra hiện tượng feature-level imbalance.
6226,E:\DATN\dataframe\train_file\70.txt,"Cụ thể như hình dưới màu sắc thể hiện sự tương ứng của các feature với nhau, cặp C5 - P5, C4 - P4 thì có vẻ khá phù hợp với nhau tuy nhiên cặp C2 - P2 và C3 - P3 thì lại có sự khác biệt về feature-level và gây ra hiện tượng kể trên."
6227,E:\DATN\dataframe\train_file\70.txt,Có khá nhiều phương pháp được đề xuất để giải quyết hiện tượng này.
6228,E:\DATN\dataframe\train_file\70.txt,"Tuy nhiên có lẽ mình sẽ tìm hiểu vào bài viết, vì nó có nhiều phương pháp khá dài và mình chưa đọc kĩ ^^!"
6229,E:\DATN\dataframe\train_file\70.txt,"Vì thế mình sẽ chỉ liệt kê các phương pháp ra: , , , , , ."
6230,E:\DATN\dataframe\train_file\70.txt,Spatial Imbalance
6231,E:\DATN\dataframe\train_file\70.txt,Imbalance in Regression Loss
6232,E:\DATN\dataframe\train_file\70.txt,"Regression loss liên quan đến việc mô hình tìm ra bounding box gần với ground truth nhất, tuy nhiên mỗi bouding box mà mô hình dự đoán trong quá trình train lại đóng góp khác nhau cho hàm loss."
6233,E:\DATN\dataframe\train_file\70.txt,"Ví dụ như hình dưới, màu xanh lam là ground truth, ba màu còn lai là bounding boxes được dự đoán."
6234,E:\DATN\dataframe\train_file\70.txt,"L1 và L2 là các regression loss, có thể thấy rằng đóng góp đến hàm loss L2 của bounding box màu vàng là lớn hơn so với L1, ngược lại của bounding box màu xanh lá thì lại nhỏ hơn."
6235,E:\DATN\dataframe\train_file\70.txt,"Đã có nhiều hàm regression loss ra đời để khắc phục có thể kể đến như: Smooth L1 Loss, Balanced L1 Loss, KL Loss hay các loss dùng thẳng giá trị IoU để tính như IoU Loss, Bounded IoU Loss, GIoU Loss, DIoU Loss và CIoU Loss."
6236,E:\DATN\dataframe\train_file\70.txt,Dưới đây là bảng tổng hợp một số regression loss
6237,E:\DATN\dataframe\train_file\70.txt,Object Location Imbalance
6238,E:\DATN\dataframe\train_file\70.txt,Phân phối về vị trí của vật thể trong các ảnh không đồng đều cũng được coi là một imbalance problem.
6239,E:\DATN\dataframe\train_file\70.txt,Hầu hếu các mô hình nhận diện vật thể đều dùng các anchor như là các cửa sổ trượt (sliding window) và các anchor này sẽ được phân phối đng đều trên ảnh vì vậy mỗi vị trí của ảnh sẽ có tầm quan trọng như nhau.
6240,E:\DATN\dataframe\train_file\70.txt,"Tuy nhiên, vị trí của vật thể trong ảnh lại không tuân theo phân phối uniform, ví dụ như hình dưới minh họa vị trí tâm của vật thể trong ảnh của các bộ dữ liệu khác nhau (kích thước ảnh đã được chuẩn hóa)"
6241,E:\DATN\dataframe\train_file\70.txt,Dựa vào feature của backbone thì nhánh prediction sẽ được thiết kế và dự đoán các vùng có vật thể từ đó có thể tạo ra các anchor phù hợp về vị trí và kích thước.
6242,E:\DATN\dataframe\train_file\70.txt,Có hai phương pháp có thể kể đến là  và .
6243,E:\DATN\dataframe\train_file\70.txt,Objective Imbalance
6244,E:\DATN\dataframe\train_file\70.txt,Như tên gọi thì vấn đề này liên quan đến các hàm mục tiêu (hàm loss) được mô hình sử dụng trong quá trình training.
6245,E:\DATN\dataframe\train_file\70.txt,Bài toán object detection là sự kết hợp của bài toán phân loại ảnh (image classification) và định vị vật thể (object localization) nên hàm loss của nó cũng phải là multi-task loss.
6246,E:\DATN\dataframe\train_file\70.txt,"Do đó, điều này có thể dẫn đến việc mất cân bằng giữa các task như sau:"
6247,E:\DATN\dataframe\train_file\70.txt,Norm của gradient có thể khác nhau giữa các task.
6248,E:\DATN\dataframe\train_file\70.txt,Ví dụ như hình thì loss của task classification đang chiếm ưu thế hơn loss của task regression
6249,E:\DATN\dataframe\train_file\70.txt,Khoảng giá trị của hàm loss của mỗi task có thể khác nhau khiến cho việc tối ưu các hàm loss cũng khó khăn hơn.
6250,E:\DATN\dataframe\train_file\70.txt,Độ phức tạp của các task cũng khác nhau nên tốc độ học các task của mô hình là khác nhau dẫn đến việc cản trở quá trình training.
6251,E:\DATN\dataframe\train_file\70.txt,"Áp dụng Task Weighting để cân bằng loss, bằng cách sử dụng các weighting factor cho các loss của các task."
6252,E:\DATN\dataframe\train_file\70.txt,Giá trị này có thể xác định bằng các sử dụng các tập val.
6253,E:\DATN\dataframe\train_file\70.txt,Một cách tiếp cận nữa là kết hợp task classification và regression (Classification-Aware Regression Loss - CARL)
6254,E:\DATN\dataframe\train_file\70.txt,Khi tham gia challenge về nhận diện người đeo khẩu trang mình đã gặp phải vấn đề là bộ dữ liệu rơi vào trường hợp Foreground-Foreground class imbalance ở dataset-level.
6255,E:\DATN\dataframe\train_file\70.txt,"Tuy nhiên, mình đã dành thời gian để tìm hiểu thêm các imbalance problem liên quan đến bài toán object detection và tổng hợp lại thành một bài viết."
6256,E:\DATN\dataframe\train_file\70.txt,Nội dung mình tham khảo chủ yếu từ paper 
6257,E:\DATN\dataframe\train_file\71.txt,Tổng quan về Face Anti-Spoofing - Bài toán chống giả mạo khuôn mặt
6258,E:\DATN\dataframe\train_file\71.txt,Mình hi vọng bài viết này có thể cung cấp một cái nhìn toàn cảnh về bài toán Face Anti-spoofing.
6259,E:\DATN\dataframe\train_file\71.txt,Các phần mình sẽ giới thiệu lần lượt là:
6260,E:\DATN\dataframe\train_file\71.txt,Giới thiệu tổng quan
6261,E:\DATN\dataframe\train_file\71.txt,Các cách tấn công giả mạo - Attack methods
6262,E:\DATN\dataframe\train_file\71.txt,Các phương pháp chống giả mạo - Anti-spoofing methods
6263,E:\DATN\dataframe\train_file\71.txt,Cách đánh giá mô hình - Evaluate metrics
6264,E:\DATN\dataframe\train_file\71.txt,Bốn loại giao thức đánh giá - Evaluation Protocols
6265,E:\DATN\dataframe\train_file\71.txt,Tổng quan về Deep Learning based methods.
6266,E:\DATN\dataframe\train_file\71.txt,Let's go !!
6267,E:\DATN\dataframe\train_file\71.txt,Giới thiệu bài toán Face Anti-Spoofing
6268,E:\DATN\dataframe\train_file\71.txt,"Những năm gần đây, hẳn bạn sẽ thấy sự xuất hiện ngày càng nhiều của bài toán nhận diện và xác thực khuôn mặt."
6269,E:\DATN\dataframe\train_file\71.txt,Ví dụ tiêu biểu nhất có thể kể đến các smartphone sử dụng khuôn mặt bạn để làm khóa mở điện thoại.
6270,E:\DATN\dataframe\train_file\71.txt,Hoặc một số ngân hàng yêu cầu xác thực khuôn mặt khi đăng ký tài khoản online.
6271,E:\DATN\dataframe\train_file\71.txt,"Một số nước, như trung quốc, đã sử dụng quét khuôn mặt để thanh toán tiền."
6272,E:\DATN\dataframe\train_file\71.txt,"Nói cách khác, việc xác thực người đứng trước màn hình có đúng là người chính chủ không, là một bài toán quan trọng."
6273,E:\DATN\dataframe\train_file\71.txt,"Tuy nhiên, việc này có thể bị trick dễ dàng bằng cách in một cái ảnh của người đó ra và đưa ra trước màn hình, hoặc hơn nữa là quay một video cần mặt người đó rồi đưa ra trước màn hình, là dễ dàng qua mặt được hệ thống nhận diện khuôn mặt."
6274,E:\DATN\dataframe\train_file\71.txt,"Bởi vì lẽ đó, sự cần thiết của bài toán Face Anti-spoofing ra đời."
6275,E:\DATN\dataframe\train_file\71.txt,(một bức ảnh vui vui lượm được từ google =))))
6276,E:\DATN\dataframe\train_file\71.txt,"Hãy lưu ý rằng, bản thân thứ mà hệ thống nhận được, là các frame của video."
6277,E:\DATN\dataframe\train_file\71.txt,Cách máy tính nhìn không giống với cách chúng ta nhìn.
6278,E:\DATN\dataframe\train_file\71.txt,"Vậy, làm cách nào để phân biệt đâu là người thật đang đứng trước màn hình, hay chỉ là một ảnh?"
6279,E:\DATN\dataframe\train_file\71.txt,"Vì lý do đó, bài toàn Face Anti Spoofing (FAS) - Bài toán chống giả mạo khuôn mặt ra đời."
6280,E:\DATN\dataframe\train_file\71.txt,Hình dưới đây cho thấy vị trí cả task face anti-spoofing trong toàn bộ hệ thống nhận diện khuôn mặt.
6281,E:\DATN\dataframe\train_file\71.txt,Một số phương pháp tấn công giả mạo
6282,E:\DATN\dataframe\train_file\71.txt,Có khá nhiều phương pháp để lừa một cái máy tính.
6283,E:\DATN\dataframe\train_file\71.txt,"Có thể phân ra thành, tấn công 2D và tấn công 3D."
6284,E:\DATN\dataframe\train_file\71.txt,"2D attacks: một cái ảnh, một tấm hình in, một video chứa mặt người đó, những ảnh được thay liên tiếp để tạo sự chuyển động giả..."
6285,E:\DATN\dataframe\train_file\71.txt,"Trong đó, replay attack là kiểu tấn công sử dụng màn hình laptop, điện thoại, monitor in hình mặt người để giả mạo."
6286,E:\DATN\dataframe\train_file\71.txt,"Print attack là kiểu tấn công sử dụng giấy, bìa in mặt người tỉ lệ 1:1 để tấn công."
6287,E:\DATN\dataframe\train_file\71.txt,"Nếu bẻ công tờ giấy (hoặc có thể cắt phần mắt để chống detect nháy mắt), ta có một kiểu tấn công hơi hướng 3D."
6288,E:\DATN\dataframe\train_file\71.txt,"3D attacks: đeo mặt nạ giả, hình in 3D, tượng mặt người, makeup hoặc thậm chí là một con robot có khuôn mặt được điều chỉnh mô phỏng khuôn mặt ai đó (hơi ảo một chút nhỉ, nhưng khó mà biết tội phạm có thể làm ra đến mức nào)"
6289,E:\DATN\dataframe\train_file\71.txt,"Trên thực tế, 2D diễn ra thường xuyên hơn, và chúng ta cũng sẽ tập trung xử lý những case phổ biến hơn."
6290,E:\DATN\dataframe\train_file\71.txt,"Vì vậy, các phương pháp mình đề cập trong bài này chủ yếu tập trung vào chống giả mạo cho 2D attacks."
6291,E:\DATN\dataframe\train_file\71.txt,Các phương pháp Face Anti-spoofing
6292,E:\DATN\dataframe\train_file\71.txt,Mình xin phép liệt kê ra năm phương pháp phổ biến.
6293,E:\DATN\dataframe\train_file\71.txt,3.1 Local binary pattern
6294,E:\DATN\dataframe\train_file\71.txt,"Nếu chúng ta còn nhớ thời kỳ đầu của computer vision, khi CNN chưa phát triển lắm, người ta đã dùng một số phương pháp lấy đặc trưng ảnh như bộ mô tả hình ảnh (image descriptors - như HOG, Haralick, Zernike, etc."
6295,E:\DATN\dataframe\train_file\71.txt,"), phát hiện keypoints (keypoint detectors - FAST, DoG, GFTT, etc."
6296,E:\DATN\dataframe\train_file\71.txt,"), và bộ mô tả bất biến cục bộ (local invariant descriptors - SIFT, SURF, RootSIFT, etc."
6297,E:\DATN\dataframe\train_file\71.txt,"Ở đây, Local Binary Pattern (LBPs) tính toán biểu diễn cục bộ (Local representation)."
6298,E:\DATN\dataframe\train_file\71.txt,Local representation này được xây dựng bằng cách so sánh từng pixel với các pixel lân cận xung quanh của nó.
6299,E:\DATN\dataframe\train_file\71.txt,Bước đầu tiên trong việc xây dựng LBP là chuyển đổi hình ảnh sang thang độ xám(gray scale).
6300,E:\DATN\dataframe\train_file\71.txt,"Đối với mỗi pixel trong hình ảnh thang độ xám, ta chọn một vùng lân cận có kích thước"
6301,E:\DATN\dataframe\train_file\71.txt,r bao quanh pixel trung tâm.
6302,E:\DATN\dataframe\train_file\71.txt,Giá trị LBP sau đó được tính cho pixel trung tâm này và được lưu trữ trong mảng 2D đầu ra có cùng chiều rộng và chiều cao với hình ảnh đầu vào.
6303,E:\DATN\dataframe\train_file\71.txt,Ví dụ: LBP có thể hoạt động trên vùng lân cận pixel 3 x 3 cố định
6304,E:\DATN\dataframe\train_file\71.txt,như sau: pixel trung tâm được lấy làm ngưỡng cho giá trị 8 pixel xung quanh.
6305,E:\DATN\dataframe\train_file\71.txt,Vậy tính giá trị ở pixel trung tâm như thế nào?
6306,E:\DATN\dataframe\train_file\71.txt,Các tính được thể hiện rõ trong hình dưới đây.
6307,E:\DATN\dataframe\train_file\71.txt,"Cứ như vậy, chúng ta sẽ tính quy đổi được tất cả các giá trị pixel trong ảnh."
6308,E:\DATN\dataframe\train_file\71.txt,Ta sẽ có một vector đặc trung của ảnh và có thể dùng SVM để phân loại.
6309,E:\DATN\dataframe\train_file\71.txt,"Tuy nhiên, đây là một phương pháp khá cũ rồi (nó được giới thiệu năm 2002 và ý tưởng thì từ 1993)."
6310,E:\DATN\dataframe\train_file\71.txt,Lợi ích duy nhất của nó là thời gian triển khai nhanh.
6311,E:\DATN\dataframe\train_file\71.txt,"Nhưng độ chính xác thấp, khả năng bị ảnh hưởng bởi nhiễu cao."
6312,E:\DATN\dataframe\train_file\71.txt,Và nó không còn phù hợp nữa.
6313,E:\DATN\dataframe\train_file\71.txt,3.2 Eye Blink Detection
6314,E:\DATN\dataframe\train_file\71.txt,Detect nháy mắt.
6315,E:\DATN\dataframe\train_file\71.txt,"Trung bình, con người nháy mắt từ 15 đến 30 lần trong một phút."
6316,E:\DATN\dataframe\train_file\71.txt,"Mỗi nháy mắt của con người, tức khoảng thời gian mí mắt sụp xuống, có thể chỉ diễn ra trong vài tích tắc (tầm 250 mm giây)."
6317,E:\DATN\dataframe\train_file\71.txt,"Trong lúc đó, tốc độ camera bắt khung hình có thể lên tới 30fps (30 frame per second), tức mỗi frame chỉ mất tầm 50 mili giây."
6318,E:\DATN\dataframe\train_file\71.txt,"Có nghĩa là, ta hoàn toàn có thể bắt được khoảng khắc mí mắt sụp xuống."
6319,E:\DATN\dataframe\train_file\71.txt,"Nếu đủ điều kiện, phương pháp này có độ chính xác rất cao."
6320,E:\DATN\dataframe\train_file\71.txt,"Tuy nhiên, nhược điểm của phương pháp này là gì?"
6321,E:\DATN\dataframe\train_file\71.txt,"Thứ nhất, phương pháp này chỉ phù hợp nếu đầu vào là một video."
6322,E:\DATN\dataframe\train_file\71.txt,"Nếu đầu vào là một ảnh tĩnh, phương pháp này không thể thực hiện được."
6323,E:\DATN\dataframe\train_file\71.txt,"Thứ hai, phương pháp này cần đến sự tham gia của người dùng."
6324,E:\DATN\dataframe\train_file\71.txt,"Nếu người dùng đứng quá xa, quá trình detect mắt trở nên khó khăn và detect nháy mắt càng khó."
6325,E:\DATN\dataframe\train_file\71.txt,"Đồng thời, nếu người dùng cố tình không chớp mắt, hoặc ảnh hưởng của một số điều kiện sức khỏe, khó chớp mắt, phương pháp này cũng không thể áp dụng."
6326,E:\DATN\dataframe\train_file\71.txt,"Hoặc đơn giản là đeo kính râm, cắt bỏ phần ảnh mắt, thì phương pháp này fail =))."
6327,E:\DATN\dataframe\train_file\71.txt,3.3 Deep Learning Features: Convolutional Neural Network
6328,E:\DATN\dataframe\train_file\71.txt,"Đúng vậy, sự ra đời của Convolutional Neural Network đã thống trị mảng computer vision suốt nhiều năm qua."
6329,E:\DATN\dataframe\train_file\71.txt,"Dù thời điểm này có thêm nhiều nghiên cứu mới đột phá, CNN vẫn luôn đóng vai trò cực kỳ quan trọng."
6330,E:\DATN\dataframe\train_file\71.txt,"Về cơ bản, có thể coi bài toán Face Anti-Spoofing như một bài toán classification với hai nhãn."
6331,E:\DATN\dataframe\train_file\71.txt,Dùng một mạng CNN để trích xuất đặc trưng rồi đưa ra output.
6332,E:\DATN\dataframe\train_file\71.txt,"Tuy nhiên, làm sao để xây dựng một mạng CNN đủ tốt."
6333,E:\DATN\dataframe\train_file\71.txt,"Có thể bạn chưa biết, nhưng 2 bức ảnh dưới đều là ảnh giả mạo."
6334,E:\DATN\dataframe\train_file\71.txt,"Một bên là ảnh print, và một bên có lẽ là ảnh qua màn hình điện thoại."
6335,E:\DATN\dataframe\train_file\71.txt,"Với bức ảnh bên trái, mắt thường cũng khó phân biệt được."
6336,E:\DATN\dataframe\train_file\71.txt,"Làm sao để đào tạo một model dêp learning đủ tốt để classify, đây là một hướng đi được rất nhiều paper nghiên cứu, mình sẽ đề cập rõ hơn ở phần bốn, bao gồm cả ưu nhược điển của nó."
6337,E:\DATN\dataframe\train_file\71.txt,3.4 Active Flash
6338,E:\DATN\dataframe\train_file\71.txt,"Sử dụng đèn flash có sẵn của thiết bị, sau đó huấn luyện mô hình để nhận ra sự thay đổi trước và sau khi bật đèn flash, đó là ý tưởng của phương pháp này."
6339,E:\DATN\dataframe\train_file\71.txt,"Mình không có nhiều kinh nghiệm đối với phương pháp này, tuy nhiên một số báo cáo cho rằng đây là phương pháp có nhiều hứa hẹn."
6340,E:\DATN\dataframe\train_file\71.txt,"Nhìn chung, bài toán face anti-spoofing vẫn là bài toán còn nhiều vấn đề chưa được khai phá."
6341,E:\DATN\dataframe\train_file\71.txt,3.5 Challenge-response
6342,E:\DATN\dataframe\train_file\71.txt,Một số ứng dụng xác thực danh tính yêu cầu người dùng thực hiện một số thao tác không đoán trước (thường random) để xác minh trước màn hình có phải người sống thực sự hay không.
6343,E:\DATN\dataframe\train_file\71.txt,Một số yêu cầu như là:
6344,E:\DATN\dataframe\train_file\71.txt,"Nghiêng đầu trái phải, di chuyển đầu lúc lắc"
6345,E:\DATN\dataframe\train_file\71.txt,Mỉm cười
6346,E:\DATN\dataframe\train_file\71.txt,Biểu cảm vui buồn
6347,E:\DATN\dataframe\train_file\71.txt,"Về cơ bản, cách này khá hiệu quả để xác thực vật thể sống."
6348,E:\DATN\dataframe\train_file\71.txt,Nhưng điểm phiền toái nhất chính là trải nghiệm khách hàng.
6349,E:\DATN\dataframe\train_file\71.txt,Thực sự rất phiền nếu cái máy chấm công ở cổng công ty bắt chúng ta làm đủ trò hề trước màn hình mới chấm công cho chúng ta phải không =)))))
6350,E:\DATN\dataframe\train_file\71.txt,3.6 3D camera
6351,E:\DATN\dataframe\train_file\71.txt,"Ý tưởng căn bản bắt đầu từ việc, khuôn mặt người thật là một khối 3D, nghĩa là nó có sự lồi lõm khác nhau, và khoảng cách từ camera tới vật thể có sự khác nhau giữa các điểm."
6352,E:\DATN\dataframe\train_file\71.txt,Ta gọi nó là bản đồ độ sâu (depth map).
6353,E:\DATN\dataframe\train_file\71.txt,"Còn với giả mạo, là một màn hình phẳng."
6354,E:\DATN\dataframe\train_file\71.txt,Và camera 3D có thể thu được thông tin về độ sâu đó.
6355,E:\DATN\dataframe\train_file\71.txt,Đây có thể coi là phương pháp hiệu quả nhất của bài toán face anti-spoofing.
6356,E:\DATN\dataframe\train_file\71.txt,"Tuy nhiên, đưa 2 ảnh và bảo phân biệt đâu là ảnh giả mạo, trường hợp này 3D camera fail =))) Và vấn đề lớn nhất có lẽ là chi phí camera, cũng như một số ảnh hưởng môi trường."
6357,E:\DATN\dataframe\train_file\71.txt,Tạm kết
6358,E:\DATN\dataframe\train_file\71.txt,Và hình dưới đây tổng kết ưu nhược điểm của cả 6 phương pháp mà mình đã nêu trên.
6359,E:\DATN\dataframe\train_file\71.txt,"(màu xanh là phần pp đó có thể hold, màu đỏ là nhược điểm)."
6360,E:\DATN\dataframe\train_file\71.txt,Evaluation Metrics
6361,E:\DATN\dataframe\train_file\71.txt,"Về các phương pháp đánh giá mô hình, có thể kể đến được dùng phổ biến nhất là Tỉ lệ từ chối sai - False Rejection Rate (FRR) và Tỉ lệ chấp nhận sai - False Acceptance Rate (FAR)."
6362,E:\DATN\dataframe\train_file\71.txt,"Hải chỉ số này thường được dùng trong xác minh sinh trắc học, nên cũng có thể dùng trong FAS."
6363,E:\DATN\dataframe\train_file\71.txt,FRR: có bao nhiêu mẫu đúng bị từ chối.
6364,E:\DATN\dataframe\train_file\71.txt,"Ví dụ: nếu FRR là 0,2%, cứ 500 người dùng được ủy quyền sẽ có một người bị từ chối nhận dạng khi họ truy cập."
6365,E:\DATN\dataframe\train_file\71.txt,FAR: có bao nhiêu kể mạo danh vượt qua ngưỡng.
6366,E:\DATN\dataframe\train_file\71.txt,"Lưu ý rằng, hai chỉ số này có tác động lẫn nhau."
6367,E:\DATN\dataframe\train_file\71.txt,"Như vậy, nếu chúng ta ưu tiên người dùng, ta tập trung vào FAR, means nếu sai một chút vẫn có thể chấp nhận."
6368,E:\DATN\dataframe\train_file\71.txt,"Ngược lại, nếu ta muốn loại bỏ mọi kẻ giả mạo nhiều nhất có thể, ta sẽ tập trung nâng cao chỉ số FRR."
6369,E:\DATN\dataframe\train_file\71.txt,"Ngoài ra, khá nhiều paper sử dụng thêm các chỉ số đánh giá sau:"
6370,E:\DATN\dataframe\train_file\71.txt,TP: True positive
6371,E:\DATN\dataframe\train_file\71.txt,TN: True negative
6372,E:\DATN\dataframe\train_file\71.txt,FP: False positive
6373,E:\DATN\dataframe\train_file\71.txt,FN: False negative
6374,E:\DATN\dataframe\train_file\71.txt,Attack Presentation Classification Error Rate (APCER ):
6375,E:\DATN\dataframe\train_file\71.txt,APCER = \frac {FP} {TN + FP}
6376,E:\DATN\dataframe\train_file\71.txt,Normal Presentation Classification Error Rate (NPCER ):
6377,E:\DATN\dataframe\train_file\71.txt,NPCER = \frac{FN}{FN + TP}
6378,E:\DATN\dataframe\train_file\71.txt,Average Classification Error Rate (ACER):
6379,E:\DATN\dataframe\train_file\71.txt,ACER = \frac{APCER + NPCER}{2}
6380,E:\DATN\dataframe\train_file\71.txt,Evaluation Protocols
6381,E:\DATN\dataframe\train_file\71.txt,"Đến khi tìm hiểu về bài toán Face Anti-Spoofing mình mới gặp những khái niệm này, nên mình cũng muốn giới thiệu một chút."
6382,E:\DATN\dataframe\train_file\71.txt,"Đối với các bài toán thông thường, hẳn bạn đã từng quen với việc chia dataset của chúng ta ra làm ba phần: train, validation và test."
6383,E:\DATN\dataframe\train_file\71.txt,"Trong đó, cả ba tập này đều có format tương tương nhau."
6384,E:\DATN\dataframe\train_file\71.txt,"Vậy FAS có chia train, valid, test như thế không?"
6385,E:\DATN\dataframe\train_file\71.txt,Tại sao bài toán FAS lại cần đến nhiều giao thức đánh giá?
6386,E:\DATN\dataframe\train_file\71.txt,"Như đã nêu trên, một trong những vấn đề của FAS là việc, có rất nhiều cách để tấn công giả mạo."
6387,E:\DATN\dataframe\train_file\71.txt,"Một số phương pháp phân biệt được tốt cách tấn công này, nhưng lại fail với cách tấn công khác."
6388,E:\DATN\dataframe\train_file\71.txt,"Thế nên, các nghiên cứu về FAS mới đưa thêm một số cách đánh giá chéo."
6389,E:\DATN\dataframe\train_file\71.txt,Intra-Dataset Intra-Type Protocol: được sử dụng trong các tình huống chỉ có sự thay đổi nhỏ về domain.
6390,E:\DATN\dataframe\train_file\71.txt,"Ở đây, training data và testing data được lấy chung từ một bộ dữ liệu."
6391,E:\DATN\dataframe\train_file\71.txt,(Fig.4 (a) in paper)
6392,E:\DATN\dataframe\train_file\71.txt,"Cross-Dataset Intra-Type Protocol: Giao thức này tập trung vào đo lường khả năng tổng quát hóa miền cấp độ tập dữ liệu chéo, thường huấn luyện các mô hình trên một hoặc một số tập dữ liệu (source domain) và sau đó kiểm tra trên các tập dữ liệu chưa nhìn thấy trước đó (thay đổi target domain)."
6393,E:\DATN\dataframe\train_file\71.txt,(Fig.4 (b) in paper)
6394,E:\DATN\dataframe\train_file\71.txt,"Intra-Dataset Cross-Type Protocol: ngược lại với giao thức phía trên, cách đánh giá này chỉ huấn luyện mô hình trên một tập data, sau đó đánh giá xem mô hình có mang tính tổng quát không bằng cách testing trên nhiều tập test ở nhiều domain khác nhau, chưa từng xuất hiện trong tập train."
6395,E:\DATN\dataframe\train_file\71.txt,"Được sử dụng nhiều nhất trong trường hợp này là dataset SiW-M, với hơn 13 loại tấn công khác nhau."
6396,E:\DATN\dataframe\train_file\71.txt,(Fig.4 (c) in paper)
6397,E:\DATN\dataframe\train_file\71.txt,"Cross-Dataset Cross-Type Protocol: Sau ba loại đánh giá trên, mặc dù bắt được kha khá các vấn đề có thể xảy ra trong thực tế, nhưng có lẽ người ta vẫn thấy chưa đủ =))))) Ở giao thức này, chúng ta đo lường mô hình FAS tổng quát trên cả miền chưa từng nhìn thấy và các kiểu tấn công không xác định."
6398,E:\DATN\dataframe\train_file\71.txt,"Thường thì, hai datasets OULU-NPU và SiW được trộn lại để huấn luyện, trong khi HKBU-MARs và 3DMask được sử dụng trong testing."
6399,E:\DATN\dataframe\train_file\71.txt,(Fig.4 (d) in paper)
6400,E:\DATN\dataframe\train_file\71.txt,Phần viết này tham khảo từ paper:
6401,E:\DATN\dataframe\train_file\71.txt, (28 June 2021)
6402,E:\DATN\dataframe\train_file\71.txt,"Về cơ bản, bài toán thật giả có thể được coi như là bài toán classification."
6403,E:\DATN\dataframe\train_file\71.txt,"Thậm chí, sử dụng các thuật toán ML như logistic regression hay SVM vẫn có thể giải quyết được bài toán ở một mức độ nào đó với kết quả không hề tệ."
6404,E:\DATN\dataframe\train_file\71.txt,Tiếp theo đây mình giới thiệu về các hướng tiếp cận sử dụng deep learning.
6405,E:\DATN\dataframe\train_file\71.txt,"Đây là hướng nghiên cứu được đào sâu nhất trong tất cả sáu hướng mình đã điểm qua ở phần ba, là hướng có nhiều paper nhất."
6406,E:\DATN\dataframe\train_file\71.txt,"Về nhược điểm của việc sử dụng deep learning, có thể kể đến hai nhược điểm lớn:"
6407,E:\DATN\dataframe\train_file\71.txt,"Thứ nhất, là khả năng học tổng quát."
6408,E:\DATN\dataframe\train_file\71.txt,"Nếu chúng ta huấn luyện model deep learning cái gì, nó sẽ học mỗi thứ đó."
6409,E:\DATN\dataframe\train_file\71.txt,"Vấn đề là, có rất nhiều phương pháp tấn công giả mạo."
6410,E:\DATN\dataframe\train_file\71.txt,Ta gọi đó là vấn đề domain.
6411,E:\DATN\dataframe\train_file\71.txt,Hầu hết các mô hình giả quyết được domain này thì lại mắc lỗi với domain khác.
6412,E:\DATN\dataframe\train_file\71.txt,Cân bằng nhiều domain thì lại giảm hiệu suất chung.
6413,E:\DATN\dataframe\train_file\71.txt,"Thứ hai, là ảnh hưởng của môi trường."
6414,E:\DATN\dataframe\train_file\71.txt,Lớn nhất có thể kể đến điều kiện ánh sáng thay đổi.
6415,E:\DATN\dataframe\train_file\71.txt,"Ảnh ở ánh sáng bình thường, ảnh bị chói sáng, ảnh bị ngược sáng, ảnh bị thiếu sáng."
6416,E:\DATN\dataframe\train_file\71.txt,Làm sao để model của chúng ta có thể cân bằng hết những hạn chế đó.
6417,E:\DATN\dataframe\train_file\71.txt,"Trong các paper gần đây nhất, hai hướng tiếp cận chủ yếu là (1) xử lý vấn đề domain và (2) đề xuất các cải tiến model deep learning."
6418,E:\DATN\dataframe\train_file\71.txt,Hình ảnh dưới đây cho thấy gần như toàn bộ các hướng tiếp cận của phương pháp Deep Learning for Face Anti-Spoofing.
6419,E:\DATN\dataframe\train_file\71.txt,"Trong đó, bạn có thể thấy:"
6420,E:\DATN\dataframe\train_file\71.txt,Commercial RGB camera: Hướng đầu tiên này nhận đầu vào là ảnh RGB.
6421,E:\DATN\dataframe\train_file\71.txt,"Điều này phổ biến hơn, vì mọi các camera thông thường hiện nay đều thu được ảnh RGB."
6422,E:\DATN\dataframe\train_file\71.txt,"Multiple modalities or specialized sensors: Hướng thứ hai là dữ liệu thu được từ một số loại sensor cammera đặc biệt, đơn cử như camera trích xuất độ sâu (Kinect, D435i), camera hồng ngoại, camera nhiệt, vân vân."
6423,E:\DATN\dataframe\train_file\71.txt,"Từ khóa Multiple modalities là để chỉ việc kết hợp nhiều dữ liệu đầu vào, ví dụ ta kết hợp cả ảnh RGB và ảnh depth thu được, với hi vọng cung cấp nhiều thông tin hữu ích hơn cho model của chúng ta."
6424,E:\DATN\dataframe\train_file\71.txt,6.1 Datasets
6425,E:\DATN\dataframe\train_file\71.txt,"(Tất cả các link dưới đây là danh sách tổng hợp các paper cho đến năm 2021, đã được phân loại theo từng phương pháp)"
6426,E:\DATN\dataframe\train_file\71.txt,6.2 Deep FAS methods with commercial RGB camera
6427,E:\DATN\dataframe\train_file\71.txt,1 Hyprid method
6428,E:\DATN\dataframe\train_file\71.txt,"Phương pháp này kết hợp những ưu điểm của hand- crafted features (mục 3.1) và mô hình deep learning, bởi vậy nên nó mới đc gọi là hyprid (lai)."
6429,E:\DATN\dataframe\train_file\71.txt,2 Common deep learning method
6430,E:\DATN\dataframe\train_file\71.txt,"Sử dụng end-to-end deep learning based method, vì xử lý bài toán như một bài classification 2 class, nên sử dụng cross entropy loss để giám sát việc huấn luyện model."
6431,E:\DATN\dataframe\train_file\71.txt,"Tuy nhiên, sử dụng mỗi binary loss chưa thể hold được toàn bộ việc huấn luyện."
6432,E:\DATN\dataframe\train_file\71.txt,"Một số paper gần đây đề xuất bổ sung thêm một số Loss như: Contrastive Loss, Triplet Loss."
6433,E:\DATN\dataframe\train_file\71.txt,Chi tiết mình sẽ cố gắng đề cập ở các bài viết sau.
6434,E:\DATN\dataframe\train_file\71.txt,"Dạo gần đây, các hướng nghiên cứu tiếp cận theo hướng pixel-wise supervision thu hút nhiều sự chú ý hơn vì nó cung cấp nhiều tín hiệu giám sát nhận biết ngữ cảnh chi tiết hơn, có lợi cho mô hình học các intrinsic spoofing cues (dịch là tín hiệu giả mạo nội tại, mình cx không chắc nữa =)), phần này vẫn còn phải đọc lại nhiều)."
6435,E:\DATN\dataframe\train_file\71.txt,"Pseudo Depth labels, Eeflection maps, Binary Mask label và 3D Point cloud maps là các điển hình cho phương pháp pixel-wise auxiliary supervisions."
6436,E:\DATN\dataframe\train_file\71.txt,Phương pháp này mô tả các dấu hiệu live/spoof cục bộ ở cấp độ pixel hoặc patch.
6437,E:\DATN\dataframe\train_file\71.txt,"Nói thêm một chút về pseudo depth, ở phương pháp này, mô hình cố gắng tạo ra các feature maps là depth maps."
6438,E:\DATN\dataframe\train_file\71.txt,Nói cách khác là cố dựng lại bản đồ độ sâu cho đối tượng.
6439,E:\DATN\dataframe\train_file\71.txt,Bạn có thể tham khảo paper: .
6440,E:\DATN\dataframe\train_file\71.txt,là một ví dụ cho phương pháp sử dụng mạng CNN kết hợp RNN để cố gắng xây dựng lại bản đồ độ sâu.
6441,E:\DATN\dataframe\train_file\71.txt,Đồng thời ở paper này giới thiệu Contrastive Depth Loss.
6442,E:\DATN\dataframe\train_file\71.txt,Mình sẽ viết một bài phân tích chi tiết về paper này ở bài viết sau.
6443,E:\DATN\dataframe\train_file\71.txt,"Một số hướng có thể suy nghĩ như là: (1) ảnh chúng ta thu được có thêm phần background dính vào (ví dụ khoảng trống ở cổ), liệu có thể loại bỏ phần này và chỉ tập trung vào khuôn mặt, có thể tham khảo ở , (2) sử dụng 3D point cloud map để giám sát các mô hình lightweight, (4) làm sao để tích hợp thêm một số thông tin phụ trợ khác, etc ..."
6444,E:\DATN\dataframe\train_file\71.txt,Sử dụng mạng GAN.
6445,E:\DATN\dataframe\train_file\71.txt,Generalized deep learning method
6446,E:\DATN\dataframe\train_file\71.txt,"Như đã nói bên trên, đó là vấn đề domain và học tổng quát."
6447,E:\DATN\dataframe\train_file\71.txt,"Sẽ như thế nào nếu gặp phải một phương pháp tấn công chưa gặp bao giờ, sẽ như thế nào nếu mô hình của chúng ta tốt với cách tấn công này nhưng fail với cách tấn công khác."
6448,E:\DATN\dataframe\train_file\71.txt,Các phương pháp Domain Adaption cần dữ liệu của miền đích target domain (không được gắn nhãn) để tìm hiểu mô hình.
6449,E:\DATN\dataframe\train_file\71.txt,Các phương pháp Domain Generalization học mô hình tổng quát mà không có kiến thức từ target domain.
6450,E:\DATN\dataframe\train_file\71.txt,"Cuối cùng, Few-shot Learning coi mỗi miền nguồn như một trung tâm dữ liệu riêng và tìm hiểu mô hình tổng quát hóa trong server thông qua tổng hợp các mô hình từ các trung tâm dữ liệu cục bộ."
6451,E:\DATN\dataframe\train_file\71.txt,"Một paper mới published gần đây nhất nằm trong phương pháp Domain Generalization là paper D2AM, với ý tưởng chung là phân chia lặp đi lặp lại các miền hỗn hợp (mixture domain) thông qua biểu diễn các miền phân biệt và đào tạo các mô hình có thể tổng quát hóa với meta-learning mà không sử dụng nhãn miền."
6452,E:\DATN\dataframe\train_file\71.txt,Bạn nên đọc:
6453,E:\DATN\dataframe\train_file\71.txt,Link paper:
6454,E:\DATN\dataframe\train_file\71.txt,6.3 Deep FAS methods with advanced sensor
6455,E:\DATN\dataframe\train_file\71.txt,: Phương pháp này bắt nguồn từ suy nghĩ rằng việc kết hợp các phương thức hoặc loại thông tin khác nhau có thể cải thiện hiệu suất (ví dụ kết hợp ảnh RGB do camnera thu được và bản đồ độ sâu depth map đc tính toán (hoặc cũng do các camera depth thu được)).
6456,E:\DATN\dataframe\train_file\71.txt,"Tuy nhiên, việc kết hợp mức độ nhiễu khác nhau và xung đột giữa các phương thức là một thách thức."
6457,E:\DATN\dataframe\train_file\71.txt,"Hơn nữa, các phương thức có ảnh hưởng định lượng khác nhau đối với kết quả dự đoán."
6458,E:\DATN\dataframe\train_file\71.txt,Phương pháp phổ biến nhất trong thực tế là kết hợp các nhúng cấp cao từ các đầu vào khác nhau bằng cách nối chúng và sau đó áp dụng softmax.
6459,E:\DATN\dataframe\train_file\71.txt,"Mình chưa có nhiều kinh nghiệm về phần này, mình sẽ cố gắng update vào các bài viết sau."
6460,E:\DATN\dataframe\train_file\71.txt,Bài đã dài rồi.
6461,E:\DATN\dataframe\train_file\71.txt,"Nhìn chung, trong hai năm trở lại đây, có lẽ do nhu cầu xã hội, các nghiên cứu lẫn paper của bài toán này tăng vọt một cách đáng kể."
6462,E:\DATN\dataframe\train_file\71.txt,Bài toán vẫn chưa tìm ra giải pháp tối ưu tổng quát nhất và vẫn đang còn rất nhiều điều cần khai phá.
6463,E:\DATN\dataframe\train_file\71.txt,"Ở các bài viết tiếp theo, mình sẽ đi sâu vào phân tích chi tiết một số phương pháp giải quyết bài toán Face Anti-spoofing và cách triển khai nó trong thực tế."
6464,E:\DATN\dataframe\train_file\71.txt,Có thể followđể đón đọc các bài viết tiếp theo nhé
6465,E:\DATN\dataframe\train_file\72.txt,Một ứng dụng nho nhỏ của giải thuật di truyền trong Reinforcement Learning - Sinh chuỗi tương tự
6466,E:\DATN\dataframe\train_file\72.txt,Lời mở đầu
6467,E:\DATN\dataframe\train_file\72.txt,Xin chào các bạn.
6468,E:\DATN\dataframe\train_file\72.txt,Chắc hẳn chúng ta đã không còn xa lạ gì với những thuật toán Reinforcement Learning sử dụng Deep Learning rồi phải không.
6469,E:\DATN\dataframe\train_file\72.txt,Có bao giờ bạn đặt ra câu hỏi rằng thay vì chúng ta cố gắng đi tìm những kiến trúc mạng khổng lồ rồi cố gắng tối ưu nó thì chúng ta sẽ thử một trong những phương pháp khác không cần dùng đến mạng nơ ron chưa?
6470,E:\DATN\dataframe\train_file\72.txt,Nếu bạn cũng đang có những băn khoăn như vậy thì bài viết này sẽ dành cho bạn.
6471,E:\DATN\dataframe\train_file\72.txt,"Trong quá trình tiến hóa tự nhiên, các đặc điểm sinh học thay đổi và các đặc điểm mới được tạo ra chỉ đơn giản là do một số đặc điểm mang lại lợi thế sinh tồn và sinh sản."
6472,E:\DATN\dataframe\train_file\72.txt,Kết quả là những sinh vật đó có thể tạo ra nhiều bản sao về di truyền học của chúng hơn trong những thế hệ tiếp theo.
6473,E:\DATN\dataframe\train_file\72.txt,"Khả năng tồn tại của một gen phụ thuộc hoàn toàn vào môi trường, môi trường này thường không thể đoán trước và liên tục thay đổi."
6474,E:\DATN\dataframe\train_file\72.txt,"Trong trường hợp áp dụng trong khoa học máy tính, quá trình tiến hóa mô phỏng đơn giản hơn nhiều, vì chúng ta thường muốn tối đa hóa hoặc giảm thiểu một số duy nhất, chẳng hạn như giá trị của hàm mất mát khi huấn luyện một mạng nơ-ron."
6475,E:\DATN\dataframe\train_file\72.txt,Trong bài này chúng ta sẽ tìm hiểu một hướng tiếp cận mới của RF khi không dùng đến Deep Learning mà sử dụng Genertic Algorithms.
6476,E:\DATN\dataframe\train_file\72.txt,"Để minh hoạ cho hoạt động của bài toán, mình sẽ sử dụng một ứng dụng rất đơn giản nhưng thú vị đó chính là Sinh chuỗi tương tự với một chuỗi đầu vào bất kì."
6477,E:\DATN\dataframe\train_file\72.txt,OK chúng ta bắt đầu thôi
6478,E:\DATN\dataframe\train_file\72.txt,Nhìn lại về học tăng cường sử dụng DL
6479,E:\DATN\dataframe\train_file\72.txt,Học tăng cường sử dụng DL
6480,E:\DATN\dataframe\train_file\72.txt,Cùng nhìn lại một chút về học tăng cường.
6481,E:\DATN\dataframe\train_file\72.txt,Tại sao chúng ta thậm chí sẽ nghĩ đến việc loại bỏ backpropagation.
6482,E:\DATN\dataframe\train_file\72.txt,"Trong khi cả DQN và policy gradient approach, chúng ta đều tạo ra một agent có policy của nó phụ thuộc vào tham số của mạng nơ ron để xấp xỉ Q function hay policy function."
6483,E:\DATN\dataframe\train_file\72.txt,"Như trong hình dưới đây, agent sẽ tương tác với môi trường, thu thập các kinh nghiệm và sau đó sử dụng lan truyền ngược để cải thiện độ chính xác của mạng nơ-ron."
6484,E:\DATN\dataframe\train_file\72.txt,Đó là policy của nó.
6485,E:\DATN\dataframe\train_file\72.txt,"Chúng ta cần phải điều chỉnh cẩn thận một số siêu tham số khác nhau, từ việc chọn hàm tối ưu phù hợp, kích thước của mini-batch và tốc độ học để quá trình huấn luyện diễn ra ổn định và thành công."
6486,E:\DATN\dataframe\train_file\72.txt,Nhưng có một vấn đề là dù đã chọn lựa rất kĩ các siêu tham số đó thì cũng không có gì khẳng định thuật toán sẽ học thành công nếu như các kĩ thuật sử dụng đạo hàm đưa chúng ta để một giải pháp tối ưu cục bộ thay vì tối ưu toàn cục.
6487,E:\DATN\dataframe\train_file\72.txt,"Đối với các thuật toán dựa trên các mạng nơ ron, các agent của chúng ta đã tương tác với môi trường, thu thập kinh nghiệm và sau đó học hỏi từ những kinh nghiệm đó."
6488,E:\DATN\dataframe\train_file\72.txt,Chúng ta lặp đi lặp lại quy trình tương tự cho mỗi epoch cho đến khi kết thúc quá trình học.
6489,E:\DATN\dataframe\train_file\72.txt,"Tùy thuộc vào môi trường và độ phức tạp của mạng, việc tạo một agent với các siêu tham số phù hợp có thể cực kỳ khó khăn."
6490,E:\DATN\dataframe\train_file\72.txt,"Hơn nữa, để có thể sử dụng được gradient descent và backpropagation, chúng ta cần một mô hình khả vi."
6491,E:\DATN\dataframe\train_file\72.txt,Chắc chắn có những mô hình thú vị và hữu ích mà bạn có thể xây dựng nhưng lại không thể huấn luyện được với gradient descent do nó không khả vi.
6492,E:\DATN\dataframe\train_file\72.txt,Điều này dẫn đến một hướng mới chúng ta có thể tiếp cận đó chính là thuật toán tiến hoá
6493,E:\DATN\dataframe\train_file\72.txt,Quá trình học dựa trên thuật toán tiến hoá
6494,E:\DATN\dataframe\train_file\72.txt,"Vậy thay vì tạo ra một agent và cải thiện nó, thay vào đó chúng ta có thể học hỏi từ Charles Darwin và sử dụng quá trình tiến hóa bằng chọn lọc tự nhiên."
6495,E:\DATN\dataframe\train_file\72.txt,"Chúng ta có thể sinh ra nhiều agent khác nhau với các bộ tham số (weights) khác nhau, quan sát tác nhân nào làm tốt nhất và “lai tạo” tác nhân tốt nhất để con cháu có thể thừa hưởng những đặc điểm mong muốn của cha mẹ chúng — giống như trong chọn lọc tự nhiên."
6496,E:\DATN\dataframe\train_file\72.txt,Chúng ta có thể mô phỏng sự tiến hóa sinh học bằng các thuật toán.
6497,E:\DATN\dataframe\train_file\72.txt,Chúng ta sẽ không cần phải vật lộn để điều chỉnh các siêu tham số và đợi mô hình được huấn luyện qua rất nhiều epoch để xem liệu agent có đang học “chính xác” hay không.
6498,E:\DATN\dataframe\train_file\72.txt,"Thay vào đó, chúng ta chỉ cần chọn các agent đã hoạt động tốt hơn."
6499,E:\DATN\dataframe\train_file\72.txt,Chúng ta có thẻ mô tả hoạt động của quá trình này trong hình sau
6500,E:\DATN\dataframe\train_file\72.txt,Loại thuật toán này không yêu cầu chúng ta huấn luyện một agent riêng lẻ.
6501,E:\DATN\dataframe\train_file\72.txt,Nó không dựa vào gradient và được gọi một cách khác là gradient-free algorithm.
6502,E:\DATN\dataframe\train_file\72.txt,Học tăng cường với thuật toán tiến hoá
6503,E:\DATN\dataframe\train_file\72.txt,"Trong phần này chúng ta sẽ nói về cách làm thế nào để tận dụng chiến lược tiến hoá, và chúng ta sẽ trình bày ngắn gọn cách để định nghĩa agent tốt nhất."
6504,E:\DATN\dataframe\train_file\72.txt,Tiếp theo chúng ta sẽ nói đến cách thức tổ hợp để sinh ra một agent mới từ một agent sẵn có.
6505,E:\DATN\dataframe\train_file\72.txt,"Sự phát triển này là một quá trình nhiều thế hệ, vì vậy chúng ta sẽ thảo luận về điều đó và tóm tắt lại toàn bộ các quá trình huấn luyện."
6506,E:\DATN\dataframe\train_file\72.txt,Lý thuyết tiến hoá trong sinh học
6507,E:\DATN\dataframe\train_file\72.txt,"Nếu bạn còn nhớ các kiến thức trong môn sinh học từ hồi học phổ thông, thì chọn lọc tự nhiên sẽ chọn ra những cá thể “phù hợp nhất” từ mỗi thế hệ."
6508,E:\DATN\dataframe\train_file\72.txt,"Trong sinh học, điều này đại diện cho những cá thể có tỉ lệ sống sót thành công lớn nhất và do đó đã truyền thông tin di truyền của họ cho các thế hệ tiếp theo."
6509,E:\DATN\dataframe\train_file\72.txt,Những con chim có hình dạng mỏ thích hợp hơn trong việc lấy hạt từ cây sẽ có nhiều thức ăn hơn và do đó có nhiều khả năng sống sót hơn để truyền gen chứa hình dạng mỏ đó cho con cháu của chúng.
6510,E:\DATN\dataframe\train_file\72.txt,"Nhưng hãy nhớ rằng, khái niệm ""phù hợp nhất"" ở đây phải liên quan đến môi trường."
6511,E:\DATN\dataframe\train_file\72.txt,Một con gấu Bắc Cực thích nghi tốt với các chỏm băng ở vùng cực nhưng sẽ rất không thích hợp trong các khu rừng nhiệt đới Amazon hay sa mạc Sahara.
6512,E:\DATN\dataframe\train_file\72.txt,"Trong sinh học, mỗi đột biến thay đổi rất nhỏ các đặc điểm của sinh vật, do đó khó có thể phân biệt thế hệ này với thế hệ khác."
6513,E:\DATN\dataframe\train_file\72.txt,"Tuy nhiên, việc cho phép những đột biến và biến thể này tích lũy qua nhiều thế hệ sẽ cho phép những thay đổi có thể nhận thấy được."
6514,E:\DATN\dataframe\train_file\72.txt,"Trong quá trình tiến hóa của mỏ chim, ví dụ, một quần thể ban đầu các loài chim sẽ có hình dạng mỏ gần giống nhau."
6515,E:\DATN\dataframe\train_file\72.txt,"Nhưng theo thời gian, các đột biến ngẫu nhiên đã được đưa vào quần thể."
6516,E:\DATN\dataframe\train_file\72.txt,"Hầu hết các đột biến này có thể không ảnh hưởng đến chim hoặc thậm chí có tác động có hại, nhưng với một quần thể đủ lớn và đủ thế hệ, các đột biến ngẫu nhiên xảy ra ảnh hưởng có lợi đến hình dạng mỏ."
6517,E:\DATN\dataframe\train_file\72.txt,Những con chim có chiếc mỏ phù hợp hơn sẽ có lợi thế kiếm thức ăn hơn những con chim khác và do đó chúng có khả năng di truyền gen cao hơn.
6518,E:\DATN\dataframe\train_file\72.txt,"Do đó, thế hệ tiếp theo sẽ có tần số tăng lên của gen mỏ có hình dạng thuận lợi."
6519,E:\DATN\dataframe\train_file\72.txt,Lý thuyết tiến hoá trong khoa học máy tính
6520,E:\DATN\dataframe\train_file\72.txt,"Trong học tăng cường sử dụng thuật toán tiến hóa, chúng ta đang chọn các đặc điểm mang lại cho agent của chúng ta phần thưởng cao nhất trong một môi trường nhất định và theo đặc điểm."
6521,E:\DATN\dataframe\train_file\72.txt,Các đặc điểm ở đây có nghĩa là các thông số mô hình (ví dụ: trọng số của mạng nơ-ron) hoặc toàn bộ cấu trúc mô hình.
6522,E:\DATN\dataframe\train_file\72.txt,Thể trạng của một agent trong RL có thể được xác định bằng phần thưởng dự kiến mà agent sẽ nhận được nếu hoạt động trong môi trường.
6523,E:\DATN\dataframe\train_file\72.txt,Mục tiêu trong học tăng cường tiến hóa hoàn toàn giống như trong đào tạo dựa trên backpropagation và đào tạo dựa trên gradient.
6524,E:\DATN\dataframe\train_file\72.txt,"Sự khác biệt duy nhất là chúng ta sử dụng quá trình tiến hóa này, thường được gọi là thuật toán di truyền, để tối ưu hóa các tham số của một mô hình chẳng hạn như mạng nơ-ron."
6525,E:\DATN\dataframe\train_file\72.txt,"Trong cách tiếp cận thuật toán tiến hóa để học tăng cường, các agent cạnh tranh trong một môi trường và các agent phù hợp hơn (tạo ra nhiều phần thưởng hơn) được ưu tiên sao chép để tạo ra thế hệ tương lai."
6526,E:\DATN\dataframe\train_file\72.txt,"Sau nhiều lần lặp lại quy trình này, chỉ còn lại những agent phù hợp nhất."
6527,E:\DATN\dataframe\train_file\72.txt,Các bước thực hiện của giải thuật di truyền trong RF
6528,E:\DATN\dataframe\train_file\72.txt,Chúng ta hãy xem xét các bước của thuật toán di truyền một cách chi tiết hơn.
6529,E:\DATN\dataframe\train_file\72.txt,Giả sử chúng ta có một mạng nơ-ron mà chúng ta muốn sử dụng làm tác nhân để chơi Gridworld và chúng ta muốn đào tạo nó bằng cách sử dụng một thuật toán di truyền.
6530,E:\DATN\dataframe\train_file\72.txt,"Hãy nhớ rằng, đào tạo mạng nơ-ron chỉ có nghĩa là cập nhật lặp đi lặp lại các tham số của nó để hiệu suất của nó được cải thiện."
6531,E:\DATN\dataframe\train_file\72.txt,"Cũng nhớ lại rằng với một kiến trúc mạng nơ-ron cố định, các tham số hoàn toàn xác định hành vi của nó, vì vậy để sao chép một mạng nơ-ron, chúng ta chỉ cần sao chép các tham số của nó."
6532,E:\DATN\dataframe\train_file\72.txt,Sau đây là các khái niệm để có thể huấn luyện được một mạng nơ ron như vậy:
6533,E:\DATN\dataframe\train_file\72.txt,Khởi tạo quần thể: tạo ra một tập hợp ban đầu của các vectơ trọng số ngẫu nhiên.
6534,E:\DATN\dataframe\train_file\72.txt,"Mỗi voector này được đại diện cho một cá thể (agent), tập hợp ban đầu này được gọi là quần thể (population)."
6535,E:\DATN\dataframe\train_file\72.txt,Giả sử quần thể ban đầu này có 100 cá thể.
6536,E:\DATN\dataframe\train_file\72.txt,Đưa quần thể vào môi trường: đưa quần thể này vào cùng chơi trò chơi Gridworld của chúng ta sau đó tiến hành ghi lại reward của mỗi cá thể.
6537,E:\DATN\dataframe\train_file\72.txt,Mỗi cá thể được chỉ định một điểm chất lượng - fitness score dựa trên phần thưởng mà chúng kiếm được.
6538,E:\DATN\dataframe\train_file\72.txt,"Vì quần thể ban đầu là ngẫu nhiên, tất cả chúng có khả năng sẽ hoạt động rất kém, nhưng sẽ có một số ít, chỉ do ngẫu nhiên, sẽ hoạt động tốt hơn những cá thể khác."
6539,E:\DATN\dataframe\train_file\72.txt,"Lựa chọn cá thể để lai tạo: Tiến hành lấy mẫu ngẫu nhiên một cặp cá thể (“bố mẹ”) từ quần thể, được tính trọng số theo điểm chất lượng tương đối của chúng (những cá thể có chất lượng cao hơn có xác suất được chọn cao hơn) để tạo ra “quần thể giống lai tạo”."
6540,E:\DATN\dataframe\train_file\72.txt,"Lai tạo sinh ra quần thể mới: Các cá thể trong quần thể sinh sản sau đó sẽ “lai tạo” để tạo ra “thế hệ kế cận” sẽ tạo thành một quần thể mới, đầy đủ gồm 100 cá thể."
6541,E:\DATN\dataframe\train_file\72.txt,"Nếu các cá thể chỉ đơn giản là vectơ tham số của số thực, việc lai ghép vectơ 1 với vectơ 2 bao gồm việc lấy một tập con từ vectơ 1 và kết hợp nó với một tập hợp con bổ sung của vectơ 2 để tạo ra một vectơ con mới có cùng kích thước."
6542,E:\DATN\dataframe\train_file\72.txt,"Ví dụ, giả sử bạn có vectơ 1: [1 2 3] và vectơ 2: [4 5 6]."
6543,E:\DATN\dataframe\train_file\72.txt,Vectơ 1 lai ghép với vectơ 2 để tạo ra [1 5 6] và [4 2 3].
6544,E:\DATN\dataframe\train_file\72.txt,Chúng tôi chỉ đơn giản là bắt cặp ngẫu nhiên các cá thể từ các quần thể sinh sản và tái tổ hợp chúng để tạo ra hai con mới cho đến khi chúng ta tạo thành một quần thể mới.
6545,E:\DATN\dataframe\train_file\72.txt,"Điều này tạo ra sự đa dạng ""di truyền"" mới với những cá thể hoạt động tốt nhất."
6546,E:\DATN\dataframe\train_file\72.txt,"Đột biến: Giờ đây, chúng ta có một quần thể mới với các cá thể hàng đầu từ thế hệ trước, cùng với các các cá thể trong thế hệ mới."
6547,E:\DATN\dataframe\train_file\72.txt,"Tại thời điểm này, chúng ta sẽ lặp lại các giải pháp của mình và đột biến ngẫu nhiên một số trong số chúng để đảm bảo rằng chúng ta đưa sự đa dạng di truyền mới vào mọi thế hệ để ngăn chặn sự hội tụ sớm về mức tối ưu cục bộ."
6548,E:\DATN\dataframe\train_file\72.txt,Sự đột biến chỉ đơn giản có nghĩa là thêm một chút nhiễu ngẫu nhiên vào các vectơ tham số.
6549,E:\DATN\dataframe\train_file\72.txt,"Nếu đây là các vectơ nhị phân, đột biến có nghĩa là lật ngẫu nhiên một vài bit; nếu không, chúng ta có thể thêm một số nhiễu Gaussian."
6550,E:\DATN\dataframe\train_file\72.txt,"Tỷ lệ đột biến cần phải khá thấp, nếu không chúng ta sẽ có nguy cơ phá hỏng các giải pháp tốt hiện có."
6551,E:\DATN\dataframe\train_file\72.txt,Lặp lại quá trình tiến hoá: Bây giờ chúng ta có một quần thể mới gồm các cá thể bị đột biến từ thế hệ trước.
6552,E:\DATN\dataframe\train_file\72.txt,Chúng ta lặp lại quá trình này với quần thể mới trong N số thế hệ hoặc cho đến khi chúng ta đạt đến sự hội tụ (đó là khi điểm chất lượng của quần thể trung bình đã không còn có sự cải thiện đáng kể).
6553,E:\DATN\dataframe\train_file\72.txt,** LƯU Ý**: Có nhiều phương pháp khác nhau để chọn “bố mẹ” cho thế hệ tiếp theo.
6554,E:\DATN\dataframe\train_file\72.txt,Một cách đơn giản là gắn một xác suất lựa chọn vào từng cá thể dựa trên điểm chất lượng tương đối của chúng và sau đó lấy mẫu từ phân phối này.
6555,E:\DATN\dataframe\train_file\72.txt,"Bằng cách này, những cá thể phù hợp nhất sẽ được chọn thường xuyên nhất, nhưng vẫn có một cơ hội nhỏ là cho những cá thể hoạt động kém được chọn."
6556,E:\DATN\dataframe\train_file\72.txt,Điều này có thể giúp duy trì sự đa dạng trong quần thể.
6557,E:\DATN\dataframe\train_file\72.txt,"Một cách khác là chỉ cần xếp hạng tất cả các cá thể và lấy N cá thể hàng đầu, và sử dụng chúng để lai tạo để tạo ra thế hệ tiếp theo."
6558,E:\DATN\dataframe\train_file\72.txt,Đối với bất kỳ phương pháp nào thì việc ưu tiên chọn những cá thể tốt nhất để tiến hành việc lai tạo sẽ có hiệu quả tốt hơn.
6559,E:\DATN\dataframe\train_file\72.txt,Có một sự đánh đổi giữa việc lựa chọn những ứng cử viên tốt nhất và giảm sự đa dạng trong quần thể — điều này rất giống với sự đánh đổi giữa exploration và exploitation trong học tăng cường.
6560,E:\DATN\dataframe\train_file\72.txt,Bài toán sinh chuối tương đồng
6561,E:\DATN\dataframe\train_file\72.txt,Mô tả bài toán
6562,E:\DATN\dataframe\train_file\72.txt,"Chúng ta sẽ tạo một tập hợp các chuỗi ngẫu nhiên và cố gắng phát triển chúng thành một chuỗi mục tiêu do chúng ta lựa chọn, chẳng hạn như “Hello World!”."
6563,E:\DATN\dataframe\train_file\72.txt,Tập hợp các chuỗi ngẫu nhiên ban đầu của chúng ta sẽ giống như “gMIgSkybXZyP” và “adlBOMXIrBH”.
6564,E:\DATN\dataframe\train_file\72.txt,Chúng ta sẽ sử dụng một hàm có thể cho chúng ta biết các chuỗi này tương tự như thế nào với chuỗi mục tiêu để cung cấp cho chúng ta điểm chất lượng.
6565,E:\DATN\dataframe\train_file\72.txt,"Sau đó, chúng ta sẽ lấy mẫu các cặp cha mẹ từ quần thể được tính theo fitness score tương đối của chúng, sao cho những cá thể có fitness score cao hơn có nhiều khả năng được chọn để trở thành cha mẹ hơn (tức cá thể có fitness score cao sẽ có tỉ lệ được chọn làm parents lớn hơn các cá thể có fitness score thấp)."
6566,E:\DATN\dataframe\train_file\72.txt,"Tiếp theo, chúng ta sẽ lai ghép những cặp bố mẹ này (còn được gọi là lai hoặc tái tổ hợp) để tạo ra hai chuỗi con và thêm chúng vào thế hệ tiếp theo."
6567,E:\DATN\dataframe\train_file\72.txt,Ngoài ra chúng ta có thể thực hiện đốt biến bằng cách biến đổi các cá thể con cái bằng cách lật ngẫu nhiên một vài ký tự trong chuỗi.
6568,E:\DATN\dataframe\train_file\72.txt,"Chúng ta sẽ lặp lại quá trình này và hy vọng rằng quần thể mới sẽ trở nên phong phú hơn với các chuỗi rất gần với mục tiêu của chúng ta; có thể ít nhất một mục tiêu sẽ đạt được chính xác mục tiêu của chúng ta (tại thời điểm đó, chúng ta sẽ dừng thuật toán)."
6569,E:\DATN\dataframe\train_file\72.txt,Quá trình tiến hóa này của chuỗi được mô tả trong hình dưới đây
6570,E:\DATN\dataframe\train_file\72.txt,"Đây có lẽ là một ví dụ ngớ ngẩn, nhưng đó là một trong những minh chứng đơn giản nhất về thuật toán di truyền và các khái niệm sẽ chuyển trực tiếp sang các nhiệm vụ học tăng cường của chúng ta."
6571,E:\DATN\dataframe\train_file\72.txt,Bây giờ chúng ta sẽ tiến hành đi sâu vào code ngay thôi
6572,E:\DATN\dataframe\train_file\72.txt,Code thôi nào
6573,E:\DATN\dataframe\train_file\72.txt,Định nghĩa target string
6574,E:\DATN\dataframe\train_file\72.txt,Đầu tiên chúng ta tiến hành import các thư viên cần thiết và định nghĩa target string.
6575,E:\DATN\dataframe\train_file\72.txt,"Ở đây chúng ta đang mong muốn các agent sẽ sinh ra các chuối giống với ""Hello World"" nhất"
6576,E:\DATN\dataframe\train_file\72.txt,import random
6577,E:\DATN\dataframe\train_file\72.txt,from matplotlib import pyplot as plt
6578,E:\DATN\dataframe\train_file\72.txt,"alphabet = ""abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ,.! """
6579,E:\DATN\dataframe\train_file\72.txt,"target = ""Hello World!"""
6580,E:\DATN\dataframe\train_file\72.txt,Định nghĩa agent
6581,E:\DATN\dataframe\train_file\72.txt,Agent của chúng ta rất đơn giản.
6582,E:\DATN\dataframe\train_file\72.txt,Nó sẽ bao gồm hai thuộc tính là string để chứa giá trị của chuỗi mà nó đang biểu diễn và fitness nhằm biểu diễn điểm chất lượng.
6583,E:\DATN\dataframe\train_file\72.txt,Điểm nầy có thể đo bằng khoảng cách edit-distance từ string mà agent đang biểu diễn đến chuỗi target.
6584,E:\DATN\dataframe\train_file\72.txt,Chúng ta sẽ định nghĩa sau
6585,E:\DATN\dataframe\train_file\72.txt,class Individual:
6586,E:\DATN\dataframe\train_file\72.txt,"    def __init__(self, string, fitness=0):"
6587,E:\DATN\dataframe\train_file\72.txt,        self.string = string
6588,E:\DATN\dataframe\train_file\72.txt,        self.fitness = fitness
6589,E:\DATN\dataframe\train_file\72.txt,Định nghĩa fitness_score
6590,E:\DATN\dataframe\train_file\72.txt,Như đã trình bày ở phần trên thì chúng ta có thể thực hiện một hàm similar đơn giản giữa hai string để biểu diễn fitness score của agent
6591,E:\DATN\dataframe\train_file\72.txt,from difflib import SequenceMatcher
6592,E:\DATN\dataframe\train_file\72.txt,"def similar(a, b):"
6593,E:\DATN\dataframe\train_file\72.txt,"    return SequenceMatcher(None, a, b).ratio()"
6594,E:\DATN\dataframe\train_file\72.txt,Khởi tạo quần thể
6595,E:\DATN\dataframe\train_file\72.txt,Chúng ta có thể khởi tạo quần thể bằng cách sinh ra các agent chứa các string ngẫu nhiên.
6596,E:\DATN\dataframe\train_file\72.txt,Giả sử quần thể của chúng ta có 100 agents
6597,E:\DATN\dataframe\train_file\72.txt,"def spawn_population(length=26,size=100):"
6598,E:\DATN\dataframe\train_file\72.txt,    for i in range(size):
6599,E:\DATN\dataframe\train_file\72.txt,"        string = ''.join(random.choices(alphabet,k=length))"
6600,E:\DATN\dataframe\train_file\72.txt,        individual = Individual(string)
6601,E:\DATN\dataframe\train_file\72.txt,    return pop
6602,E:\DATN\dataframe\train_file\72.txt,Đây là một bước đã trình bày trong phần lý thuyết.
6603,E:\DATN\dataframe\train_file\72.txt,Về cơ bản chúng ta sẽ thay đổi ngẫu nhiên một vài kí tự trong string mà agent đang biểu diễn bởi một xác suất nào đó.
6604,E:\DATN\dataframe\train_file\72.txt,Giá sử là 0.01.
6605,E:\DATN\dataframe\train_file\72.txt,Tỉ lệ đột biến này phải đủ nhỏ để không bị phá vỡ tính chất tiến hoá của quần thể.
6606,E:\DATN\dataframe\train_file\72.txt,"def mutate(x, mut_rate=0.01):"
6607,E:\DATN\dataframe\train_file\72.txt,    for char in x.string:
6608,E:\DATN\dataframe\train_file\72.txt,        if random.random() < mut_rate:
6609,E:\DATN\dataframe\train_file\72.txt,    new_x = Individual(''.join(new_x_))
6610,E:\DATN\dataframe\train_file\72.txt,    return new_x
6611,E:\DATN\dataframe\train_file\72.txt,Tái tổ hợp
6612,E:\DATN\dataframe\train_file\72.txt,Tái tổ hợp là một trong những phép toán quan trọng trong giải thuật di truyền.
6613,E:\DATN\dataframe\train_file\72.txt,Nó giúp cho qúa trình tiến hoá tạo ra được các cá thể mới.
6614,E:\DATN\dataframe\train_file\72.txt,Ở đây chúng ta thực hiện việc tái tổ hợp đơn giản bằng cánh chọn một điểm chia ngẫu nhiên cross_pt sau đó hoán vị thành phần của hai vector đầu vào tại vị trí điểm chia để tạo thành hai vector mới.
6615,E:\DATN\dataframe\train_file\72.txt,Tái tổ hợp là yếu tố then chốt trong quá trình lai tạo.
6616,E:\DATN\dataframe\train_file\72.txt,"def recombine(p1_, p2_): #produces two children from two parents"
6617,E:\DATN\dataframe\train_file\72.txt,    p1 = p1_.string
6618,E:\DATN\dataframe\train_file\72.txt,    p2 = p2_.string
6619,E:\DATN\dataframe\train_file\72.txt,"    cross_pt = random.randint(0,len(p1))"
6620,E:\DATN\dataframe\train_file\72.txt,    c1 = Individual(''.join(child1))
6621,E:\DATN\dataframe\train_file\72.txt,    c2 = Individual(''.join(child2))
6622,E:\DATN\dataframe\train_file\72.txt,"    return c1, c2"
6623,E:\DATN\dataframe\train_file\72.txt,Đánh giá quần thể
6624,E:\DATN\dataframe\train_file\72.txt,Việc đánh giá quần thể giúp cho chúng ta biết được giải thuật của chúng ta đang hội tụ như thế nào.
6625,E:\DATN\dataframe\train_file\72.txt,Việc này đơn giản là lấy fitness_score trung bình của các cá thể trong quần thể
6626,E:\DATN\dataframe\train_file\72.txt,"def evaluate_population(pop, target):"
6627,E:\DATN\dataframe\train_file\72.txt,    avg_fit = 0
6628,E:\DATN\dataframe\train_file\72.txt,    for i in range(len(pop)):
6629,E:\DATN\dataframe\train_file\72.txt,"        fit = similar(pop[i].string, target)"
6630,E:\DATN\dataframe\train_file\72.txt,        pop[i].fitness = fit
6631,E:\DATN\dataframe\train_file\72.txt,        avg_fit += fit
6632,E:\DATN\dataframe\train_file\72.txt,    avg_fit /= len(pop)
6633,E:\DATN\dataframe\train_file\72.txt,"    return pop, avg_fit"
6634,E:\DATN\dataframe\train_file\72.txt,Tạo thế hệ tiếp theo
6635,E:\DATN\dataframe\train_file\72.txt,"def next_generation(pop, size=100, length=26, mut_rate=0.01):"
6636,E:\DATN\dataframe\train_file\72.txt,    while len(new_pop) < size:
6637,E:\DATN\dataframe\train_file\72.txt,"        parents = random.choices(pop,k=2, weights=[x.fitness for x in pop])"
6638,E:\DATN\dataframe\train_file\72.txt,"        offspring_ = recombine(parents[0],parents[1])"
6639,E:\DATN\dataframe\train_file\72.txt,"        offspring = [mutate(offspring_[0], mut_rate=mut_rate), mutate(offspring_[1], mut_rate=mut_rate)]"
6640,E:\DATN\dataframe\train_file\72.txt,        new_pop.extend(offspring) #add offspring to next generation
6641,E:\DATN\dataframe\train_file\72.txt,    return new_pop
6642,E:\DATN\dataframe\train_file\72.txt,Đây là bước tạo ra thế hệ tiếp theo từ thế hệ có sẵn của chúng ta.
6643,E:\DATN\dataframe\train_file\72.txt,Chúng ta có một điểm cần lưu ý trong việc chọn lựa parents.
6644,E:\DATN\dataframe\train_file\72.txt,"parents = random.choices(pop,k=2, weights=[x.fitness for x in pop])"
6645,E:\DATN\dataframe\train_file\72.txt,Chúng ta để ý rằng ở đây chúng ta lựa chọn ngẫu nhiên có trọng số 2 agent để làm parents cho tiếp hệ tiếp theo.
6646,E:\DATN\dataframe\train_file\72.txt,Tại sao mình lại in đậm phần ngẫu nhiên có trọng số bởi lẽ chúng ta sẽ lựa chọn ưu tiên những cá thể nào có fitness_score cao hơn để làm bố mẹ.
6647,E:\DATN\dataframe\train_file\72.txt,Nhưng vẫn dành một xác suất nhỏ hơn để những cá thể có finesss nhỏ hơn ở thế hệ hiện tại vẫn có khả năng được lai ghép.
6648,E:\DATN\dataframe\train_file\72.txt,Điều này giúp cho quần thể giữ được tính đa dạng trong những thế hệ tiếp theo.
6649,E:\DATN\dataframe\train_file\72.txt,Tiến hành huấn luyện thôi
6650,E:\DATN\dataframe\train_file\72.txt,pop = spawn_population(length=len(target))
6651,E:\DATN\dataframe\train_file\72.txt,num_generations = 400
6652,E:\DATN\dataframe\train_file\72.txt,population_size = 5000
6653,E:\DATN\dataframe\train_file\72.txt,str_len = len(target)
6654,E:\DATN\dataframe\train_file\72.txt,mutation_rate = 0.001 # 0.1% mutation rate per character
6655,E:\DATN\dataframe\train_file\72.txt,"pop = spawn_population(size=population_size, length=str_len) #initial population"
6656,E:\DATN\dataframe\train_file\72.txt,for gen in range(num_generations):
6657,E:\DATN\dataframe\train_file\72.txt,"    pop, avg_fit = evaluate_population(pop, target)"
6658,E:\DATN\dataframe\train_file\72.txt,    pop_fit.append(avg_fit) #record population average fitness
6659,E:\DATN\dataframe\train_file\72.txt,"    new_pop = next_generation(pop, size=population_size, length=str_len, mut_rate=mutation_rate)"
6660,E:\DATN\dataframe\train_file\72.txt,    pop = new_pop
6661,E:\DATN\dataframe\train_file\72.txt,Tiến hành vẽ biểu đồ fitness
6662,E:\DATN\dataframe\train_file\72.txt,Chúng ta có thể vẽ lại biểu đồ thể hiện sự thay đổi của fitness qua từng thế hệ
6663,E:\DATN\dataframe\train_file\72.txt,Chúng ta có thể thấy càng về những generations cuối thì điểm fitness trung bình các ít thay đổi và ở mức cao.
6664,E:\DATN\dataframe\train_file\72.txt,Điều này chúng tỏ quần thể chúng ta đã chứa những cá thể có fitness tốt nhất với target string
6665,E:\DATN\dataframe\train_file\72.txt,Kiểm tra kết quả
6666,E:\DATN\dataframe\train_file\72.txt,chúng ta tiến hành kiếm tra những cá thể có fitness score cao nhất
6667,E:\DATN\dataframe\train_file\72.txt,"pop.sort(key=lambda x: x.fitness, reverse=True) #sort in place, highest fitness first"
6668,E:\DATN\dataframe\train_file\72.txt,"Chúng ta thấy rằng từ những chuỗi ngâu nhiên ban đầu nhưng qua quá trình tiến hoá bằng giải thuật di truyền, bản thân quần thể của chúng ta có thể sinh ra được các chuỗi giống như chuỗi target lúc đầu mà không cần phải tối ưu những mạng nơ ron phức tạp."
6669,E:\DATN\dataframe\train_file\72.txt,Giải thuật di truyền là một trong những thuật toán có tư tưởng gần gũi với qua trình tiến hoá nhất.
6670,E:\DATN\dataframe\train_file\72.txt,Chúng ta có thể áp dụng linh hoạt nó trong nhiều bài toán khác nhau.
6671,E:\DATN\dataframe\train_file\72.txt,Việc áp dụng nó cho Reinforcement Learning giúp chúng ta có thể thay thế các mạng nơ ron phức tạp.
6672,E:\DATN\dataframe\train_file\72.txt,Xin chào các bạn và hẹn gặp lại trong những bài tiếp theo 
6673,E:\DATN\dataframe\train_file\73.txt,Tìm hiểu về Machine learning Model Serving với BentoML
6674,E:\DATN\dataframe\train_file\73.txt,"Hẳn là chúng ta đã quen với việc train, evaluate model machine learning rồi."
6675,E:\DATN\dataframe\train_file\73.txt,Vậy train xong rồi thì làm gì?
6676,E:\DATN\dataframe\train_file\73.txt,Khi đưa mô hình ML từ research lên môi trường production (ví dụ như app điện thoại hoặc phần mềm máy tính) thì phải làm thế nào?
6677,E:\DATN\dataframe\train_file\73.txt,"Trên thực tế, model serving thường có nghĩa là model sẽ được deploy như một service và các service khác có thể giao tiếp với nó, yêu cầu đưa ra dự đoán và sử dụng kết quả đó."
6678,E:\DATN\dataframe\train_file\73.txt,"Trong bài này mình sẽ tìm hiểu về việc làm thế nào để ""serve"" một machine learning model - biến mô hình đã được train thành một service để người khác cũng có thể sử dụng."
6679,E:\DATN\dataframe\train_file\73.txt,"Có nhiều công cụ giúp việc serve model trở nên dễ dàng như Torch Serve, Tensorflow Serving, Cortex, tuy nhiên trong bài này mình sẽ giới thiệu một công cụ tiện lợi và hỗ trợ nhiều ML framework, đó là BentoML"
6680,E:\DATN\dataframe\train_file\73.txt,"BentoML là một framework mã nguồn mở dùng cho serving, quản lý và deploy mô hình học máy, nhằm mục đích thu hẹp khoảng cách giữa Data Science và DevOps."
6681,E:\DATN\dataframe\train_file\73.txt,Các nhà khoa học dữ liệu có thể dễ dàng đóng gói model của họ với BentoML và reproduce model để serve trong quá trình production.
6682,E:\DATN\dataframe\train_file\73.txt,"BentoML giúp quản lý các mô hình đóng gói ở định dạng BentoML và cho phép DevOps triển khai chúng dưới dạng các online API serving endpoints hoặc offline batch inference jobs, trên bất kỳ nền tảng đám mây nào."
6683,E:\DATN\dataframe\train_file\73.txt,"Hỗ trợ nhiều framework ML, bao gồm Tensorflow, PyTorch, Keras, XGBoost, vv."
6684,E:\DATN\dataframe\train_file\73.txt,"Deploy trên nền tảng đám mây với Docker, Kubernetes, AWS, Azure, vv."
6685,E:\DATN\dataframe\train_file\73.txt,High-Performance online API serving and offline batch serving
6686,E:\DATN\dataframe\train_file\73.txt,Web dashboards và APIs để đăng ký mô hình và quản lý deployment
6687,E:\DATN\dataframe\train_file\73.txt,"Dưới đây mình sẽ trình bày các bước sử dụng BentoML để serve một model spacy qua một REST API server, và containerize model server với Docker để phục vụ production deployment."
6688,E:\DATN\dataframe\train_file\73.txt,Bạn cũng có thể làm tương tự với các framework khác.
6689,E:\DATN\dataframe\train_file\73.txt,"BentoML yêu cầu python phiên bản 3.6 trở lên, chúng ta có thể cài đặt package bằng pip:"
6690,E:\DATN\dataframe\train_file\73.txt,!pip install -q bentoml spacy>=2.3.0
6691,E:\DATN\dataframe\train_file\73.txt,Dưới đây là một cấu trúc thư mục cơ bản của một BentoML project:
6692,E:\DATN\dataframe\train_file\73.txt,Download pretrained model của spacy để serving với BentoML
6693,E:\DATN\dataframe\train_file\73.txt,!python3 -m spacy download en_core_web_sm
6694,E:\DATN\dataframe\train_file\73.txt,Load và train model với một vài sample:
6695,E:\DATN\dataframe\train_file\73.txt,import en_core_web_sm
6696,E:\DATN\dataframe\train_file\73.txt,nlp = en_core_web_sm.load()
6697,E:\DATN\dataframe\train_file\73.txt,# Getting the pipeline component
6698,E:\DATN\dataframe\train_file\73.txt,# training data
6699,E:\DATN\dataframe\train_file\73.txt,"              (""Walmart is a leading e-commerce company"", {""entities"": [(0, 7, ""ORG"")]}),"
6700,E:\DATN\dataframe\train_file\73.txt,"              (""I reached Chennai yesterday."
6701,E:\DATN\dataframe\train_file\73.txt,""", {""entities"": [(19, 28, ""GPE"")]}),"
6702,E:\DATN\dataframe\train_file\73.txt,"              (""I recently ordered a book from Amazon"", {""entities"": [(24,32, ""ORG"")]}),"
6703,E:\DATN\dataframe\train_file\73.txt,"              (""I was driving a BMW"", {""entities"": [(16,19, ""PRODUCT"")]}),"
6704,E:\DATN\dataframe\train_file\73.txt,"              (""I ordered this from ShopClues"", {""entities"": [(20,29, ""ORG"")]}),"
6705,E:\DATN\dataframe\train_file\73.txt,"              (""Fridge can be ordered in Amazon "", {""entities"": [(0,6, ""PRODUCT"")]}),"
6706,E:\DATN\dataframe\train_file\73.txt,"              (""I bought a new Washer"", {""entities"": [(16,22, ""PRODUCT"")]}),"
6707,E:\DATN\dataframe\train_file\73.txt,"              (""I bought a old table"", {""entities"": [(16,21, ""PRODUCT"")]}),"
6708,E:\DATN\dataframe\train_file\73.txt,"              (""I bought a fancy dress"", {""entities"": [(18,23, ""PRODUCT"")]}),"
6709,E:\DATN\dataframe\train_file\73.txt,"              (""I rented a camera"", {""entities"": [(12,18, ""PRODUCT"")]}),"
6710,E:\DATN\dataframe\train_file\73.txt,"              (""I rented a tent for our trip"", {""entities"": [(12,16, ""PRODUCT"")]}),"
6711,E:\DATN\dataframe\train_file\73.txt,"              (""I rented a screwdriver from our neighbour"", {""entities"": [(12,22, ""PRODUCT"")]}),"
6712,E:\DATN\dataframe\train_file\73.txt,"              (""I repaired my computer"", {""entities"": [(15,23, ""PRODUCT"")]}),"
6713,E:\DATN\dataframe\train_file\73.txt,"              (""I got my clock fixed"", {""entities"": [(16,21, ""PRODUCT"")]}),"
6714,E:\DATN\dataframe\train_file\73.txt,"              (""I got my truck fixed"", {""entities"": [(16,21, ""PRODUCT"")]}),"
6715,E:\DATN\dataframe\train_file\73.txt,"              (""Flipkart started it's journey from zero"", {""entities"": [(0,8, ""ORG"")]}),"
6716,E:\DATN\dataframe\train_file\73.txt,"              (""I recently ordered from Max"", {""entities"": [(24,27, ""ORG"")]}),"
6717,E:\DATN\dataframe\train_file\73.txt,"              (""Flipkart is recognized as leader in market"",{""entities"": [(0,8, ""ORG"")]}),"
6718,E:\DATN\dataframe\train_file\73.txt,"              (""I recently ordered from Swiggy"", {""entities"": [(24,29, ""ORG"")]})"
6719,E:\DATN\dataframe\train_file\73.txt,"for _, annotations in TRAIN_DATA:"
6720,E:\DATN\dataframe\train_file\73.txt,"  for ent in annotations.get(""entities""):"
6721,E:\DATN\dataframe\train_file\73.txt,# Disable pipeline components you dont need to change
6722,E:\DATN\dataframe\train_file\73.txt,"pipe_exceptions = [""ner"", ""trf_wordpiecer"", ""trf_tok2vec""]"
6723,E:\DATN\dataframe\train_file\73.txt,unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]
6724,E:\DATN\dataframe\train_file\73.txt,# Import requirements
6725,E:\DATN\dataframe\train_file\73.txt,import random
6726,E:\DATN\dataframe\train_file\73.txt,"from spacy.util import minibatch, compounding"
6727,E:\DATN\dataframe\train_file\73.txt,from pathlib import Path
6728,E:\DATN\dataframe\train_file\73.txt,# TRAINING THE MODEL
6729,E:\DATN\dataframe\train_file\73.txt,with nlp.disable_pipes(*unaffected_pipes):
6730,E:\DATN\dataframe\train_file\73.txt,  # Training for 30 iterations
6731,E:\DATN\dataframe\train_file\73.txt,  for iteration in range(300):
6732,E:\DATN\dataframe\train_file\73.txt,    # shuufling examples  before every iteration
6733,E:\DATN\dataframe\train_file\73.txt,    # batch up the examples using spaCy's minibatch
6734,E:\DATN\dataframe\train_file\73.txt,"    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))"
6735,E:\DATN\dataframe\train_file\73.txt,    for batch in batches:
6736,E:\DATN\dataframe\train_file\73.txt,"        texts, annotations = zip(*batch)"
6737,E:\DATN\dataframe\train_file\73.txt,"                    texts,  # batch of texts"
6738,E:\DATN\dataframe\train_file\73.txt,"                    annotations,  # batch of annotations"
6739,E:\DATN\dataframe\train_file\73.txt,"                    drop=0.5,  # dropout - make it harder to memorise data"
6740,E:\DATN\dataframe\train_file\73.txt,"        print(""Losses"", losses)"
6741,E:\DATN\dataframe\train_file\73.txt,Tạo một Prediction Service
6742,E:\DATN\dataframe\train_file\73.txt,Việc serving mô hình với BentoML được thực hiện sau khi một mô hình đã được train xong.
6743,E:\DATN\dataframe\train_file\73.txt,"Bước đầu tiên là tạo một class cho prediction servce, class này định nghĩa các mô hình được sử dụng và các API dùng cho inference."
6744,E:\DATN\dataframe\train_file\73.txt,"Dưới đây là một prediction service được tạo để serve mô hình spacy NER được đào tạo ở trên, được viết trong file bento_service.py:"
6745,E:\DATN\dataframe\train_file\73.txt,%%writefile bento_service.py
6746,E:\DATN\dataframe\train_file\73.txt,"from bentoml import BentoService, api, env, artifacts"
6747,E:\DATN\dataframe\train_file\73.txt,from bentoml.frameworks.spacy import SpacyModelArtifact
6748,E:\DATN\dataframe\train_file\73.txt,from bentoml.adapters import JsonInput
6749,E:\DATN\dataframe\train_file\73.txt,class SpacyNERService(BentoService):
6750,E:\DATN\dataframe\train_file\73.txt,"    @api(input=JsonInput(), batch=True)"
6751,E:\DATN\dataframe\train_file\73.txt,"    def predict(self, parsed_json_list):"
6752,E:\DATN\dataframe\train_file\73.txt,"        for index, parsed_json in enumerate(parsed_json_list):"
6753,E:\DATN\dataframe\train_file\73.txt,            doc = self.artifacts.nlp(parsed_json['text'])
6754,E:\DATN\dataframe\train_file\73.txt,"            result.append([{'entity': ent.text, 'label': ent.label_} for ent in doc.ents])"
6755,E:\DATN\dataframe\train_file\73.txt,        return result
6756,E:\DATN\dataframe\train_file\73.txt,Đoạn code trên định nghĩa một prediction service mà đóng gói mô hình spacy và cung cấp một inference API nhận một đối tượng JsonInput làm đầu vào của nó.
6757,E:\DATN\dataframe\train_file\73.txt,"BentoML cũng hỗ trợ các kiểu dữ liệu đầu vào API khác bao gồm DataframeInput, ImageInput, FileInput, vv."
6758,E:\DATN\dataframe\train_file\73.txt,"Trong BentoML, tất cả các inference API chấp nhận một list các input và trả về một list kết quả."
6759,E:\DATN\dataframe\train_file\73.txt,"Trong trường hợp DataframeInput, mỗi hàng của dataframe sẽ được map với một prediction request nhận được từ máy client."
6760,E:\DATN\dataframe\train_file\73.txt,Thiết kế này cho phép BentoML nhóm các API request thành các batch nhỏ khi serving online.
6761,E:\DATN\dataframe\train_file\73.txt,"So với máy chủ mô hình dựa trên flask hoặc FastAPI, điều này có thể tăng thông lượng tổng thể của máy chủ API lên 10-100 lần tùy thuộc vào khối lượng công việc."
6762,E:\DATN\dataframe\train_file\73.txt,"Đoạn code sau sẽ đóng gói mô hình được train với prediction service class được định nghĩa ở trên, sau đó lưu một instance vào đĩa ở định dạng BentoML format để phân phối và triển khai:"
6763,E:\DATN\dataframe\train_file\73.txt,from bento_service import SpacyNERService
6764,E:\DATN\dataframe\train_file\73.txt,# Create a SpacyNER service instance
6765,E:\DATN\dataframe\train_file\73.txt,svc = SpacyNERService()
6766,E:\DATN\dataframe\train_file\73.txt,# Pack the newly trained model artifact
6767,E:\DATN\dataframe\train_file\73.txt,"svc.pack('nlp', nlp)"
6768,E:\DATN\dataframe\train_file\73.txt,saved_path = svc.save()
6769,E:\DATN\dataframe\train_file\73.txt,REST API Model Serving
6770,E:\DATN\dataframe\train_file\73.txt,"Để khởi động máy chủ mô hình API REST với spacy NER được lưu ở trên, chúng ta sử dụng lệnh bentoml serve."
6771,E:\DATN\dataframe\train_file\73.txt,"Nếu sử dụng Google Colab, bạn có thể khởi động dev server với tùy chọn --run-with-ngrok, để có quyền access API endpoint với ngrok:"
6772,E:\DATN\dataframe\train_file\73.txt,!bentoml serve SpacyNERService:latest --run-with-ngrok
6773,E:\DATN\dataframe\train_file\73.txt,Nếu bạn chạy trên máy local thì model spacy lúc này đã được served tại localhost:5000.
6774,E:\DATN\dataframe\train_file\73.txt,Sử dụng curl command để gửi prediction request:
6775,E:\DATN\dataframe\train_file\73.txt,curl -i \
6776,E:\DATN\dataframe\train_file\73.txt,    --request POST \
6777,E:\DATN\dataframe\train_file\73.txt,"    --header ""Content-Type: application/json"" \"
6778,E:\DATN\dataframe\train_file\73.txt,"    --data ""{\""text\"":\""I am driving BMW\""}"" \"
6779,E:\DATN\dataframe\train_file\73.txt,Hoặc dùng request library của python:
6780,E:\DATN\dataframe\train_file\73.txt,import requests
6781,E:\DATN\dataframe\train_file\73.txt,"response = requests.post(""http://127.0.0.1:5000/predict"", json={""text"":""I am driving BMW""})"
6782,E:\DATN\dataframe\train_file\73.txt,The BentoML API server also provides a simple web UI dashboard.
6783,E:\DATN\dataframe\train_file\73.txt,Go to  in the browser and use the Web UI to send prediction request:
6784,E:\DATN\dataframe\train_file\73.txt,Máy chủ API BentoML cũng cung cấp một cái dashboard đơn giản qua giao diện web.
6785,E:\DATN\dataframe\train_file\73.txt,Truy cập http: // localhost: 5000 trong trình duyệt và sử dụng giao diện này để gửi prediction request:
6786,E:\DATN\dataframe\train_file\73.txt,Container hóa model server với Docker
6787,E:\DATN\dataframe\train_file\73.txt,Một cách phổ biến để phân phối model API server trong production là thông qua Docker container.
6788,E:\DATN\dataframe\train_file\73.txt,Và BentoML hỗ trợ chúng ta làm điều đó một cách rất dễ dàng.
6789,E:\DATN\dataframe\train_file\73.txt,"Nếu bạn đã có Docker trong máy local, chỉ cần chạy lệnh sau để tạo ra một Docker container serving prediction service được nói ở trên:"
6790,E:\DATN\dataframe\train_file\73.txt,!bentoml containerize SpacyNERService:latest
6791,E:\DATN\dataframe\train_file\73.txt,!docker run -p 5000:5000 spacynerservice
6792,E:\DATN\dataframe\train_file\73.txt,"Như vậy trong bài này mình đã trình bày cách sử dụng BentoML để đưa một mô hình học máy, cụ thể là spacy từ research lên production."
6793,E:\DATN\dataframe\train_file\73.txt,Vì kiến thức còn có hạn nên đây mới chỉ là một bài hướng dẫn khá sơ khai.
6794,E:\DATN\dataframe\train_file\73.txt,Cảm ơn các bạn đã đọc!
6795,E:\DATN\dataframe\train_file\74.txt,Đánh giá các mô hình học máy
6796,E:\DATN\dataframe\train_file\74.txt,"Trong quá trình xây dựng một mô hình Machine Learning, một phần không thể thiếu để xét xem mô hình có chất lượng tốt hay không chính là đánh giá mô hình."
6797,E:\DATN\dataframe\train_file\74.txt,Đánh giá mô hình giúp chúng ta chọn lựa được các mô hình phù hợp với bài toán cụ thể.
6798,E:\DATN\dataframe\train_file\74.txt,"Để có thể áp dụng đúng thước đo đánh giá mô hình phù hợp, chúng ta cần hiểu bản chất, ý nghĩa cũng như các trường hợp sử dụng nó."
6799,E:\DATN\dataframe\train_file\74.txt,Cùng phân tích và tìm hiểu các thước đo này nhé!
6800,E:\DATN\dataframe\train_file\74.txt,Mong rằng bài viết này của mình sẽ giúp các bạn hiểu hơn về các Metric đánh giá mô hình học máy ^^
6801,E:\DATN\dataframe\train_file\74.txt,"Để rõ ràng hơn, mình sẽ tập trung phân tích các metric đánh giá đối với: mô hình phân loại (classification), mô hình hồi quy (regression) và xếp hạng (Ranking)"
6802,E:\DATN\dataframe\train_file\74.txt,Bài toán phân loại (Classification)
6803,E:\DATN\dataframe\train_file\74.txt,"Classifcation là một bài toán được sử dụng vô cùng rộng rãi trong Machine Learning với các tính ứng dụng đa dạng như nhận diện khuôn mặt, phân loại video Youtube, phân loại văn bản, phân loại giọng nói, …"
6804,E:\DATN\dataframe\train_file\74.txt,"Có thể kể tới một vài mô hình tiêu biểu như Support Vector Machine (SVM), Logistic Regression, Decision Trees, Random Forest, XGboost, … Dưới đây là một số metrics để đánh giá mô hình phân loại mà mình sưu tầm được:"
6805,E:\DATN\dataframe\train_file\74.txt,"Confusion Matrix (Đây không phải là 1 metric, nhưng rất quan trọng)"
6806,E:\DATN\dataframe\train_file\74.txt,Chúng ta cùng tìm hiểu một thuật ngữ cơ bản được sử dụng trong các bài toán phân loại – Confusion matrix (AKA error matrix).
6807,E:\DATN\dataframe\train_file\74.txt,"Nó thể hiện được có bao nhiêu điểm dữ liệu thực sự thuộc vào một class, và được dự đoán là rơi vào một class."
6808,E:\DATN\dataframe\train_file\74.txt,"Để dễ hiểu hơn, chúng ta cùng làm một ví dụ nhé"
6809,E:\DATN\dataframe\train_file\74.txt,"Ví dụ một bài toán phân loại ảnh đó là mèo hay không, trong dữ liệu dự đoán có 100 ảnh là mèo, 1000 ảnh không phải là mèo."
6810,E:\DATN\dataframe\train_file\74.txt,"Ở đây, kết quả dự đoán là như sau"
6811,E:\DATN\dataframe\train_file\74.txt,"Trong 100 ảnh mèo dự đoán đúng 90 ảnh, còn 10 ảnh được dự đoán là không phải."
6812,E:\DATN\dataframe\train_file\74.txt,"Nếu ta coi cat là “positive” và non-cat là “negative”, thì 90 ảnh được dự đoán là cat, được gọi là True Positive, còn 10 ảnh được dự đoán non-cat kia được gọi là False Negative"
6813,E:\DATN\dataframe\train_file\74.txt,"Trong 1000 ảnh non-cat, dự đoán đúng được 940 ảnh là non-cat, được gọi là True Negative, còn 60 ảnh bị dự đoán nhầm sang cat được gọi là False Positive"
6814,E:\DATN\dataframe\train_file\74.txt,"Có thể tới đây nhiều người sẽ khá là lẫn lộn, “True”, “False” rồi “Positive”, “Negative”."
6815,E:\DATN\dataframe\train_file\74.txt,"Vậy để có một cách dễ nhớ, có một mánh nhỏ như sau"
6816,E:\DATN\dataframe\train_file\74.txt,True/False ý chỉ những gì ta đã dự đoán là đúng hay chưa
6817,E:\DATN\dataframe\train_file\74.txt,"Positive/Negative chỉ những gì ta dự đoán (có hoặc không) Nói cách khách, nếu thấy chữ True tức là dự đoán là đúng (là cat hay non-cat, chỉ cần đúng), còn False thì ngược lại."
6818,E:\DATN\dataframe\train_file\74.txt,Classification Accuracy
6819,E:\DATN\dataframe\train_file\74.txt,"Đây là độ đo của bài toán phân loại mà đơn giản nhất, tính toán bằng cách lấy số dự đoán đúng chia cho toàn bộ các dự đoán."
6820,E:\DATN\dataframe\train_file\74.txt,"Ví dụ với bài toán Cat/Non-cat như trên, độ chính xác sẽ được tính như sau:"
6821,E:\DATN\dataframe\train_file\74.txt,Classification Accuracy = (90+940)/(1000+100) = 93.6%
6822,E:\DATN\dataframe\train_file\74.txt,"Nhược điểm của cách đánh giá này là chỉ cho ta biết được bao nhiêu phần trăm lượng dữ liệu được phân loại đúng mà không chỉ ra được cụ thể mỗi loại được phân loại như thế nào, lớp nào được phân loại đúng nhiều nhất hay dữ liệu của lớp nào thường bị phân loại nhầm nhất vào các lớp khác."
6823,E:\DATN\dataframe\train_file\74.txt,"Như đã nói phía trên, sẽ có rất nhiều trường hợp thước đo Accuracy không phản ánh đúng hiệu quả của mô hình."
6824,E:\DATN\dataframe\train_file\74.txt,"Giả sử mô hình dự đoán tất cả 1100 ảnh là Non-cat, thì Accuracy vẫn đạt tới 1000/1100 = 90.9%, khá cao nhưng thực chất mô hình khá là tồi Vì vậy chúng ta cần một metric có thể khắc phục được những yếu điểm này."
6825,E:\DATN\dataframe\train_file\74.txt,"Precision là một trong những metrics có thể khắc phục được, công thức như sau:"
6826,E:\DATN\dataframe\train_file\74.txt,"Áp dụng vào bài toán Cat/Non-cat, Precision sẽ được tính như sau:"
6827,E:\DATN\dataframe\train_file\74.txt,Precision(cat) = 90/(90+60) = 60% Precision(non-cat) = 940/(940+10) = 98.9%
6828,E:\DATN\dataframe\train_file\74.txt,Có thể thấy việc dự đoán Cat chưa thực sự tốt nhờ phép đó Precision này.
6829,E:\DATN\dataframe\train_file\74.txt,Precision sẽ cho chúng ta biết thực sự có bao nhiêu dự đoán Positive là thật sự True
6830,E:\DATN\dataframe\train_file\74.txt,"Recall cũng là một metric quan trọng, nó đo lường tỷ lệ dự báo chính xác các trường hợp positive trên toàn bộ các mẫu thuộc nhóm positive."
6831,E:\DATN\dataframe\train_file\74.txt,Công thức của Recall như sau:
6832,E:\DATN\dataframe\train_file\74.txt,"Áp dụng vào bài toán Cat/Non-cat, Precision sẽ được tính như sau:"
6833,E:\DATN\dataframe\train_file\74.txt,Recall(cat) = 90/(90+10) = 90%
6834,E:\DATN\dataframe\train_file\74.txt,Recall(non-cat) = 940/(940+60) = 94%
6835,E:\DATN\dataframe\train_file\74.txt,"Recall cao đồng nghĩa với việc True Positive Rate cao, tức là tỷ lệ bỏ sót các điểm thực sự là positive là thấp"
6836,E:\DATN\dataframe\train_file\74.txt,Tùy thuộc vào bài toán mà bạn sẽ muốn ưu tiến sử dụng Recall hay Precision.
6837,E:\DATN\dataframe\train_file\74.txt,Nhưng cũng có rất nhiều bai toán mà cả Precision hay Recall đều quan trọng.
6838,E:\DATN\dataframe\train_file\74.txt,Một metric phổ biến đã kết hợp cả Recall và Precision lại được gọi là F1-score
6839,E:\DATN\dataframe\train_file\74.txt,F1-score được tính theo công thức sau:
6840,E:\DATN\dataframe\train_file\74.txt,Sensitivity – Specificity
6841,E:\DATN\dataframe\train_file\74.txt,Sensitivity và Specificity là 2 metrics được sử dụng trong các bài toán phân loại liên quan đến y tế và sinh học.
6842,E:\DATN\dataframe\train_file\74.txt,Chúng được định nghĩa như sau:
6843,E:\DATN\dataframe\train_file\74.txt,AUC (Area Under the Curve) là một phép đo tổng hợp về hiệu suất của phân loại nhị phân trên tất cả các giá trị ngưỡng có thể có.
6844,E:\DATN\dataframe\train_file\74.txt,"Để hiểu rõ hơn về metric này, chúng ta sẽ tìm hiểu về một khai niệm cơ sở trước, đó là ROC Curve"
6845,E:\DATN\dataframe\train_file\74.txt,ROC Curve (The receiver operating characteristic curve) là một đường cong biểu diễn hiệu suất phân loại của một mô hình phân loại tại các ngưỡng threshold.
6846,E:\DATN\dataframe\train_file\74.txt,"Về cơ bản, nó hiển thị True Positive Rate (TPR) so với False Positive Rate (FPR) đối với các giá trị ngưỡng khác nhau."
6847,E:\DATN\dataframe\train_file\74.txt,"Các giá trị TPR, FPR được tính như sau:"
6848,E:\DATN\dataframe\train_file\74.txt,Cùng làm một ví dụ cho dễ hình dung nhé
6849,E:\DATN\dataframe\train_file\74.txt,"Có rất nhiều mô hình phân loại mang tính xác suất, ví dụ dự doán xác suất của một mẫu là Cat."
6850,E:\DATN\dataframe\train_file\74.txt,"Chúng so sánh xác suất đầu ra với một số ngưỡng giới hạn và nếu nó lớn hơn ngưỡng đó, mô hình dự đoán nhãn là Cat, còn không thì là Non-cat."
6851,E:\DATN\dataframe\train_file\74.txt,"Ví dụ mô hình của bạn dự đoán giá trị xác suất cho 4 samples lần lượt là [0.45, 0.6, 0.7, 0.3]."
6852,E:\DATN\dataframe\train_file\74.txt,Tùy vào giá trị ngưỡng mà sẽ có các nhãn đầu ra dự đoán khác nhau:
6853,E:\DATN\dataframe\train_file\74.txt,"Ngưỡng là 0.5: Sample 2,3 là Cat"
6854,E:\DATN\dataframe\train_file\74.txt,Ngưỡng là 0.25: Tất cả samples đều là Cat
6855,E:\DATN\dataframe\train_file\74.txt,Ngưỡng là 0.8: Tất cả sample là Non-cat
6856,E:\DATN\dataframe\train_file\74.txt,"Có thể thấy với các ngưỡng khác nhau, chúng ta sẽ có kết quả dự đoán nhãn khác nhau, kéo theo các giá trị như precision hay recall cũng sẽ khác nhau"
6857,E:\DATN\dataframe\train_file\74.txt,ROC tìm ra TPR và FPR ứng với các giá tị ngưỡng khác nhau và vẽ biểu đồ để dễ dàng quan sát TPR so với FPR.
6858,E:\DATN\dataframe\train_file\74.txt,Ví dụ dưới đây là một đường cong ROC
6859,E:\DATN\dataframe\train_file\74.txt,AUC là chỉ số được tính toán dựa trên đường cong ROC nhằm đánh giá khả năng phân loại của mô hình tốt như thê nào.
6860,E:\DATN\dataframe\train_file\74.txt,"Phần diện tích nằm dưới đường cong ROC và trên trục hoành chính là AUC, có giá trị nằm trong khoảng [0, 1]."
6861,E:\DATN\dataframe\train_file\74.txt,"Khi diện tích này càng lớn, đường cong này sẽ dần tiệm cận với đường thẳng y=1 tương đương với khả năng phân loại của mô hình càng tốt."
6862,E:\DATN\dataframe\train_file\74.txt,"Còn khi đường cong ROC nằm sát với đường chéo đi qua hai điểm (0, 0) và (1, 1), mô hình sẽ tương đương với một phân loại ngẫu nhiên."
6863,E:\DATN\dataframe\train_file\74.txt,Bài toán hồi quy (Regression)
6864,E:\DATN\dataframe\train_file\74.txt,Mô hình hồi quy (Regerssion model) được sử dụng để dự đoán các giá trị mục tiêu là giá tị liên tục.
6865,E:\DATN\dataframe\train_file\74.txt,"Mô hình này cũng có tính ứng dụng vô cùng rộng, từ bài toán dự đoán giá nhà, hệ thống định giá thương mại điện tử, dự báo thời tiết, dự đoán thị trường chứng khoán, cho đến chuyển hóa độ phân giải hình ảnh siêu cao, tính năng học tập thông qua bộ mã hóa tự động, nén hình ảnh"
6866,E:\DATN\dataframe\train_file\74.txt,"Một vài mô hình hồi quy phổ biến có thể kể tới như hồi quy tuyến tính (Linear Regression), Random Forest, Convolution neural netwok (tùy vào bài toán mà CNN sẽ phục vụ, CNN có thể đáp ứng cả bài toán phân loại cũng như hồi quy), …"
6867,E:\DATN\dataframe\train_file\74.txt,"Các metrics được sử dụng để đánh giá mô hình hồi quy phải có khả năng làm việc với tập các giá trị liên tục, và mình xin giới thiệu một số metrics phổ biến sau:"
6868,E:\DATN\dataframe\train_file\74.txt,MSE (Mean Square Error) có lẽ là một metric phổ biến nhất trong các bài toán hồi quy.
6869,E:\DATN\dataframe\train_file\74.txt,"Về cơ bản, nó tính trung bình của bình phương sai số giữa giá trị thực tế và giá trị dự đoán"
6870,E:\DATN\dataframe\train_file\74.txt,"Giả sử ta có một bài toán mà chắc hẳn ai đọc về Machine Learning cũng từng đọc qua, chính là bài toán dự đoán giá nhà."
6871,E:\DATN\dataframe\train_file\74.txt,"Coi giá trị thực tế của nhà thứ i là yi, còn giá trị dự đoán của căn nhà đó là yi’."
6872,E:\DATN\dataframe\train_file\74.txt,"Vậy, MSE có thể được tính như sau:"
6873,E:\DATN\dataframe\train_file\74.txt,MAE (Mean Absolute Error) là 1 metric đánh giá mô hình bằng cách tính trung bình giá trị tuyệt đối sai số giữa giá trị thực tế và giá trị dự đoán.
6874,E:\DATN\dataframe\train_file\74.txt,Công thức MAE được định nghĩa như sau:
6875,E:\DATN\dataframe\train_file\74.txt,MAE được biết đến là mạnh mẽ hơn đối với các yếu tố ngoại lai (outliers) so với MSE.
6876,E:\DATN\dataframe\train_file\74.txt,"Lý do chính bởi vì MSE sử dụng bình phương lỗi, các ngoại lai (những samples mà có lỗi cao hơn hẳn các samples khác) sẽ được chú ý và chiếm ưu thế hơn (do tính bình phương) trong việc đánh giá và điều này tác động đến các thông số của mô hình."
6877,E:\DATN\dataframe\train_file\74.txt,Inlier Ratio Metric
6878,E:\DATN\dataframe\train_file\74.txt,"Ngoài ra còn có một metric khác dùng để đánh giá các mô hình hồi quy, được gọi là tỷ lệ Inlier."
6879,E:\DATN\dataframe\train_file\74.txt,"Metric này mình thấy cũng không có nhiều bài báo khoa học dùng, về cơ bản là tính tỷ lệ phần trăm các điểm dữ liệu được dự đoán có lỗi nhỏ hơn biên."
6880,E:\DATN\dataframe\train_file\74.txt,Số liệu này chủ yếu được sử dụng trong mô hình RANSAC4 và các phần mở rộng của nó.
6881,E:\DATN\dataframe\train_file\74.txt,Các bạn có thể tham khảo thêm tại
6882,E:\DATN\dataframe\train_file\74.txt,Bài toán xếp hạng (Ranking)
6883,E:\DATN\dataframe\train_file\74.txt,"Ranking được coi là một vấn đề cơ bản trong Machine Learning, nó xếp hạng một danh sách các mục dựa vào sự liên quan giữa chúng trong các bài toán cụ thể (ví dụ như xếp hạng các pages trên Google dựa vào sự liên quan với câu truy vấn tìm kiếm)."
6884,E:\DATN\dataframe\train_file\74.txt,"Theo mình tìm hiểu được, Ranking được ứng dụng rộng rãi trong thương mại điện tử (E-commerce) và các công cụ tìm kiếm (search engines), cụ thể:"
6885,E:\DATN\dataframe\train_file\74.txt,"Gợi ý phim ảnh (Netflix, Youtube)"
6886,E:\DATN\dataframe\train_file\74.txt,Xếp hạng page của Google
6887,E:\DATN\dataframe\train_file\74.txt,Xếp hạng sản phẩm thương mại điện tử (Amazon)
6888,E:\DATN\dataframe\train_file\74.txt,Tự động hoàn thiện câu truy vấn
6889,E:\DATN\dataframe\train_file\74.txt,Tìm kiếm hình ảnh (vimeo)
6890,E:\DATN\dataframe\train_file\74.txt,Tìm kiếm nhà nghỉ (Expedia/Booking)
6891,E:\DATN\dataframe\train_file\74.txt,"Trong bài toán Ranking, mo hình cố gắng dự đoán thứ hạng (hoặc chỉ số liên quan) của một danh sách các mục đối với task cụ thể."
6892,E:\DATN\dataframe\train_file\74.txt,Thuật toán đối với Ranking có thể chia làm các nhóm sau:
6893,E:\DATN\dataframe\train_file\74.txt,"Point-wise models: Dự đoán một điểm số đối với từng cặp truy vấn-văn bản trong dataset, và sử dụng nó để xếp hạng các mục"
6894,E:\DATN\dataframe\train_file\74.txt,Pair-wise models: Học một phân loại nhị phân mà có thể trả lời rằng văn bản này có liên quan tới truy vấn này hay không?
6895,E:\DATN\dataframe\train_file\74.txt,"List-wise models: Tối ưu hóa trực tiếp giá trị của một trong các thước đô đánh giá, được tính trung bình trên tất cả các truy vấn (Đoạn này hơi khó hiểu chút, bạn có thể tham khảo thêm tại"
6896,E:\DATN\dataframe\train_file\74.txt,"Trong quá trình đánh giá, dự trên thức tự thực của danh sách các mục cho một số truy vấn, chúng ta muốn biết việc dự đoán các mục đó tốt như thế nào."
6897,E:\DATN\dataframe\train_file\74.txt,"Có khá nhiều metrics được đề xuất như MRR, Precision@K, DCG&NDCG, MAP, Kendall’s tau, … tuy nhiên mình sẽ tập trung vào 3 metrics sau:"
6898,E:\DATN\dataframe\train_file\74.txt,Mean Reciprocal Rank (MRR) là một trong những metrics đơn giản nhất trong việc đánh giá các ranking models.
6899,E:\DATN\dataframe\train_file\74.txt,"MRR tính trung bình của các thức hạng tương ứng của mục liên quan đầu tiên đối với tập các truy vấn Q, có thể địn nghĩa nó như sau"
6900,E:\DATN\dataframe\train_file\74.txt,"Ví dụ, ta có bảng sau, tương ứng với các queries 1,2,3 sẽ có danh sách dự đoán và đáp án đúng"
6901,E:\DATN\dataframe\train_file\74.txt,Vậy MRR = 1/3 * (1/2 + 1/1 + 1/3) = 11/18
6902,E:\DATN\dataframe\train_file\74.txt,"Một trong những hạn chế của MRR là nó chỉ tính đến thứ hạng của một trong các mục (mục có liên quan nhất, như ở query 2, chỉ quan tâm tới dự đoán d đầu tiên) và bỏ qua mục khác."
6903,E:\DATN\dataframe\train_file\74.txt,Precision at k
6904,E:\DATN\dataframe\train_file\74.txt,Precision@k : số tài liệu thật sự liên quan đến truy vấn trong k tài liệu có dự đoán liên quan cao nhất
6905,E:\DATN\dataframe\train_file\74.txt,"Để mình ví dụ hơn cho dễ hiểu nhé, bạn tìm kiếm từ khóa “Phim Mỹ”, và trong trang đầu tiến, có 8 trên 10 phim gợi ý bạn là phim Mỹ, vậy Precision@10 đối với truy vấn này là 8/10 = 0.8"
6906,E:\DATN\dataframe\train_file\74.txt,"Khái quát hóa, để tính Precision@k của tập các truy vấn Q, bạn có thể tính bằng cách lấy trung bình của các giá trị Precision@k của các queries trong Q"
6907,E:\DATN\dataframe\train_file\74.txt,Hạn chế của Precision@k đó là nó không tốt đối với việc tính đến vị trị các tài liệu liên quan bởi nó chỉ tính số lượng
6908,E:\DATN\dataframe\train_file\74.txt,DCG – NDCG
6909,E:\DATN\dataframe\train_file\74.txt,Normalized Discounted Cumulative Gain (NDCG) có lẽ là metric được được dung phổ biến nhất trong các bài toán learning to rank.
6910,E:\DATN\dataframe\train_file\74.txt,"Trái ngược với các metrics trước đó, NDCG xem xét thứ tự và sự liên quan quan trọng của các tài liệu, đồng thời chú trọng việc đưa ra các tài liệu có liên quan cao và danh sách được đề xuất"
6911,E:\DATN\dataframe\train_file\74.txt,Nghe khá là khó hiểu nhỉ?
6912,E:\DATN\dataframe\train_file\74.txt,"Trước khi tìm hiểu kĩ hơn về NDCG, cùng nhau tìm hiểu 2 metrics liên quan là Cumulative Gain (CG) và Discounted Cumulative Gain (DCG) nào!"
6913,E:\DATN\dataframe\train_file\74.txt,"Cumulative Gain (CG) của một tập các tài liệu được truy xuất là tổng các điểm liên quan (relevance score) của chúng đối với câu truy vấn, được định nghĩa như sau:"
6914,E:\DATN\dataframe\train_file\74.txt,"Discounted Cumulative Gain (DCG) là phiên bản có trọng số của CG, sử dụng logarit để giảm relevance score tương ứng với vị trí của các kết quả."
6915,E:\DATN\dataframe\train_file\74.txt,Điều này hữu ích với việc muốn ưu tiên cao hơn cho một vài mục tiêu đầu tiến sau khi phân tích hiệu suất của một hệ thống
6916,E:\DATN\dataframe\train_file\74.txt,DCG dựa trên giả định sau:
6917,E:\DATN\dataframe\train_file\74.txt,Các tài liệu có liên quan cao sẽ hưu ích hơn nếu xuất hiện sớm hơn trong kết quả tìm kiếm
6918,E:\DATN\dataframe\train_file\74.txt,Các tài liệu có liên quan cao sẽ hữu ích hơn các tài liệu có liên quan bên lề tốt hơn các tài liệu không liên quan
6919,E:\DATN\dataframe\train_file\74.txt,Normalized Discounted Cumulative Gain (NDCG) cố gắng nâng cao DCG để phù hợp hơn với các ứng dụng thực tế.
6920,E:\DATN\dataframe\train_file\74.txt,"Bởi tập hợp các mục được truy xuất có thể khác nhau về kích thước giữa các truy vấn hay hệ thống, NDCG cố gắng so sánh hiệu suất bằng các sử dụng phiên bản chuẩn hóa của DCG."
6921,E:\DATN\dataframe\train_file\74.txt,"Nói cách khác, nó sắp xếp các tài liệu của 1 danh sách kết quả theo mức độ liên quan, tìm vị trí p có DCG cao nhất, và sử dụng để chuẩn hóa DCG như sau:"
6922,E:\DATN\dataframe\train_file\74.txt,"Trong đó, IDCG (Ideal Discounted Cumulative Gain), được định nghĩa như sau:"
6923,E:\DATN\dataframe\train_file\74.txt,"NDCG là một metric khá phổ biến, tuy nhiên cũng có một số hạn chế nhất định."
6924,E:\DATN\dataframe\train_file\74.txt,Một trong những hạn chế chính của nó là nó không bắt được các “bad documents” trong kết quả.
6925,E:\DATN\dataframe\train_file\74.txt,Nó có thể không phù hợp để đo lường hiệu xuất của các truy vấn mà thường có một số kết quả tốt ngang nhau.
6926,E:\DATN\dataframe\train_file\74.txt,Lời kết
6927,E:\DATN\dataframe\train_file\74.txt,Trên đây là một số metrics đánh giá ứng với các bài toán Machine Learning điển hình mà mình nghĩ các bạn sẽ cần.
6928,E:\DATN\dataframe\train_file\74.txt,Đây chưa phải là tất cả nhưng mình thấy khá phổ biến nên đã tìm hiểu và viết bài chia sẻ cho mọi người.
6929,E:\DATN\dataframe\train_file\74.txt,Mong là bài viết giúp ích được cho mọi người trên con đường chinh phục Machine Learning.
6930,E:\DATN\dataframe\train_file\74.txt,Cảm ơn các bạn đã đọc!
6931,E:\DATN\dataframe\train_file\74.txt,Rất mong nhận được những đóng góp cũng như các vấn đề mọi người quan tâm để mình có thể viết thêm bài chia sẻ!
6932,E:\DATN\dataframe\train_file\74.txt,Tài liệu tham khảo
6933,E:\DATN\dataframe\train_file\75.txt,Transfer Learning và bài toán Face Recognition
6934,E:\DATN\dataframe\train_file\75.txt,"Trong quá trình xây dựng một mô hình học máy, chắc hẳn các bạn đã gặp phải một số vấn đề như mô hình dự đoán có độ chính xác thấp dù đã dùng một kiến trúc phức tạp, hay lượng dữ liệu quá ít để có thể huấn luyện một mô hình hoàn chỉnh."
6935,E:\DATN\dataframe\train_file\75.txt,"Thông thường, một mô hình có kết quả dự báo kém là do một số nguyên nhân sau"
6936,E:\DATN\dataframe\train_file\75.txt,"Dữ liệu nhỏ không đại diện: Bộ dữ liệu của chúng ta có kích thước quá bé so với mô hình được huấn luyện, khiến cho mô hình không học được các đặc trưng của ảnh để giải quyết các bài toán cụ thể như phân loại, nhận dạng, …"
6937,E:\DATN\dataframe\train_file\75.txt,"Mô hình mất cân bằng dữ liệu: Khi mà tập dữ liệu của chúng ta có sự chênh lệch lớn giữa các nhóm, ví dụ như chỉ có 100 ảnh cho con chó và 100.000 ảnh cho con mèo, tất nhiên mô hình sẽ “thiên vị” dự đoán nghiêng về con mèo nhiều hơn"
6938,E:\DATN\dataframe\train_file\75.txt,Kiến trúc mô hình quá phức tạp: Khi ta có bộ dữ liệu lớn tới vài trăm triệu ảnh thì tất nhiên kiến trúc mô hình phức tạp có thể mang lại độ chính xác cao.
6939,E:\DATN\dataframe\train_file\75.txt,"Tuy nhiên đối với những bộ dữ liệu nhỏ, vừa phải thì mô hình quá phức tạp lại đem lại độ chính xác không cao."
6940,E:\DATN\dataframe\train_file\75.txt,Cần chọn kiến trúc mô hình phù hợp với lượng data chúng ta làm việc cùng
6941,E:\DATN\dataframe\train_file\75.txt,Quá trình tối ưu hóa gặp khó khăn: Có thể các hyperparameter được thiết lập chưa tốt như learning rate khiến cho mô hình huấn luyện lâu hội tụ hoặc chưa đạt tới điểm global optimal
6942,E:\DATN\dataframe\train_file\75.txt,"Vậy khi chúng ta có một lượng data nhỏ nhưng muốn hoàn thiện một bài toán sử dụng mô hình hoàn chỉnh, làm thế nào để mô hình đó hoạt động tốt?"
6943,E:\DATN\dataframe\train_file\75.txt,Transfer Learning có thế giải quyết điều đó.
6944,E:\DATN\dataframe\train_file\75.txt,Transfer Learning là gì?
6945,E:\DATN\dataframe\train_file\75.txt,"“Transfer learning là việc ứng dụng kỹ năng/tri thức mình học được từ vấn đề này (source domain – Ds), với ứng dụng này (source task – Ts) sang vấn đề khác (target domain -Dt) với ứng dụng khác (target task – Tt) có liên quan."
6946,E:\DATN\dataframe\train_file\75.txt,Transfer learning nhằm cải thiện việc học hàm f(.)
6947,E:\DATN\dataframe\train_file\75.txt,cho ứng dụng Tt trên miền Dt”
6948,E:\DATN\dataframe\train_file\75.txt,"Nói một cách đơn giản, Chúng ta sẽ áp dụng tri thức đã được học từ một pre-trained model sang bài toán hiện tại với điều kiện 2 bài toán phải có liên quan tới nhau."
6949,E:\DATN\dataframe\train_file\75.txt,"Tưởng tượng xem, thay vì chạy bộ từ đầu đến cuối đường, chúng ta bắt grab đến đoạn mà grab không thể đi được thì chúng ta tự đi tiếp."
6950,E:\DATN\dataframe\train_file\75.txt,Hãy hình dung sẽ ra sao nếu đoạn đường grab đi được là gần hết quãng đường mà chúng ta cần đi?
6951,E:\DATN\dataframe\train_file\75.txt,"Ví dụ bạn tìm trên mạng thấy VGGFace2 có dataset tới 3.31 triệu ảnh của 9131 người, tức là trung bình mỗi người có 362 ảnh."
6952,E:\DATN\dataframe\train_file\75.txt,Bài toán Nhận diện khuôn mặt người của họ sử dụng Convolutional Neural Network (CNN) và mô hình của họ đạt accuracy tới hơn 99%.
6953,E:\DATN\dataframe\train_file\75.txt,"Bài toán của bạn cũng là nhận diện khuôn mặt, tuy nhiên mỗi đối tượng bạn có chỉ khoảng 9-10 ảnh."
6954,E:\DATN\dataframe\train_file\75.txt,Đây quả là thách thức lớn!
6955,E:\DATN\dataframe\train_file\75.txt,"Lục lại kiến thức về mạng CNN nào, đặc trưng của mạng này là có thể lấy ra các đặc trưng của ảnh và học các đặc trưng đó."
6956,E:\DATN\dataframe\train_file\75.txt,"Các pre-trained model thường là các bài toán với lượng dữ liệu lớn, kiến trúc phù hợp và đem lại độ chính xác tương đối cao."
6957,E:\DATN\dataframe\train_file\75.txt,"Vì vậy ở đây, với bài toán Face Recognition, ta hoàn toàn có thể sử dụng phần ConvNet của VGGFace2 model vào bài toán nhận diện khuôn mặt của mình."
6958,E:\DATN\dataframe\train_file\75.txt,Quá trình sử dụng pre-trained model như trên chính là Transfer Learning.
6959,E:\DATN\dataframe\train_file\75.txt,Quá trình Transfer learning sẽ tận dụng lại các đặc trưng được học từ pre-trained model.
6960,E:\DATN\dataframe\train_file\75.txt,Kiến trúc mô hình sử dụng transfer learning bao gồm 2 phần
6961,E:\DATN\dataframe\train_file\75.txt,"Một mạng Based network có tác dụng trích lọc đặc trưng, based network này được trích xuất từ một phần của pre-trained model sau khi loại bỏ các top fully connected layers"
6962,E:\DATN\dataframe\train_file\75.txt,Các lớp Fully Connected Layers giúp giảm chiều dữ liệu và tính toán phân phối xác suất ở output.
6963,E:\DATN\dataframe\train_file\75.txt,Bản chất Fully Connected Layers chính là một mạng Multiple Layer Perceptron (MLP) - một kiến trúc nguyên thủy nhất của thuật toán neural network.
6964,E:\DATN\dataframe\train_file\75.txt,Tùy vào các bài toán cụ thể sẽ điều chỉnh số lượng các units ở output
6965,E:\DATN\dataframe\train_file\75.txt,Quá trình khởi tạo mô hình ta sẽ tận dụng các weights của Based network.
6966,E:\DATN\dataframe\train_file\75.txt,"Dữ liệu ảnh sau khi đi qua Based network sẽ tạo ra những đặc trưng tốt, những đặc trưng này chính là đầu vào cho mạng MLP để dự báo cho bài toán yêu cầu."
6967,E:\DATN\dataframe\train_file\75.txt,Thử nghiệm Transfer Learning trên Python cùng Tensorflow
6968,E:\DATN\dataframe\train_file\75.txt,"Để dễ hình dung các bước của transfer learning, sau đây mình sẽ thử nghiệm trên Python cùng Tensorflow nhé"
6969,E:\DATN\dataframe\train_file\75.txt,Import các thư viện cần thiết
6970,E:\DATN\dataframe\train_file\75.txt,Ở đây mình sẽ sử dụng Based Network là VGG16
6971,E:\DATN\dataframe\train_file\75.txt,import numpy as np
6972,E:\DATN\dataframe\train_file\75.txt,import os
6973,E:\DATN\dataframe\train_file\75.txt,from PIL import Image
6974,E:\DATN\dataframe\train_file\75.txt,import tensorflow as tf
6975,E:\DATN\dataframe\train_file\75.txt,from tensorflow.keras import layers
6976,E:\DATN\dataframe\train_file\75.txt,from tensorflow.keras import Model
6977,E:\DATN\dataframe\train_file\75.txt,from tensorflow.keras.applications import vgg16
6978,E:\DATN\dataframe\train_file\75.txt,from tensorflow.keras.preprocessing.image import ImageDataGenerator
6979,E:\DATN\dataframe\train_file\75.txt,from sklearn.model_selection import train_test_split
6980,E:\DATN\dataframe\train_file\75.txt,Load dữ liệu ảnh và các nhãn tương ứng
6981,E:\DATN\dataframe\train_file\75.txt,"Đọc dữ liệu ảnh, gán nhãn, đồng bộ kích cỡ ảnh về 1 cỡ cố định, chuyển đổi ảnh về numpy ndarray, phân loại dữ liệu ảnh thành 2 tập training và validation set"
6982,E:\DATN\dataframe\train_file\75.txt,"folder_images = [os.path.join(data_path, f) for f in os.listdir(data_path)]"
6983,E:\DATN\dataframe\train_file\75.txt,for folder in folder_images:
6984,E:\DATN\dataframe\train_file\75.txt,  id_person = int(os.path.basename(folder))
6985,E:\DATN\dataframe\train_file\75.txt,"  vector_label = get_label_vector(num_classes, id_person)"
6986,E:\DATN\dataframe\train_file\75.txt,"  images = [os.path.join(folder, f) for f in os.listdir(folder)]"
6987,E:\DATN\dataframe\train_file\75.txt,  for image in images:
6988,E:\DATN\dataframe\train_file\75.txt,    face_image = Image.open(image)
6989,E:\DATN\dataframe\train_file\75.txt,    # resize the image
6990,E:\DATN\dataframe\train_file\75.txt,"    face_image = face_image.resize((img_rows, img_cols))"
6991,E:\DATN\dataframe\train_file\75.txt,"    face_numpy = np.array(face_image, 'uint8')"
6992,E:\DATN\dataframe\train_file\75.txt,numpy_images = np.array(numpy_images)
6993,E:\DATN\dataframe\train_file\75.txt,labels = np.array(labels)
6994,E:\DATN\dataframe\train_file\75.txt,# split data
6995,E:\DATN\dataframe\train_file\75.txt,"X_train, X_val, y_train, y_val = train_test_split(numpy_images, labels, test_size=0.15, random_state=42)"
6996,E:\DATN\dataframe\train_file\75.txt,"print(X_train.shape, y_train.shape)"
6997,E:\DATN\dataframe\train_file\75.txt,"print(X_val.shape, y_val.shape)"
6998,E:\DATN\dataframe\train_file\75.txt,Load Based Network và đóng băng các layers để không training lại các layers đó
6999,E:\DATN\dataframe\train_file\75.txt,# load model VGG16
7000,E:\DATN\dataframe\train_file\75.txt,"based_model = vgg16.VGG16(weights = 'imagenet',"
7001,E:\DATN\dataframe\train_file\75.txt,"                    include_top = False,"
7002,E:\DATN\dataframe\train_file\75.txt,"                    input_shape = (img_rows, img_cols, 3))"
7003,E:\DATN\dataframe\train_file\75.txt,"# Freeze layers, not training these layers"
7004,E:\DATN\dataframe\train_file\75.txt,for layer in based_model.layers:
7005,E:\DATN\dataframe\train_file\75.txt,    layer.trainable = False
7006,E:\DATN\dataframe\train_file\75.txt,# Summary model
7007,E:\DATN\dataframe\train_file\75.txt,Ở đây include_top = False để loại bỏ lớp Fully Connected trên cùng.
7008,E:\DATN\dataframe\train_file\75.txt,Đây là kiến trúc Based Network
7009,E:\DATN\dataframe\train_file\75.txt,Xây dựng mạng MLP
7010,E:\DATN\dataframe\train_file\75.txt,"Ở đây mình dùng thử một tập dữ liệu nhỏ của tầm 19 người, tức là số classes =19."
7011,E:\DATN\dataframe\train_file\75.txt,"Mình tọa một mạng MLP gồm 3 lớp Fully Connected, trong đó lớp cuối cùng sẽ có số units chính là số classes."
7012,E:\DATN\dataframe\train_file\75.txt,"Các lớp Fully Connected treeb mình sử dụng activation ReLU, còn ở layer cuối mình sử dụng activation Softmax cho bài toán phân loại."
7013,E:\DATN\dataframe\train_file\75.txt,Đầu vào của mạng MLP chính là đầu ra của Based Network
7014,E:\DATN\dataframe\train_file\75.txt,"def layer_added(output_based_network, num_classes):"
7015,E:\DATN\dataframe\train_file\75.txt,  x = output_based_network
7016,E:\DATN\dataframe\train_file\75.txt,  x = layers.Flatten()(x)
7017,E:\DATN\dataframe\train_file\75.txt,"  x = layers.Dense(1024, activation='relu')(x)"
7018,E:\DATN\dataframe\train_file\75.txt,"  x = layers.Dense(256, activation='relu')(x)"
7019,E:\DATN\dataframe\train_file\75.txt,"  x = layers.Dense(num_classes, activation='softmax')(x)"
7020,E:\DATN\dataframe\train_file\75.txt,  return x
7021,E:\DATN\dataframe\train_file\75.txt,output_based_network = based_model.output
7022,E:\DATN\dataframe\train_file\75.txt,"output_layer = layer_added(output_based_network, num_classes)"
7023,E:\DATN\dataframe\train_file\75.txt,"model = Model(based_model.input, output_layer)"
7024,E:\DATN\dataframe\train_file\75.txt,Đây là kiến trúc mô hình hoàn chỉnh sau khi thêm các Fully Connected layers.
7025,E:\DATN\dataframe\train_file\75.txt,Có thể thấy kiến trúc mô hình đã thêm các lớp Fully Connected sao với Based Network
7026,E:\DATN\dataframe\train_file\75.txt,Compile & Fit
7027,E:\DATN\dataframe\train_file\75.txt,"Khi xây dựng được backbone của mô hình, mình sẽ compile mô hình và fit dữ liệu vào mô hình."
7028,E:\DATN\dataframe\train_file\75.txt,# compile model
7029,E:\DATN\dataframe\train_file\75.txt,"model.compile(optimizer = tf.keras.optimizers.Adam(),"
7030,E:\DATN\dataframe\train_file\75.txt,"              loss = tf.keras.losses.CategoricalCrossentropy(),"
7031,E:\DATN\dataframe\train_file\75.txt,# fit model
7032,E:\DATN\dataframe\train_file\75.txt,"history = model.fit(X_train, y_train, validation_data=(X_val, y_val),"
7033,E:\DATN\dataframe\train_file\75.txt,Kết quả quá trình training với 10 epochs:
7034,E:\DATN\dataframe\train_file\75.txt,"Có thể thấy kết quả tương đối tốt, train_acc và val_acc đều tăng dần tới 1, tuy loss_val vẫn còn cao tuy nhiên vẫn có xu hướng giảm."
7035,E:\DATN\dataframe\train_file\75.txt,Do thời gian hạn hẹp nên mình chỉ training với 10 epochs.
7036,E:\DATN\dataframe\train_file\75.txt,Các bạn có thể chạy thử với số epochs cao hơn xem kết quả thế nào nhé ^^
7037,E:\DATN\dataframe\train_file\75.txt,Test model
7038,E:\DATN\dataframe\train_file\75.txt,Mình thử dùng mô hình test với 1 số ảnh của những người thuộc các lớp training xem kết quả thế nào
7039,E:\DATN\dataframe\train_file\75.txt,path_test = '/content/drive/MyDrive/Colab Notebooks/data_test_fr'
7040,E:\DATN\dataframe\train_file\75.txt,"test_images = [os.path.join(path_test, f) for f in os.listdir(path_test)]"
7041,E:\DATN\dataframe\train_file\75.txt,for image in test_images:
7042,E:\DATN\dataframe\train_file\75.txt,    face_image = Image.open(image)
7043,E:\DATN\dataframe\train_file\75.txt,    # resize the image
7044,E:\DATN\dataframe\train_file\75.txt,"    face_image = face_image.resize((img_rows, img_cols))"
7045,E:\DATN\dataframe\train_file\75.txt,"    face_numpy = np.array(face_image, 'uint8')"
7046,E:\DATN\dataframe\train_file\75.txt,    face_numpy = [face_numpy]
7047,E:\DATN\dataframe\train_file\75.txt,    face_numpy = np.array(face_numpy)
7048,E:\DATN\dataframe\train_file\75.txt,    predict = model.predict(face_numpy/255)
7049,E:\DATN\dataframe\train_file\75.txt,    id_predict = predict[0].tolist().index(max(predict[0])) + 1
7050,E:\DATN\dataframe\train_file\75.txt,    id_true = int(os.path.basename(image).split('.
7051,E:\DATN\dataframe\train_file\75.txt,    if id_predict == id_true:
7052,E:\DATN\dataframe\train_file\75.txt,"      print(""True with "", max(predict[0]))"
7053,E:\DATN\dataframe\train_file\75.txt,"      print(""False"", id_predict,' with ', max(predict[0]), ' but ', id_true, predict[0][id_true-1])"
7054,E:\DATN\dataframe\train_file\75.txt,Và cho kết quả khá tốt
7055,E:\DATN\dataframe\train_file\75.txt,Có thể thấy kết quả cao như vậy có thể nói phần lớn do mạng Backbone khá tốt trong việc trích xuất đặc trưng ảnh.
7056,E:\DATN\dataframe\train_file\75.txt,"Dễ hiểu thôi, VGG16 là mạng lớn và được training trên số lượng dữ liệu vô cùng lớn mà"
7057,E:\DATN\dataframe\train_file\75.txt,Cảm ơn các bạn đã đọc bài viết đầu tiên của mình.
7058,E:\DATN\dataframe\train_file\75.txt,"Rất mong được nghe các sự góp ý từ mọi người ^^ Nếu thấy bài viết hay và hữu ích, đừng quên upvote cho mình nhé."
7059,E:\DATN\dataframe\train_file\75.txt,Thank you!
7060,E:\DATN\dataframe\train_file\76.txt,Các giải thuật tìm kiếm thường được sử dụng trong Natural Language Generation
7061,E:\DATN\dataframe\train_file\76.txt,"Chào mọi người, trong bài viết này mình sẽ cùng mọi người tìm hiểu một số thuật toán tìm kiếm được sử dụng trong Natural Language Generation."
7062,E:\DATN\dataframe\train_file\76.txt,I. Tổng quan về Natural Language Generation
7063,E:\DATN\dataframe\train_file\76.txt,Natural Language Generation là gì?
7064,E:\DATN\dataframe\train_file\76.txt,Natural Language Generation(NLG) là việc sử dụng AI để tạo ra các câu chuyện viết hoặc nói từ một tập dữ liệu.
7065,E:\DATN\dataframe\train_file\76.txt,"NLG liên quan đến tương tác giữa người với máy và máy với người, bao gồm computational linguistics , natural language processing (NLP) and natural language understanding (NLU)."
7066,E:\DATN\dataframe\train_file\76.txt,Natural Language Generation được sử dụng như thế nào?
7067,E:\DATN\dataframe\train_file\76.txt,Tạo phản hồi của các chatbots(dialogue) và voice assistants như Alexa của Google và Siri của Apple
7068,E:\DATN\dataframe\train_file\76.txt,Chuyển đổi các báo cáo tài chính và các loại dữ liệu kinh doanh khác thành nội dung dễ hiểu cho nhân viên và khách hàng
7069,E:\DATN\dataframe\train_file\76.txt,"Tự động hóa các phản hồi email, tin nhắn và trò chuyện của khách hàng tiềm năng"
7070,E:\DATN\dataframe\train_file\76.txt,"Tổng hợp, tổng hợp các bản tin thời sự (Text summarization)"
7071,E:\DATN\dataframe\train_file\76.txt,Tạo mô tả sản phẩm cho các trang web thương mại điện tử và nhắn tin cho khách hàng
7072,E:\DATN\dataframe\train_file\76.txt,Machine Translation
7073,E:\DATN\dataframe\train_file\76.txt,Làm thơ
7074,E:\DATN\dataframe\train_file\76.txt,NLG trong Deep Learning
7075,E:\DATN\dataframe\train_file\76.txt,"Trong Deep Learning hiện nay, NLG thường được biểu diễn bằng kiến trúc Encoder-Decoder."
7076,E:\DATN\dataframe\train_file\76.txt,"Encoder đọc văn bản đầu và trả về một vector đại diện cho văn bản đó, Decoder lấy vector đó rồi tạo ra một đoạn văn bản tương ứng."
7077,E:\DATN\dataframe\train_file\76.txt,Các bạn có thể tham khảo thêm một số bài viết về NLG ở phần tài liệu tham khảo bên dưới.
7078,E:\DATN\dataframe\train_file\76.txt,Các giải thuật tìm kiếm trong NLG
7079,E:\DATN\dataframe\train_file\76.txt,VÌ sao cần các giải thuật tìm kiếm này?
7080,E:\DATN\dataframe\train_file\76.txt,"Trong NLG khi chúng ta tạo ra các đoạn văn bản hay các câu, các giải thuật tìm kiếm giúp chúng ta tìm ra những câu hoặc đoạn văn hợp lý, giống ngôn ngữ con người và tránh những sự mơ hồ không đáng có khi sản sinh văn bản."
7081,E:\DATN\dataframe\train_file\76.txt,"Tại mỗi bước thời gian trong quá trình decode, chúng ta lấy vector(chứa thông tin từ bước này sang bước khác) và tính toán xác suất khả năng xảy ra của mỗi từ bằng hàm softmax."
7082,E:\DATN\dataframe\train_file\76.txt,P(x_i:x_{1:i-1}) = \frac{exp(u_i)}{\sum_j exp(u_j)}
7083,E:\DATN\dataframe\train_file\76.txt,1:i−1
7084,E:\DATN\dataframe\train_file\76.txt,Greedy Decoding
7085,E:\DATN\dataframe\train_file\76.txt,Giải thuật này là đơn giản nhất.
7086,E:\DATN\dataframe\train_file\76.txt,Tại mỗi bước thời gian nó chỉ cần chọn token có khả năng xảy ra cao nhất.
7087,E:\DATN\dataframe\train_file\76.txt,Mặc dù đơn giản là vậy và cảm tưởng có vẻ rất hợp lý nhưng trên thực tế nó lại tạo ra những đoạn văn bản không phải là tốt nhất có thể.
7088,E:\DATN\dataframe\train_file\76.txt,Điều này do phân phối của dữ liệu gây ra khiến chúng ta mắc kẹt ở những kết quả chưa tốt.
7089,E:\DATN\dataframe\train_file\76.txt,Ví dụ greedy decoding tạo ra kết quả không tốt cho nhiệm vụ tóm tắt văn bản:
7090,E:\DATN\dataframe\train_file\76.txt,Beam Search
7091,E:\DATN\dataframe\train_file\76.txt,Do phân phối của dữ liệu nên Greedy Decoding không thể tìm ra được câu hợp lý nhất.
7092,E:\DATN\dataframe\train_file\76.txt,Cách giải thích hợp lý hơn đó là do mỗi bước thời gian
7093,E:\DATN\dataframe\train_file\76.txt,t chúng ta cần tìm
7094,E:\DATN\dataframe\train_file\76.txt,∣x
7095,E:\DATN\dataframe\train_file\76.txt,1:t−1
7096,E:\DATN\dataframe\train_file\76.txt,) do đó chưa chắc tích các xác suất cao nhất ở mỗi bước thời gian
7097,E:\DATN\dataframe\train_file\76.txt,t là lớn nhất.
7098,E:\DATN\dataframe\train_file\76.txt,Vậy nên để tìm kiếm xác suất lớn nhất ta phải xem xét toàn bộ xác suất của các token ở mỗi bước thời gian
7099,E:\DATN\dataframe\train_file\76.txt,t. Tìm kiếm đến cuối cùng có thể giải quyết vấn đề trước đó vì nó sẽ tìm kiếm toàn bộ không gian.
7100,E:\DATN\dataframe\train_file\76.txt,"Tuy nhiên, nó sẽ rất tốn kém về mặt tính toán."
7101,E:\DATN\dataframe\train_file\76.txt,"Giả sử có 10.000 từ vựng, để tạo ra một câu có độ dài 10 tokens, nó sẽ là (10.000) ¹⁰ - một con số quá lớn."
7102,E:\DATN\dataframe\train_file\76.txt,Beam search có thể đối phó với vấn đề này.
7103,E:\DATN\dataframe\train_file\76.txt,Tại mỗi bước thời gian
7104,E:\DATN\dataframe\train_file\76.txt,"t, nó tạo ra tất cả các token có thể có trong danh sách từ vựng, sau đó, nó sẽ chọn các k token có xác suất cao nhất ."
7105,E:\DATN\dataframe\train_file\76.txt,Xác suất của k token này sẽ là cơ sở để tính toán cho k token ở bước thời gian tiếp theo.
7106,E:\DATN\dataframe\train_file\76.txt,"Cuối cùng, ta có k đoạn văn bản được tạo ra."
7107,E:\DATN\dataframe\train_file\76.txt,Không gian tìm kiếm chỉ là (10.000) * k.
7108,E:\DATN\dataframe\train_file\76.txt,Hình ảnh minh họa Beam Search với k = 2
7109,E:\DATN\dataframe\train_file\76.txt,"Beam search với k lớn sẽ có kết quả gần như là tìm kiếm trên toàn bộ không gian, và với k nhỏ(đặc biệt k = 1) sẽ cho ra kết quả giống hoặc gần giống với Greedy decoding."
7110,E:\DATN\dataframe\train_file\76.txt,Random sampling
7111,E:\DATN\dataframe\train_file\76.txt,Mặc dù beam search hiệu quả là vậy nhưng đôi khi trong 1 số nhiệm vụ nhất định ta lại thấy beam search khá tồi.
7112,E:\DATN\dataframe\train_file\76.txt,"Hãy tưởng tượng khi khách hàng phản hồi tốt về sản phẩm của bạn, con bot của bạn chỉ biết nói ""Cảm ơn""??"
7113,E:\DATN\dataframe\train_file\76.txt,Quá là nhàm chán.
7114,E:\DATN\dataframe\train_file\76.txt,"Random sampling sẽ giúp chúng ta thoát khỏi cảnh nhàm chán đó bằng câu khác như ""Cảm ơn vì sự tin tưởng của quý khách dành cho chúng tôi""."
7115,E:\DATN\dataframe\train_file\76.txt,"Giải thuật này khá đơn giản, ta chỉ cần chọn ngẫu nhiên một từ ở mỗi bước thời gian"
7116,E:\DATN\dataframe\train_file\76.txt,t dưa vào phân phối xác suất của đầu ra hàm softmax.
7117,E:\DATN\dataframe\train_file\76.txt,Với lấy mẫu ngẫu nhiên các token có xác suất 0.2 đôi khi lại không được chọn mà chọn token có xác suất 0.01.
7118,E:\DATN\dataframe\train_file\76.txt,Nhưng đương nhiên là từ có xác suất 0.01 rất khó có khả năng xảy ra.
7119,E:\DATN\dataframe\train_file\76.txt,Random sampling với Temperature
7120,E:\DATN\dataframe\train_file\76.txt,"Random sampling đôi khi tự nó có thể có khả năng tạo ra một từ rất ngẫu nhiên một cách tình cờ(như trình bày bên trên), không hợp lý chút nào."
7121,E:\DATN\dataframe\train_file\76.txt,Temperature được sử dụng để tăng xác suất của các token có thể xảy ra trong khi giảm xác suất của token không hợp lý.
7122,E:\DATN\dataframe\train_file\76.txt,0 \prec \tau \leq 1
7123,E:\DATN\dataframe\train_file\76.txt,0≺τ≤1 .
7124,E:\DATN\dataframe\train_file\76.txt,Lưu ý khi
7125,E:\DATN\dataframe\train_file\76.txt,\tau = 1
7126,E:\DATN\dataframe\train_file\76.txt,τ=1 việc sử dụng temperature không có ý nghĩa.
7127,E:\DATN\dataframe\train_file\76.txt,Ta có hàm softmax mới như sau:
7128,E:\DATN\dataframe\train_file\76.txt,P(x_i|x_{1:i-1}) = \frac{exp(u_i/\tau)}{\sum_j exp(u_j/\tau)}
7129,E:\DATN\dataframe\train_file\76.txt,∣x
7130,E:\DATN\dataframe\train_file\76.txt,1:i−1
7131,E:\DATN\dataframe\train_file\76.txt,"Trong hình trên, với"
7132,E:\DATN\dataframe\train_file\76.txt,"τ = 0,5, các từ có thể xảy ra nhất như i , yeah , me , có nhiều cơ hội được tạo hơn."
7133,E:\DATN\dataframe\train_file\76.txt,"Đồng thời, điều này cũng làm giảm xác suất của những token ít có khả năng xảy ra hơn, mặc dù điều này chỉ làm giảm sự xảy ra của chúng."
7134,E:\DATN\dataframe\train_file\76.txt,Top-K Sampling
7135,E:\DATN\dataframe\train_file\76.txt,"Random sampling hiệu quả nhưng đôi khi nó tạo ra những câu vô nghĩa, mặc dù đã sử dụng temperature"
7136,E:\DATN\dataframe\train_file\76.txt,τ nhưng việc tạo ra những câu không ai hiểu là chuyện vẫn có thể xảy ra.
7137,E:\DATN\dataframe\train_file\76.txt,"Để tránh điều này, Top-K Sampling được đề xuất."
7138,E:\DATN\dataframe\train_file\76.txt,Trong Top-K sampling chỉ xem xét k token có xác suất cao nhất ở mỗi bước thời gian
7139,E:\DATN\dataframe\train_file\76.txt,"t. GPT-2 đã áp dụng giải thuật này, đây là một trong những lý do giúp nó thành công trong việc tạo ra những câu chuyện."
7140,E:\DATN\dataframe\train_file\76.txt,"Tùy từng tác vụ mà k được chọn là khác nhau, ví dụ như trong 1 số paper về Neural Machine Translation có đề xuất thì k = 10, nhưng với những nhiệm vụ tạo ra những bài thơ hay bài hát thì k có thể lớn hơn."
7141,E:\DATN\dataframe\train_file\76.txt,Ví dụ với k = 6:
7142,E:\DATN\dataframe\train_file\76.txt,"Như hình minh họa, top 6 tokens có xác suất cao nhất được xem xét và chọn ngẫu nhiên trong 6 tokens này."
7143,E:\DATN\dataframe\train_file\76.txt,Top-p(nucleus) sampling
7144,E:\DATN\dataframe\train_file\76.txt,"Mặc dù được đánh giá rất cao và đã cho kết quả thực nghiệm tốt, nhưng gần đây các nhà nghiên cứu chỉ ra một số hạn chế của top-k sampling như là tổng xác suất của k token được chọn trên quá nhỏ dẫn đến thiếu đi một số lựa chọn thú vị, hoặc tổng xác suất của k token được chọn quá lớn khiến các từ không nên chọn vẫn tồn tại."
7145,E:\DATN\dataframe\train_file\76.txt,"Thay vì xem xét xác suất của k token có nhiều khả năng nhất , trong Top-p sampling chọn các token có xác suất cao nhất sao cho tổng các xác suất này lớn hơn hoặc bằng p:"
7146,E:\DATN\dataframe\train_file\76.txt,\sum_{x\epsilon V^p} P(x|x_{1:i-1}) \geq p
7147,E:\DATN\dataframe\train_file\76.txt,P(x∣x
7148,E:\DATN\dataframe\train_file\76.txt,1:i−1
7149,E:\DATN\dataframe\train_file\76.txt,)≥p
7150,E:\DATN\dataframe\train_file\76.txt,"Bằng cách này, kích thước của tập hợp các token cần xem xét có thể tự động tăng và giảm theo phân phối xác suất của từng bước thời gian"
7151,E:\DATN\dataframe\train_file\76.txt,Ví dụ với p = 0.92:
7152,E:\DATN\dataframe\train_file\76.txt,"Như hình minh họa, top-p sampling sẽ chọn ra những token có xác suất cao nhất sao cho tổng xác suất"
7153,E:\DATN\dataframe\train_file\76.txt,\geq 0.92
7154,E:\DATN\dataframe\train_file\76.txt,≥0.92
7155,E:\DATN\dataframe\train_file\76.txt,Như vậy mình đã cùng mọi người tìm hiểu sơ lược về các giải thuật tìm kiếm trong NLG.
7156,E:\DATN\dataframe\train_file\76.txt,"Không thể kết luận là giải thuật này tốt hơn giải thuật kia vì còn tùy từng nhiệm vụ như trong NMT thì thường là Beam search và Greedy decoding(top-k sampling cũng có thể được dùng nhưng phải trong những tập data rất lớn trên 10M câu), tạo ra các bài thơ thì thường là Random-sampling, Top-k sampling, v.v."
7157,E:\DATN\dataframe\train_file\76.txt,Gần đây còn có một phương pháp mới đó là kết hợp cả top-k và top-p Sampling.
7158,E:\DATN\dataframe\train_file\76.txt,Tài liệu tham khảo
7159,E:\DATN\dataframe\train_file\76.txt, - bài giảng về NLG trong khóa cs224
7160,E:\DATN\dataframe\train_file\77.txt,XÂY DỰNG MÔ HÌNH 1 PHA PHÁT HIỆN VÀ NHẬN DẠNG VĂN BẢN NHIỀU DÒNG
7161,E:\DATN\dataframe\train_file\77.txt,"Tổng quan bài toán: Trong lĩnh vực xử lí ảnh trong Học sâu, đặc biệt là liên quan đến bài toán nhận dạng kí tự quan học, các bài toán phát hiện và nhận dạng văn bản vẫn đang là một bài toán thử thách và có tính ứng dụng cao trong cộng đồng phân tích tài liệu văn bản."
7162,E:\DATN\dataframe\train_file\77.txt,"Không những về độ khó đòi hỏi mô hình xử lí có cấu trúc phức tạp mà nó còn là một đề tài nghiên cứu có tính ứng dụng cao trong cuộc sống như : trích xuất thông tin từ hóa đơn, trích xuất thông tin từ giấy tờ tùy thân (chứng minh thư, căn cước công dân, bằng lái xe,...)."
7163,E:\DATN\dataframe\train_file\77.txt,"Trong bài toán phát hiện và nhận dạng văn bản trước đây, các nhà nghiên cứu đều đưa ra các mô hình riêng biệt để xử lí chúng, cụ thể là mô hình phát hiện văn bản và mô hình nhận dạng văn bản."
7164,E:\DATN\dataframe\train_file\77.txt,Các mô hình học sâu trở đều trở nên cốt lõi và thông trị cả 2 bài toán trên.
7165,E:\DATN\dataframe\train_file\77.txt,"Trong bài toán phát hiện văn bản, hầu hết mô hình đều sử dụng một mạng tích chập để trích xuất đặc trưng từ ảnh, sau đó các mô hình sử dụng các phương thức khác nhau để giải mã các khu vực chứa văn bản."
7166,E:\DATN\dataframe\train_file\77.txt,"Trong khi đó, bài toán nhận dạng văn bản cũng sử dụng một mạng tích chập để trích xuất thông tin từ ảnh sau đó sử dụng một mạng dự đoán tuần tự để tìm ra chữ cái xuất hiện trên ảnh đầu vào."
7167,E:\DATN\dataframe\train_file\77.txt,"Điều này có nhược điểm về thời gian lớn khi phải xử lí trên những ảnh có rất nhiều vùng văn bản như hợp đồng, sách báo,... Hơn nữa, việc các mô hình độc lập xử lí từng tác vụ sẽ làm cho mô hình phát hiện văn bản không được bổ sung tri thức từ nhận dạng văn bản, điều này làm cho mô hình phát hiện văn bản có thể dự đoán sai vùng là văn bản nhưng không đọc được."
7168,E:\DATN\dataframe\train_file\77.txt,"Đặt vấn đề: Hiện nay, ở Việt Nam, việc áp dụng các thiết bị máy quay trên các đường cao tốc, đường phố để phát hiện các lỗi vi phạm và phạt nguội các tài xế thông qua việc nhận dạng biển số xe đang trở nên phổ biến."
7169,E:\DATN\dataframe\train_file\77.txt,"Tuy nhiên, do đòi hỏi tốc độ xử lí cao trên thiết bị đích nên các mô hình học sâu được áp dụng để giải quyết 2 bài toán tách biệt này gặp trở ngại rất lớn về thời gian."
7170,E:\DATN\dataframe\train_file\77.txt,"Hơn nữa, biển số xe ở Việt Nam hiện nay đang có cả biển 1 dòng và biển 2 dòng, vấn đề này gặp khó khăn trong các mô hình nhận dạng văn bản theo tuần tự từ trái sang phải, điều này chỉ giải quyết trong dữ liệu biển 1 dòng."
7171,E:\DATN\dataframe\train_file\77.txt,"Phương pháp đề xuất: Để giải quyết các vấn đề trên, trong bài viết này, chúng tôi đưa ra một mô hình đầu cuối cho phát hiện và nhận dạng văn bản sử dụng cơ chế thích nghi không gian để xử lí dữ liệu nhiều dòng."
7172,E:\DATN\dataframe\train_file\77.txt,"Mô hình sử dụng một mạng trích xuất đặc trưng chung, giải mã chúng và sử dụng kết quả dự đoán của nhánh phát hiện văn bản làm đầu vào của nhánh nhận dạng văn bản."
7173,E:\DATN\dataframe\train_file\77.txt,"Ở nhánh phát hiện văn bản, mô hình sử dụng kiến trúc FPN để giải mã chúng, sau đó nhánh phát hiện văn bản sẽ đề xuất các vùng mà nó cho là văn bản thông qua phương thức lấy mẫu, trong đó RoI Rotate là phương pháp đạt kết quả tối ưu nhất trong bài toán của chúng tôi."
7174,E:\DATN\dataframe\train_file\77.txt,"Roi Rotate có nhiệm vụ cầu nối giữa nhánh phát hiện văn bản và nhánh nhận dạng văn bản, nó sử dụng một ma trận để điều chỉnh, biển đổi không gian của vùng đề xuất từ ảnh có chữ nghiên, chéo về ảnh chữ thẳng."
7175,E:\DATN\dataframe\train_file\77.txt,"Ở nhánh nhận dạng văn bản, chúng tôi sử dụng mô hình Transformer để dự đoán tuần tự kí tự, cùng với đó, chúng tôi áp dụng phương thức Mã hóa trị trí 2 chiều vào để mô hình có thể hiểu và tập trung nhận dạng được kí tự tuần tự theo từng dòng."
7176,E:\DATN\dataframe\train_file\77.txt,Phương pháp đề xuất
7177,E:\DATN\dataframe\train_file\77.txt,"Chúng tôi đề xuất một phương pháp đầu cuối kết hợp 2 nhiệm vụ phát hiện và nhận diện văn bản nhiều dòng, mô hình là sự thống nhất giữa nhánh phát hiện và nhánh nhận dạng ."
7178,E:\DATN\dataframe\train_file\77.txt,"Theo hình 1, mô hình có các thành phần chính như sau: Mạng chia sẻ, nhánh phát hiện đối tượng, RoI Rotate, Mã hóa vị trí 2 chiều và nhánh Nhận dạng."
7179,E:\DATN\dataframe\train_file\77.txt,Tổng quan về mô hình
7180,E:\DATN\dataframe\train_file\77.txt,Hình 1: Cấu trúc mô hình đề xuất
7181,E:\DATN\dataframe\train_file\77.txt,"Lấy nguồn cảm hứng từ mô hình FOTS, chúng tôi chọn ResNet-50 làm mô hình cơ sở trích xuất đặc trưng ."
7182,E:\DATN\dataframe\train_file\77.txt,"Để cải thiện độ chính xác phát hiện cho các biển số xe nhiều tỷ lệ to nhỏ, chúng tôi sử dụng kiến trúc mạng FPN để kết hợp các bản đồ đối tượng đặc trưng cấp thấp và cấp cao."
7183,E:\DATN\dataframe\train_file\77.txt,"Khi cho ảnh đầu vào qua kiến trúc Mạng chia sẻ, thu được ma trận đặc trưng chia sẻ có tỉ lệ bằng"
7184,E:\DATN\dataframe\train_file\77.txt,1/4 tỉ lệ ảnh đầu vào.
7185,E:\DATN\dataframe\train_file\77.txt,"Sau đó, nhánh phát hiện sử dụng một mạng tích chập lên ma trận đặc trưng chia sẻ để thu được kết quả dự đoán về lớp, tọa độ bao đóng, được xác định và tối ưu trên từng pixel."
7186,E:\DATN\dataframe\train_file\77.txt,"Dựa trên kết dự đoán ra bao đóng của nhánh phát hiện hoặc nhãn đầu vào, RoI Rotate được đề xuất sẽ cắt bỏ vùng tương ứng với chiều cao cố định và thay đổi chiều rộng để giữ tỷ lệ của vùng ban đầu."
7187,E:\DATN\dataframe\train_file\77.txt,"Cuối cùng, trong nhánh nhận dạng, trước tiên, chúng tôi đưa vùng được RoI Rotate đề xuất cho qua các khối CNN nông để trích xuất thêm một số đặc trưng chi tiết về cấp kí tự."
7188,E:\DATN\dataframe\train_file\77.txt,"Tiếp theo, lấy ý tưởng ban đầu từ SATRN, chúng tôi áp dụng mã hóa vị trí 2 chiều cho các vùng do RoI Rotate đề xuất để làm cho mô hình có khả năng chú ý đến nhiều dòng."
7189,E:\DATN\dataframe\train_file\77.txt,"Cuối cùng, cho qua mô hình Transformer để có thể mã hóa kí tự từ đặc trưng ảnh."
7190,E:\DATN\dataframe\train_file\77.txt,Mạng chia sẻ
7191,E:\DATN\dataframe\train_file\77.txt,Hình 2: Cấu trúc Mạng chia sẻ
7192,E:\DATN\dataframe\train_file\77.txt,"Quan sát thấy rằng cả hai mô hình phát hiện văn bản và nhận dạng văn bản trước đây đều sử dụng hai mạng cơ sở riêng biệt để trích xuất các tính năng, chúng tôi đề xuất kết hợp hoàn toàn hai mạng cơ sở thành một mạng chung thống nhất."
7193,E:\DATN\dataframe\train_file\77.txt,"Chúng tôi áp dụng kiến trúc mạng tích chập chia sẻ được đề xuất trong FOTS để tích hợp với mô hình của chúng tôi trong đó, để sử dụng phù hợp với mô hình của chúng tôi, chúng tôi phải tùy chỉnh các siêu tham số để phù hợp với phương pháp của chúng tôi."
7194,E:\DATN\dataframe\train_file\77.txt,Mạng chia sẻ sử dụng ResNet-50 làm bộ mã hóa và kiến trúc mạng FPN làm bộ giải mã.
7195,E:\DATN\dataframe\train_file\77.txt,"Khi hình ảnh đầu vào được Mạng chia sẻ chuyển tiếp, độ phân giải đầu ra sẽ là một trong bốn hình ảnh gốc."
7196,E:\DATN\dataframe\train_file\77.txt,"Đặc biệt, chúng tôi sử dụng tới năm lớp ResNet-50."
7197,E:\DATN\dataframe\train_file\77.txt,Chúng tôi nối các lớp 3-5 dưới dạng bản đồ tính năng cấp thấp với kết quả đầu ra tương ứng của lớp Deconv dưới dạng bản đồ đối tượng đại dương cấp cao.
7198,E:\DATN\dataframe\train_file\77.txt,"Lớp có tên Deconv bao gồm một kênh tính năng tích phân suy giảm, tiếp theo là một hoạt động lấy mẫu hai tuyến tính."
7199,E:\DATN\dataframe\train_file\77.txt,"Trong các thử nghiệm sau này của chúng tôi, chúng tôi nhận thấy rằng số lượng kênh trong mỗi lớp có tác động giữa hai bên."
7200,E:\DATN\dataframe\train_file\77.txt,Đây là một siêu tham số xác định sự cân bằng của mạng đường trục giữa nhánh phát hiện và nhánh nhận dạng.
7201,E:\DATN\dataframe\train_file\77.txt,"Để hiểu rõ hơn về kiến trúc Mạng chia sẻ, chúng tôi sẽ giới thiệu về kiến trúc mạng cơ sở ResNet và kiến trúc mạng FPN"
7202,E:\DATN\dataframe\train_file\77.txt,Mạng cơ sở Resnet
7203,E:\DATN\dataframe\train_file\77.txt,Hình 3: Khối phần dư
7204,E:\DATN\dataframe\train_file\77.txt,"Trước đây, vấn đề phổ biến của các mô hình học sâu là xảy ra hiện tưởng Gradient biến mất và Gradient bùng nổ."
7205,E:\DATN\dataframe\train_file\77.txt,Điều này làm cản trở mô hình học sâu xây dựng được kiến trúc sâu hơn.
7206,E:\DATN\dataframe\train_file\77.txt,Trước khi Resnet ra đời thì kiến trúc mạng VGG cũng được xem là khá nông vì chỉ gồm một số khối CNN.
7207,E:\DATN\dataframe\train_file\77.txt,Resnet giải quyết được vấn đề về Gradient biến mất nhờ sử dụng phương pháp Khối phần dư có kiến trúc như trong hình 3.
7208,E:\DATN\dataframe\train_file\77.txt,Có công thức biểu diễn như sau:
7209,E:\DATN\dataframe\train_file\77.txt,"y = F(x,{W_i})+x"
7210,E:\DATN\dataframe\train_file\77.txt,"Trong đó x,y lần lượt là véc-tơ đầu vào và đầu ra của Khối phần dư."
7211,E:\DATN\dataframe\train_file\77.txt,) được biểu diễn là kiến trúc học cho phần dư.
7212,E:\DATN\dataframe\train_file\77.txt,"Theo hình 3 thì F có hai lớp , được tính"
7213,E:\DATN\dataframe\train_file\77.txt,F = W_2\theta(W_1x)
7214,E:\DATN\dataframe\train_file\77.txt,"x), trong đó"
7215,E:\DATN\dataframe\train_file\77.txt,θ là hàm kích hoạt ReLU.
7216,E:\DATN\dataframe\train_file\77.txt,Tác dụng của Khối dư làm cho mô hình có thể xây dựng được một kiến trúc sâu mà không làm mất đi mức độ tổng quát của dữ liệu mà còn thêm tính năng cho đầu vào khi mỗi lần đi qua một Khôi phần dư.
7217,E:\DATN\dataframe\train_file\77.txt,"Nhìn chung, kiến trúc của ResNet sẽ sử dụng kết hợp rất nhiều các Khối dư lại với nhau để xây dựng mô hình có kiến trúc sâu"
7218,E:\DATN\dataframe\train_file\77.txt,Hình 4: Thông số kiến trúc các mạng cơ sở resnet
7219,E:\DATN\dataframe\train_file\77.txt,"Ta có theo hình 4, tổng quan mô hình ResNet có 5 lớp gồm lớp conv1,conv2_x,conv3_x,conv4_x và conv5_x."
7220,E:\DATN\dataframe\train_file\77.txt,"Trong các kiến trúc khác nhau như ResNet-18,Resnet 34 hay ResNet-50,... thì kiến trúc tại các lớp có sự khác nhau."
7221,E:\DATN\dataframe\train_file\77.txt,"Trong mô hình của chúng tôi, chúng tôi sử dụng kiến trúc mạng ResNet-50."
7222,E:\DATN\dataframe\train_file\77.txt,Kiến trúc mạng FPN
7223,E:\DATN\dataframe\train_file\77.txt,Hình 5: Kiến trúc mạng FPN
7224,E:\DATN\dataframe\train_file\77.txt,Kiến trúc mạng FPN là một công cụ trích xuất tính năng được thiết kế giống như một kim tự tháp và nó đạt được khả năng trích xuất tính chính xác hơn và tốc độ nhanh hơn.
7225,E:\DATN\dataframe\train_file\77.txt,"Với kiến trúc đa tỉ lệ, FPN cho chúng ta thông tin từ thấp đến cao, việc này giúp cho quá trình trích xuất không bị bỏ sót các đối tượng có kích thước nhỏ."
7226,E:\DATN\dataframe\train_file\77.txt,"Hơn nữa, qua mỗi tầng giãi mã, nó còn sử dụng thông tin tương ứng của tầng mã hóa, làm cho thông tin được khôi phục tốt và không làm mất đi đặc trưng của nó."
7227,E:\DATN\dataframe\train_file\77.txt,"Kiến trúc FPN có thiết kế và ý tưởng khác rõ ràng, nó giải quyết tốt cho các bài toán phát hiện đối tượng."
7228,E:\DATN\dataframe\train_file\77.txt,Hiện nay các mô hình về phát hiện đối tượng phổ biến hiện nay đều sử dụng các kiến trúc dựa trên cơ sở kiến trúc FPN.
7229,E:\DATN\dataframe\train_file\77.txt,Nhánh phát hiện đối tượng
7230,E:\DATN\dataframe\train_file\77.txt,"Lấy cảm hứng từ FOTS, chúng tôi sử dụng một lớp tích chập để dự đoán hộp bao đóng dựa trên từng pixel."
7231,E:\DATN\dataframe\train_file\77.txt,"Giả sử rằng nhận được một ma trận đặc trưng từ Mạng chia sẻ, nó có kích thước"
7232,E:\DATN\dataframe\train_file\77.txt,"(N, C', H/4, W/4)"
7233,E:\DATN\dataframe\train_file\77.txt,",H/4,W/4), trong đó"
7234,E:\DATN\dataframe\train_file\77.txt,"N là kích thước của lô,"
7235,E:\DATN\dataframe\train_file\77.txt," là số lượng kênh đầu ra của Share Convolution,"
7236,E:\DATN\dataframe\train_file\77.txt,W lần lượt là chiều cao và chiều rộng tương ứng của ảnh đầu vào.
7237,E:\DATN\dataframe\train_file\77.txt,Chúng tôi áp dụng lớp tích chập cho ma trận đặc trưng trên để thay đổi số lượng kênh từ
7238,E:\DATN\dataframe\train_file\77.txt, xuống còn 6.
7239,E:\DATN\dataframe\train_file\77.txt,"Trong đó, kênh đầu tiên có nhiệm vụ để tính xác suất của mỗi pixel để nó thuộc lớp tích cực , ví dụ các pixel nằm trong vùng chưa văn bản được coi là tích cực."
7240,E:\DATN\dataframe\train_file\77.txt,"Trong 4 kênh tiếp theo, mô hình thực hiện học và dự đoán ra khoảng cách từ mỗi pixel được coi là tích cực đến các cạnh trên, dưới, trái và phải của hộp bao đóng tương ứng."
7241,E:\DATN\dataframe\train_file\77.txt,"Cuối cùng, kênh cuối cùng có nhiệm vụ học và dự đoán hướng của hộp bao đóng chứa văn bản, điều này giúp cho việc biến đổi vùng ảnh ở phần sau sao cho chữ được thẳng lại, giúp cho quá trình nhận dạng trở nên dễ dàng và chính xác hơn."
7242,E:\DATN\dataframe\train_file\77.txt,"Và để nhánh này phát hiện được tốt đối tượng, cũng như 6 kênh trên học được tốt từng nhiệm vụ của chúng thì chúng tôi đưa ra 2 hàm phạt đó là : cross entropy loss và regression loss."
7243,E:\DATN\dataframe\train_file\77.txt,Hàm phạt đầu tiên dùng để phạt những dự đoán của mô hình và tối thiểu hóa sự khác biệt giá trị giữa dự đoán đầu ra của mô hình về nhãn và nhãn thật của từng pixel.
7244,E:\DATN\dataframe\train_file\77.txt,Hàm cross entropy loss được đề xuất như sau:
7245,E:\DATN\dataframe\train_file\77.txt,"L_{cls} = \frac{1}{|\Omega|}\sum_{x \in \Omega}H(p_x,p_x^*)"
7246,E:\DATN\dataframe\train_file\77.txt,∣Ω∣
7247,E:\DATN\dataframe\train_file\77.txt,x∈Ω
7248,E:\DATN\dataframe\train_file\77.txt,=\frac{1}{|\Omega|}\sum_{x\in\Omega}(-p_x^*logp_x - (1-p_x^*)log(1-p_x))
7249,E:\DATN\dataframe\train_file\77.txt,∣Ω∣
7250,E:\DATN\dataframe\train_file\77.txt,x∈Ω
7251,E:\DATN\dataframe\train_file\77.txt,(−p
7252,E:\DATN\dataframe\train_file\77.txt,−(1−p
7253,E:\DATN\dataframe\train_file\77.txt,)log(1−p
7254,E:\DATN\dataframe\train_file\77.txt,Trong đó
7255,E:\DATN\dataframe\train_file\77.txt,∣Ω∣ là số lượng các phần tử mà ở đây là các pixel có trong lô huấn luyện đó.
7256,E:\DATN\dataframe\train_file\77.txt,) biểu diễn hàm cross entropy loss giữa dự đoán ma trận điểm do mô hình dự đoán ra là
7257,E:\DATN\dataframe\train_file\77.txt, và nhãn nhị phân ban đầu
7258,E:\DATN\dataframe\train_file\77.txt,"Ở hàm phạt thứ hai, chúng tôi cũng áp dụng hàm IoU và rotation angel loss được biểu diễn như nau:"
7259,E:\DATN\dataframe\train_file\77.txt,"L_{reg}=\frac{1}{|\Omega|}\sum_{x\in|Omega}IoU(R_x,R_x^*) + \lambda_\theta(1-cos(\theta_x,\theta_x^*))"
7260,E:\DATN\dataframe\train_file\77.txt,∣Ω∣
7261,E:\DATN\dataframe\train_file\77.txt,x∈∣Omega
7262,E:\DATN\dataframe\train_file\77.txt,(1−cos(θ
7263,E:\DATN\dataframe\train_file\77.txt,Trong đó
7264,E:\DATN\dataframe\train_file\77.txt,) biểu diễn hàm IoU giữa dự đoán bao đóng của mô hình
7265,E:\DATN\dataframe\train_file\77.txt, và vùng thật
7266,E:\DATN\dataframe\train_file\77.txt, lần lượt là dự đoán về hướng và nhãn của dữ liệu.
7267,E:\DATN\dataframe\train_file\77.txt,"Trong việc huấn luyện, chúng tôi cài đặt siêu tham số"
7268,E:\DATN\dataframe\train_file\77.txt, là 5.
7269,E:\DATN\dataframe\train_file\77.txt,"Cuối cùng, tổng hàm phạt trong nhánh phát hiện đội tượng này như sau:"
7270,E:\DATN\dataframe\train_file\77.txt,L_{detect} = L_{cls} + L_{reg}
7271,E:\DATN\dataframe\train_file\77.txt,Do nhận thấy 2 hàm phạt đóng vai trò quan trọng như nhau nên chúng tôi đặt tham số cho hai hàm phạt là giống nhau.
7272,E:\DATN\dataframe\train_file\77.txt,Roi Rotate
7273,E:\DATN\dataframe\train_file\77.txt,Việc ý tưởng đề xuất một mô hình thống nhất thay vì hai mô hình riêng biệt để xử lí từng tác vụ của bài toán phát hiện và nhận dạng là rất hay.
7274,E:\DATN\dataframe\train_file\77.txt,Tuy nhiên để làm được điều này cần phải có cầu nối giữa chúng.
7275,E:\DATN\dataframe\train_file\77.txt,Phương pháp lấy mẫu đã có từ lâu trong các mô hình về phát hiện đối tượng như Faster RCNN sử dụng phương pháp lấy mẫu Roi Pooling hay Mask RCNN đã sử dụng phương pháp lấy mẫu Roi Align.
7276,E:\DATN\dataframe\train_file\77.txt,"Để tạo ra một mô hình đầu cuối phát hiện và nhận dạng, hầu hết các phương thức trước đây đều áp dụng các loại lớp lấy mẫu khác nhau, như RoI Pooling, RoI Align, RoI Rotate đóng vai trò là cầu nối giữa nhánh phát hiện văn bản và nhánh nhận dạng văn bản."
7277,E:\DATN\dataframe\train_file\77.txt,"Trong phương pháp của chúng tôi, chúng tôi thử nghiệm với cả 3 phương pháp lấy mẫu trên, và kết quả của từng phương thức được chúng tôi thể hiện ở hình 9."
7278,E:\DATN\dataframe\train_file\77.txt,"Do dữ liệu của chúng tôi có sự đa dạng bao gồm dữ liệu ảnh có biển số xe cong, nghiêng và nhiều dòng, nên việc sử dụng phương pháp lấy mẫu RoI Rotate cho kết quả tốt nhất trong 3 phương pháp trên."
7279,E:\DATN\dataframe\train_file\77.txt,"RoI Pooling chuyển đổi vùng từ ma trận đặc trưng thành một vùng có kích thước cố định thông qua phương pháp gộp lấy phần tử lớn nhất còn gọi là max-pooling, trong khi RoI Align và RoI Rotate sử dụng bộ nội suy song tuyến tính để tính toán các giá trị đầu ra."
7280,E:\DATN\dataframe\train_file\77.txt,"Bởi vì đầu ra của phương thức lấy mẫu này sẽ là dữ liệu đầu vào cho nhánh nhận dạng nên việc giữ lại thông tin đặc trưng của từng kí tự là việc rất quan trọng, việc RoI Pooling sử dụng max-pooling làm cho thông tin đặc trưng về hình dạng của các kí tự bị mất đi đáng kể."
7281,E:\DATN\dataframe\train_file\77.txt,"RoI Rotate vẫn giữ được tỉ lệ của vùng đề xuất ban đầu bằng cách cố định chiều cao của vùng đầu ra, sau đó tính chiều rộng bằng cách lấy tỉ lệ giữa chiều rộng và chiều cao của vùng ban đầu để nhân với chiều cao cố định."
7282,E:\DATN\dataframe\train_file\77.txt,"Trong cùng 1 lô dữ liệu, tăng thêm kích thước ma trận để đưa chúng về cùng kích thước."
7283,E:\DATN\dataframe\train_file\77.txt,"So với việc sử dụng nội suy song tuyến tính giống RoI Align, RoI Rotate có sử dụng việc điều chỉnh không gian ma trận và vẫn giữ được tỉ lệ giữa chiều cao và chiều rộng của bao đóng chứa văn bản."
7284,E:\DATN\dataframe\train_file\77.txt,"Do đó, RoI Rotate có thế lấy mẫu từ ma trận đặc trưng một cách tốt nhất với kiễu dữ liệu đa dạng mà vẫn giữ được đặc trưng của từng ký tự, giúp cho việc nhận dạng trở nên dễ dàng hơn rất nhiều."
7285,E:\DATN\dataframe\train_file\77.txt,RoI Rotate được chia làm hai giai đoạn.
7286,E:\DATN\dataframe\train_file\77.txt,"Đầu tiên, các tham số chuyển đổi của ma trận chuyển được tính toán thông qua tọa độ dự đoán hoặc tọa độ nhãn chứa văn bản."
7287,E:\DATN\dataframe\train_file\77.txt,"Sau đó, ma trận chuyển được áp dụng vào các ma trận đặc trưng cho từng khu vực tương ứng."
7288,E:\DATN\dataframe\train_file\77.txt,"Theo bài báo FOTS, Liu cùng với cộng sự tính toán ma trận chuyển không gian như sau:"
7289,E:\DATN\dataframe\train_file\77.txt,\begin{array}{c} t_{x}=l * \cos \theta-t * \sin \theta-x \\ t_{y}=t * \cos \theta+l * \sin \theta-y \\ s=\frac{h_{t}}{t+b} \\ w_{t}=s *(l+r) \\ M=\left[\begin{array}{ccc} \cos \theta & -\sin \theta & 0 \\ \sin \theta & \cos \theta & 0 \\ 0 & 0 & 1 \end{array}\right]\left[\begin{array}{lll} s & 0 & 0 \\ 0 & s & 0 \\ 0 & 0 & 1 \end{array}\right]\left[\begin{array}{ccc} 1 & 0 & t_{x} \\ 0 & 1 & t_{y} \\ 0 & 0 & 1 \end{array}\right] \\ =s\left[\begin{array}{ccc} \cos \theta & -\sin \theta & t_{x} \cos \theta-t_{y} \sin \theta \\ \sin \theta & \cos \theta & t_{x} \sin \theta+t_{y} \cos \theta \\ 0 & 0 & \frac{1}{s} \end{array}\right] \end{array}
7290,E:\DATN\dataframe\train_file\77.txt,=l∗cosθ−t∗sinθ−x
7291,E:\DATN\dataframe\train_file\77.txt,=t∗cosθ+l∗sinθ−y
7292,E:\DATN\dataframe\train_file\77.txt,=s∗(l+r)
7293,E:\DATN\dataframe\train_file\77.txt,−sinθ
7294,E:\DATN\dataframe\train_file\77.txt,−sinθ
7295,E:\DATN\dataframe\train_file\77.txt,cosθ−t
7296,E:\DATN\dataframe\train_file\77.txt,"Trong đó, M là ma trận chuyển không gian."
7297,E:\DATN\dataframe\train_file\77.txt, là chiều cao và chiều rộng của ma trận đặc trưng sau khi biến đổi không gian.
7298,E:\DATN\dataframe\train_file\77.txt,"(x,y biểu diễn tọa độ của điểm trên ma trận đặc trưng chia sẻ là đầu ra của Mạng chia sẻ và"
7299,E:\DATN\dataframe\train_file\77.txt,"(t,b,l,r) lần lượt là khoảng cách từ cạnh trên, dưới, trái và phải của bao đóng chứa văn bản."
7300,E:\DATN\dataframe\train_file\77.txt,θ là hướng của bao đóng.
7301,E:\DATN\dataframe\train_file\77.txt,"(t,b,l,r) và"
7302,E:\DATN\dataframe\train_file\77.txt,θ nhận được từ nhãn trong quá trình huấn luyện và nhận được từ nhánh phát hiện trong giai đoạn thử nghiệm.
7303,E:\DATN\dataframe\train_file\77.txt,"Sau khi có ma trận chuyển M, áp dụng vào để tính các đặc trưng của vùng thích nghi:"
7304,E:\DATN\dataframe\train_file\77.txt,"\begin{array}{l} \left(\begin{array}{l} x_{i}^{s} \\ y_{i}^{s} \\ 1 \end{array}\right)=\mathbf{M}^{-1}\left(\begin{array}{l} x_{i}^{t} \\ y_{i}^{t} \\ 1 \end{array}\right) \\ \text { và } \forall i \in\left[1 \ldots h_{t}\right], \forall j \in\left[1 \ldots w_{t}\right], \forall c \in[1 \ldots C], \\ V_{i j}^{c}=\sum_{n}^{h_{s}} \sum_{m}^{w_{s}} U_{n m}^{c} k\left(x_{i j}^{s}-m ; \Phi_{x}\right) k\left(y_{i j}^{s}-n ; \Phi_{y}\right) \end{array}"
7305,E:\DATN\dataframe\train_file\77.txt,−1
7306,E:\DATN\dataframe\train_file\77.txt, ∀i∈[1…h
7307,E:\DATN\dataframe\train_file\77.txt,"],∀j∈[1…w"
7308,E:\DATN\dataframe\train_file\77.txt,"],∀c∈[1…C],"
7309,E:\DATN\dataframe\train_file\77.txt,−m;Φ
7310,E:\DATN\dataframe\train_file\77.txt,−n;Φ
7311,E:\DATN\dataframe\train_file\77.txt,Trong đó
7312,E:\DATN\dataframe\train_file\77.txt, là giá trị đầu ra của vị trí
7313,E:\DATN\dataframe\train_file\77.txt,"(i,j) trong kênh"
7314,E:\DATN\dataframe\train_file\77.txt,c và
7315,E:\DATN\dataframe\train_file\77.txt, là giá trị đầu vào tại vị trí
7316,E:\DATN\dataframe\train_file\77.txt,"(n,m) của kênh"
7317,E:\DATN\dataframe\train_file\77.txt," biễu diễn chiều cao và rộng của đầu vào, và"
7318,E:\DATN\dataframe\train_file\77.txt, là các tham số của bộ lọc mẫu k() dùng để xác định phương pháp nội suy song tuyến.
7319,E:\DATN\dataframe\train_file\77.txt,"Khác với phân loại đối tượng, nhận dạng văn bản rất nhạy cảm với nhiễu phát hiện."
7320,E:\DATN\dataframe\train_file\77.txt,"Một lỗi nhỏ trong vùng văn bản được dự đoán có thể cắt bỏ một số ký tự, điều này có hại cho việc đào tạo mạng, vì vậy chúng tôi sử dụng tọa độ bao đóng văn bản nhãn thay vì tạo độ bao đón chứa văn bản được dự đoán trong quá trình đào tạo."
7321,E:\DATN\dataframe\train_file\77.txt,"Khi thử nghiệm, ngưỡng và NMS được áp dụng để lọc các vùng văn bản được dự đoán."
7322,E:\DATN\dataframe\train_file\77.txt,"Sau khi RoI Rotate, các bản đồ đối tượng được chuyển đổi sẽ được đưa đến nhánh nhận dạng văn bản."
7323,E:\DATN\dataframe\train_file\77.txt,Mã hóa vị trí hai chiều
7324,E:\DATN\dataframe\train_file\77.txt,"Trong kiến trúc Transformer, mã hóa vị trí (Positional Encoding - PE) được định nghĩa là một phương thức làm cho mô hình có thể tính toán theo thứ tự ."
7325,E:\DATN\dataframe\train_file\77.txt,"PE có thể giữ đươc thông tin về mối quan hệ về vị trí giữa các mã hóa trong dãy, từ đó khi đưa vào mô hình Transformer nó có thêm thông tin về vị trí, sư tương quan lẫn nhau giữa các mã hóa trong dãy, giúp cho việc dự đoán trở nên tốt hơn."
7326,E:\DATN\dataframe\train_file\77.txt,"Trong bài toán OCR, Transformer thường sẽ được kết hợp cùng với mạng trích xuất đặc trưng CNN."
7327,E:\DATN\dataframe\train_file\77.txt,PE đóng vai trò quan trọng là cầu nối giữa CNN và Transformer.
7328,E:\DATN\dataframe\train_file\77.txt,"Ban đầu, PE được thiết kế để nhúng các giá trị vị trí thành 1 ma trận đặc trưng 1 chiều, tuy nhiên, điều này làm cho mô hình chỉ chú ý vào dãy tuần tự từ trái sang phải và nó không phù hợp với dữ liệu nhiều dòng."
7329,E:\DATN\dataframe\train_file\77.txt,"Lấy cảm hứng từ ý tưởng được đưa ra trong bài báo On Recognizing Texts of Arbitrary Shapes with 2D Self-Attention , chúng tôi áp dụng kỹ thuật mã hóa vị trí hai chiều (2D Positional Encoding - 2DPE) vào trong nhánh nhận dạng của mô hình."
7330,E:\DATN\dataframe\train_file\77.txt,Trong khi PE làm mất đi thông tin vị trí theo chiều dọc của ảnh thì 2DPE có thể giải quyết được vấn đề này bằng cách cho mô hình chú ý là cả chiều dọc và chiều ngang của ảnh.
7331,E:\DATN\dataframe\train_file\77.txt,Điều này làm cho mô hình có thể chú ý trên từng dòng của và từ trái qua phải.
7332,E:\DATN\dataframe\train_file\77.txt,"Do vậy, nhánh nhận dạng có thể học dữ liệu cong, xiêng, nhiều dòng mà không cần xoay ảnh."
7333,E:\DATN\dataframe\train_file\77.txt,Giả sử rằng chúng ta có một ma trận đặc trưng hai chiều được sinh ra bởi Mạng chia sẻ.
7334,E:\DATN\dataframe\train_file\77.txt,Đặt nó là ma trận
7335,E:\DATN\dataframe\train_file\77.txt,S và có chiều
7336,E:\DATN\dataframe\train_file\77.txt,"(N,64,H/4,W/4), trong đó"
7337,E:\DATN\dataframe\train_file\77.txt,"N là kích thước của 1 lô dữ liệu,"
7338,E:\DATN\dataframe\train_file\77.txt,H và
7339,E:\DATN\dataframe\train_file\77.txt,W lần lượt là chiều cao và chiều rộng của dữ liệu ảnh đầu vào.
7340,E:\DATN\dataframe\train_file\77.txt,Cho rằng
7341,E:\DATN\dataframe\train_file\77.txt,"w=W/4, chúng ta có ma trận"
7342,E:\DATN\dataframe\train_file\77.txt,S được xem là
7343,E:\DATN\dataframe\train_file\77.txt,Khi đó cơ chế tự chú ý được tính toán như sau:
7344,E:\DATN\dataframe\train_file\77.txt,\text{Attention}_{hw} = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
7345,E:\DATN\dataframe\train_file\77.txt,Trong đó
7346,E:\DATN\dataframe\train_file\77.txt, là trọng số tuyến tính của mô hình.
7347,E:\DATN\dataframe\train_file\77.txt, là trọng số thể hiện hệ số chú ý của ma trận đặc trưng khi
7348,E:\DATN\dataframe\train_file\77.txt,"(h,w), trong khi ma trận truy vấn đặc trưng có kích thước"
7349,E:\DATN\dataframe\train_file\77.txt,"), trong cơ chế tự chú ý thì"
7350,E:\DATN\dataframe\train_file\77.txt,Mã hóa vị trí hai chiều 2DPE được biểu diễn như sau:
7351,E:\DATN\dataframe\train_file\77.txt,\text{attn\_weight} = QK^T = p_{hw}W^qW^{k^T}p_{h'w'}
7352,E:\DATN\dataframe\train_file\77.txt,p_{hw} = \alpha(S)p_h^{sinu}+\beta(S)p_w^{sinu}
7353,E:\DATN\dataframe\train_file\77.txt,p_{h'w'} = \alpha(S)p_h'^{sinu}+\beta(S)p_w'^{sinu}
7354,E:\DATN\dataframe\train_file\77.txt,′sinu
7355,E:\DATN\dataframe\train_file\77.txt,′sinu
7356,E:\DATN\dataframe\train_file\77.txt,"Trong đó,"
7357,E:\DATN\dataframe\train_file\77.txt, là các mã hóa vị trí theo chiều cao và chiều rộng có dạng hình sin :
7358,E:\DATN\dataframe\train_file\77.txt,"p_{p,2i}^{sinu} = \text{sin}(p/10000^{2i/D})"
7359,E:\DATN\dataframe\train_file\77.txt,2i/D
7360,E:\DATN\dataframe\train_file\77.txt,"p_{p,2i+1}^{sinu} = \text{cos}(p/10000^{2i/D})"
7361,E:\DATN\dataframe\train_file\77.txt,2i/D
7362,E:\DATN\dataframe\train_file\77.txt,"Ở đây,"
7363,E:\DATN\dataframe\train_file\77.txt,p và
7364,E:\DATN\dataframe\train_file\77.txt,i chỉ số vị trí trong dãy và số chiều.
7365,E:\DATN\dataframe\train_file\77.txt,"Các hệ số tỷ lệ,"
7366,E:\DATN\dataframe\train_file\77.txt,α(S) và
7367,E:\DATN\dataframe\train_file\77.txt,"β(S), được tính toán từ ma trận đặc trưng đầu vào \textbf{S} với hai lớp tích chập được áp dụng vào tính năng trung bình toàn cục như sau:"
7368,E:\DATN\dataframe\train_file\77.txt,"\alpha(S) = \text{sigmoid}(\text{max}(0,g(S)W_1^h)W_2^h)"
7369,E:\DATN\dataframe\train_file\77.txt,"\beta(S) = \text{sigmoid}(\text{max}(0,g(S)W_1^w)W_2^w)"
7370,E:\DATN\dataframe\train_file\77.txt,"Trong đó,"
7371,E:\DATN\dataframe\train_file\77.txt, là trọng số tuyến tính của mô hình.
7372,E:\DATN\dataframe\train_file\77.txt,g(S) chỉ ra một hình thức gộp trung bình trên tất cả các tính năng của
7373,E:\DATN\dataframe\train_file\77.txt,S. Đầu ra được cho qua hàm kích hoạt sigmoid.
7374,E:\DATN\dataframe\train_file\77.txt,A(S) và
7375,E:\DATN\dataframe\train_file\77.txt,β(S) đã xác định ảnh hưởng trực tiếp đến mã hóa vị trí chiều rộng và chiều cao để kiểm soát tỷ lệ tương ứng giữa trục dọc và trục ngang để duy trì sự đa dạng về không gian.
7376,E:\DATN\dataframe\train_file\77.txt,"Theo đó, 2DPE cho phép mô hình phản ánh một cách thích ứng sự liền kề của chiều rộng và chiều cao khi tính toán trọng lượng của sự chú ý bằng cách sử dụng"
7377,E:\DATN\dataframe\train_file\77.txt,α và
7378,E:\DATN\dataframe\train_file\77.txt,Nhánh nhận dạng
7379,E:\DATN\dataframe\train_file\77.txt,Chúng tôi sử dụng một kiến trúc mạng CNN nông đóng vai trò là thành phần để trích xuất tính năng và kiến trúc Transformer làm mô-đun bộ mã hóa và giải mã trong nhánh nhận dạng.
7380,E:\DATN\dataframe\train_file\77.txt,"Vì Mạng chia sẻ đóng một vai trò quan trọng trong trình trích xuất tính năng, chúng tôi chỉ cần chọn một kiến trúc CNN nông, cấu trúc được mô tả trong hình 6."
7381,E:\DATN\dataframe\train_file\77.txt,Lựa chọn một mạng CNN nông là vừa không làm cho mô hình trở nên quá công kềnh và giảm sự tính toán không cần thiết.
7382,E:\DATN\dataframe\train_file\77.txt,Hình 6: Kiến trúc nhánh nhận dạng
7383,E:\DATN\dataframe\train_file\77.txt,"Sau khi đưa ma trận đặc trưng và tọa độ bao đóng dự đoán được ở phần phát hiện đối tượng vào phương thức lấy mẫu, sau đó đưa qua một mạng CNN nông ta thu được một tensor"
7384,E:\DATN\dataframe\train_file\77.txt,"R(N, 128, H'/2, W')"
7385,E:\DATN\dataframe\train_file\77.txt,"Trong thí nghiệm của chúng tôi, chúng tôi lựa chọn chiều cao"
7386,E:\DATN\dataframe\train_file\77.txt,H' = 8
7387,E:\DATN\dataframe\train_file\77.txt,"=8, trong đó chiều rộng phụ thuộc vào từng lô dữ liệu."
7388,E:\DATN\dataframe\train_file\77.txt,"R đi qua mã hóa vị trí không gian hai chiều (2DPE), thu được"
7389,E:\DATN\dataframe\train_file\77.txt,"X(N, 128, H'/2*W')"
7390,E:\DATN\dataframe\train_file\77.txt,/2∗W
7391,E:\DATN\dataframe\train_file\77.txt,Mô-đun Transformer lấy
7392,E:\DATN\dataframe\train_file\77.txt,"X là đầu vào của mô hình mã hóa, trong đó"
7393,E:\DATN\dataframe\train_file\77.txt,) cùng với đầu ra của mô hình mã hóa là đầu vào của mô hình giải mã.
7394,E:\DATN\dataframe\train_file\77.txt,Trong đó
7395,E:\DATN\dataframe\train_file\77.txt,"T là tổng số lượng ký tự trong văn bản,"
7396,E:\DATN\dataframe\train_file\77.txt, là vị trí tương ứng của kí từ trong tập từ điển.
7397,E:\DATN\dataframe\train_file\77.txt,"Để giúp mô hình chống hiện tượng học quá khớp, chúng tôi sử dụng kỹ thuật làm mượt nhãn cho hàm phạt, việc sử dụng kĩ thuật này làm cho mô hình học tốt và đạt kết quả cao hơn do chống được hiện tượng học quá khớp."
7398,E:\DATN\dataframe\train_file\77.txt,"Việc sử dụng kĩ thuật làm mượt nhãn, chúng tôi thay thể véc-tơ mã hóa one-hot"
7399,E:\DATN\dataframe\train_file\77.txt, với việc kết hợp
7400,E:\DATN\dataframe\train_file\77.txt, và phân phối đều như sau:
7401,E:\DATN\dataframe\train_file\77.txt,y_{ls} = (1-\gamma)y_{hot} + \frac{\gamma}{K}
7402,E:\DATN\dataframe\train_file\77.txt,=(1−γ)y
7403,E:\DATN\dataframe\train_file\77.txt,Trong đó
7404,E:\DATN\dataframe\train_file\77.txt,K là số lượng nhãn và
7405,E:\DATN\dataframe\train_file\77.txt,γ là siêu tham số để xác định lượng mà muốn làm mượt nhãn.
7406,E:\DATN\dataframe\train_file\77.txt,Hàm phạt của nhánh nhận dạng được viết như sau:
7407,E:\DATN\dataframe\train_file\77.txt,"L_{recog} = \frac{1}{N}\sum^NH(p_{ls},q_{pred})"
7408,E:\DATN\dataframe\train_file\77.txt,= -\frac{1}{N}\sum^N((1-\gamma)y_{hot} + \frac{\gamma}{k})log(q_{pred})
7409,E:\DATN\dataframe\train_file\77.txt,((1−γ)y
7410,E:\DATN\dataframe\train_file\77.txt,Trong đó
7411,E:\DATN\dataframe\train_file\77.txt, được tính bởi hàm kích hoạt softmax:
7412,E:\DATN\dataframe\train_file\77.txt,q_{pred} = \frac{exp(z_i)}{\sum_{j=1}^Kexp(z_j)}
7413,E:\DATN\dataframe\train_file\77.txt, là giá trị tương ứng của lớp
7414,E:\DATN\dataframe\train_file\77.txt,"i. Kết hợp hàm phạt của nhánh phát hiện, hàm phạt cuối cùng của mô hình như sau:"
7415,E:\DATN\dataframe\train_file\77.txt,L = L_{detect}+L_{recog}
7416,E:\DATN\dataframe\train_file\77.txt,Kết quả áp dụng mô hình vào bài toán phát hiện và nhận dạng biển số xe Việt Nam trên
7417,E:\DATN\dataframe\train_file\77.txt,Hình 7: hình ảnh dữ liệu biển số xe Việt Nam
7418,E:\DATN\dataframe\train_file\77.txt,Hình 8: Biểu đồ thay đổi giá trị hàm mất mát trong quá trình huấn luyện
7419,E:\DATN\dataframe\train_file\77.txt,Hình 9: Kết quả thực nghiệm trên bộ dữ liệu tính theo độ đô cuộc thi phát hiện và nhận dạng văn bản IC
7420,E:\DATN\dataframe\train_file\77.txt,Hình 10: Kết quả so sánh tốc dộ dự đoán giữa mô hình 1 pha mà sử dụng 2 mô hình riêng biệt
7421,E:\DATN\dataframe\train_file\77.txt,Hình 11: Một số trường hợp dự đoán của mô hình
7422,E:\DATN\dataframe\train_file\77.txt,Mô hình là 1 sự kết hợp của một số kĩ thuật đã có hiện nay để giải quyết đồng thời 2 bài toán đó là phát hiện và nhận dạng biển số xe nhiều dòng.
7423,E:\DATN\dataframe\train_file\77.txt,"Mô hình có khả năng huấn luyện và dự đoán đồng thời 2 tác vụ trên, ngoài ra mô hình còn giúp tăng đáng kể thời gian dự đoán so với việc sử dụng 2 mô hình riêng biệt."
7424,E:\DATN\dataframe\train_file\77.txt,Bài viết này của mình đưa ra mô hướng tiếp cận mới cho bài toán phát hiện và nhận dạng biển số xe nhiều dòng tại Việt Nam.
7425,E:\DATN\dataframe\train_file\77.txt,"Nếu thấy bài viết bổ ích thì chần chờ gì nữa mà không upvote cho mình nhé, cảm ơn các bạn"
7426,E:\DATN\dataframe\train_file\78.txt,Self-Attention Text Recognition Network
7427,E:\DATN\dataframe\train_file\78.txt,"Scene Text Recognition (STR) là một bài toán khó, đặc biệt khi Text trong ảnh không có hình dạng nhất định."
7428,E:\DATN\dataframe\train_file\78.txt,"Một phương pháp thú vị giới thiệu bởi các tác giả đến từ team Clova AI Research, NAVER."
7429,E:\DATN\dataframe\train_file\78.txt,"Trong paper này, Self-Attention Text Recognition Network (SATRN) được nghiên cứu và thực nghiệm nhằm giải quyết các bài toán Scene text recognition."
7430,E:\DATN\dataframe\train_file\78.txt,"Với bài toán Scene Text Recognition, có hai hướng tiếp cận phổ biến: chuẩn hóa ảnh đầu vào (input rectification) và sử dụng 2D feature maps."
7431,E:\DATN\dataframe\train_file\78.txt,Phương pháp đầu tiên thường sử dụng mạng Spatial Transformer Networks (STN - các bạn có thể tham khảo thêm .
7432,E:\DATN\dataframe\train_file\78.txt,Tuy nhiên các quá trình áp dụng thực tế cho thấy vẫn tồn tại một nhược điểm lớn đó là chất lượng bị phụ thuộc vào khả năng transform chuẩn hóa ảnh đầu vào (đặc biệt các trường hợp khó như ảnh text dọc)
7433,E:\DATN\dataframe\train_file\78.txt,Phương pháp thứ 2 hướng tới việc sử dụng feature map 2D của ảnh đầu vào mà không ảnh hưởng đến hình dạng của ảnh.
7434,E:\DATN\dataframe\train_file\78.txt,"Tuy nhiên các nghiên cứu trước đây theo hướng này tương đối phức tạp (AON), đòi hỏi bouding box của ký tự (ATR), và bị phụ thuộc và các mô hình CNN như ResNet để trích xuất các feature map."
7435,E:\DATN\dataframe\train_file\78.txt,"Một vấn đề khác do việc sử dụng RNN/LSTM và cùng height pooling dẫn tới việc không tận dụng được các thông tin về không gian (spatial dependency/information) giữa các ký tự trong ảnh, một vấn đề nan giải trong các bài toán STR."
7436,E:\DATN\dataframe\train_file\78.txt,"Mạng SATR tối ưu cơ chế self-attention với mục đích thu được các feature về không gian, 2D feature map ảnh text scene."
7437,E:\DATN\dataframe\train_file\78.txt,"Lấy ý tưởng trên mô hình Transformer, kiến trúc rất nổ trong các bài toán NLP và CV gần đây."
7438,E:\DATN\dataframe\train_file\78.txt,Phương pháp của tác giả cũng bao gồm kiến trúc encoder-decoder nhằm giải quyết vấn đề representation giữa ảnh và text.
7439,E:\DATN\dataframe\train_file\78.txt,Ý tưởng chính
7440,E:\DATN\dataframe\train_file\78.txt,"Giống như Transformer, kiến trúc tổng quát của mạng SATRN bao gồm encoder (bộ mã hóa) - cột trái, với mục đích embedding ảnh thành 2D feature map và decoder (bộ giải mã) giúp trích xuất chuỗi ký tự từ feature map."
7441,E:\DATN\dataframe\train_file\78.txt,Hãy cùng đi sâu vào kiến trúc phần Encoder.
7442,E:\DATN\dataframe\train_file\78.txt,Encoder sẽ đưa ảnh qua khối Shallow CNN nhằm lấy được local pattern và texture.
7443,E:\DATN\dataframe\train_file\78.txt,Feature map trích xuất sẽ được đưa qua module self-attention cùng với Adaptive 2D positional encoding.
7444,E:\DATN\dataframe\train_file\78.txt,"Khác với Transformer, tác giả đã thay pointwise feed forward bằng locality-aware feed forward layer."
7445,E:\DATN\dataframe\train_file\78.txt,Shallow CNN block
7446,E:\DATN\dataframe\train_file\78.txt,Shallow CNN có mục đích trích xuất các patern low lever cùng với texture của bức ảnh.
7447,E:\DATN\dataframe\train_file\78.txt,"Không như dữ liệu text, một bức ảnh đòi hỏi mức trích xuất trên nhiều mức độ khác nhau (ví dụ background texture)."
7448,E:\DATN\dataframe\train_file\78.txt,Chính vì vậy việc bằng cách thêm một lớp CNN Shallow sẽ giảm được mức độ tính toán so với việc áp dụng trực tiếp self-attention block.
7449,E:\DATN\dataframe\train_file\78.txt,"Block CNN được sử dụng khá cơ bản chỉ bao gồm 2 lớp convolution với 3x3 kernel, với 2 lớp max pooling 2x2 stride 2."
7450,E:\DATN\dataframe\train_file\78.txt,Adaptive 2D positional encoding
7451,E:\DATN\dataframe\train_file\78.txt,Feature map ở bước trước sẽ được đưa qua block self-attention.
7452,E:\DATN\dataframe\train_file\78.txt,"Trong kiến trúc Transformer, các thông tin về vị trí được thêm bởi positional encoding (PE) vector để tạo thành chuỗi feature map 1 chiều."
7453,E:\DATN\dataframe\train_file\78.txt,"Tuy nhiên, việc này trở nên bất khả thi trong việc lưu trữ các đặc tính về không gian (giống như lớp fully-connected)."
7454,E:\DATN\dataframe\train_file\78.txt,Và chính các thông tin này khiến mô hình khó có thể rút ra các thông tin dạng chuỗi.
7455,E:\DATN\dataframe\train_file\78.txt,Nhóm tác giả đề xuất Adaptive 2D positional Encoding (2DPE) nhằm xác định được PE cả chiều lẫn chiều ngang của ảnh đầu vào.
7456,E:\DATN\dataframe\train_file\78.txt,E là 2D feature map và
7457,E:\DATN\dataframe\train_file\78.txt, là vị trí tương ứng
7458,E:\DATN\dataframe\train_file\78.txt,Self-attion không có PE được giới thiệu như sau
7459,E:\DATN\dataframe\train_file\78.txt,\textbf{att-out}_{hw} = \sum_{h' w'} \text{softmax} (\text{rel}_{(h' w') \rightarrow (h' w')}) \textbf{v}_{h' w'}
7460,E:\DATN\dataframe\train_file\78.txt,)→(h
7461,E:\DATN\dataframe\train_file\78.txt,Trong đó
7462,E:\DATN\dataframe\train_file\78.txt,\textbf{v}_{hw} = \textbf{e}_{hw} W^{v}
7463,E:\DATN\dataframe\train_file\78.txt,rel_{(h' w') \rightarrow (h' w')} \propto \textbf{e}_{hw} W^{q} W^{k^T} \textbf{e}_{h'w'}^T
7464,E:\DATN\dataframe\train_file\78.txt,)→(h
7465,E:\DATN\dataframe\train_file\78.txt,∝e
7466,E:\DATN\dataframe\train_file\78.txt, lần lượt là các trọng số map đầu vào cuar queries
7467,E:\DATN\dataframe\train_file\78.txt,q_{hw} = e_{hw}W_q
7468,E:\DATN\dataframe\train_file\78.txt, và keys
7469,E:\DATN\dataframe\train_file\78.txt,k_{hw} = e_{hw} W_k
7470,E:\DATN\dataframe\train_file\78.txt,Hay nói cách khác
7471,E:\DATN\dataframe\train_file\78.txt,rel_{(h' w') \rightarrow (h' w')}
7472,E:\DATN\dataframe\train_file\78.txt,)→(h
7473,E:\DATN\dataframe\train_file\78.txt, biểu diễn trọng số attention của feature tại
7474,E:\DATN\dataframe\train_file\78.txt,"(h,w) với query feature là"
7475,E:\DATN\dataframe\train_file\78.txt,"\textbf{p}_{h, w}"
7476,E:\DATN\dataframe\train_file\78.txt, có thể được biểu diễn như sau
7477,E:\DATN\dataframe\train_file\78.txt,\text{rel}_{(h' w') \rightarrow (h' w')} \propto (\textbf{e}_{hw}+\textbf{p}_{h w}) W^{q} W^{k^T} \textbf{e}_{h'w'}^T (\textbf{e}_{h' w'} + \textbf{p}_{h' w'})^T
7478,E:\DATN\dataframe\train_file\78.txt,)→(h
7479,E:\DATN\dataframe\train_file\78.txt,∝(e
7480,E:\DATN\dataframe\train_file\78.txt,trong đó
7481,E:\DATN\dataframe\train_file\78.txt,\textbf{p}_{h w} = \alpha(\textbf{E})\textbf{p}_h^{sinu}+\beta(\textbf{E})\textbf{p}_w^{sinu}
7482,E:\DATN\dataframe\train_file\78.txt,"\textbf{p}_{p,2i}^{sinu} = sin(p/10000^{2i/D})"
7483,E:\DATN\dataframe\train_file\78.txt,2i/D
7484,E:\DATN\dataframe\train_file\78.txt,"\textbf{p}_{p,2i+1}^{sinu} = cos(p/10000^{2i/D})"
7485,E:\DATN\dataframe\train_file\78.txt,2i/D
7486,E:\DATN\dataframe\train_file\78.txt,i lần lượt là index của vị trí và chiều hidden
7487,E:\DATN\dataframe\train_file\78.txt,"\alpha(\text{E}) = sigmoid(max(0, g(E)W_1^h)W_2^h"
7488,E:\DATN\dataframe\train_file\78.txt,"\beta(\text{E}) = sigmoid(max(0, g(E)W_1^h)W_2^h"
7489,E:\DATN\dataframe\train_file\78.txt,"So sánh mô hình với các lớp PE khác nhau trên tập CUTE80 (tập dữ liệu chứa nhiều ảnh text cong và hình dạng phức tạp), kết quả cho thấy A2DPE có độ chính xác cao nhất trong 4 lựa chọn."
7490,E:\DATN\dataframe\train_file\78.txt,Locality-aware feedforward layer
7491,E:\DATN\dataframe\train_file\78.txt,Self-attention cực kỳ hữu ích trong việc lưu trữ bộ nhớ long-term và shor-term trong 2D feature map.
7492,E:\DATN\dataframe\train_file\78.txt,Tuy nhiên việc chồng nhiều lớp self-attention chỉ để lữu trữ thuộc tính short-term là điều không thực sự cần thiết.
7493,E:\DATN\dataframe\train_file\78.txt,"Chính vì vậy, nhóm tác giả đã thay lớp point-wise feedforward (1x1 Conv) (a) bằng Conv (b) cùng Depthwise (c)."
7494,E:\DATN\dataframe\train_file\78.txt,Phần decoder có nhiệm vụ lấy cách 2D feature từ encode và mapping thành chuỗi ký tự.
7495,E:\DATN\dataframe\train_file\78.txt,Việc chuyển hóa giữa ảnh và text diễn ra tại module multi-head attention thứ 2.
7496,E:\DATN\dataframe\train_file\78.txt,Model này lấy đặc trưng của ký tự hiện tại để tìm được ký tự tiếp theo trên 2D feature map.
7497,E:\DATN\dataframe\train_file\78.txt,Nhìn chung phần kiến trúc này không có nhiều khác biệt với decoder Transformer.
7498,E:\DATN\dataframe\train_file\78.txt,Kết quả được đánh giá trên 7 test dataset khác nhau bao gồm dữ liệu dễ (regular) và khó (irregular - gồm hình dạng không cố định)
7499,E:\DATN\dataframe\train_file\78.txt,SATRN cho kết quả tốt hơn 4 phương pháp sử dụng 2D feature map khác.
7500,E:\DATN\dataframe\train_file\78.txt,"Trên các bộ dữ liệu khó (IC15, SVTP, CT80), SATRN thâm chí còn vượt xa phương pháp tốt nhất trước đó ESIR với xấp xỉ 4.5pp."
7501,E:\DATN\dataframe\train_file\78.txt,"Để đánh giá hiệu quả giữa self-attention / convolution trong encoder, self-attention / LSTM trong decoder, nhóm tác giả đã so sánh cụ thể hơn 2 mô hình SATRN và SAR."
7502,E:\DATN\dataframe\train_file\78.txt,Độ cân bằng giữa chính xác - hiệu quả
7503,E:\DATN\dataframe\train_file\78.txt,Bảng trên so sánh độ chính xác và hiệu quả (số lượng params và FLOPs) giữa các loại encoder và decoder khác nhau.
7504,E:\DATN\dataframe\train_file\78.txt,"Sử dụng SATRN (2D) ecoder có kết quả nhỉnh hơn ResNet encoder, và kết quả cũng tương tự khi thay LSTM decoder bằng SATRN trong khi cải thiện được hiệu quả về bộ nhớ cũng như hiệu năng (giảm 12 triệu params và 5.5 FLOPs)."
7505,E:\DATN\dataframe\train_file\78.txt,"Kết quả này cho thấy encoder dựa trên self-attention có thể trích xuất nhiều thông tin feature maps từ ảnh hơn so với ResNet thông thường, đồng thời giảm được lượng tham số và chỉ số FLOPS."
7506,E:\DATN\dataframe\train_file\78.txt,Phần decoder giữ nguyên cấu trúc của Transformer cũng cho accuracy cao hơn 0.3pp tuy nhiên lại tốn nhiều bộ nhớ và hiệu năng thấp hơn (tăng 11M params và 19.5 FLOPs).
7507,E:\DATN\dataframe\train_file\78.txt,Hình 5 cho thấy việc sử dụng lớp self-attention cho khả năng trade-off giữa độ chính xác và hiệu quả tốt hơn.
7508,E:\DATN\dataframe\train_file\78.txt,So sánh Định tính
7509,E:\DATN\dataframe\train_file\78.txt,Self Attention map của ký tự tương ứng với ROI
7510,E:\DATN\dataframe\train_file\78.txt,"Tác giả công nhận rằng với ký tự 'M', lớp self-attention sẽ tiếp nhận được ký tự 'A' là tiếp theo."
7511,E:\DATN\dataframe\train_file\78.txt,"SA ở lớp 2 (depth 2) đã chuyển 'sự chú ý' đến ký tự tiếp theo, tận dụng được khả năng tính toán liên kết xa (long-range connection) của self-attention."
7512,E:\DATN\dataframe\train_file\78.txt,"Cũng nhờ lý do này, SATRN có khả năng đạt hiệu năng tốt cũng như lược bỏ các đặc trưng không cần thiết lặp lại (do convolutional encoder)."
7513,E:\DATN\dataframe\train_file\78.txt,"Ngoài ra, bằng việc điều chỉnh động vector encoding"
7514,E:\DATN\dataframe\train_file\78.txt,r = ||\alpha(E)||_{1} / ||\beta(E)||_{1}
7515,E:\DATN\dataframe\train_file\78.txt,r=∣∣α(E)∣∣
7516,E:\DATN\dataframe\train_file\78.txt,/∣∣β(E)∣∣
7517,E:\DATN\dataframe\train_file\78.txt," hay tỉ lệ encoding chiều cao với encoding chiều dọc (nôm na là dùng để phân loại dạng text), A2DPE có thể giảm được gánh nặng tính toán cho các module khác."
7518,E:\DATN\dataframe\train_file\78.txt,Một ví dụ khác: 2D attention maps với dạng text nhiều dòng
7519,E:\DATN\dataframe\train_file\78.txt,Đây là phương pháp tiếp cận khá thú vị với tận dụng 2D feature map cùng cơ chế self-attention.
7520,E:\DATN\dataframe\train_file\78.txt,"Bằng cách này, nhóm giả đã có thể giải quyết được một phần vấn đề với hình ảnh text dạng không cố định."
7521,E:\DATN\dataframe\train_file\78.txt,"Tại thời điểm publish paper này, mô hình đạt SOTA trong bài toán nhận diện text dạng khó"
7522,E:\DATN\dataframe\train_file\78.txt,"Cảm ơn các bạn đã đọc, nếu hay thì xin hãy upvote hoặc xem lại lần nữa =))"
7523,E:\DATN\dataframe\train_file\78.txt,[1] SATRN -
7524,E:\DATN\dataframe\train_file\78.txt,[3] SAR -
7525,E:\DATN\dataframe\train_file\78.txt,[4] STN -
7526,E:\DATN\dataframe\train_file\78.txt,[5] Một vài bài viết liên quan 
7527,E:\DATN\dataframe\train_file\79.txt,Gradient Boosting - Tất tần tật về thuật toán mạnh mẽ nhất trong Machine Learning
7528,E:\DATN\dataframe\train_file\79.txt,"Xin chào các bạn, sau 1 thời gian vắng bóng vì cạn ý tưởng viết bài và cũng cảm thấy bản thân chưa làm được điều gì nên hồn để chia sẻ, mình đã quay trở lại với Viblo để viết về một chủ đề không mới, về một thuật toán không mới, tuy nhiên không phải ai cũng hoàn toàn hiểu được và vận dụng được nó : Gradient Boosting."
7529,E:\DATN\dataframe\train_file\79.txt,Ý tưởng để gợi lên mình viết bài viết này có lẽ bắt nguồn từ bài viết  của tác giả Phạm Minh Hoàng.
7530,E:\DATN\dataframe\train_file\79.txt,"Đây là một bài viết khá hay và phần giải thích dễ hiểu về các thuật toán ensemble, tuy nhiên có 1 điều khá đáng tiếc là sau hơn 1 năm chờ đợi, tác giả đã viết rất nhiều bài viết chất lượng khác, nhưng tuyệt nhiên lại không có bài viết nào liên quan đến ""Ensemble learning và các biến thể (P2)"", làm các fan comment chờ đợi trong vô vọng."
7531,E:\DATN\dataframe\train_file\79.txt,"Thế nên là ""Tự túc là hạnh phúc"", hôm nay mình viết bài này, xin phép nối tiếp nội dung mà tác giả đang chia sẻ dở, một bài viết về thuật toán Ensemble tiếp theo, sau Bagging, chính là về Boosting."
7532,E:\DATN\dataframe\train_file\79.txt,"Các bạn có thể gọi bài viết này với một tiêu đề khác là ""Ensemble learning và các biến thể (P2)"" cũng được"
7533,E:\DATN\dataframe\train_file\79.txt,"Oke, bắt đầu vào nội dung chính của bài viết nào !"
7534,E:\DATN\dataframe\train_file\79.txt,Nhắc lại 1 chút về Ensemble Methods
7535,E:\DATN\dataframe\train_file\79.txt,"Ensemble Method hay gọi một cách Việt hóa là Học Kết Hợp, là một phương pháp với tư tưởng là Thay vì cố gắng xây dựng một mô hình tốt duy nhất, chúng ta sẽ xây dựng một họ các mô hình yếu hơn một chút, nhưng khi kết hợp các mô hình lại, (nếu có thể kết hợp một cách chính xác) sẽ thu được một mô hình còn vượt trội hơn cả."
7536,E:\DATN\dataframe\train_file\79.txt,1.1 Single weak learner
7537,E:\DATN\dataframe\train_file\79.txt,"Nếu tiếp xúc đủ lâu với Machine Learning, các bạn chắc hẳn đều đã biết đến những giải thuật, những mô hình kinh điển trong lĩnh vực này :"
7538,E:\DATN\dataframe\train_file\79.txt,Linear Discriminant Analysis
7539,E:\DATN\dataframe\train_file\79.txt,Decision Trees
7540,E:\DATN\dataframe\train_file\79.txt,Neural Networks
7541,E:\DATN\dataframe\train_file\79.txt,Na ̈ıve Bayes Classifier
7542,E:\DATN\dataframe\train_file\79.txt,k-Nearest Neighbor
7543,E:\DATN\dataframe\train_file\79.txt,Support Vector Machines and Kernel Methods
7544,E:\DATN\dataframe\train_file\79.txt,"Khi gặp một bài toán bất kì, dù là phân lớp (classification) hay hồi quy (regression) thì việc chọn ra một mô hình đủ tốt luôn là một quyết định quan trọng và khó khăn nhất."
7545,E:\DATN\dataframe\train_file\79.txt,"Khác với Deep Learning, việc tìm ra mô hình tốt là việc cố gắng thay đổi số layer hay thay đổi cấu trúc mạng, ở Machine Learning, việc lựa chọn mô hình là việc tối ưu tham số, quan sát các đặc điểm về số chiều của không gian dữ liệu, đặt ra các giả thiết về phân phối dữ liệu, ..."
7546,E:\DATN\dataframe\train_file\79.txt,Có thể mô tả một quá trình giải quyết bài toán machine learning như sau :
7547,E:\DATN\dataframe\train_file\79.txt,Phân tích dữ liệu
7548,E:\DATN\dataframe\train_file\79.txt,"Thử các mô hình (thử có định hướng sau khi giả định về tính chất dữ liệu, hoặc thử tất cả các phương pháp có thể)"
7549,E:\DATN\dataframe\train_file\79.txt,Finetune lại mô hình để tìm ra các tham số tốt nhất
7550,E:\DATN\dataframe\train_file\79.txt,Đánh giá kết quả
7551,E:\DATN\dataframe\train_file\79.txt,Quay lại bước 1 nếu kết quả đánh giá không tốt =))
7552,E:\DATN\dataframe\train_file\79.txt,Tất cả các thao tác trên bản chất là xoay quanh để giải quyết vấn đề giữa bias và variance ().
7553,E:\DATN\dataframe\train_file\79.txt,"Hiểu đơn giản về bias-variance trade off tức là ""chúng ta mong muốn mô hình khi fit vào dữ liệu sẽ có bias thấp và variance thấp, tuy nhiên, bias và variance thường có xu hướng nghịch đảo với nhau."
7554,E:\DATN\dataframe\train_file\79.txt,"- bias thấp nhưng variance cao hoặc variance thấp nhưng bias cao, và chúng ta chỉ có thể lựa chọn tăng cái này và chấp nhận giảm cái kia""."
7555,E:\DATN\dataframe\train_file\79.txt,"Một điều đặc biệt là, khi chúng ta chỉ sử dụng single model hay single learner (tức là chỉ dùng đúng duy nhất một model để fit vào dữ liệu), bias-variance trade off là điều không thể tránh khỏi - Single weak learner ."
7556,E:\DATN\dataframe\train_file\79.txt,1.2 Combine weak learners
7557,E:\DATN\dataframe\train_file\79.txt,"Để giải quyết được vấn đề bias-variance trade off, một hướng giải quyết được đề xuất là : ""Nếu 1 model không thể tự giải quyết được, hãy để nhiều model cùng nhau giải quyết""."
7558,E:\DATN\dataframe\train_file\79.txt,"Tất nhiên, nhiều model ở đây có thể là cùng một loại nhưng áp dụng trên những phần dữ liệu khác nhau (kì vọng là độc lập với nhau) hoặc những model hoàn toàn khác loại được kết hợp lại."
7559,E:\DATN\dataframe\train_file\79.txt,"Mỗi kiểu kết hợp model lại được áp dụng tùy theo mục đích nhất định, chứ không phải là kết hợp tùy tiện."
7560,E:\DATN\dataframe\train_file\79.txt,"Dựa vào tính chất này, chúng ta chia các thuật toán ensemble thành các nhóm chính sau (phần này mình xin trích lại từ  nha):"
7561,E:\DATN\dataframe\train_file\79.txt,Bagging (Mục tiêu là giảm variance - áp dụng cho các model đã có sẵn bias thấp và đang bị variance cao): Xây dựng một lượng lớn các model (thường là cùng loại) trên những subsamples khác nhau từ tập training dataset (random sample trong 1 dataset để tạo 1 dataset mới).
7562,E:\DATN\dataframe\train_file\79.txt,Những model này sẽ được train độc lập và song song với nhau nhưng đầu ra của chúng sẽ được trung bình cộng để cho ra kết quả cuối cùng.
7563,E:\DATN\dataframe\train_file\79.txt,Boosting (Mục tiêu là giảm bias - áp dụng cho các model có variance thấp và bị bias cao): Xây dựng một lượng lớn các model (thường là cùng loại).
7564,E:\DATN\dataframe\train_file\79.txt,"Mỗi model sau sẽ học cách sửa những errors của model trước (dữ liệu mà model trước dự đoán sai) -> tạo thành một chuỗi các model mà model sau sẽ tốt hơn model trước bởi trọng số được update qua mỗi model (cụ thể ở đây là trọng số của những dữ liệu dự đoán đúng sẽ không đổi, còn trọng số của những dữ liệu dự đoán sai sẽ được tăng thêm) ."
7565,E:\DATN\dataframe\train_file\79.txt,Chúng ta sẽ lấy kết quả của model cuối cùng trong chuỗi model này làm kết quả trả về.
7566,E:\DATN\dataframe\train_file\79.txt,"Stacking (Mục tiêu là giảm bias - áp dụng cho các model có variance thấp và bị bias cao): Xây dựng một số model (thường là khác loại) và một meta model (supervisor model), train những model này độc lập, sau đó meta model sẽ học cách kết hợp kết quả dự báo của một số mô hình một cách tốt nhất."
7567,E:\DATN\dataframe\train_file\79.txt,"Bỏ qua Bagging, chúng ta đến với Boosting"
7568,E:\DATN\dataframe\train_file\79.txt,2.1 Ý tưởng của Boosting
7569,E:\DATN\dataframe\train_file\79.txt,"Qua Part 1, chúng ta đã biết được Bagging được kết hợp từ các model được fit trên các tập dữ liệu con (được lấy theo boostrap sample để các tập con được kì vọng là độc lập), từ đó kết hợp các kết quả từ các model này để đưa ra kết quả cuối cùng."
7570,E:\DATN\dataframe\train_file\79.txt,"Tuy nhiên, có 1 số điều chúng ta có thể để ý ở đây"
7571,E:\DATN\dataframe\train_file\79.txt,"Các model trong Bagging đều là học một cách riêng rẽ, không liên quan hay ảnh hưởng gì đến nhau, điều này trong một số trường hợp có thể dẫn đến kết quả tệ khi các model có thể học cùng ra 1 kết quả."
7572,E:\DATN\dataframe\train_file\79.txt,Chúng ta không thể kiểm soát được hướng phát triển của các model con thêm vào bagging
7573,E:\DATN\dataframe\train_file\79.txt,"Chúng ta mong đợi các model yếu của thể hỗ trợ lẫn nhau, học được từ nhau để tránh đi vào các sai lầm của model trước đó."
7574,E:\DATN\dataframe\train_file\79.txt,Đây là điều Bagging không làm được
7575,E:\DATN\dataframe\train_file\79.txt,Boosting ra đời dựa trên việc mong muốn cải thiện những hạn chế trên.
7576,E:\DATN\dataframe\train_file\79.txt,"Ý tưởng cơ bản là Boosting sẽ tạo ra một loạt các model yếu, học bổ sung lẫn nhau."
7577,E:\DATN\dataframe\train_file\79.txt,"Nói cách khác, trong Boosting, các model sau sẽ cố gắng học để hạn chế lỗi lầm của các model trước."
7578,E:\DATN\dataframe\train_file\79.txt,Vậy làm thể nào để hạn chế được sai lầm từ các model trước ?
7579,E:\DATN\dataframe\train_file\79.txt,Boosting tiến hành đánh trọng số cho các mô hình mới được thêm vào dựa trên các cách tối ưu khác nhau.
7580,E:\DATN\dataframe\train_file\79.txt,"Tùy theo cách đánh trọng số (cách để các model được fit một cách tuần tự) và cách tổng hợp lại các model, từ đó hình thành nên 2 loại Boosting :"
7581,E:\DATN\dataframe\train_file\79.txt,Adaptive Boosting (AdaBoost)
7582,E:\DATN\dataframe\train_file\79.txt,Gradient Boosting
7583,E:\DATN\dataframe\train_file\79.txt,Chúng ta sẽ phân tích sâu hơn về 2 dạng Boosting này ở phần sau.
7584,E:\DATN\dataframe\train_file\79.txt,"Để kết thúc phần này, có một vài nhận xét về Boosting như sau:"
7585,E:\DATN\dataframe\train_file\79.txt,"Boosting là một quá trình tuần tự, không thể xử lí song song, do đó, thời gian train mô hình có thể tương đối lâu."
7586,E:\DATN\dataframe\train_file\79.txt,"Sau mỗi vòng lặp, Boosting có khả năng làm giảm error theo cấp số nhân."
7587,E:\DATN\dataframe\train_file\79.txt,Boosting sẽ hoạt động tốt nếu base learner của nó không quá phức tạp cũng như error không thay đổi quá nhanh.
7588,E:\DATN\dataframe\train_file\79.txt,Boosting giúp làm giảm giá trị bias cho các model base learner.
7589,E:\DATN\dataframe\train_file\79.txt,2.2 AdaBoost - Gradient Boosting
7590,E:\DATN\dataframe\train_file\79.txt,Cả AdaBoost và Gradient Boosting đều xây dựng thuật toán nhằm giải quyết bài toán tối ưu sau :
7591,E:\DATN\dataframe\train_file\79.txt,"\text{min}_{c_n=1:N, w_n=1:N} L(y, \sum^N_{n=1} c_n w_n))"
7592,E:\DATN\dataframe\train_file\79.txt,"=1:N,w"
7593,E:\DATN\dataframe\train_file\79.txt,Trong đó :
7594,E:\DATN\dataframe\train_file\79.txt,L : giá trị loss function
7595,E:\DATN\dataframe\train_file\79.txt,y : label
7596,E:\DATN\dataframe\train_file\79.txt, : confidence score của weak learner thứ n (hay còn gọi là trọng số)
7597,E:\DATN\dataframe\train_file\79.txt, : weak learner thứ n
7598,E:\DATN\dataframe\train_file\79.txt,"Thoạt nhìn, công thức trên có vẻ khá giống với Bagging, thế nhưng cách tính ra các giá trị confidence score kia lại làm nên sự khác biệt về hướng giải quyết của Boosting."
7599,E:\DATN\dataframe\train_file\79.txt,Thay vì cố gằng quét tìm tất cả các giá trị
7600,E:\DATN\dataframe\train_file\79.txt,"c_n, w_n"
7601,E:\DATN\dataframe\train_file\79.txt," để tìm nghiệm tối ưu toàn cục - một công việc tốn nhiều thời gian và tài nguyên, chúng ta sẽ cố gắng tìm các giá trị nghiệm cục bộ sau khi thêm mỗi một mô hình mới vào chuỗi mô hình với mong muốn dần đi đến nghiệm toàn cục."
7602,E:\DATN\dataframe\train_file\79.txt,"\text{min}_{c_n, w_n} L(y, W_{n-1} + c_n w_n))"
7603,E:\DATN\dataframe\train_file\79.txt,n−1
7604,E:\DATN\dataframe\train_file\79.txt,W_{n-1} = \sum^{N-1}_{n=1} c_n w_n
7605,E:\DATN\dataframe\train_file\79.txt,n−1
7606,E:\DATN\dataframe\train_file\79.txt,N−1
7607,E:\DATN\dataframe\train_file\79.txt,Adaptive Boosting
7608,E:\DATN\dataframe\train_file\79.txt,"AdaBoost tiến hành train các mô hình mới dựa trên việc đánh lại trọng số cho các điểm dữ liệu hiện tại, nhằm giúp các mô hình mới có thể tập trung hơn vào các mẫu dữ liệu đang bị học sai, từ đó làm giảm giá trị loss của mô hình."
7609,E:\DATN\dataframe\train_file\79.txt,"Cụ thể, các bước triển khai thuật toán như sau :"
7610,E:\DATN\dataframe\train_file\79.txt,Khởi tạo weight ban đầu là bằng nhau (bằng
7611,E:\DATN\dataframe\train_file\79.txt,1/N) cho mỗi điểm dữ liệu
7612,E:\DATN\dataframe\train_file\79.txt,Tại vòng lặp thứ i
7613,E:\DATN\dataframe\train_file\79.txt,train model
7614,E:\DATN\dataframe\train_file\79.txt, (weak learner) mới được thêm vào
7615,E:\DATN\dataframe\train_file\79.txt,"tính toán giá trị loss (error), từ đó tính toán ra giá trị confidence score"
7616,E:\DATN\dataframe\train_file\79.txt, của model vừa train
7617,E:\DATN\dataframe\train_file\79.txt,Cập nhật model chính
7618,E:\DATN\dataframe\train_file\79.txt,W = W + c_i * w_i
7619,E:\DATN\dataframe\train_file\79.txt,∗w
7620,E:\DATN\dataframe\train_file\79.txt,"Cuối cùng, đánh lại trọng số cho các điểm dữ liệu (Các điểm dữ liệu bị đoán sai --> tăng trọng số, các điểm dữ liệu đoán đúng --> giảm trọng số)."
7621,E:\DATN\dataframe\train_file\79.txt,Sau đó lặp lại với vòng lặp thêm model tiếp theo i + 1.
7622,E:\DATN\dataframe\train_file\79.txt,"Chi tiết về cách thuật toán hoạt động, bạn có thể đọc thêm example tại"
7623,E:\DATN\dataframe\train_file\79.txt,"FYI: AdaBoost có thể được áp dụng mà không cần dựa vào việc đánh trọng số lại các điểm dữ liệu, thay vào đó, chúng ta có thể re-sample để lấy dữ liệu train cho các model tiếp theo dựa vào xác suất được xác định bới các trọng số."
7624,E:\DATN\dataframe\train_file\79.txt,Gradient Boosting
7625,E:\DATN\dataframe\train_file\79.txt,Gradient Boosting là một dạng tổng quát hóa của AdaBoost.
7626,E:\DATN\dataframe\train_file\79.txt,"Cụ thể như sau, vẫn vấn đề tối ưu ban đầu"
7627,E:\DATN\dataframe\train_file\79.txt,"\text{min}_{c_n, w_n} L(y, W_{n-1} + c_n w_n))"
7628,E:\DATN\dataframe\train_file\79.txt,n−1
7629,E:\DATN\dataframe\train_file\79.txt,Trước tiên mình xin nhắc lại một chút lí thuyết mà các bạn đã khá quen trong neural network:
7630,E:\DATN\dataframe\train_file\79.txt,\theta_n = \theta_{n-1} - \eta \frac{\partial}{\partial \theta}L(\theta_{n-1})
7631,E:\DATN\dataframe\train_file\79.txt,n−1
7632,E:\DATN\dataframe\train_file\79.txt,−η
7633,E:\DATN\dataframe\train_file\79.txt,∂θ
7634,E:\DATN\dataframe\train_file\79.txt,n−1
7635,E:\DATN\dataframe\train_file\79.txt,Phía trên là công thức cập nhật tham số mô hình theo hướng giảm của đạo hàm (Gradient Descent).
7636,E:\DATN\dataframe\train_file\79.txt,"Công thức này được sử dụng không gian tham số, tuy nhiên, để liên hệ với bài toán chúng ta đang xét, mình chuyển công thức sang góc nhìn của không gian hàm số."
7637,E:\DATN\dataframe\train_file\79.txt,"Khá đơn giản thôi, nếu chúng ta coi chuỗi các model boosting là một hàm số"
7638,E:\DATN\dataframe\train_file\79.txt,"W, thì mỗi hàm learner có thể coi là một tham số"
7639,E:\DATN\dataframe\train_file\79.txt,"w. Đến đây, để cực tiểu hóa hàm loss"
7640,E:\DATN\dataframe\train_file\79.txt,"L(y, W)"
7641,E:\DATN\dataframe\train_file\79.txt,"L(y,W), chúng ta áp dụng Gradient Descent"
7642,E:\DATN\dataframe\train_file\79.txt,W_n = W_{n-1} - \eta \frac{\partial}{\partial w}L(W_{n-1})
7643,E:\DATN\dataframe\train_file\79.txt,n−1
7644,E:\DATN\dataframe\train_file\79.txt,−η
7645,E:\DATN\dataframe\train_file\79.txt,∂w
7646,E:\DATN\dataframe\train_file\79.txt,n−1
7647,E:\DATN\dataframe\train_file\79.txt,"Đến đây, ta có thể thấy mối quan hệ liên quan sau"
7648,E:\DATN\dataframe\train_file\79.txt,c_n w_n \approx - \eta \frac{\partial}{\partial w}L(W_{n-1})
7649,E:\DATN\dataframe\train_file\79.txt,≈−η
7650,E:\DATN\dataframe\train_file\79.txt,∂w
7651,E:\DATN\dataframe\train_file\79.txt,n−1
7652,E:\DATN\dataframe\train_file\79.txt, là model được thêm vào tiếp theo.
7653,E:\DATN\dataframe\train_file\79.txt,"Khi đó, model mới cần học để fit để vào giá trị"
7654,E:\DATN\dataframe\train_file\79.txt,- \eta \frac{\partial}{\partial w}L(W_{n-1})
7655,E:\DATN\dataframe\train_file\79.txt,−η
7656,E:\DATN\dataframe\train_file\79.txt,∂w
7657,E:\DATN\dataframe\train_file\79.txt,n−1
7658,E:\DATN\dataframe\train_file\79.txt,- \eta \frac{\partial}{\partial w}L(W_{n-1})
7659,E:\DATN\dataframe\train_file\79.txt,−η
7660,E:\DATN\dataframe\train_file\79.txt,∂w
7661,E:\DATN\dataframe\train_file\79.txt,n−1
7662,E:\DATN\dataframe\train_file\79.txt,) còn có 1 tên gọi khác là pseudo-residuals)
7663,E:\DATN\dataframe\train_file\79.txt,"Tóm lại, chúng ta có thể tóm tắt quá trình triển khai thuật toán như sau:"
7664,E:\DATN\dataframe\train_file\79.txt,Khởi tạo giá trị pseudo-residuals là bằng nhau cho từng điểm dữ liệu
7665,E:\DATN\dataframe\train_file\79.txt,Tại vòng lặp thứ i
7666,E:\DATN\dataframe\train_file\79.txt,Train model mới được thêm vào để fit vào giá trị của pseudo-residuals đã có
7667,E:\DATN\dataframe\train_file\79.txt,Tính toán giá trị confidence score
7668,E:\DATN\dataframe\train_file\79.txt, của model vừa train
7669,E:\DATN\dataframe\train_file\79.txt,Cập nhật model chính
7670,E:\DATN\dataframe\train_file\79.txt,W = W + c_i * w_i
7671,E:\DATN\dataframe\train_file\79.txt,∗w
7672,E:\DATN\dataframe\train_file\79.txt,"Cuối cùng, tính toán giá trị pseudo-residuals"
7673,E:\DATN\dataframe\train_file\79.txt,- \eta \frac{\partial}{\partial w}L(W_{n-1})
7674,E:\DATN\dataframe\train_file\79.txt,−η
7675,E:\DATN\dataframe\train_file\79.txt,∂w
7676,E:\DATN\dataframe\train_file\79.txt,n−1
7677,E:\DATN\dataframe\train_file\79.txt,) để làm label cho model tiếp theo
7678,E:\DATN\dataframe\train_file\79.txt,Sau đó lặp lại với vòng lặp i + 1.
7679,E:\DATN\dataframe\train_file\79.txt,Nếu bạn để ý thì phương pháp cập nhật lại trọng số của điểm dữ liệu của AdaBoost cũng là 1 trong các case của Gradient Boosting.
7680,E:\DATN\dataframe\train_file\79.txt,"Do đó, Gradient Boosting bao quát được nhiều trường hợp hơn"
7681,E:\DATN\dataframe\train_file\79.txt,LightGBM và XGBOOST
7682,E:\DATN\dataframe\train_file\79.txt,"Các phần trên là lí thuyết tổng quát về Ensemble Learning, Boosting và Gradient Boosting cho tất cả các loại model."
7683,E:\DATN\dataframe\train_file\79.txt,"Tuy nhiên, dù Bagging hay Boosting thì base model mà chúng ta biết đển nhiều nhất là dựa trên Decision Tree."
7684,E:\DATN\dataframe\train_file\79.txt,"Lí do là việc ensemble với các thuật toán Tree base cho kết quả cải thiện rõ ràng nhất, cũng là những thuật toán tốt nhất hiện nay đối với dạng dữ liệu có cấu trúc."
7685,E:\DATN\dataframe\train_file\79.txt,"Với Gradient Boosting có base model là Decision Tree, ta biết đến 2 framework phổ biến nhất là XGBoost và LightGBM"
7686,E:\DATN\dataframe\train_file\79.txt,3.1 XGBOOST
7687,E:\DATN\dataframe\train_file\79.txt,"XGBoost (Extreme Gradient Boosting) là một giải thuật được base trên gradient boosting, tuy nhiên kèm theo đó là những cải tiến to lớn về mặt tối ưu thuật toán, về sự kết hợp hoàn hảo giữa sức mạnh phần mềm và phần cứng, giúp đạt được những kết quả vượt trội cả về thời gian training cũng như bộ nhớ sử dụng."
7688,E:\DATN\dataframe\train_file\79.txt,"Mã nguồn mở với ~350 contributors và ~3,600 commits trên Gihub, XGBoost cho thấy những khả năng ứng dụng đáng kinh ngạc của mình như :"
7689,E:\DATN\dataframe\train_file\79.txt,"XGBoost có thể được sử dụng để giải quyết được tất cả các vấn đề từ hồi quy (regression), phân loại (classification), ranking và giải quyết các vấn đề do người dùng tự định nghĩa."
7690,E:\DATN\dataframe\train_file\79.txt,"XGBoost hỗ trợ trên Windows, Linux và OS X."
7691,E:\DATN\dataframe\train_file\79.txt,"Hỗ trợ tất cả các ngôn ngữ lập trình chính bao gồm C ++, Python, R, Java, Scala và Julia."
7692,E:\DATN\dataframe\train_file\79.txt,"Hỗ trợ các cụm AWS, Azure và Yarn và hoạt động tốt với Flink, Spark và các hệ sinh thái khác."
7693,E:\DATN\dataframe\train_file\79.txt,"Kể từ lần đầu ra mắt năm 2014, XGBoost nhanh chóng được đón nhận và là giải thuật được sử dụng chính, tạo ra nhiều kết quả vượt trội, giành giải cao trong các cuộc thi trên kaggle do tính đơn giản và hiểu quả của nó."
7694,E:\DATN\dataframe\train_file\79.txt,3.2 LightGBM
7695,E:\DATN\dataframe\train_file\79.txt,"Mặc dù đạt được những kết quả vượt trội, XGBoost gặp một vấn đề là thời gian training khá lâu, đặc biệt với những bộ dữ liệu lớn."
7696,E:\DATN\dataframe\train_file\79.txt,"Đến tháng 1 năm 2016, Microsoft lần đầu realease phiên bản thử nghiệm LightGBM, và LightGBM nhanh chóng thay thế vị trí của XGBoost, trở thành thuật toán ensemble được ưa chuộng nhất."
7697,E:\DATN\dataframe\train_file\79.txt,LightGBM có những cải tiến gì?
7698,E:\DATN\dataframe\train_file\79.txt,Chúng ta sẽ điểm qua một vài điểm chính sau đây:
7699,E:\DATN\dataframe\train_file\79.txt,"LightGBM sử dụng ""histogram-based algorithms"" thay thế cho ""pre-sort-based algorithms "" thường được dùng trong các boosting tool khác để tìm kiếm split point trong quá trình xây dựng tree."
7700,E:\DATN\dataframe\train_file\79.txt,"Cải tiến này giúp LightGBM tăng tốc độ training, đồng thời làm giảm bộ nhớ cần sử dụng .Thật ra cả xgboost và lightgbm đều sử dụng histogram-based algorithms, điểm tối ưu của lightgbm so với xgboost là ở 2 thuật toán: GOSS (Gradient Based One Side Sampling) và EFB (Exclusive Feature Bundling) giúp tăng tốc đáng kể trong quá trình tính toán."
7701,E:\DATN\dataframe\train_file\79.txt,"Chi tiết về GOSS và EFB, các bạn có thể đọc thêm tại:"
7702,E:\DATN\dataframe\train_file\79.txt,"LightGBM phát triển tree dựa trên leaf-wise, trong khi hầu hết các boosting tool khác (kể cả xgboost) dựa trên level (depth)-wise."
7703,E:\DATN\dataframe\train_file\79.txt,"Leaf-wise lựa chọn nút để phát triển cây dựa trên tối ưu toàn bộ tree, trong khi level-wise tối ưu trên nhánh đang xét, do đó, với số node nhỏ, các tree xây dựng từ leaf-wise thường out-perform level-wise."
7704,E:\DATN\dataframe\train_file\79.txt,"Note: Leaf-wise tuy tốt, nhưng với những bộ dữ liệu nhỏ, các tree xây dựng dựa trên leaf-wise thường dẫn đến overfit khá sớm."
7705,E:\DATN\dataframe\train_file\79.txt,"Do đó, lightgbm sử dụng thêm 1 hyperparameter là maxdepth nhằm cố gắng hạn chế điều này."
7706,E:\DATN\dataframe\train_file\79.txt,"Dù vậy, LightGBM vẫn được khuyến khích sử dụng khi bộ dữ liệu là đủ to."
7707,E:\DATN\dataframe\train_file\79.txt,"Chi tiết hơn về các cải tiến của LightGBM, các bạn có thể đọc thêm tại:"
7708,E:\DATN\dataframe\train_file\79.txt,"Bài cũng đã dài, mình định thêm 1 phần code minh họa nữa nhưng chắc sẽ các bạn cũng có thể tìm thấy rất nhiều đoạn code sử dụng LightGBM trên Kaggle nên mình không nếu thêm ra nữa."
7709,E:\DATN\dataframe\train_file\79.txt,"Hi vọng qua bài viết này, các bạn hiểu thêm về lí thuyết, tư tưởng của thuật toán Gradient Boosting, cũng như vận dụng tốt hơn 2 framework mạnh mẽ XGBoost và LightGBM để giải quyết các bài toán của bản thân."
7710,E:\DATN\dataframe\train_file\79.txt,"Nếu các bạn cần tham khảo thêm về tham số của 2 thư viện này, các bạn có thể đọc thêm tại  hoặc tại chính docs của 2 framework này để nắm vững hơn"
7711,E:\DATN\dataframe\train_file\8.txt,Percentiles trong Machine Learning
7712,E:\DATN\dataframe\train_file\8.txt,"Hello các bạn, hôm nay mình muốn giới thiệu đến các bạn thế nào là Percentile trong Machine Learning để các bạn có thể hiểu rõ hơn các khái niệm này và ứng dụng nó tốt hơn trong thực tế =)) Mình nghĩ ghi mở đầu cũng được kha khá chữ rồi."
7713,E:\DATN\dataframe\train_file\8.txt,À do mình kiệm lời nên không thích viết nhiều =)) Giờ bắt đầu thôi.
7714,E:\DATN\dataframe\train_file\8.txt,Let's go!
7715,E:\DATN\dataframe\train_file\8.txt,Percentiles là gì ?
7716,E:\DATN\dataframe\train_file\8.txt,Percentiles là một số mô tả giá trị phần trăm nhất định của các giá trị thấp hơn nó.
7717,E:\DATN\dataframe\train_file\8.txt,Đọc định nghĩa có lẽ nhiều bạn còn hoang mang?
7718,E:\DATN\dataframe\train_file\8.txt,Bây giờ đi trực tiếp vào ví dụ để dễ hiểu hơn nhé!
7719,E:\DATN\dataframe\train_file\8.txt,Example 1: Giả sử chúng ta có một loạt số lượng bánh của tất cả 21 cửa hàng bán ra trong một ngày tại một quận
7720,E:\DATN\dataframe\train_file\8.txt,#Sử dụng phương pháp NumPy percentile()để tìm các phân vị:
7721,E:\DATN\dataframe\train_file\8.txt,import numpy
7722,E:\DATN\dataframe\train_file\8.txt,#Danh sách số lượng bánh bán ra trong 1 ngày của 21 cửa hàng trong 1 quận
7723,E:\DATN\dataframe\train_file\8.txt,"cakes = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]"
7724,E:\DATN\dataframe\train_file\8.txt,"x = numpy.percentile(cakes, 75)"
7725,E:\DATN\dataframe\train_file\8.txt,Kết quả: 43.0
7726,E:\DATN\dataframe\train_file\8.txt,Kết quả trên cho ta biết rằng 75% cửa hàng có số lượng bánh bán ra trong một ngày nhỏ hơn 43 bánh hay nói cách khác là số 43 lớn hơn 75% giá trị có chứa trong danh sách số lượng bánh bán ra trong 1 ngày của 21 cửa hàng.
7727,E:\DATN\dataframe\train_file\8.txt,Ghi đến đây không biết các bạn hiểu được chưa nữa =)) Bạn nào chưa hiểu thì làm tiếp Ví dụ 2 bên dưới nha.
7728,E:\DATN\dataframe\train_file\8.txt,Cũng tương tự Ví dụ 1 nhưng mình ghi theo một cách diễn đạt khác.
7729,E:\DATN\dataframe\train_file\8.txt,"Example 2: Tương tự ví dụ 1, Ta muốn tìm giá trị mà tại đó nó lớn hơn 85% cửa hàng có số lượng bánh bán ra trong 1 ngày"
7730,E:\DATN\dataframe\train_file\8.txt,import numpy
7731,E:\DATN\dataframe\train_file\8.txt,"cakes = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]"
7732,E:\DATN\dataframe\train_file\8.txt,Kết quả: 50.0
7733,E:\DATN\dataframe\train_file\8.txt,"Xong gòi đó  Bye, hẹn gặp lại các bạn!"
7734,E:\DATN\dataframe\train_file\80.txt,Kỹ thuật Dropout (Bỏ học) trong Deep Learning
7735,E:\DATN\dataframe\train_file\80.txt,"Trong bài viết này, mình xin phép giới thiệu về Dropout (Bỏ học) trong mạng Neural, sau đó là mình sẽ có 1 số đoạn code để xem Dropout ảnh hưởng thế nào đến hiệu suất của mạng Neural."
7736,E:\DATN\dataframe\train_file\80.txt,Dropout trong mạng Neural là gì
7737,E:\DATN\dataframe\train_file\80.txt,Theo  - Thuật ngữ 'Dropout' đề cập đến việc bỏ qua các đơn vị (units) ẩn và hiện trong 1 mạng Neural.
7738,E:\DATN\dataframe\train_file\80.txt,Hiểu 1 cách đơn giản thì Dropout là việc bỏ qua các đơn vị (tức là 1 nút mạng) trong quá trình đào tạo 1 cách ngẫu nhiên.
7739,E:\DATN\dataframe\train_file\80.txt,Bằng việc bỏ qua này thì đơn vị đó sẽ không được xem xét trong quá trình forward và backward.
7740,E:\DATN\dataframe\train_file\80.txt,"Theo đó, p được gọi là xác suất giữ lại 1 nút mạng trong mỗi giai đoạn huấn luyện, vì thế xác suất nó bị loại bỏ là (1 - p)."
7741,E:\DATN\dataframe\train_file\80.txt,Tại sao lại cần Dropout
7742,E:\DATN\dataframe\train_file\80.txt,Câu hỏi là: Tại sao phải tắt 1 số nút mạng theo đúng nghĩa đen trong quá trình huấn luyện ?
7743,E:\DATN\dataframe\train_file\80.txt,Câu trả lời là: Tránh học tủ (Over-fitting)
7744,E:\DATN\dataframe\train_file\80.txt,"Nếu 1 lớp fully connected có quá nhiều tham số và chiếm hầu hết tham số, các nút mạng trong lớp đó quá phụ thuộc lẫn nhau trong quá trình huấn luyện thì sẽ hạn chế sức mạnh của mỗi nút, dẫn đến việc kết hợp quá mức."
7745,E:\DATN\dataframe\train_file\80.txt,Các kỹ thuật khác
7746,E:\DATN\dataframe\train_file\80.txt,"Nếu bạn muốn biết Dropout là gì, thì chỉ 2 phần lý thuyết phía trên là đủ."
7747,E:\DATN\dataframe\train_file\80.txt,Ở phần này mình cũng giới thiệu 1 số kỹ thuật có cùng tác dụng với Dropout.
7748,E:\DATN\dataframe\train_file\80.txt,"Trong Machine Learning, việc chính quy hóa (regularization) sẽ làm giảm over-fitting bằng cách thêm 1 khoảng giá trị 'phạt' vào hàm loss."
7749,E:\DATN\dataframe\train_file\80.txt,"Bằng cách thêm 1 giá trị như vậy, mô hình của bạn sẽ không học quá nhiều sự phụ thuộc giữa các trọng số."
7750,E:\DATN\dataframe\train_file\80.txt,Chắc hẳn nhiều người đã biết đến Logistic Regression thì đều biết đến L1 (Laplacian) và L2 (Gaussian) là 2 kỹ thuật 'phạt'.
7751,E:\DATN\dataframe\train_file\80.txt,"Quá trình training: Đối với mỗi lớp ẩn, mỗi example, mỗi vòng lặp, ta sẽ bỏ học 1 cách ngẫu nhiên với xác suất (1 - p) cho mỗi nút mạng."
7752,E:\DATN\dataframe\train_file\80.txt,"Quá trình test: Sử dụng tất cả các kích hoạt, nhưng sẽ giảm đi 1 hệ số p (để tính cho các kích hoạt bị bỏ học)."
7753,E:\DATN\dataframe\train_file\80.txt,Một số nhận xét
7754,E:\DATN\dataframe\train_file\80.txt,Dropout sẽ được học thêm các tính năng mạnh mẽ hữu ích
7755,E:\DATN\dataframe\train_file\80.txt,Nó gần như tăng gấp đôi số epochs cần thiết để hội tụ.
7756,E:\DATN\dataframe\train_file\80.txt,"Tuy nhiên, thời gian cho mỗi epoch là ít hơn."
7757,E:\DATN\dataframe\train_file\80.txt,"Ta có H đơn vị ẩn, với xác suất bỏ học cho mỗi đơn vị là (1 - p) thì ta có thể có 2^H mô hình có thể có."
7758,E:\DATN\dataframe\train_file\80.txt,"Nhưng trong giai đoạn test, tất cả các nút mạng phải được xét đến, và mỗi activation sẽ giảm đi 1 hệ số p."
7759,E:\DATN\dataframe\train_file\80.txt,"Nói thì hơi khó hiểu, nên mình sẽ code 2 phần để xem Dropout là như thế nào."
7760,E:\DATN\dataframe\train_file\80.txt,Đặt vấn đề: Bạn đi xem 1 trận đấu bóng đá và bạn thử dự đoán xem thủ môn sút vào vị trí nào thì cầu thủ nhà đánh đầu được quả bóng.
7761,E:\DATN\dataframe\train_file\80.txt,Mình import các thư viện cần thiết
7762,E:\DATN\dataframe\train_file\80.txt,# import packages
7763,E:\DATN\dataframe\train_file\80.txt,import numpy as np
7764,E:\DATN\dataframe\train_file\80.txt,import matplotlib.pyplot as plt
7765,E:\DATN\dataframe\train_file\80.txt,"from reg_utils import sigmoid, relu, plot_decision_boundary, initialize_parameters, load_2D_dataset, predict_dec"
7766,E:\DATN\dataframe\train_file\80.txt,"from reg_utils import compute_cost, predict, forward_propagation, backward_propagation, update_parameters"
7767,E:\DATN\dataframe\train_file\80.txt,import sklearn
7768,E:\DATN\dataframe\train_file\80.txt,import sklearn.datasets
7769,E:\DATN\dataframe\train_file\80.txt,import scipy.io
7770,E:\DATN\dataframe\train_file\80.txt,from testCases import *
7771,E:\DATN\dataframe\train_file\80.txt,%matplotlib inline
7772,E:\DATN\dataframe\train_file\80.txt,"plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots"
7773,E:\DATN\dataframe\train_file\80.txt,plt.rcParams['image.interpolation'] = 'nearest'
7774,E:\DATN\dataframe\train_file\80.txt,plt.rcParams['image.cmap'] = 'gray'
7775,E:\DATN\dataframe\train_file\80.txt,Visualize dữ liệu 1 chút
7776,E:\DATN\dataframe\train_file\80.txt,"train_X, train_Y, test_X, test_Y = load_2D_dataset()"
7777,E:\DATN\dataframe\train_file\80.txt,Ta được kết quả
7778,E:\DATN\dataframe\train_file\80.txt,"Dấu chấm đỏ là cầu thủ nhà đã từng đánh đầu, chấm xanh là cầu thủ bạn đánh đầu."
7779,E:\DATN\dataframe\train_file\80.txt,Việc chúng ta là dự đoán xem thủ môn nên sút bóng vào khu vực nào để cầu thủ nhà đánh đầu được.
7780,E:\DATN\dataframe\train_file\80.txt,Nhìn có vẻ như chỉ cần kẻ 1 đường thẳng để phân chia 2 khu vực là được.
7781,E:\DATN\dataframe\train_file\80.txt,Mô hình không có chính quy hóa
7782,E:\DATN\dataframe\train_file\80.txt,"def model(X, Y, learning_rate = 0.3, num_iterations = 30000, print_cost = True):"
7783,E:\DATN\dataframe\train_file\80.txt,    Triển khai mạng với 3 layer: LINEAR->RELU->LINEAR->RELU->LINEAR->SIGMOID.
7784,E:\DATN\dataframe\train_file\80.txt,"    X -- Dữ liệu đầu vào, kích thước (input size, number of examples)"
7785,E:\DATN\dataframe\train_file\80.txt,"    Y -- 1 vector (1 là chấm xanh / 0 là chấm đỏ), kích thước (output size, number of examples)"
7786,E:\DATN\dataframe\train_file\80.txt,    learning_rate -- Tỷ lệ học
7787,E:\DATN\dataframe\train_file\80.txt,    num_iterations -- Số epochs
7788,E:\DATN\dataframe\train_file\80.txt,"    print_cost -- Nếu là True, in ra coss cho mỗi 10000 vòng lặp"
7789,E:\DATN\dataframe\train_file\80.txt,"    parameters -- Tham số học được, được dùng để dự đoán"
7790,E:\DATN\dataframe\train_file\80.txt,    costs = []                            # to keep track of the cost
7791,E:\DATN\dataframe\train_file\80.txt,    m = X.shape[1]                        # number of examples
7792,E:\DATN\dataframe\train_file\80.txt,"    layers_dims = [X.shape[0], 20, 3, 1]"
7793,E:\DATN\dataframe\train_file\80.txt,    # Initialize parameters dictionary.
7794,E:\DATN\dataframe\train_file\80.txt,    parameters = initialize_parameters(layers_dims)
7795,E:\DATN\dataframe\train_file\80.txt,    # Loop (gradient descent)
7796,E:\DATN\dataframe\train_file\80.txt,"    for i in range(0, num_iterations):"
7797,E:\DATN\dataframe\train_file\80.txt,        # Forward propagation: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID.
7798,E:\DATN\dataframe\train_file\80.txt,"        a3, cache = forward_propagation(X, parameters)"
7799,E:\DATN\dataframe\train_file\80.txt,        # Cost function
7800,E:\DATN\dataframe\train_file\80.txt,"        cost = compute_cost(a3, Y)"
7801,E:\DATN\dataframe\train_file\80.txt,"        grads = backward_propagation(X, Y, cache)"
7802,E:\DATN\dataframe\train_file\80.txt,        # Update parameters.
7803,E:\DATN\dataframe\train_file\80.txt,"        parameters = update_parameters(parameters, grads, learning_rate)"
7804,E:\DATN\dataframe\train_file\80.txt,        # Print the loss every 10000 iterations
7805,E:\DATN\dataframe\train_file\80.txt,        if print_cost and i % 10000 == 0:
7806,E:\DATN\dataframe\train_file\80.txt,"            print(""Cost after iteration {}: {}"".format(i, cost))"
7807,E:\DATN\dataframe\train_file\80.txt,        if print_cost and i % 1000 == 0:
7808,E:\DATN\dataframe\train_file\80.txt,    # plot the cost
7809,E:\DATN\dataframe\train_file\80.txt,"    plt.xlabel('iterations (x1,000)')"
7810,E:\DATN\dataframe\train_file\80.txt,"    plt.title(""Learning rate ="" + str(learning_rate))"
7811,E:\DATN\dataframe\train_file\80.txt,    return parameters
7812,E:\DATN\dataframe\train_file\80.txt,Hàm dự đoán
7813,E:\DATN\dataframe\train_file\80.txt,"print(""On the training set:"")"
7814,E:\DATN\dataframe\train_file\80.txt,"predictions_train = predict(train_X, train_Y, parameters)"
7815,E:\DATN\dataframe\train_file\80.txt,"print(""On the test set:"")"
7816,E:\DATN\dataframe\train_file\80.txt,"predictions_test = predict(test_X, test_Y, parameters)"
7817,E:\DATN\dataframe\train_file\80.txt,Xem kết quả
7818,E:\DATN\dataframe\train_file\80.txt,Cost after iteration 0: 0.6557412523481002
7819,E:\DATN\dataframe\train_file\80.txt,Cost after iteration 10000: 0.16329987525724216
7820,E:\DATN\dataframe\train_file\80.txt,Cost after iteration 20000: 0.13851642423255986
7821,E:\DATN\dataframe\train_file\80.txt,On the training set:
7822,E:\DATN\dataframe\train_file\80.txt,Accuracy: 0.947867298578
7823,E:\DATN\dataframe\train_file\80.txt,On the test set:
7824,E:\DATN\dataframe\train_file\80.txt,Accuracy: 0.915
7825,E:\DATN\dataframe\train_file\80.txt,Có thể thấy độ chính xác ở tập training là 94% và tập test là 91% (khá cao).
7826,E:\DATN\dataframe\train_file\80.txt,Ta sẽ visualize 1 chút
7827,E:\DATN\dataframe\train_file\80.txt,"Khi không có chính quy hóa, ta thấy đường phân chia vẽ rất chi tiết, tức là nó đang over-fitting."
7828,E:\DATN\dataframe\train_file\80.txt,Mô hình chính quy hóa với Dropout
7829,E:\DATN\dataframe\train_file\80.txt,Quá trình Forward Propagation
7830,E:\DATN\dataframe\train_file\80.txt,"def forward_propagation_with_dropout(X, parameters, keep_prob=0.5):"
7831,E:\DATN\dataframe\train_file\80.txt,    Triển khai 3 layer: LINEAR -> RELU + DROPOUT -> LINEAR -> RELU + DROPOUT -> LINEAR -> SIGMOID.
7832,E:\DATN\dataframe\train_file\80.txt,"    X -- Dữ liệu đầu vào, kích thước (2, number of examples)"
7833,E:\DATN\dataframe\train_file\80.txt,"    parameters -- Các đối số chúng ta có ""W1"", ""b1"", ""W2"", ""b2"", ""W3"", ""b3"":"
7834,E:\DATN\dataframe\train_file\80.txt,"                    W1 -- weight matrix of shape (20, 2)"
7835,E:\DATN\dataframe\train_file\80.txt,"                    b1 -- bias vector of shape (20, 1)"
7836,E:\DATN\dataframe\train_file\80.txt,"                    W2 -- weight matrix of shape (3, 20)"
7837,E:\DATN\dataframe\train_file\80.txt,"                    b2 -- bias vector of shape (3, 1)"
7838,E:\DATN\dataframe\train_file\80.txt,"                    W3 -- weight matrix of shape (1, 3)"
7839,E:\DATN\dataframe\train_file\80.txt,"                    b3 -- bias vector of shape (1, 1)"
7840,E:\DATN\dataframe\train_file\80.txt,    keep_prob - xác suất giữ lại 1 unit
7841,E:\DATN\dataframe\train_file\80.txt,"    A3 -- giá trị đầu ra mô hình, kích thước (1,1)"
7842,E:\DATN\dataframe\train_file\80.txt,    cache -- lưu các đối số để tính cho phần Backward Propagation
7843,E:\DATN\dataframe\train_file\80.txt,    # retrieve parameters
7844,E:\DATN\dataframe\train_file\80.txt,"    W1 = parameters[""W1""]"
7845,E:\DATN\dataframe\train_file\80.txt,"    b1 = parameters[""b1""]"
7846,E:\DATN\dataframe\train_file\80.txt,"    W2 = parameters[""W2""]"
7847,E:\DATN\dataframe\train_file\80.txt,"    b2 = parameters[""b2""]"
7848,E:\DATN\dataframe\train_file\80.txt,"    W3 = parameters[""W3""]"
7849,E:\DATN\dataframe\train_file\80.txt,"    b3 = parameters[""b3""]"
7850,E:\DATN\dataframe\train_file\80.txt,    # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID
7851,E:\DATN\dataframe\train_file\80.txt,"    Z1 = np.dot(W1, X) + b1"
7852,E:\DATN\dataframe\train_file\80.txt,    A1 = relu(Z1)
7853,E:\DATN\dataframe\train_file\80.txt,    ### START CODE HERE ### (approx.
7854,E:\DATN\dataframe\train_file\80.txt,4 lines)         # Steps 1-4 below correspond to the Steps 1-4 described above.
7855,E:\DATN\dataframe\train_file\80.txt,"    D1 = np.random.rand(A1.shape[0], A1.shape[1])     # Step 1: khởi tạo ngẫu nhiên 1 ma trận kích thước bằng kích thước A1, giá trị (0, 1)"
7856,E:\DATN\dataframe\train_file\80.txt,"    D1 = D1 < keep_prob                            # Step 2: chuyển các giá trị về 0 hoặc 1, trả về 1 nếu giá trị đó nhỏ hơn keep_prob"
7857,E:\DATN\dataframe\train_file\80.txt,"    A1 = A1 * D1                                      # Step 3: giữ nguyên các phần tự trong A1 ứng với phần tử 1 của D1, và đổi thành 0 nếu vị trị trong D1 tương tứng là 0"
7858,E:\DATN\dataframe\train_file\80.txt,"    A1 = A1 / keep_prob                               # Step 4: giảm đi 1 hệ số keep_prob, để tính cho các phần tử đã bỏ học."
7859,E:\DATN\dataframe\train_file\80.txt,    ### END CODE HERE ###
7860,E:\DATN\dataframe\train_file\80.txt,"    Z2 = np.dot(W2, A1) + b2"
7861,E:\DATN\dataframe\train_file\80.txt,    A2 = relu(Z2)
7862,E:\DATN\dataframe\train_file\80.txt,    ### START CODE HERE ### (approx.
7863,E:\DATN\dataframe\train_file\80.txt,4 lines)
7864,E:\DATN\dataframe\train_file\80.txt,"    D2 = np.random.rand(A2.shape[0], A2.shape[1])"
7865,E:\DATN\dataframe\train_file\80.txt,    D2 = D2 < keep_prob
7866,E:\DATN\dataframe\train_file\80.txt,    A2 = A2 * D2
7867,E:\DATN\dataframe\train_file\80.txt,    A2 = A2 / keep_prob
7868,E:\DATN\dataframe\train_file\80.txt,    ### END CODE HERE ###
7869,E:\DATN\dataframe\train_file\80.txt,"    Z3 = np.dot(W3, A2) + b3"
7870,E:\DATN\dataframe\train_file\80.txt,    A3 = sigmoid(Z3)
7871,E:\DATN\dataframe\train_file\80.txt,"    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)"
7872,E:\DATN\dataframe\train_file\80.txt,"    return A3, cache"
7873,E:\DATN\dataframe\train_file\80.txt,Quá trình Backward Propagation
7874,E:\DATN\dataframe\train_file\80.txt,"def backward_propagation_with_dropout(X, Y, cache, keep_prob):"
7875,E:\DATN\dataframe\train_file\80.txt,    Các đối số:
7876,E:\DATN\dataframe\train_file\80.txt,"    X -- Dữ liệu đầu vào, kích thước (2, number of examples)"
7877,E:\DATN\dataframe\train_file\80.txt,"    Y -- kích thước (output size, number of examples)"
7878,E:\DATN\dataframe\train_file\80.txt,    cache -- lưu đầu ra của forward_propagation_with_dropout()
7879,E:\DATN\dataframe\train_file\80.txt,    keep_prob - như forward
7880,E:\DATN\dataframe\train_file\80.txt,"    gradients -- Đạo hàm của tất cả các weight, activation"
7881,E:\DATN\dataframe\train_file\80.txt,    m = X.shape[1]
7882,E:\DATN\dataframe\train_file\80.txt,"    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache"
7883,E:\DATN\dataframe\train_file\80.txt,    dZ3 = A3 - Y
7884,E:\DATN\dataframe\train_file\80.txt,    dW3 = 1.
7885,E:\DATN\dataframe\train_file\80.txt,"/ m * np.dot(dZ3, A2.T)"
7886,E:\DATN\dataframe\train_file\80.txt,    db3 = 1.
7887,E:\DATN\dataframe\train_file\80.txt,"/ m * np.sum(dZ3, axis=1, keepdims=True)"
7888,E:\DATN\dataframe\train_file\80.txt,"    dA2 = np.dot(W3.T, dZ3)"
7889,E:\DATN\dataframe\train_file\80.txt,    ### START CODE HERE ### (≈ 2 lines of code)
7890,E:\DATN\dataframe\train_file\80.txt,    dA2 = dA2 * D2              # Step 1: Áp dụng D2 để tắt các unit tương ứng với forward
7891,E:\DATN\dataframe\train_file\80.txt,    dA2 = dA2 / keep_prob              # Step 2: Giảm giá trị 1 hệ số keep_prob
7892,E:\DATN\dataframe\train_file\80.txt,    ### END CODE HERE ###
7893,E:\DATN\dataframe\train_file\80.txt,"    dZ2 = np.multiply(dA2, np.int64(A2 > 0))"
7894,E:\DATN\dataframe\train_file\80.txt,    dW2 = 1.
7895,E:\DATN\dataframe\train_file\80.txt,"/ m * np.dot(dZ2, A1.T)"
7896,E:\DATN\dataframe\train_file\80.txt,    db2 = 1.
7897,E:\DATN\dataframe\train_file\80.txt,"/ m * np.sum(dZ2, axis=1, keepdims=True)"
7898,E:\DATN\dataframe\train_file\80.txt,"    dA1 = np.dot(W2.T, dZ2)"
7899,E:\DATN\dataframe\train_file\80.txt,    ### START CODE HERE ### (≈ 2 lines of code)
7900,E:\DATN\dataframe\train_file\80.txt,    dA1 = dA1 * D1
7901,E:\DATN\dataframe\train_file\80.txt,    dA1 = dA1 / keep_prob
7902,E:\DATN\dataframe\train_file\80.txt,    ### END CODE HERE ###
7903,E:\DATN\dataframe\train_file\80.txt,"    dZ1 = np.multiply(dA1, np.int64(A1 > 0))"
7904,E:\DATN\dataframe\train_file\80.txt,    dW1 = 1.
7905,E:\DATN\dataframe\train_file\80.txt,"/ m * np.dot(dZ1, X.T)"
7906,E:\DATN\dataframe\train_file\80.txt,    db1 = 1.
7907,E:\DATN\dataframe\train_file\80.txt,"/ m * np.sum(dZ1, axis=1, keepdims=True)"
7908,E:\DATN\dataframe\train_file\80.txt,"    gradients = {""dZ3"": dZ3, ""dW3"": dW3, ""db3"": db3,""dA2"": dA2,"
7909,E:\DATN\dataframe\train_file\80.txt,"                 ""dZ2"": dZ2, ""dW2"": dW2, ""db2"": db2, ""dA1"": dA1,"
7910,E:\DATN\dataframe\train_file\80.txt,"                 ""dZ1"": dZ1, ""dW1"": dW1, ""db1"": db1}"
7911,E:\DATN\dataframe\train_file\80.txt,    return gradients
7912,E:\DATN\dataframe\train_file\80.txt,"Sau khi có Forward và Backward, ta thay 2 hàm này vào hàm model của phần trước:"
7913,E:\DATN\dataframe\train_file\80.txt,"parameters = model(train_X, train_Y, keep_prob=0.86, learning_rate=0.3)"
7914,E:\DATN\dataframe\train_file\80.txt,"print(""On the train set:"")"
7915,E:\DATN\dataframe\train_file\80.txt,"predictions_train = predict(train_X, train_Y, parameters)"
7916,E:\DATN\dataframe\train_file\80.txt,"print(""On the test set:"")"
7917,E:\DATN\dataframe\train_file\80.txt,"predictions_test = predict(test_X, test_Y, parameters)"
7918,E:\DATN\dataframe\train_file\80.txt,Cost after iteration 10000: 0.06101698657490559
7919,E:\DATN\dataframe\train_file\80.txt,Cost after iteration 20000: 0.060582435798513114
7920,E:\DATN\dataframe\train_file\80.txt,On the train set:
7921,E:\DATN\dataframe\train_file\80.txt,Accuracy: 0.928909952607
7922,E:\DATN\dataframe\train_file\80.txt,On the test set:
7923,E:\DATN\dataframe\train_file\80.txt,Accuracy: 0.95
7924,E:\DATN\dataframe\train_file\80.txt,"Ta thấy, độ chính xác trong tập test đã lên đến 95%, mặc dù tập training bị giảm."
7925,E:\DATN\dataframe\train_file\80.txt,Thực hiện visualize:
7926,E:\DATN\dataframe\train_file\80.txt,"plt.title(""Model with dropout"")"
7927,E:\DATN\dataframe\train_file\80.txt,axes = plt.gca()
7928,E:\DATN\dataframe\train_file\80.txt,"axes.set_xlim([-0.75, 0.40])"
7929,E:\DATN\dataframe\train_file\80.txt,"axes.set_ylim([-0.75, 0.65])"
7930,E:\DATN\dataframe\train_file\80.txt,"plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
7931,E:\DATN\dataframe\train_file\80.txt,Ta được
7932,E:\DATN\dataframe\train_file\80.txt,"Ta thấy đường phân chia không quá chi tiết, nên đã tránh được over-fitting."
7933,E:\DATN\dataframe\train_file\80.txt,Không dùng Dropout cho quá trình test
7934,E:\DATN\dataframe\train_file\80.txt,Áp dụng Dropout cho cả quá trình Forward và Backward
7935,E:\DATN\dataframe\train_file\80.txt,"Giá trị kích hoạt phải giảm đi 1 hệ số keep_prob, tính cả cho những nút bỏ học"
7936,E:\DATN\dataframe\train_file\81.txt,Tạo dữ liệu cho bài toán OCR Tiếng Việt trong 5 bước.
7937,E:\DATN\dataframe\train_file\81.txt,"Bài toán OCR hay nhận dạng chữ Tiếng Việt đã không còn xa lạ và đã được ứng dụng vào rất nhiều cuộc sống như ứng dụng trích xuất thông tin văn bản, số hóa dữ liệu, ... đã thu được rất nhiều thành quả đáng kinh ngạc."
7938,E:\DATN\dataframe\train_file\81.txt,"Và bài toán OCR cũng là một chủ đề có độ khó vừa phải để những người mới bắt đầu cũng có thể học, nghiên cứu thu thập nhiều kiến thức mới."
7939,E:\DATN\dataframe\train_file\81.txt,"Tuy nhiên làm sao để chúng ta tạo được những mô hình OCR, điều đầu tiên chúng ta cần phải có là dữ liệu."
7940,E:\DATN\dataframe\train_file\81.txt,Đúng chính xác rồi đó chính là dữ liệu.
7941,E:\DATN\dataframe\train_file\81.txt,"Dù là bài toán Object Detection, Segmentation, Classification thì điều cần phải có là dữ liệu."
7942,E:\DATN\dataframe\train_file\81.txt,"Ý dữ liệu mình nói ở đây là một dữ liệu ""tốt"" còn tốt như thế nào thì tùy vào các bài toán, kỳ vọng chúng ta sẽ có những cách đánh giá khác nhau."
7943,E:\DATN\dataframe\train_file\81.txt,"Dữ liệu cho bài toán OCR, theo ý kiến cá nhân của mình có thể chia làm hai loại:"
7944,E:\DATN\dataframe\train_file\81.txt,Dữ liệu thật
7945,E:\DATN\dataframe\train_file\81.txt,Dữ liệu nhân tạo
7946,E:\DATN\dataframe\train_file\81.txt,Dữ liệu thật đó là những dữ liệu có trong ngoài thực tế như ảnh một câu hoặc một từ mình cắt ra rồi chúng ta sẽ gán nhãn nội dung cho từng ảnh tương ứng.
7947,E:\DATN\dataframe\train_file\81.txt,"Tuy nhiên việc tạo ra dữ liệu thật lại tốn rất nhiều công sức và thời gian để xử lý, gán nhãn dữ liệu và có nguy cơ nhầm lẫn do mô hình OCR cần rất nhiều dữ liệu nên chúng ta cũng không thể nào đảm bảo chúng ta sẽ gán nhãn chính xác trên hàng trăm ngàn, hàng triệu, hàng chục triệu ảnh cả."
7948,E:\DATN\dataframe\train_file\81.txt,Và đó chính là những lý do mà chúng ta cần đến dữ liệu nhân tạo.
7949,E:\DATN\dataframe\train_file\81.txt,Dữ liệu nhân tạo theo mình định nghĩa ở đây là dữ liệu do con người tạo ra bằng các đoạn chương trình.
7950,E:\DATN\dataframe\train_file\81.txt,"Một số phương pháp mà các bạn cũng khá quen thuộc là augmentation giúp làm đa dạng dữ liệu của bạn bằng một số cách như làm nhiễu ảnh, làm mờ, xoay ngang, xoay dọc,..... Tuy nhiên cách này không giúp chúng ta đa dạng về nội dung ảnh ở đây là ý mình nói là chữ trong ảnh."
7951,E:\DATN\dataframe\train_file\81.txt,"Vì vậy hôm nay mình sẽ giới thiệu cho các bạn một phương pháp có thể dễ dàng tạo dữ liệu OCR để có thể ứng dụng vào trong học tập, nghiên cứu."
7952,E:\DATN\dataframe\train_file\81.txt,Nào cùng mình tìm hiểu nhé
7953,E:\DATN\dataframe\train_file\81.txt,Tải mã nguồn
7954,E:\DATN\dataframe\train_file\81.txt,Ở đây mình có sử dụng một tool sinh dữ liệu của repo .
7955,E:\DATN\dataframe\train_file\81.txt,"Tuy nhiên, để chuẩn bị sẵn các dữ liệu cần thiết để các bạn có thể thực hành sử dụng ngay thì các bạn có thể tải về repo mình nhé."
7956,E:\DATN\dataframe\train_file\81.txt,git clone https://github.com/buiquangmanhhp1999/ImageTextGenerator.git
7957,E:\DATN\dataframe\train_file\81.txt,Cài đặt môi trường
7958,E:\DATN\dataframe\train_file\81.txt,pip -r requirements.txt
7959,E:\DATN\dataframe\train_file\81.txt,Tìm hiểu một số cấu hình cần biết
7960,E:\DATN\dataframe\train_file\81.txt,Trong repo này tác giả cung cấp rất nhiều cấu hình khác nhau hỗ trợ việc sinh ảnh trong file .
7961,E:\DATN\dataframe\train_file\81.txt,Việc tìm hiểu hết tất cả các chức năng tốn nhiều thời gian.
7962,E:\DATN\dataframe\train_file\81.txt,Mình sẽ cung cấp cho các bạn một số cấu hình mà sẽ được sử dụng nhiều trong thực tế.
7963,E:\DATN\dataframe\train_file\81.txt,Các tham số chính:
7964,E:\DATN\dataframe\train_file\81.txt,-c hoặc --count: Số lượng ảnh cần tạo.
7965,E:\DATN\dataframe\train_file\81.txt,-f hoặc --format: Chiều cao của ảnh được tạo ra
7966,E:\DATN\dataframe\train_file\81.txt,-t hoặc --thread_count: Số lượng luồng dùng trong quá trình sinh ảnh.
7967,E:\DATN\dataframe\train_file\81.txt,Càng nhiều luồng thì tốc độ sinh ảnh càng nhanh
7968,E:\DATN\dataframe\train_file\81.txt,-i hoặc --input_file: đường dẫn tới file text chứa text sẽ được chuyển thành ảnh.
7969,E:\DATN\dataframe\train_file\81.txt,--output_dir: đường dẫn tới thư mục chứa ảnh sau khi tạo
7970,E:\DATN\dataframe\train_file\81.txt,--font_dir: đường dẫn tới thư mục chứa font chữ.
7971,E:\DATN\dataframe\train_file\81.txt,--image_dir: đường dẫn tới thư mục chứa ảnh nền.
7972,E:\DATN\dataframe\train_file\81.txt,"-b hoặc --background: Nhận một trong 4 giá trị: 0, 1, 2, 3, 4."
7973,E:\DATN\dataframe\train_file\81.txt,-cs hoặc --character_spacing: khoảng cách giữa hai kí tự.
7974,E:\DATN\dataframe\train_file\81.txt,-sw hoặc --space_width: khoảng cách giữa hai từ
7975,E:\DATN\dataframe\train_file\81.txt,Ngoài ra còn có một số tham số cấu hình khác như:
7976,E:\DATN\dataframe\train_file\81.txt,-e hoặc --extension: định dạng file ảnh sẽ được sinh ra.
7977,E:\DATN\dataframe\train_file\81.txt,"Ví dụ: jpg, png, jpeg, ...."
7978,E:\DATN\dataframe\train_file\81.txt,-rk hoặc --random_skew: độ nghiêng tối đa của text trong ảnh.
7979,E:\DATN\dataframe\train_file\81.txt,Chỉ nhận giá trị dương
7980,E:\DATN\dataframe\train_file\81.txt,-bl hoặc --blur: mức làm mờ ảnh bằng nhiễu Gausian.
7981,E:\DATN\dataframe\train_file\81.txt,-na hoặc --name_format: cách địng dạng tên ảnh sẽ được lưu.
7982,E:\DATN\dataframe\train_file\81.txt,"Tham số này nhận một trong ba giá trị 0, 1, 2."
7983,E:\DATN\dataframe\train_file\81.txt,Trong đó: 0: TEXT_ID.EXT; 1: ID_TEXT.EXT; 2: ID.EXT + file labels.txt chứa tên nhãn và ảnh tương ứng.
7984,E:\DATN\dataframe\train_file\81.txt,"Mình thì hay dùng option 2 hơn vì có một số text chứa các ký tự đặc biệt như: //, /,... hay bị nhầm thành đường dẫn khi dùng các định dạng khác."
7985,E:\DATN\dataframe\train_file\81.txt,-tc hoặc --text_color: mã hexa tương ứng với màu chữ trong ảnh cần sinh ra.
7986,E:\DATN\dataframe\train_file\81.txt,Màu đen mình thường để mặc địn luôn là #000000.
7987,E:\DATN\dataframe\train_file\81.txt,Chuẩn bị dữ liệu
7988,E:\DATN\dataframe\train_file\81.txt,Có ba dữ liệu mình sẽ cần chuẩn bị đó là :
7989,E:\DATN\dataframe\train_file\81.txt,Ảnh nền (ảnh background): Tùy thuộc vào từng bài toán mình sẽ chuẩn bị những ảnh nền thích hợp nhé.
7990,E:\DATN\dataframe\train_file\81.txt,Ví dụ bài toán của bạn là các văn bản thì phông các bạn cũng là ảnh trắng thôi.
7991,E:\DATN\dataframe\train_file\81.txt,Font tiếng Việt:Mình đã chuẩn bị sẵn font chữ tiếng Việt ở trong repo nếu các bạn sử dụng repo của mình để bên trên.
7992,E:\DATN\dataframe\train_file\81.txt,"Còn nếu không, cách dễ nhất là các bạn có thể tải các font tiếng Việt của google bằng cách click  nhé."
7993,E:\DATN\dataframe\train_file\81.txt,Tuy nhiên bạn nên kiểm tra kỹ lại từng font vì có mấy font thỉnh thoảng lúc tạo dữ liệu bị mất dấu tiếng Việt.
7994,E:\DATN\dataframe\train_file\81.txt,Các bạn cẩn thận nhé
7995,E:\DATN\dataframe\train_file\81.txt,Dữ liệu text:là một file .txt chứa các câu văn tiếng Việt.
7996,E:\DATN\dataframe\train_file\81.txt,Mỗi câu là một dòng trong file txt.
7997,E:\DATN\dataframe\train_file\81.txt,"Tool sẽ lấy dữ liệu trên từng dòng ghép với một font, một ảnh nền khác để tạo ra file ảnh tương ứng."
7998,E:\DATN\dataframe\train_file\81.txt,Mình có cung cấp sẵn khoảng 500 sample.
7999,E:\DATN\dataframe\train_file\81.txt,Các bạn có thể xem tại file .
8000,E:\DATN\dataframe\train_file\81.txt,Sinh dữ liệu
8001,E:\DATN\dataframe\train_file\81.txt,"Sau bước chuẩn bị dữ liệu, bạn có thể dễ dàng sinh ảnh như ý muốn của mình chỉ với một dòng lệnh."
8002,E:\DATN\dataframe\train_file\81.txt,Đơn giản đúng không nào
8003,E:\DATN\dataframe\train_file\81.txt,python3 run.py -c 500 -w 1 -f 32 -b 3 \
8004,E:\DATN\dataframe\train_file\81.txt,	--blur 0 \
8005,E:\DATN\dataframe\train_file\81.txt,	--input_file data/test_data.txt \
8006,E:\DATN\dataframe\train_file\81.txt,	--output_dir $(pwd)/out/ \
8007,E:\DATN\dataframe\train_file\81.txt,	--font_dir fonts/vi/ \
8008,E:\DATN\dataframe\train_file\81.txt,	--image_dir images/ \
8009,E:\DATN\dataframe\train_file\81.txt,	--thread_count 4 \
8010,E:\DATN\dataframe\train_file\81.txt,	--character_spacing 1 \
8011,E:\DATN\dataframe\train_file\81.txt,Kết quả bạn sẽ thu về một số file ảnh và file labels.txt chứa nhãn chứa trong thư mục bạn đã chỉ định như sau:
8012,E:\DATN\dataframe\train_file\81.txt,Vậy là mình cùng nhau hoàn thành hết 5 bước để tạo ra dữ liệu cho bài tóan OCR rồi.
8013,E:\DATN\dataframe\train_file\81.txt,Quá là đơn giản đúng không nào ?
8014,E:\DATN\dataframe\train_file\81.txt,Các bạn có thể dễ dàng tạo ra hàng trăm hàng ngàn ảnh để tiến hàng việc huấn luyện phục vụ cho mục đích học tập cũng như làm sản phẩm OCR.
8015,E:\DATN\dataframe\train_file\81.txt,"Bài viết đến đây là hết rồi, cảm ơn các bạn đã theo dõi bài viết của mình."
8016,E:\DATN\dataframe\train_file\81.txt,"Và hơi PR một chút, Nếu các bạn thấy hay, thì đừng ngần ngại hãy upvote để mình có thể thêm động lực ra những bài tiếp theo nhé"
8017,E:\DATN\dataframe\train_file\82.txt,Triển khai các mô hình với OpenVINO
8018,E:\DATN\dataframe\train_file\82.txt,I. Giới thiệu
8019,E:\DATN\dataframe\train_file\82.txt,"Xin chào các bạn và lại là mình đây, trong thời gian gần đây mình có tìm hiểu về cách triển khai các mô hình deep learning trên các thiết bị Edge và trong bài viết lần trước mình có giới thiệu tới mọi người bài viết về  các bạn nên đọc qua bài viết này của mình để có thể hiểu được các chuyển đổi mô hình từ Pytorch sang định dạng ONNX như thế nào nhé."
8020,E:\DATN\dataframe\train_file\82.txt,Về chủ đề OpenVINO thì tác giải Phan Hoàng cũng có một bài viết  rất hay các bạn có thể tham khảo.
8021,E:\DATN\dataframe\train_file\82.txt,Nhiều bạn sẽ đặt câu hỏi là tại sao người ta viết thì viết lại làm gì.... ờ thì đơn giản mình viết để mình có một cơ hội tổng hợp lại kiến thức khi nào quên thì xem nên có gì sau mong anh em chỉ bảo .
8022,E:\DATN\dataframe\train_file\82.txt,Hiện nay chúng ta đang sống trong thời đại của điện toán đám mây (cloud computing).
8023,E:\DATN\dataframe\train_file\82.txt,Mọi thứ bây giờ đều có trên cloud.
8024,E:\DATN\dataframe\train_file\82.txt,"Các dịch vụ cloud như AWS, Azure, GCP, v.v."
8025,E:\DATN\dataframe\train_file\82.txt,đã giúp các thiết bị IoT của bạn dễ dàng bù đắp cho việc thiếu tốc độ xử lý trong máy cục bộ và sử dụng sức mạnh xử lý trên cloud.
8026,E:\DATN\dataframe\train_file\82.txt,"Nhưng không phải trong mọi trường hợp, bạn có thể tin tưởng vào các dịch vụ cloud."
8027,E:\DATN\dataframe\train_file\82.txt,Luôn có nguy cơ rò rỉ dữ liệu cá nhân nhạy cảm của bạn nếu bạn gửi dữ liệu đó lên cloud.
8028,E:\DATN\dataframe\train_file\82.txt,"Có thể có vấn đề về mạng hoặc vấn đề về độ trễ khi bạn muốn triển khai mô hình AI của mình để đưa ra quyết định trong thời gian thực, chẳng hạn như ô tô tự lái."
8029,E:\DATN\dataframe\train_file\82.txt,Bạn thực sự không muốn ô tô tự lái của mình phải chờ phản hồi từ máy chủ trong khi đang lái.
8030,E:\DATN\dataframe\train_file\82.txt,Hoặc thậm chí có thể có tình huống mà mạng hoàn toàn không khả dụng.
8031,E:\DATN\dataframe\train_file\82.txt,"Sự phát triển của các thiết bị IoT đã làm tăng ứng dụng tiên tiến của AI, có rất nhiều thiết bị mục tiêu có tài nguyên phần cứng hạn chế mà bạn có thể muốn triển khai mô hình AI."
8032,E:\DATN\dataframe\train_file\82.txt,Cạnh có nghĩa là xử lý cục bộ.
8033,E:\DATN\dataframe\train_file\82.txt,Điều đó có nghĩa là bạn có thể sử dụng mô hình AI trong một thiết bị và sử dụng sức mạnh xử lý của nó để đưa ra quyết định mà không cần kết nối với dịch vụ đám mây.
8034,E:\DATN\dataframe\train_file\82.txt,Intel OpenVINO là gì?
8035,E:\DATN\dataframe\train_file\82.txt,Tên OpenVINO là viết tắt của Open Visual Inferencing and Neural Network Optimization.
8036,E:\DATN\dataframe\train_file\82.txt,Nó là một phần mềm mã nguồn mở được phát triển bởi Intel.
8037,E:\DATN\dataframe\train_file\82.txt,"Trọng tâm chính của OpenVINO là tối ưu hóa mạng nơ-ron để có thể suy luận nhanh trên các phần cứng khác nhau của Intel như CPU, GPU, VPU, FPGA, IPU, v.v."
8038,E:\DATN\dataframe\train_file\82.txt,bằng một API chung.
8039,E:\DATN\dataframe\train_file\82.txt,Phần mềm OpenVINO tối ưu hóa kích thước và tốc độ của mô hình để mô hình có thể chạy vượt trội với tài nguyên phần cứng hạn chế.
8040,E:\DATN\dataframe\train_file\82.txt,Nó không làm tăng độ chính xác của mô hình.
8041,E:\DATN\dataframe\train_file\82.txt,"Thay vào đó, đôi khi bạn có thể cần chọn giảm độ chính xác để có hiệu suất cao hơn ở rìa."
8042,E:\DATN\dataframe\train_file\82.txt,Gồm 2 phần chính:
8043,E:\DATN\dataframe\train_file\82.txt,Model Optimizer
8044,E:\DATN\dataframe\train_file\82.txt,Inference Engine
8045,E:\DATN\dataframe\train_file\82.txt,Quy trình làm việc của OpenVINO
8046,E:\DATN\dataframe\train_file\82.txt,Các bước như sau:
8047,E:\DATN\dataframe\train_file\82.txt,Huấn luyện mô hình
8048,E:\DATN\dataframe\train_file\82.txt,Feed model vào Optimizer với mục đích nén mô hình với đầu ra là Intermediate Representation bao gồm 2 file .xml và .bin
8049,E:\DATN\dataframe\train_file\82.txt,Feed Intermediate Representation vào Inference Engine với mục đích để kiểm tra tính tương thích của mô hình trên framework (được sử dụng để huấn luyện mô hình) với mô trường (hardware)
8050,E:\DATN\dataframe\train_file\82.txt,Triển khai trên ứng dụng
8051,E:\DATN\dataframe\train_file\82.txt,Model Optimizer
8052,E:\DATN\dataframe\train_file\82.txt,Model Optimizer để nén mô hình convert model trên các framework khác nhau sang Intermediate Representation là định dạng của OpenVINO.
8053,E:\DATN\dataframe\train_file\82.txt,Nó bao gồm:
8054,E:\DATN\dataframe\train_file\82.txt,"frozen-*.xml: network topology, là 1 file xml định nghĩa các layer của model, hay network graph"
8055,E:\DATN\dataframe\train_file\82.txt,"frozen-*.bin: file chứa weight + bias của model, có thể convert dưới các định dạng: FP32, FP16, INT8"
8056,E:\DATN\dataframe\train_file\82.txt,Một số framework OpenVINO cung cấp hỗ trợ convert sang định dạng IR như sau:
8057,E:\DATN\dataframe\train_file\82.txt,ONNX(PyTorch and Apple ML)
8058,E:\DATN\dataframe\train_file\82.txt,Quá trình convert pretrained là một quá trình khá đơn giản.
8059,E:\DATN\dataframe\train_file\82.txt,Bạn cần configure optimizer cho từng framework  sau đó thực hiện chạy .
8060,E:\DATN\dataframe\train_file\82.txt,OpenVINO support khá nhiều  với các mục đích như:
8061,E:\DATN\dataframe\train_file\82.txt,Object Detection
8062,E:\DATN\dataframe\train_file\82.txt,Object Recognition
8063,E:\DATN\dataframe\train_file\82.txt,Pose Estimation
8064,E:\DATN\dataframe\train_file\82.txt,OpenVINO cũng cung cấp một số phương thức Optmizer model với mục đích để mô hình nhẹ và nhanh hơn.
8065,E:\DATN\dataframe\train_file\82.txt,Trong bài viết này tôi sẽ chỉ trình bày về 3 phương pháp
8066,E:\DATN\dataframe\train_file\82.txt,Về các phương pháp tối ưu mô hình thì có khá nhiều phương pháp các bạn có thể tham khảo các bài viết dưới đây mà tôi khá tâm đắc:
8067,E:\DATN\dataframe\train_file\82.txt,của tác giả Phạm Hữu Quang.
8068,E:\DATN\dataframe\train_file\82.txt, của tác giả Nguyễn Văn Đạt
8069,E:\DATN\dataframe\train_file\82.txt,Weights và bias của các mô hình được đào tạo trước trong OpenVINO có các phân biệt khác nhau:
8070,E:\DATN\dataframe\train_file\82.txt,FP32- Floating Point 32-bit
8071,E:\DATN\dataframe\train_file\82.txt,FP16- Floating Point 16-bit
8072,E:\DATN\dataframe\train_file\82.txt,INT8- Integer 8-bit
8073,E:\DATN\dataframe\train_file\82.txt,Các mô hình có độ chính xác cao có thể mang lại kết quả tốt tuy nhiên nó lại khá lớn nên lúc inference sẽ gây ra chậm và tốn tài nguyên khi chạy.
8074,E:\DATN\dataframe\train_file\82.txt,Mặt khác với những mô hình có độ chính xác thấp hơn nhưng tốc độ nhanh hơn nên tùy vào từng yêu cầu cụ thể của bài toán mà các bạn lựa chọn.
8075,E:\DATN\dataframe\train_file\82.txt,Quantization quan tâm tới việc tối ưu hóa lưu weight làm sao để hiệu qủa nhất.
8076,E:\DATN\dataframe\train_file\82.txt,Bạn có thể đánh đổi một chút độ chính xác để lưu weight từ dạng FP32 xuống FP16 hoặc INT8.
8077,E:\DATN\dataframe\train_file\82.txt,Freezing ở đây khác với Freezing trong quá trình huấn luyện mô hình nên bạn đừng nhầm lẫn nhé.
8078,E:\DATN\dataframe\train_file\82.txt,"Trong huấn luyện mô hình, điều này có nghĩa là đóng băng các lớp nhất định để bạn có thể tinh chỉnh và đào tạo chỉ trên một tập hợp con của các lớp."
8079,E:\DATN\dataframe\train_file\82.txt,"Ở đây, nó được sử dụng trong bối cảnh của toàn bộ mô hình và mô hình Tensorflow nói riêng."
8080,E:\DATN\dataframe\train_file\82.txt,Đóng băng các mô hình TensorFlow sẽ loại bỏ một số hoạt động nhất định và siêu dữ liệu chỉ cần thiết cho đào tạo.
8081,E:\DATN\dataframe\train_file\82.txt,"Ví dụ, việc lan truyền ngược chỉ được yêu cầu trong khi đào tạo và không được yêu cầu trong khi inference."
8082,E:\DATN\dataframe\train_file\82.txt,Đóng băng mô hình TensorFlow thường là một ý tưởng hay cho dù trước khi thực hiện suy luận trực tiếp hoặc chuyển đổi với Trình tối ưu hóa mô hình.
8083,E:\DATN\dataframe\train_file\82.txt,Fusion có nghĩa là kết hợp nhiều lớp thành một lớp duy nhất.
8084,E:\DATN\dataframe\train_file\82.txt,"Ví dụ, một lớp chuẩn hóa hàng loạt, lớp kích hoạt và lớp phức hợp có thể được kết hợp thành một lớp duy nhất."
8085,E:\DATN\dataframe\train_file\82.txt,Inference Engine
8086,E:\DATN\dataframe\train_file\82.txt,"Inference Engine, như tên cho thấy, chạy suy luận thực tế trên mô hình."
8087,E:\DATN\dataframe\train_file\82.txt,Nó chỉ hoạt động với Biểu diễn trung gian (IR) đến từ trình tối ưu hóa mô hình hoặc các mô hình được đào tạo trước của Intel đã có mặt ở định dạng IR.
8088,E:\DATN\dataframe\train_file\82.txt,"Giống như Trình tối ưu hóa mô hình, cung cấp các cải tiến trên cơ sở kích thước và độ phức tạp của mô hình để cải thiện bộ nhớ và thời gian tính toán, Công cụ suy luận cung cấp các tối ưu hóa dựa trên phần cứng để có được những cải tiến hơn nữa trong mô hình."
8089,E:\DATN\dataframe\train_file\82.txt,"Bản thân Inference Engine thực sự được xây dựng trên C ++, dẫn đến các hoạt động tổng thể nhanh hơn; tuy nhiên, việc sử dụng trình bao bọc Python tích hợp sẵn để tương tác với nó trong Python là rất phổ biến."
8090,E:\DATN\dataframe\train_file\82.txt,Hỗ trợ trên tất cả các thiết bị phần cứng của Intel như sau:
8091,E:\DATN\dataframe\train_file\82.txt,CPU (Central Processing Unit)
8092,E:\DATN\dataframe\train_file\82.txt,GPU (Graphics Processing Unit)
8093,E:\DATN\dataframe\train_file\82.txt,NCS-2 (Neural Compute Stick)
8094,E:\DATN\dataframe\train_file\82.txt,FPGA (Field Programmable Gate Array)
8095,E:\DATN\dataframe\train_file\82.txt,Inference Engine có 2 classes chính như sau :
8096,E:\DATN\dataframe\train_file\82.txt,IECore-> Python Wrapper để làm việc với IE
8097,E:\DATN\dataframe\train_file\82.txt,IENetwork -> Lấy các tệp .xml và .bin và load mô hình vào IECore.
8098,E:\DATN\dataframe\train_file\82.txt,"Sau khi tải IENetwork lên IECore thành công, bạn sẽ nhận được một Executable Network, nơi bạn sẽ gửi Inference Requests."
8099,E:\DATN\dataframe\train_file\82.txt,Có 2 loại Inference Requests:
8100,E:\DATN\dataframe\train_file\82.txt,"Trong trường hợp Suy luận Đồng bộ, hệ thống sẽ đợi và không hoạt động cho đến khi phản hồi suy luận được trả về (chặn luồng chính)."
8101,E:\DATN\dataframe\train_file\82.txt,"Trong trường hợp này, chỉ một khung được xử lý cùng một lúc và không thể tập hợp khung tiếp theo cho đến khi hoàn tất suy luận của khung hiện tại"
8102,E:\DATN\dataframe\train_file\82.txt,"Như bạn có thể đã đoán, trong trường hợp Suy luận không đồng bộ, nếu phản hồi cho một yêu cầu cụ thể mất nhiều thời gian, thì bạn không cần chờ đợi, thay vào đó bạn tiếp tục với quy trình tiếp theo trong khi quy trình hiện tại đang thực thi."
8103,E:\DATN\dataframe\train_file\82.txt,Suy luận không đồng bộ đảm bảo suy luận nhanh hơn so với Suy luận đồng bộ.
8104,E:\DATN\dataframe\train_file\82.txt,Bài viết của mình đến đây là kết thúc hết phần 1 và mình đang viết tiếp phần 2 hướng dẫn thực hiện convert 1 mô hình thực tế từ pytorch hãy follow để xem các bài viết tiếp theo nhé.
8105,E:\DATN\dataframe\train_file\82.txt,Cảm ơn các bạn đã theo dõi bài viết của mình.
8106,E:\DATN\dataframe\train_file\82.txt,Đừng tiếc gì hãy cho mình xin 1 lượt upvote nha các bạn.
8107,E:\DATN\dataframe\train_file\83.txt,MLP-Mixer - Hướng giải quyết các bài toán Computer Vision mới bên cạnh CNN và Transformer
8108,E:\DATN\dataframe\train_file\83.txt,Có thể nói rằng Convolutional Neural Network hay CNN đã và đang được cho là mô hình vô cùng phù hợp cho thị giác máy tính.
8109,E:\DATN\dataframe\train_file\83.txt,"Bên cạnh đó các mạng dựa trên cơ chế attention, chẳng hạn như Vision Transformer, cũng dần được quan tâm và sử dụng nhiều hơn."
8110,E:\DATN\dataframe\train_file\83.txt,"Tuy vậy trong paper mới được publish của mình với tên gọi , nhóm Google Brain ở Zurich và Berlin đã tuyên bố rằng năm 2021 rồi ai cùng dùng mấy cái đấy nữa mặc dù các kiến trúc trên đều mang lại hiệu xuất cũng như độ chính xác cao, việc sử dụng chúng đôi khi là không cần thiết."
8111,E:\DATN\dataframe\train_file\83.txt,"Vậy nên trong bài viết này, chúng ta sẽ cùng tìm hiểu cách thức hoạt động của kiến trúc này cũng như sự khác biệt của nó với các kiến trúc mạng khác."
8112,E:\DATN\dataframe\train_file\83.txt,Tổng quan kiến trúc của MLP-Mixer
8113,E:\DATN\dataframe\train_file\83.txt,"Như có thể dễ dàng nhận thấy, sự xuất hiện của các bộ dữ liệu với kích thước ngày càng lớn và cùng với đó là khả năng tính toán của máy móc càng ngày càng được cải thiện dẫn đến nhiều kiến trúc mô hình được ra đời cũng như dần được cải tiến."
8114,E:\DATN\dataframe\train_file\83.txt,"Trong khi Convolutional Neural Network đã và đang là tiêu chuẩn thực tế cho thị giác máy tính, gần đây Vision Transformers (ViT), một giải pháp thay thế dựa trên các lớp self-attention đã đạt được hiệu suất của các mô hình hiện đại được công bố trước đó."
8115,E:\DATN\dataframe\train_file\83.txt,"ViT tiếp tục xu hướng lâu dài là loại bỏ các đặc trưng ""hand-crafted"" và ""inductive biases"" khỏi các mô hình và dựa vào việc học hỏi nhiều hơn từ dữ liệu thô."
8116,E:\DATN\dataframe\train_file\83.txt,"Tiếp nối truyền thống tre chưa già mà măng đã mọc, kiến trúc MLP-Mixer được nhóm tác giả đề xuất và được cho là đơn giản hơn các mô hình trước đây nhưng không hề thua kém về hiệu xuất khi không sử dụng đến các lớp convolution hay cơ chế self-attention."
8117,E:\DATN\dataframe\train_file\83.txt,"Thay vào đó kiến trúc của Mixer hoàn toàn dựa trên perceptron nhiều lớp, thứ được áp dụng nhiều lần trên thông tin không gian cũng như các đặc trưng theo channel."
8118,E:\DATN\dataframe\train_file\83.txt,Dữ liệu đầu vào
8119,E:\DATN\dataframe\train_file\83.txt,Hình minh họa trên được trích từ paper mô tả tổng quan kiến trúc của Mixer.
8120,E:\DATN\dataframe\train_file\83.txt,Kiến trúc này nhận đầu vào là một chuỗi các phần của hình ảnh được chiếu tuyến tính (được đề cập trong paper với khái niệm token) như một bảng có kích thước là
8121,E:\DATN\dataframe\train_file\83.txt,(số token x số channel)
8122,E:\DATN\dataframe\train_file\83.txt,"Như trong hình minh họa trên đang thể hiện kiến trúc của một mô hình phân lớp, hình ảnh đầu vào được chia thành 9 phần tương ứng với 9 token là đầu vào cho mạng."
8123,E:\DATN\dataframe\train_file\83.txt,"Để hình dung rõ hơn, ta hãy cùng quan sát phần mã Pytorch được cài đặt cho phần PatchEmbed ở repo  được thể hiện ở hình dưới đây."
8124,E:\DATN\dataframe\train_file\83.txt,"Có thể thấy rằng qua module này, ảnh đầu vào với kích thước"
8125,E:\DATN\dataframe\train_file\83.txt,"(224, 224)"
8126,E:\DATN\dataframe\train_file\83.txt,"(224,224) được chia thành từng phần với kích thước"
8127,E:\DATN\dataframe\train_file\83.txt,"(16, 16)"
8128,E:\DATN\dataframe\train_file\83.txt,"(16,16) sau đó được từng phần nhỏ kia được chuyển đổi thành một vector có kích thước"
8129,E:\DATN\dataframe\train_file\83.txt,16 * 16 * 3 = 768
8130,E:\DATN\dataframe\train_file\83.txt,"16∗16∗3=768 do ảnh đầu vào có 3 channel lần lượt là R, G, B như thông thường."
8131,E:\DATN\dataframe\train_file\83.txt,Khi đó bảng giá trị đầu vào sẽ có kích thước là
8132,E:\DATN\dataframe\train_file\83.txt,(196 * 768)
8133,E:\DATN\dataframe\train_file\83.txt,(196∗768) do ta có tổng cộng
8134,E:\DATN\dataframe\train_file\83.txt,(224/16) * (224/16)
8135,E:\DATN\dataframe\train_file\83.txt,(224/16)∗(224/16) token tương ứng với từng đó phần của ảnh đầu vào.
8136,E:\DATN\dataframe\train_file\83.txt,Cấu trúc của MixerLayer
8137,E:\DATN\dataframe\train_file\83.txt,Mixer lấy ý tưởng từ việc sử dụng convolution với các kernel nhỏ đến cực điểm: bằng cách giảm kích thước kernel xuống 1 × 1 và việc này biến các phép convolution thành phép nhân ma trận dense tiêu chuẩn được áp dụng độc lập cho từng vị trí không gian.
8138,E:\DATN\dataframe\train_file\83.txt,"Tuy vậy chỉ riêng sửa đổi này không cho phép tổng hợp thông tin không gian và để bù lại, nhóm tác giả áp dụng phép nhân ma trận dense được áp dụng cho mọi đối tượng trên tất cả các vị trí không gian."
8139,E:\DATN\dataframe\train_file\83.txt,"Điểm này khiến cho MLP-Mixer khác với các loại kiến trúc mạng khác khi thay vì dùng các thành phần convolution hay cơ chế self-attention, Mixer sử dụng MixerLayer được tạo nên bằng cách sử dụng hai loại MLP như sau:"
8140,E:\DATN\dataframe\train_file\83.txt,Channel-mixing MLP: cho phép giao tiếp giữa các channel khác nhau; chúng hoạt động trên từng token một cách độc lập và lấy các hàng riêng lẻ của bảng làm đầu vào.
8141,E:\DATN\dataframe\train_file\83.txt,Token-mixing MLP: cho phép giao tiếp giữa các vị trí không gian khác nhau (token); chúng hoạt động trên từng channel độc lập và lấy các cột riêng lẻ của bảng làm đầu vào.
8142,E:\DATN\dataframe\train_file\83.txt,Hai loại lớp này được xen kẽ để cho phép tương tác của cả hai thứ nguyên đầu vào là theo từng token và theo từng channel và tạo nên một MixerLayer.
8143,E:\DATN\dataframe\train_file\83.txt,"Quay trở lại với hình minh họa, ta có thể thấy rằng trong mỗi MixerLayer, bảng dữ liệu đầu vào sau khi qua một LayerNorm sẽ được chuyển vị và truyền qua các token-mixing MLP với theo từng channel sau đó tiếp tục được chuyển vị về kích thước cũ và truyền qua các channel-mixing MLP sau khi đã truyền qua một LayerNorm thứ hai."
8144,E:\DATN\dataframe\train_file\83.txt,"Bên cạnh đó, trước mỗi LayerNorm luôn có skip-connections, là một kĩ thuật được đã giới thiệu tại paper , cho phép đào tạo các mạng thần kinh rất sâu với hàng trăm lớp và được cải thiện hơn nữa hiệu suất."
8145,E:\DATN\dataframe\train_file\83.txt,Phần mã dưới đây thể hiện cách thức cài đặt của MixerLayer.
8146,E:\DATN\dataframe\train_file\83.txt,"Có thể thấy rằng cấu trúc của MixerLayer được cài đặt đầy đủ trong class MixerBlock (không giống như repo nào đấy của Yolov4 treo đầu dê bán thịt chó, trong paper có PAN mà tìm không thấy đâu) khi mà mỗi MixerBlock có hai LayerNorm trước mỗi lớp MLP cũng như cài đặt mã phục vụ cho quá trình skip-connections ."
8147,E:\DATN\dataframe\train_file\83.txt,"Cuối cùng, thành phần nhỏ nhấn được thể hiện trong hình minh họa là các khối MLP."
8148,E:\DATN\dataframe\train_file\83.txt,Chúng được cấu tạo bởi hai lớp fully-connected và một hàm kích hoạt phi tuyến tính được áp dụng độc lập cho mỗi hàng của tensor dữ liệu đầu vào cụ thể là hàm GELU có công thức là
8149,E:\DATN\dataframe\train_file\83.txt,\text{GELU}\left(x\right) = x{P}\left(X\leq{x}\right) = x\Phi\left(x\right) = x \cdot \frac{1}{2}\left[1 + \text{erf}(x/\sqrt{2})\right]
8150,E:\DATN\dataframe\train_file\83.txt,GELU(x)=xP(X≤x)=xΦ(x)=x⋅
8151,E:\DATN\dataframe\train_file\83.txt,[1+erf(x/
8152,E:\DATN\dataframe\train_file\83.txt,Mã cài đặt của chúng được thể hiện trong hình dưới đây:
8153,E:\DATN\dataframe\train_file\83.txt,So sánh với các kiến trúc khác
8154,E:\DATN\dataframe\train_file\83.txt,"Do ý tưởng thiết kế được bắt nguồn từ ý tưởng từ các tài liệu trên Convolutional Neural Network và Transformers, MLP-Mixer có một số điểm tương đồng cũng như khác biệt với hai kiểu kiến trúc trên."
8155,E:\DATN\dataframe\train_file\83.txt,"Đầu tiên, các token-mixing MLP hoạt động trên từng channel độc lập và lấy các cột riêng lẻ của bảng làm đầu vào."
8156,E:\DATN\dataframe\train_file\83.txt,"Ràng buộc các tham số của channel-mixing MLP (trong mỗi lớp) là một lựa chọn tự nhiên — nó cung cấp bất biến vị trí (nguyên văn là positional invariance, thể hiện việc ta có thể phát hiện và phân lớp các đối tượng kể cả khi vị trí chúng được thay đổi) vốn là một tính năng nổi bật của việc sử dụng convolution."
8157,E:\DATN\dataframe\train_file\83.txt,"Tuy vậy, việc ràng buộc các thông số trên các channel ít được sử dụng hơn."
8158,E:\DATN\dataframe\train_file\83.txt,"Ví dụ như việc lấy separable convolution, được sử dụng trong một số kiến trúc CNN, thường được thực hiện bằng cách áp dụng áp dụng convolution cho từng channel độc lập, sử dụng một kernel khác nhau để áp dụng cho mỗi channel."
8159,E:\DATN\dataframe\train_file\83.txt,Điều này không giống như các token-mixing MLP trong Mixer khi chúng chia sẻ cùng một kernel (của receptive fied) cho tất cả các channel.
8160,E:\DATN\dataframe\train_file\83.txt,"Do đó như được trình bày trong paper, điều này dẫn đến việc ràng buộc tham số đã ngăn không cho kiến trúc không phát triển quá nhanh khi tăng kích thước bảng dữ liệu và giúp đến tiết kiệm bộ nhớ đáng kể."
8161,E:\DATN\dataframe\train_file\83.txt,"Cuối cùng, mỗi lớp trong Mixer (ngoại trừ lớp chiếu các phần ảnh đầu vào ban đầu) nhận một đầu vào có cùng kích thước."
8162,E:\DATN\dataframe\train_file\83.txt,"Thiết kế ""đẳng hướng"" này gần giống với Transformer hoặc các kiến trúc RNN sâu khác."
8163,E:\DATN\dataframe\train_file\83.txt,"Điều này không giống như hầu hết các kiến trúc mạng tích chập khi các kiến trúc mạng này có cấu trúc hình chóp: các lớp sâu hơn có đầu vào độ phân giải thấp hơn, nhưng nhiều channel hơn."
8164,E:\DATN\dataframe\train_file\83.txt,"Và hơn nữa, không giống như kiến trúc ViT, Mixer không sử dụng embedding cho thông tin vị trí bởi các token-mixing MLP có thông tin về thứ tự các token đầu vào và do đó nó có thể học thể hiện thông tin vị trí."
8165,E:\DATN\dataframe\train_file\83.txt,Kết quả thực nghiệm
8166,E:\DATN\dataframe\train_file\83.txt,"Để chứng minh hiệu năng của kiến trúc mô hình này, nhóm tác giả đã thực nghiệm trên các một số bộ dữ liệu lớn."
8167,E:\DATN\dataframe\train_file\83.txt,Kết quả thu được như sau được thể hiện ở hình được trích từ paper dưới đây thể hiện các thông tin về độ chính xác và tài nguyên được sử dụng khi so sánh Mixer với các mô hình hiện đại khác.
8168,E:\DATN\dataframe\train_file\83.txt,"Các cột “ImNet” và “ReaL” đề cập đến các nhãn xác thực ImageNet ban đầu và các nhãn ReaL đã được làm sạch trong khi đó “Avg 5 ”là viết tắt của hiệu suất trung bình trên tất cả năm tác vụ ImageNet, CIFAR-10, CIFAR-100, Pets, Flowers."
8169,E:\DATN\dataframe\train_file\83.txt,"Mặc dù hoạt động không tốt khi train từ đầu trên mageNet-1k, Mixer đạt được hiệu suất tổng thể khá cao (84,15% top-1 trên ImageNet) khi được pre-trained trên ImageNet-21k với Regularization bổ sung, mặc dù hơi kém so với các mô hình khác."
8170,E:\DATN\dataframe\train_file\83.txt,"Regularization trong trường hợp này là cần thiết và Mixer sẽ bị overfit nếu không sử dụng nó, và theo nhóm tác giả, điều này phù hợp với các quan sát tương tự đối với ViT."
8171,E:\DATN\dataframe\train_file\83.txt,"Khi kích thước của tập dữ liệu tăng lên, hiệu suất của Mixer sẽ cải thiện đáng kể."
8172,E:\DATN\dataframe\train_file\83.txt,"Đặc biệt, Mixer-H/14 đạt độ chính xác top-1 là 87,94% trên ImageNet, tốt hơn 0,5% so với BiTResNet152x4 và chỉ thấp hơn 0,5% so với ViT-H/14."
8173,E:\DATN\dataframe\train_file\83.txt,"Đáng chú ý, Mixer-H/14 chạy nhanh hơn 2,5 lần so với ViT-H/14 và gần như gấp đôi BiT."
8174,E:\DATN\dataframe\train_file\83.txt,"Tuy được tuyên bố như vậy trong paper, có một số ý kiến khác được đưa ra khi thảo luận về về MLP-Mixer."
8175,E:\DATN\dataframe\train_file\83.txt,cho rằng MLP-Mixer sẽ không hoạt động hiệu quả trên các tập dữ liệu với kích thước nhỏ hơn.
8176,E:\DATN\dataframe\train_file\83.txt,"Thậm chí,  cho rằng việc sử dụng MLP trong MLP-Mixer không phải quá độc đáo và kiến trúc này không có tiềm năng đáng kể vì các lớp được kết nối đầy đủ đã là một phần của kiến trúc CNN ngay từ đầu (LeNet) nhưng đã dần bị loại bỏ theo thời gian."
8177,E:\DATN\dataframe\train_file\83.txt,"Bằng cách giới hạn các tương tác đến ""chỉ giữa các vị trí không gian"", các bậc tự do được giảm xuống mức mà bây giờ MLP-Mixer chỉ cần 100 triệu hình ảnh tiền đào tạo hoặc 1 triệu hình ảnh tiền đào tạo và Regularization để đạt được kết quả gần như SOTA."
8178,E:\DATN\dataframe\train_file\83.txt,"Một số khác cũng cho rằng bên cạnh việc đòi hỏi quá nhiều dữ liệu, đi kèm với độ lớn của model và dữ liệu là đòi hỏi năng lực tính toán rất lớn."
8179,E:\DATN\dataframe\train_file\83.txt,"Do là miếng gạch đầu tiên đặt vào một hướng đi mới nhằm giải quyết các bài toán thị giác máy, MLP-Mixer có kiến trúc khá đơn giản và bên cạnh đó còn khá nhiều vấn đề cần được giải quyết như việc cần quá nhiều dữ liệu để huấn luyện cũng như cần có khả năng tính toán tương xứng với kích thước của mô hình, vốn được cho rằng khá lớn so với các kiến trúc mạng khác."
8180,E:\DATN\dataframe\train_file\83.txt,"Trên hết, theo nhóm tác giả đề cập trong paper, họ hy vọng rằng kết quả nghiên cứu này sẽ thúc đẩy các nghiên cứu sâu hơn, vượt ra ngoài lĩnh vực của các mô hình đã được thiết lập dựa trên convolution và self-attention và sẽ đặc biệt thú vị khi xem liệu một thiết kế như vậy có hoạt động trong NLP hay các miền khác hay không."
8181,E:\DATN\dataframe\train_file\83.txt,Bài viết đến đây là kết thúc cảm ơn mọi người đã giành thời gian đọc.
8182,E:\DATN\dataframe\train_file\83.txt,Tài liệu tham khảo
8183,E:\DATN\dataframe\train_file\84.txt,Tìm hiểu về Text Steganography
8184,E:\DATN\dataframe\train_file\84.txt,Steganography là gì ?
8185,E:\DATN\dataframe\train_file\84.txt,"Nếu là một fan trinh thám hay các văn hóa phẩm về điệp viên, chắc hẳn bạn không còn lạ gì với việc truyền tin bằng những đoạn tin quảng cáo tưởng như rất bình thường trên báo, với mật mã ""hình nhân nhảy múa"" trong Sherlock Holmes, hay gần gũi nhất là hồi nhỏ chúng ta thử nghiệm mực vô hình: dùng nước chanh viết lên giấy, đợi khô rồi hơ nóng, thông điệp viết bằng nước chanh sẽ dần hiện ra."
8186,E:\DATN\dataframe\train_file\84.txt,Những ví dụ trên đều là một hình thức của Steganography.
8187,E:\DATN\dataframe\train_file\84.txt,"Nói đơn giản là chúng ta sẽ tạo ra một loại thông điệp hoặc mật mã mà người ngoài nhìn vào, không những không giải được mà còn không nhận ra được rằng nó có ẩn chứa một thông điệp bí mật - ""The art of disguise is knowing how to hide in plain sight"""
8188,E:\DATN\dataframe\train_file\84.txt,Theo định nghĩa từ Wikipedia:
8189,E:\DATN\dataframe\train_file\84.txt,"Steganography (Kỹ thuật giấu tin hay kỹ thuật giấu thư, kỹ thuật ẩn mã) là nghệ thuật và khoa học về việc viết và chuyển tải các thông điệp một cách bí mật, sao cho ngoại trừ người gửi và người nhận, không ai biết đến sự tồn tại của thông điệp, là một dạng của bảo mật bằng cách che giấu."
8190,E:\DATN\dataframe\train_file\84.txt,"Từ steganography có gốc Hy lạp có nghĩa là ""giấu tin"" kết hợp từ hai từ steganos (στεγανός) nghĩa là ""ẩn nấp để bảo vệ"" và graphein (γράφειν) nghĩa là ""viết""."
8191,E:\DATN\dataframe\train_file\84.txt,"Trong không gian số, steganography tồn tại dưới dạng file, lời nhắn, hình ảnh hoặc đoạn video được ẩn giấu trong một file/ lời nhắn/ hình ảnh hoặc video khác."
8192,E:\DATN\dataframe\train_file\84.txt,Các file media là lớp vỏ bọc (cover) lý tưởng để giấu tin vì chúng có kích thước lớn.
8193,E:\DATN\dataframe\train_file\84.txt,"Ví dụ người gửi có thể thay đổi thành phần màu sắc của một số pixel trên tấm ảnh tương ứng với các ký tự trong bảng chữ cái, sự thay đổi này rất nhỏ đến mức không thể nhận ra bằng mắt thường."
8194,E:\DATN\dataframe\train_file\84.txt,"Trong hai hình phía dưới, hình bên trái là stego image - hình ảnh đã được cài ""thông điệp"" bí mật bằng cách xử lý color component của từng pixel."
8195,E:\DATN\dataframe\train_file\84.txt,"Hình bên phải là ""thông điệp"" sau khi được extract ra."
8196,E:\DATN\dataframe\train_file\84.txt,"Như vậy chắc các bạn cũng đã nhận ra ưu điểm của steganography so với cryptography (mã hóa thông tin), đó là nó sẽ không thu hút sự chú ý. Một mật mã dù mạnh đến đâu, cũng vẫn sẽ bị để ý đến hoặc tìm cách phá giải, thậm chí bị coi là phạm pháp ở một số quốc gia."
8197,E:\DATN\dataframe\train_file\84.txt,"Đặt trong bối cảnh ngày nay, thời đại mà thông tin trao đổi qua lại của chúng ta trở thành mỏ vàng cho các công ty quảng cáo, thời đại mà tự do ngôn luận ở một số quốc gia lại là điều xa xỉ, thời đại mà ""Big Brother is watching you"" không phải chỉ dừng lại ở một viễn cảnh, thì steganography lại càng trở nên đáng được quan tâm hơn bao giờ hết."
8198,E:\DATN\dataframe\train_file\84.txt,Text Steganography
8199,E:\DATN\dataframe\train_file\84.txt,"Như đã nói ở trên, có rất nhiều phương tiện có thể dùng để làm vật trung gian mang tin: file, audio, hình ảnh, video, vv."
8200,E:\DATN\dataframe\train_file\84.txt,Nhưng trong cuộc sống hàng ngày thì văn bản (text) chính là phương tiện truyền tin phổ biến nhất.
8201,E:\DATN\dataframe\train_file\84.txt,"Tuy nhiên so với các file media thì text có mức độ mã hóa thông tin cao hơn dẫn đến ít thông tin dư thừa (redundant information) hơn, làm cho việc giấu thông tin trong đó khó hơn rất nhiều."
8202,E:\DATN\dataframe\train_file\84.txt,"Trong phạm vi bài viết này, mình sẽ tìm hiểu về bài toán steganography với định dạng text cũng như một số kỹ thuật giấu tin (generation-based) trong văn bản được phát triển trong thời gian gần đây."
8203,E:\DATN\dataframe\train_file\84.txt,Đặt vấn đề
8204,E:\DATN\dataframe\train_file\84.txt,Giả sử A muốn gửi cho B một tin nhắn chứa thông tin nhạy cảm qua một kênh được giám sát bởi C. Kênh này có thể được sử dụng chung để liên lạc bởi nhiều bên khác nhau.
8205,E:\DATN\dataframe\train_file\84.txt,Thông tin được truyền đi trong kênh là văn bản chứa ngôn ngữ tự nhiên (natural language).
8206,E:\DATN\dataframe\train_file\84.txt,"A vừa phải đảm bảo chỉ có mình B hiểu được nội dung tin nhắn, vừa phải tránh gửi những nội dung ""mất tự nhiên"" có thể khiến C nghi ngờ."
8207,E:\DATN\dataframe\train_file\84.txt,Vậy A và B có thể thực hiện các bước như sau:
8208,E:\DATN\dataframe\train_file\84.txt,"A mã hóa nội dung tin nhắn thành một đoạn văn bản mã hóa (ciphertext), key để mã hóa được nắm giữ bởi cả A và B"
8209,E:\DATN\dataframe\train_file\84.txt,A giấu đoạn ciphertext (thường là một chuỗi các bit) vào trong một tin nhắn dưới dạng ngôn ngữ tự nhiên bình thường (stegotext)
8210,E:\DATN\dataframe\train_file\84.txt,A gửi đoạn stegotext qua kênh liên lạc do C giám sát
8211,E:\DATN\dataframe\train_file\84.txt,B nhận được và trích xuất ra ciphertext
8212,E:\DATN\dataframe\train_file\84.txt,B giải mã đoạn ciphertext với key chung để lấy được thông tin mật.
8213,E:\DATN\dataframe\train_file\84.txt,Mô hình tổng quát của bài toán giấu tin được thể hiện như sau:
8214,E:\DATN\dataframe\train_file\84.txt,Trong đó:
8215,E:\DATN\dataframe\train_file\84.txt,m là tin nhắn bí mật (thường được mã hóa thành một một chuỗi các bit tuân theo phân phối đều (uniform distribution)
8216,E:\DATN\dataframe\train_file\84.txt,y là đoạn cover text - stegotext
8217,E:\DATN\dataframe\train_file\84.txt,q(y) là phân phối xác suất của y
8218,E:\DATN\dataframe\train_file\84.txt,f là một hàm khả nghịch dùng để biến đổi m thành y
8219,E:\DATN\dataframe\train_file\84.txt,Cả A và B đều sử dụng cùng một mô hình ngôn ngữ
8220,E:\DATN\dataframe\train_file\84.txt," trong quá trình encode, giấu tin và decode"
8221,E:\DATN\dataframe\train_file\84.txt,Như vậy ta có thể thấy quá trình này liên quan đến hai công đoạn chính: (1) mã hóa đoạn tin cần chuyển đi và (2) giấu nó vào trong một đoạn văn bản bình thường.
8222,E:\DATN\dataframe\train_file\84.txt,Vậy để hệ thống steganography hoạt động hiệu quả thì hai công đoạn này cần phải đạt những mục tiêu nào?
8223,E:\DATN\dataframe\train_file\84.txt,"Hay nói cách khác, có những metrics nào để đánh giá tính hiệu quả của của một phương pháp giấu tin?"
8224,E:\DATN\dataframe\train_file\84.txt,Evaluation metrics
8225,E:\DATN\dataframe\train_file\84.txt,Perplexity là thước đo đánh giá chất lượng của một mô hình ngôn ngữ (language model).
8226,E:\DATN\dataframe\train_file\84.txt,"Giả sử khi chúng ta xây dựng một mô hình ngôn ngữ từ một tập mẫu câu, ta sẽ giữ lại một tập câu để test (held-out):"
8227,E:\DATN\dataframe\train_file\84.txt,"x^{(1)}, x^{(2)}, ..., x^{(m)}"
8228,E:\DATN\dataframe\train_file\84.txt,Với mỗi câu
8229,E:\DATN\dataframe\train_file\84.txt," trong tập test, ta có thể tính được xác suất"
8230,E:\DATN\dataframe\train_file\84.txt,) của nó bằng mô hình ngôn ngữ vừa được xây dựng.
8231,E:\DATN\dataframe\train_file\84.txt,Như vậy chất lượng của mô hình có thể được tính bằng xác suất của tất cả các câu trong test set:
8232,E:\DATN\dataframe\train_file\84.txt,Giá trị này càng cao thì có nghĩa là mô hình ngôn ngữ hoạt động càng tốt: mô hình ít bị bất ngờ đối với những câu chưa từng xuất hiện.
8233,E:\DATN\dataframe\train_file\84.txt,Lấy log cơ số 2 của giá trị này chia trung bình cho số từ vựng có trong bộ test
8234,E:\DATN\dataframe\train_file\84.txt,M = \sum_{i=1}^{m}n_{i}
8235,E:\DATN\dataframe\train_file\84.txt,M=∑
8236,E:\DATN\dataframe\train_file\84.txt, là số từ trong câu
8237,E:\DATN\dataframe\train_file\84.txt, ) ta có:
8238,E:\DATN\dataframe\train_file\84.txt,\frac{1}{M}\sum_{i=1}^{m}\log_{2}p(x^{(i)}) = l
8239,E:\DATN\dataframe\train_file\84.txt,Ta có Perplexity được tính bằng công thức sau:
8240,E:\DATN\dataframe\train_file\84.txt,2^{-l}
8241,E:\DATN\dataframe\train_file\84.txt,−l
8242,E:\DATN\dataframe\train_file\84.txt,Vậy: Perplexity càng thấp tương ứng với chất lượng của language model càng cao.
8243,E:\DATN\dataframe\train_file\84.txt,Metric này dùng để đánh giá hệ thống giấu tin xây dựng trên mạng LSTM dựa trên tập dataset có sẵn.
8244,E:\DATN\dataframe\train_file\84.txt,"Mục đích của nó là đánh giá xem đoạn stegotext sinh ra có ""tự nhiên"", có đúng ngữ pháp hay không, vv."
8245,E:\DATN\dataframe\train_file\84.txt,"Còn đối với những cách tiếp cận mới hơn dùng mô hình ngôn ngữ pretrained (ví dụ GPT-2), đồng thời để đánh giá xem hệ thống giấu tin có ""đánh lừa"" được những phần mềm được tạo ra để phát hiện điều bất thường (thường dựa trên phân phối xác suất của đoạn văn bản được sinh ra) thì chúng ta cần sử dụng metrics thứ 2 dưới đây."
8246,E:\DATN\dataframe\train_file\84.txt,KL Divergence
8247,E:\DATN\dataframe\train_file\84.txt,Một metrics nữa thường dùng để đo lường tính hiệu quả của mô hình steganography là KL Divergence.
8248,E:\DATN\dataframe\train_file\84.txt,Cụ thể là
8249,E:\DATN\dataframe\train_file\84.txt,(q∣∣P
8250,E:\DATN\dataframe\train_file\84.txt," là phân phối xác suất thực tế của ngôn ngữ tự nhiên,"
8251,E:\DATN\dataframe\train_file\84.txt,q là phân phối xác suất của stegotext
8252,E:\DATN\dataframe\train_file\84.txt,y được tạo ra bởi thuật toán.
8253,E:\DATN\dataframe\train_file\84.txt,Tuy nhiên vì không thể tính toán được
8254,E:\DATN\dataframe\train_file\84.txt, nên người ta sẽ tính
8255,E:\DATN\dataframe\train_file\84.txt,(q∣∣P
8256,E:\DATN\dataframe\train_file\84.txt, là phân phối của mô hình ngôn ngữ được sử dụng khi generate stegotext.
8257,E:\DATN\dataframe\train_file\84.txt,D_{KL} = 0
8258,E:\DATN\dataframe\train_file\84.txt,=0 có nghĩa là hệ thống là an toàn tuyệt đối vì người/ công cụ giám sát không thể phân biệt được sự khác nhau giữa văn bản ngôn ngữ tự nhiên với stegotext.
8259,E:\DATN\dataframe\train_file\84.txt,Như vậy mục tiêu về mặt an ninh của mô hình steganography là đảm bảo
8260,E:\DATN\dataframe\train_file\84.txt," nhỏ, tức là phân phối của"
8261,E:\DATN\dataframe\train_file\84.txt,q càng gần với phân phối
8262,E:\DATN\dataframe\train_file\84.txt, càng tốt.
8263,E:\DATN\dataframe\train_file\84.txt,"Để đánh giá tính hiệu quả về mặt nén dữ liệu của mô hình, người ta sử dụng tỷ số bits/word."
8264,E:\DATN\dataframe\train_file\84.txt,Tỷ lệ này được tính bằng số bit của message đầu vào sau khi được mã hóa (ciphertext) chia cho số từ ở đầu ra (stegotext).
8265,E:\DATN\dataframe\train_file\84.txt,Tức là trong một đoạn text đầu ra có thể chứa được nhiều hay ít thông tin cần truyền đi.
8266,E:\DATN\dataframe\train_file\84.txt,Encoding techniques
8267,E:\DATN\dataframe\train_file\84.txt,Trong phần này mình sẽ giới thiệu một số phương pháp encode - giấu tin thường được sử dụng
8268,E:\DATN\dataframe\train_file\84.txt,(được giới thiệu trong paper )
8269,E:\DATN\dataframe\train_file\84.txt,B1: Mã hóa thông tin cần giấu thành một chuỗi bit
8270,E:\DATN\dataframe\train_file\84.txt,m (cách đơn giản nhất có thể dùng ASCII coding map)
8271,E:\DATN\dataframe\train_file\84.txt,B2: Chia chuỗi
8272,E:\DATN\dataframe\train_file\84.txt,m thành các bit block nhỏ hơn với độ dài
8273,E:\DATN\dataframe\train_file\84.txt,"∣B∣, như vậy sẽ có tổng cộng"
8274,E:\DATN\dataframe\train_file\84.txt,∣B∣
8275,E:\DATN\dataframe\train_file\84.txt,∣m∣
8276,E:\DATN\dataframe\train_file\84.txt, bit block.
8277,E:\DATN\dataframe\train_file\84.txt,Ví dụ nếu
8278,E:\DATN\dataframe\train_file\84.txt,m = 100001 và
8279,E:\DATN\dataframe\train_file\84.txt,"∣B∣=2 thì ta sẽ có các bit block là 10, 00, 01."
8280,E:\DATN\dataframe\train_file\84.txt,"B3: Tạo bộ key chung của người gửi và người nhận: Ta có bộ từ vựng V bao gồm tất cả các token (từ, dấu câu, vv.)"
8281,E:\DATN\dataframe\train_file\84.txt,có thể xuất hiện.
8282,E:\DATN\dataframe\train_file\84.txt,Chia random bộ từ vựng thành
8283,E:\DATN\dataframe\train_file\84.txt,∣B∣
8284,E:\DATN\dataframe\train_file\84.txt," bins (thùng chứa), mỗi bin ("
8285,E:\DATN\dataframe\train_file\84.txt,) tương ứng với một bit block và chứa
8286,E:\DATN\dataframe\train_file\84.txt,∣B∣
8287,E:\DATN\dataframe\train_file\84.txt,∣V∣
8288,E:\DATN\dataframe\train_file\84.txt,∣V∣ là số từ trong bộ từ vựng)
8289,E:\DATN\dataframe\train_file\84.txt,"B4: Dựa trên chuỗi bit block ở B2, ta sẽ sử dụng mô hình LSTM để sinh ra các câu."
8290,E:\DATN\dataframe\train_file\84.txt,Với mỗi bit block
8291,E:\DATN\dataframe\train_file\84.txt,"B, mô hình LSTM sẽ lựa chọn một token cất trong bin"
8292,E:\DATN\dataframe\train_file\84.txt,"Mạng LSTM bị giới hạn chỉ có thể chọn token từ trong một bin nhất định tuy nhiên một bin có thể chứa lượng token đủ phong phú để đoạn văn bản được sinh ra trông ""tự nhiên""."
8293,E:\DATN\dataframe\train_file\84.txt,Ví dụ một đoạn text được gen ra từ chuỗi “1000011011” và key ở bảng trên:
8294,E:\DATN\dataframe\train_file\84.txt,"Để tăng tính tự nhiên và linh hoạt của đoạn văn bản được sinh ra, ta có thể thêm cùng một tập common-token vào tất cả các bin."
8295,E:\DATN\dataframe\train_file\84.txt,"Khi mạng LSTM chọn phải một common token trong một bin, ta sẽ bắt nó chọn thêm một token từ chính bin đó cho đến khi chọn được một token không thuộc tập common token."
8296,E:\DATN\dataframe\train_file\84.txt,"Ngày nay khi các mô hình ngôn ngữ pretrained phát triển ngày càng mạnh mẽ và chính xác, ta có thể thay thế mạng LSTM trong việc lựa chọn token ở bước này bằng cách chọn trong bin"
8297,E:\DATN\dataframe\train_file\84.txt, token được xác định là có likelihood cao nhất theo mô hình ngôn ngữ.
8298,E:\DATN\dataframe\train_file\84.txt,Variable-length coding (VLC) - Huffman + patient Huffman
8299,E:\DATN\dataframe\train_file\84.txt,Thay vì fixed-length coding (một stegotext token chỉ encode
8300,E:\DATN\dataframe\train_file\84.txt,"∣B∣ bits) như ở phần 2.1., thuật toán VLC (Huffman coding) có thể encode nhiều hơn 1 bit trong mỗi token được sinh ra."
8301,E:\DATN\dataframe\train_file\84.txt,"Ngoài ra thì để cải thiện KL Divergence của stegotext, thuật toán patient-Huffman cũng đã được phát triển."
8302,E:\DATN\dataframe\train_file\84.txt,(được giới thiệu trong paper )
8303,E:\DATN\dataframe\train_file\84.txt,Điểm mới của patient-Huffman là đưa vào giá trị ngưỡng
8304,E:\DATN\dataframe\train_file\84.txt,δ: tại mỗi bước encode ta sẽ kiểm tra xem KL divergence (hoặc total variance distance) giữa
8305,E:\DATN\dataframe\train_file\84.txt, và phân phối của cây Huffman có đủ nhỏ không.
8306,E:\DATN\dataframe\train_file\84.txt,Nếu giá trị này lớn hơn một ngưỡng
8307,E:\DATN\dataframe\train_file\84.txt,δ nhất định thì ta sẽ sinh ra token tiếp theo dựa vào phân phối của
8308,E:\DATN\dataframe\train_file\84.txt," thay vì phân phối Huffman và ""kiên nhẫn"" đợi thời cơ tiếp theo."
8309,E:\DATN\dataframe\train_file\84.txt,Tại mỗi bước encoding:
8310,E:\DATN\dataframe\train_file\84.txt,B1: Từ language model và prefix
8311,E:\DATN\dataframe\train_file\84.txt,"h là phần prefix tức kết quả đã được encode trước đó), tính toán được phân phối xác suất"
8312,E:\DATN\dataframe\train_file\84.txt,p cho token tiếp theo
8313,E:\DATN\dataframe\train_file\84.txt,B2: Xây dựng cây Huffman
8314,E:\DATN\dataframe\train_file\84.txt,c cho phân phối
8315,E:\DATN\dataframe\train_file\84.txt,"p () Theo phân phối Huffman mới, mỗi token nằm tại tầng thứ"
8316,E:\DATN\dataframe\train_file\84.txt,r sẽ có hàm khối xác suất (probability mass) là
8317,E:\DATN\dataframe\train_file\84.txt,B3: Tính TVD (hoặc KL divergence) giữa
8318,E:\DATN\dataframe\train_file\84.txt,p và phân phối Huffman tương ứng
8319,E:\DATN\dataframe\train_file\84.txt,Nếu TVD (hoặc KL divergence) >
8320,E:\DATN\dataframe\train_file\84.txt,δ thì sample ra một token
8321,E:\DATN\dataframe\train_file\84.txt,w theo phân phối
8322,E:\DATN\dataframe\train_file\84.txt,Nếu TVD (hoặc KL divergence) <
8323,E:\DATN\dataframe\train_file\84.txt,δ thì chúng ta sẽ sample ra token mới
8324,E:\DATN\dataframe\train_file\84.txt,w theo cây Huffman
8325,E:\DATN\dataframe\train_file\84.txt,c bằng cách tuân theo chuỗi bit
8326,E:\DATN\dataframe\train_file\84.txt,"m. Bắt đầu từ gốc, nếu gặp bit 0 thì rẽ nhánh bên trái và rẽ nhánh phải nếu gặp bit 1, cho đến khi gặp một lá (leaf)"
8327,E:\DATN\dataframe\train_file\84.txt,B5: Nối token mới
8328,E:\DATN\dataframe\train_file\84.txt,w với prefix
8329,E:\DATN\dataframe\train_file\84.txt,Arithmetic coding - mã hóa số học
8330,E:\DATN\dataframe\train_file\84.txt,(được giới thiệu trong paper )
8331,E:\DATN\dataframe\train_file\84.txt,Arithmetic coding là một phương pháp nén dữ liệu chuyên dùng để mã hóa các chuỗi với phân phối đã biết.
8332,E:\DATN\dataframe\train_file\84.txt,"Trong phương pháp mã hóa số học truyền thống, một chuỗi các phần tử sẽ được map với một chuỗi nhị phân phân phối đều (uniformly distributed)."
8333,E:\DATN\dataframe\train_file\84.txt,"Để sử dụng phương pháp này trong steganography, chúng ta đảo ngược thứ tự: một đoạn mã có sẵn (uniformly sampled) sẽ được map với một chuỗi các từ."
8334,E:\DATN\dataframe\train_file\84.txt,"B1: Phương thức mã hóa được mô hình hóa trong hình trên (hình minh họa, trong thực tế phân phối xác suất của các từ sẽ được lấy từ xác suất có điều kiện trong một mô hình ngôn ngữ pre-trained)."
8335,E:\DATN\dataframe\train_file\84.txt,"Các đường tròn đồng tâm thể hiện các bước timestep (trong cùng là t=1, rồi lần lượt là t=2, t=3, vv.)."
8336,E:\DATN\dataframe\train_file\84.txt,Mỗi đường tròn thể hiện xác suất có điều kiện
8337,E:\DATN\dataframe\train_file\84.txt,p(yt∣y<t).
8338,E:\DATN\dataframe\train_file\84.txt,Ví dụ: cho
8339,E:\DATN\dataframe\train_file\84.txt,"y1 = ""Once"" thì"
8340,E:\DATN\dataframe\train_file\84.txt,"p(y2∣y1) có ""upon"" và ""I"" là hai token duy nhất với xác suất bằng nhau."
8341,E:\DATN\dataframe\train_file\84.txt,"Sơ đồ hình tròn biểu diễn đoạn [0,1) với mốc 0 ở trên cùng."
8342,E:\DATN\dataframe\train_file\84.txt,B2: Mã hóa thông tin cần giấu thành một chuỗi bit
8343,E:\DATN\dataframe\train_file\84.txt,m sẽ được coi như một biểu diễn dưới dạng nhị phân của một phân số trong đoạn
8344,E:\DATN\dataframe\train_file\84.txt,0\leq m<1
8345,E:\DATN\dataframe\train_file\84.txt,0≤m<1.
8346,E:\DATN\dataframe\train_file\84.txt,Phân số này sẽ biểu diễn một điểm duy nhất trên đường tròn cũng như một đường thẳng duy nhất nối từ tâm đến điểm đó.
8347,E:\DATN\dataframe\train_file\84.txt,B3: Bước encoding được thực hiện bằng cách lấy các token mà đường thẳng nói trên đi qua
8348,E:\DATN\dataframe\train_file\84.txt,Như vậy ta có thể áp dụng phương thức này để tạo ra các đoạn stegotext dựa vào context cho trước.
8349,E:\DATN\dataframe\train_file\84.txt,"Để đảm bảo đoạn text tạo ra được ""tự nhiên"" hơn, người ta có thể áp dụng các kỹ thuật như temperature sampling và top-k sampling."
8350,E:\DATN\dataframe\train_file\84.txt,"Các nghiên cứu đã cho thấy, phương pháp mã hóa hình học đạt hiệu quả tối ưu không chỉ trong nén dữ liệu (data compression) mà cả đối với kỹ thuật giấu tin."
8351,E:\DATN\dataframe\train_file\84.txt,"Giả sử phân phối đích mà ta muốn ""bắt chước"" là"
8352,E:\DATN\dataframe\train_file\84.txt,", thì khi áp dụng phương pháp trên cho chuỗi phân phối đều"
8353,E:\DATN\dataframe\train_file\84.txt,"m ban đầu, ta sẽ được một phân phối"
8354,E:\DATN\dataframe\train_file\84.txt,q mà
8355,E:\DATN\dataframe\train_file\84.txt,q = p_{s}
8356,E:\DATN\dataframe\train_file\84.txt,", hay nói cách khác là"
8357,E:\DATN\dataframe\train_file\84.txt,D_{KL}(q||p_{s}) = 0
8358,E:\DATN\dataframe\train_file\84.txt,(q∣∣p
8359,E:\DATN\dataframe\train_file\84.txt,)=0 đối với những câu dài.
8360,E:\DATN\dataframe\train_file\84.txt,H(q) = H(p_{s})
8361,E:\DATN\dataframe\train_file\84.txt,) và số bit trung bình dùng để mã hóa chính bằng entropy của
8362,E:\DATN\dataframe\train_file\84.txt,Như vậy trong bài này mình đã trình bày một số khái niệm cơ bản về kỹ thuật giấu tin - steganography cũng như giới thiệu qua một số phương pháp giấu tin bằng cách generate văn bản chưa tin mật.
8363,E:\DATN\dataframe\train_file\84.txt,Trong này những phần nặng hơn về toán mình cũng chưa có điều kiện để trình bày nên nếu quan tâm các bạn có thể đọc thêm trong từng paper nhé.
8364,E:\DATN\dataframe\train_file\85.txt,Những vấn đề liên quan đến dữ liệu ảnh trong Computer Vision
8365,E:\DATN\dataframe\train_file\85.txt,Như mọi người cũng biết data cực kỳ quan trọng đối với Machine learning vì vậy hôm nay mình sẽ chia sẻ xung quanh vấn đề ảnh.
8366,E:\DATN\dataframe\train_file\85.txt,Bài viết bao gồm các phần:
8367,E:\DATN\dataframe\train_file\85.txt,Lưu trữ Image
8368,E:\DATN\dataframe\train_file\85.txt,Các tool annotate data
8369,E:\DATN\dataframe\train_file\85.txt,Lưu trữ image
8370,E:\DATN\dataframe\train_file\85.txt,"Khi chúng ta nói về deep learning, thường thì điều đầu tiên xuất hiện là một lượng dữ liệu khổng lồ hoặc một số lượng lớn hình ảnhViệc lưu trữ cực kì đơn giản trong khi tập data của chúng ta chỉ có vài chục cho đến vài nghìn ảnh."
8371,E:\DATN\dataframe\train_file\85.txt,Tuy nhiên khi lượng ảnh của bạn càng lớn thì việc lưu trữ trên máy tính sẽ làm tốn diện tích bộ nhớ.
8372,E:\DATN\dataframe\train_file\85.txt,"ImageNet là một cơ sở dữ liệu hình ảnh nổi tiếng được tập hợp để training các mô hình về các nhiệm vụ như classification, detection, và segmentation và nó bao gồm hơn 14 triệu hình ảnh."
8373,E:\DATN\dataframe\train_file\85.txt,Sau đây mình sẽ chia sẻ cho các bạn 3 cách lưu trữ hình ảnh.
8374,E:\DATN\dataframe\train_file\85.txt,Lưu ở file .png trên disk
8375,E:\DATN\dataframe\train_file\85.txt,Với việc lưu trữ ở trên disk này bạn nên cài đặt pillow để đơn giản và hiệu quả hơn
8376,E:\DATN\dataframe\train_file\85.txt,$pip install pillow
8377,E:\DATN\dataframe\train_file\85.txt,Cách lưu trữ
8378,E:\DATN\dataframe\train_file\85.txt,from PIL import Image
8379,E:\DATN\dataframe\train_file\85.txt,import csv
8380,E:\DATN\dataframe\train_file\85.txt,"def store_single_disk(image, image_id, label):"
8381,E:\DATN\dataframe\train_file\85.txt,"    Image.fromarray(image).save(disk_dir / f""{image_id}.png"")"
8382,E:\DATN\dataframe\train_file\85.txt,"    with open(disk_dir / f""{image_id}.csv"", ""wt"") as csvfile:"
8383,E:\DATN\dataframe\train_file\85.txt,        writer = csv.writer(
8384,E:\DATN\dataframe\train_file\85.txt,"            csvfile, delimiter="" "", quotechar=""|"", quoting=csv.QUOTE_MINIMAL"
8385,E:\DATN\dataframe\train_file\85.txt,khi xử lý data được lưu ở trong disk chúng ta nên lưu trữ một file label riêng ra một file .csv để tránh hiện tượng phải mở hết tất cả các file mỗi lần chỉ cần đọ vài bức ảnh thôi.
8386,E:\DATN\dataframe\train_file\85.txt,Lưu trong lightning memory-mapped databases (LMDB)
8387,E:\DATN\dataframe\train_file\85.txt,LMDB là một hệ thống lưu trữ giá trị khóa trong đó mỗi mục được lưu trữ dưới dạng mảng byte.
8388,E:\DATN\dataframe\train_file\85.txt,Khóa sẽ là một định danh duy nhất cho mỗi hình ảnh và giá trị sẽ là chính hình ảnh đó.
8389,E:\DATN\dataframe\train_file\85.txt,LMDB được ánh xạ bộ nhớ.
8390,E:\DATN\dataframe\train_file\85.txt,"Điều này có nghĩa là nó trả về con trỏ trực tiếp đến địa chỉ bộ nhớ của cả khóa và giá trị, mà không cần sao chép bất cứ thứ gì trong bộ nhớ như hầu hết các cơ sở dữ liệu khác."
8391,E:\DATN\dataframe\train_file\85.txt,Cùng cài đặt LMDB và thử thôi nào
8392,E:\DATN\dataframe\train_file\85.txt,$ pip install lmdb
8393,E:\DATN\dataframe\train_file\85.txt,Ở đây chúng ta sẽ thử với tập  nhé
8394,E:\DATN\dataframe\train_file\85.txt,class CIFAR_Image:
8395,E:\DATN\dataframe\train_file\85.txt,"    def __init__(self, image, label):"
8396,E:\DATN\dataframe\train_file\85.txt,        # Dimensions of image for reconstruction - not really necessary
8397,E:\DATN\dataframe\train_file\85.txt,"        # for this dataset, but some datasets may include images of"
8398,E:\DATN\dataframe\train_file\85.txt,        # varying sizes
8399,E:\DATN\dataframe\train_file\85.txt,        self.channels = image.shape[2]
8400,E:\DATN\dataframe\train_file\85.txt,        self.size = image.shape[:2]
8401,E:\DATN\dataframe\train_file\85.txt,        self.image = image.tobytes()
8402,E:\DATN\dataframe\train_file\85.txt,        self.label = label
8403,E:\DATN\dataframe\train_file\85.txt,    def get_image(self):
8404,E:\DATN\dataframe\train_file\85.txt,"        """""" Returns the image as a numpy array. """""""
8405,E:\DATN\dataframe\train_file\85.txt,"        image = np.frombuffer(self.image, dtype=np.uint8)"
8406,E:\DATN\dataframe\train_file\85.txt,"        return image.reshape(*self.size, self.channels)"
8407,E:\DATN\dataframe\train_file\85.txt,import lmdb
8408,E:\DATN\dataframe\train_file\85.txt,import pickle
8409,E:\DATN\dataframe\train_file\85.txt,"def store_single_lmdb(image, image_id, label):"
8410,E:\DATN\dataframe\train_file\85.txt,    map_size = image.nbytes * 10
8411,E:\DATN\dataframe\train_file\85.txt,    # Create a new LMDB environment
8412,E:\DATN\dataframe\train_file\85.txt,"    env = lmdb.open(str(lmdb_dir / f""single_lmdb""), map_size=map_size)"
8413,E:\DATN\dataframe\train_file\85.txt,    # Start a new write transaction
8414,E:\DATN\dataframe\train_file\85.txt,    with env.begin(write=True) as txn:
8415,E:\DATN\dataframe\train_file\85.txt,        # All key-value pairs need to be strings
8416,E:\DATN\dataframe\train_file\85.txt,"        value = CIFAR_Image(image, label)"
8417,E:\DATN\dataframe\train_file\85.txt,"        key = f""{image_id:08}"""
8418,E:\DATN\dataframe\train_file\85.txt,"        txn.put(key.encode(""ascii""), pickle.dumps(value))"
8419,E:\DATN\dataframe\train_file\85.txt,Lưu dưới dạng (HDF5)
8420,E:\DATN\dataframe\train_file\85.txt,"Với HDF5 bạn có thể lưu trữ nhiều hơn 1 tập dữ liệu, bạn có thể chia nhỏ data rồi lưu trữ."
8421,E:\DATN\dataframe\train_file\85.txt,Cài đặt với pip trước nào:
8422,E:\DATN\dataframe\train_file\85.txt,$ pip install h5py
8423,E:\DATN\dataframe\train_file\85.txt,Tạo file hdf5:
8424,E:\DATN\dataframe\train_file\85.txt,import numpy as np
8425,E:\DATN\dataframe\train_file\85.txt,import h5py
8426,E:\DATN\dataframe\train_file\85.txt,data_order = 'tf'  #  'tf' for Tensorflow
8427,E:\DATN\dataframe\train_file\85.txt,# check the order of data and chose proper data shape to save image
8428,E:\DATN\dataframe\train_file\85.txt,"train_shape = (len(train_addrs), 224, 224, 3)"
8429,E:\DATN\dataframe\train_file\85.txt,"val_shape = (len(val_addrs), 224, 224, 3)"
8430,E:\DATN\dataframe\train_file\85.txt,"test_shape = (len(test_addrs), 224, 224, 3)"
8431,E:\DATN\dataframe\train_file\85.txt,# open a hdf5 file and create earrays
8432,E:\DATN\dataframe\train_file\85.txt,"hdf5_file = h5py.File(hdf5_path, mode='w')"
8433,E:\DATN\dataframe\train_file\85.txt,"hdf5_file.create_dataset(""train_img"", train_shape, np.int8)"
8434,E:\DATN\dataframe\train_file\85.txt,"hdf5_file.create_dataset(""val_img"", val_shape, np.int8)"
8435,E:\DATN\dataframe\train_file\85.txt,"hdf5_file.create_dataset(""test_img"", test_shape, np.int8)"
8436,E:\DATN\dataframe\train_file\85.txt,"hdf5_file.create_dataset(""train_mean"", train_shape[1:], np.float32)"
8437,E:\DATN\dataframe\train_file\85.txt,"hdf5_file.create_dataset(""train_labels"", (len(train_addrs),), np.int8)"
8438,E:\DATN\dataframe\train_file\85.txt,"hdf5_file[""train_labels""][...] = train_labels"
8439,E:\DATN\dataframe\train_file\85.txt,"hdf5_file.create_dataset(""val_labels"", (len(val_addrs),), np.int8)"
8440,E:\DATN\dataframe\train_file\85.txt,"hdf5_file[""val_labels""][...] = val_labels"
8441,E:\DATN\dataframe\train_file\85.txt,"hdf5_file.create_dataset(""test_labels"", (len(test_addrs),), np.int8)"
8442,E:\DATN\dataframe\train_file\85.txt,"hdf5_file[""test_labels""][...] = test_label"
8443,E:\DATN\dataframe\train_file\85.txt,Cách load và lưu
8444,E:\DATN\dataframe\train_file\85.txt,"mean = np.zeros(train_shape[1:], np.float32)"
8445,E:\DATN\dataframe\train_file\85.txt,# loop over train addresses
8446,E:\DATN\dataframe\train_file\85.txt,for i in range(len(train_addrs)):
8447,E:\DATN\dataframe\train_file\85.txt,    # print how many images are saved every 1000 images
8448,E:\DATN\dataframe\train_file\85.txt,    if i % 1000 == 0 and i > 1:
8449,E:\DATN\dataframe\train_file\85.txt,"        print 'Train data: {}/{}'.format(i, len(train_addrs))"
8450,E:\DATN\dataframe\train_file\85.txt,"    # read an image and resize to (224, 224)"
8451,E:\DATN\dataframe\train_file\85.txt,"    # cv2 load images as BGR, convert it to RGB"
8452,E:\DATN\dataframe\train_file\85.txt,    addr = train_addrs[i]
8453,E:\DATN\dataframe\train_file\85.txt,    img = cv2.imread(addr)
8454,E:\DATN\dataframe\train_file\85.txt,"    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)"
8455,E:\DATN\dataframe\train_file\85.txt,"    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
8456,E:\DATN\dataframe\train_file\85.txt,    # add any image pre-processing here
8457,E:\DATN\dataframe\train_file\85.txt,"    # if the data order is Theano, axis orders should change"
8458,E:\DATN\dataframe\train_file\85.txt,    if data_order == 'th':
8459,E:\DATN\dataframe\train_file\85.txt,"        img = np.rollaxis(img, 2)"
8460,E:\DATN\dataframe\train_file\85.txt,    # save the image and calculate the mean so far
8461,E:\DATN\dataframe\train_file\85.txt,"    hdf5_file[""train_img""][i, ...] = img[None]"
8462,E:\DATN\dataframe\train_file\85.txt,    mean += img / float(len(train_labels))
8463,E:\DATN\dataframe\train_file\85.txt,# loop over validation addresses
8464,E:\DATN\dataframe\train_file\85.txt,for i in range(len(val_addrs)):
8465,E:\DATN\dataframe\train_file\85.txt,    # print how many images are saved every 1000 images
8466,E:\DATN\dataframe\train_file\85.txt,    if i % 1000 == 0 and i > 1:
8467,E:\DATN\dataframe\train_file\85.txt,"        print 'Validation data: {}/{}'.format(i, len(val_addrs))"
8468,E:\DATN\dataframe\train_file\85.txt,"    # read an image and resize to (224, 224)"
8469,E:\DATN\dataframe\train_file\85.txt,"    # cv2 load images as BGR, convert it to RGB"
8470,E:\DATN\dataframe\train_file\85.txt,    addr = val_addrs[i]
8471,E:\DATN\dataframe\train_file\85.txt,    img = cv2.imread(addr)
8472,E:\DATN\dataframe\train_file\85.txt,"    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)"
8473,E:\DATN\dataframe\train_file\85.txt,"    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
8474,E:\DATN\dataframe\train_file\85.txt,    # add any image pre-processing here
8475,E:\DATN\dataframe\train_file\85.txt,"    # if the data order is Theano, axis orders should change"
8476,E:\DATN\dataframe\train_file\85.txt,    if data_order == 'th':
8477,E:\DATN\dataframe\train_file\85.txt,"        img = np.rollaxis(img, 2)"
8478,E:\DATN\dataframe\train_file\85.txt,    # save the image
8479,E:\DATN\dataframe\train_file\85.txt,"    hdf5_file[""val_img""][i, ...] = img[None]"
8480,E:\DATN\dataframe\train_file\85.txt,# loop over test addresses
8481,E:\DATN\dataframe\train_file\85.txt,for i in range(len(test_addrs)):
8482,E:\DATN\dataframe\train_file\85.txt,    # print how many images are saved every 1000 images
8483,E:\DATN\dataframe\train_file\85.txt,    if i % 1000 == 0 and i > 1:
8484,E:\DATN\dataframe\train_file\85.txt,"        print 'Test data: {}/{}'.format(i, len(test_addrs))"
8485,E:\DATN\dataframe\train_file\85.txt,"    # read an image and resize to (224, 224)"
8486,E:\DATN\dataframe\train_file\85.txt,"    # cv2 load images as BGR, convert it to RGB"
8487,E:\DATN\dataframe\train_file\85.txt,    addr = test_addrs[i]
8488,E:\DATN\dataframe\train_file\85.txt,    img = cv2.imread(addr)
8489,E:\DATN\dataframe\train_file\85.txt,"    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)"
8490,E:\DATN\dataframe\train_file\85.txt,"    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
8491,E:\DATN\dataframe\train_file\85.txt,    # add any image pre-processing here
8492,E:\DATN\dataframe\train_file\85.txt,"    # if the data order is Theano, axis orders should change"
8493,E:\DATN\dataframe\train_file\85.txt,    if data_order == 'th':
8494,E:\DATN\dataframe\train_file\85.txt,"        img = np.rollaxis(img, 2)"
8495,E:\DATN\dataframe\train_file\85.txt,    # save the image
8496,E:\DATN\dataframe\train_file\85.txt,"    hdf5_file[""test_img""][i, ...] = img[None]"
8497,E:\DATN\dataframe\train_file\85.txt,# save the mean and close the hdf5 file
8498,E:\DATN\dataframe\train_file\85.txt,"hdf5_file[""train_mean""][...] = mean"
8499,E:\DATN\dataframe\train_file\85.txt,"Trên đây mình đã nêu ra 3 cách lưu trữ data, tiếp theo sẽ tiếp tục đến phần mới."
8500,E:\DATN\dataframe\train_file\85.txt,Các Tool annotated data
8501,E:\DATN\dataframe\train_file\85.txt,Trong bài toán Học máy phần xử lý và phân tích dữ liệu là cực kỳ quan trọng vì vậy mình sẽ giới thiệu cho mọi người một số tool annotated data giúp cho công việc làm dữ liệu trở nên đơn giản hơn.
8502,E:\DATN\dataframe\train_file\85.txt,"Với tool này phù hợp với các bài toán segmentation như tìm xe ô tô, đường, các tế bào trong y học để hỗ trợ chẩn đoán."
8503,E:\DATN\dataframe\train_file\85.txt,Hình 2: Hai hình ảnh này là những ví dụ về hình ảnh segment (internet)
8504,E:\DATN\dataframe\train_file\85.txt,Tool này được sử dụng thuật toán watershed marked của OpenCV.
8505,E:\DATN\dataframe\train_file\85.txt,Mọi người có thể vào để tải tool về và dùng.
8506,E:\DATN\dataframe\train_file\85.txt,Hình 3: Giao diện của Tool
8507,E:\DATN\dataframe\train_file\85.txt,Cách dùng: bạn có thể đổi màu sắc ở file config trong source code và sau đó để số lượng màu tương ứng với các vùng bạn muốn segmentation khác nhau.
8508,E:\DATN\dataframe\train_file\85.txt,"Sau đó bạn chỉ cần dùng chuột ""chấm"" màu và nhấn phím ""enter"" theo từng vùng màu của bạn mong muốn."
8509,E:\DATN\dataframe\train_file\85.txt,Tool sinh dữ liệu
8510,E:\DATN\dataframe\train_file\85.txt,Text Recognition Data Generator là một tool dùng để sinh ra text.
8511,E:\DATN\dataframe\train_file\85.txt,Với tool này bạn có thể sinh ra các kiểu chữ và màu sắc khác nhau để phục vụ cho bài toán text detection của mình.
8512,E:\DATN\dataframe\train_file\85.txt,Bạn chỉ cần lưu các file cn.txt ở trong dicts và font chữ cũng lưu ở thư mục cn luôn và chạy code theo dòng code như sau:
8513,E:\DATN\dataframe\train_file\85.txt,python run.py -l cn -c 1000 -w 1 -t 6 -k 3 -rk -b 3 -bl 1 -rbl
8514,E:\DATN\dataframe\train_file\85.txt,để tự sinh data đúng theo yêu cầu bài toán bạn nên tìm hiểu kỹ ở
8515,E:\DATN\dataframe\train_file\85.txt,Tool LabelImg
8516,E:\DATN\dataframe\train_file\85.txt,LabelImg cũng là một tool dùng để annotated dữ liệu nhưng khác hơn Pixeltool ở chỗ LabelImg dùng để lấy ra 4 góc xung quanh.
8517,E:\DATN\dataframe\train_file\85.txt,Để cài đặt tool bạn có thể Clone github về hoặc sử dụng pip
8518,E:\DATN\dataframe\train_file\85.txt,pip3 install pyqt5 lxml # Install qt and lxml by pip
8519,E:\DATN\dataframe\train_file\85.txt,make qt5py3
8520,E:\DATN\dataframe\train_file\85.txt,python3 labelImg.py
8521,E:\DATN\dataframe\train_file\85.txt,python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]
8522,E:\DATN\dataframe\train_file\85.txt,Bài viết của mình có phần lủng củng mong mọi người đọc cho góp ý để mình viết tốt hơn của các bài về sau ạ. Mình cảm ơn ạ!
8523,E:\DATN\dataframe\train_file\86.txt,Xử lý ngon lành Microsoft Office Word với Python-Docx
8524,E:\DATN\dataframe\train_file\86.txt,"Microsoft Word (MS)- một trong các tiện ích từ bộ Microsoft Office là một trong những phần mềm phổ biến trong việc tạo ra file document, hỗ trợ đọc và ghi nội dung từ đơn giản đến phức tạp."
8525,E:\DATN\dataframe\train_file\86.txt,"Mặc dù con người có thể trực tiếp tạo và viết nội dung lên file MS, tuy nhiên trong rất nhiều tác vụ cần máy tính xử lý và tự động tạo nội dung trên các file MS. Ví dụ bạn đọc nội dung từ file pdf và muốn chuyển nội dung sang file docx hoặc bạn đang phát triển một mô hình xử lý ngôn ngữ tự nhiên và cần đọc dữ liệu đầu vào là các file MS thì  là một trong những thư viện rất đáng để bạn lựa chọn."
8526,E:\DATN\dataframe\train_file\86.txt,"Hôm nay mình xin giới thiệu các bạn cách tạo ra tự động file MS cũng như các tính năng thêm, sửa, xóa các nội dung dưới sự hỗ trợ của thư viện Python Docx."
8527,E:\DATN\dataframe\train_file\86.txt,Cài đặt thư viện
8528,E:\DATN\dataframe\train_file\86.txt,"Nếu các bạn đang sử dụng anaconda, các bạn có thể dễ dàng cài đặt bằng cách sau đây:"
8529,E:\DATN\dataframe\train_file\86.txt,pip install python-docx
8530,E:\DATN\dataframe\train_file\86.txt,Khởi tạo file
8531,E:\DATN\dataframe\train_file\86.txt,"Để mở một file đã tồn tại trước đó, bạn sử dụng câu lệnh sau"
8532,E:\DATN\dataframe\train_file\86.txt,from docx import Document
8533,E:\DATN\dataframe\train_file\86.txt,document = Document('existing-document-file.docx')
8534,E:\DATN\dataframe\train_file\86.txt,"Nếu file này chưa tồn tại, bạn sử dụng câu lệnh sau:"
8535,E:\DATN\dataframe\train_file\86.txt,document = Document()
8536,E:\DATN\dataframe\train_file\86.txt,"Sau khi bạn khởi tạo file, bạn có thể chỉnh sửa nội dung của file MS như thêm đoạn văn, thêm bảng, ... thông qua biến document như ví dụ bên trên."
8537,E:\DATN\dataframe\train_file\86.txt,Sau khi hoàn thiện bạn có lưu lại những thay đổi bằng câu lệnh sau :
8538,E:\DATN\dataframe\train_file\86.txt,"Ở đây, filename là tên file mà bạn muốn lưu."
8539,E:\DATN\dataframe\train_file\86.txt,Tất nhiên đuôi là .docx nhé.
8540,E:\DATN\dataframe\train_file\86.txt,"Heading, title"
8541,E:\DATN\dataframe\train_file\86.txt,Thư viện python-docx hỗ trợ ghi phần title hoặc heading của văn bản theo nhiều level mà người dùng chỉ định.
8542,E:\DATN\dataframe\train_file\86.txt,Content: nội dung title hoặc heading
8543,E:\DATN\dataframe\train_file\86.txt,"Level: bậc của heading (0, 1, 2, ...)."
8544,E:\DATN\dataframe\train_file\86.txt,Số càng nhỏ font chữ càng lớn.
8545,E:\DATN\dataframe\train_file\86.txt,"document.add_heading(content, level)"
8546,E:\DATN\dataframe\train_file\86.txt,"Theo mặc định của python-docx, title có level là 0"
8547,E:\DATN\dataframe\train_file\86.txt,"document.add_heading(""This is a title part, level=0)"
8548,E:\DATN\dataframe\train_file\86.txt,Ta có kết quả tương ứng sẽ là :
8549,E:\DATN\dataframe\train_file\86.txt,"Đối với các phần heaing, ta có các level 1, 2, 3...."
8550,E:\DATN\dataframe\train_file\86.txt,Level 1
8551,E:\DATN\dataframe\train_file\86.txt,"document.add_heading(""This is a heading 1"", level=1)"
8552,E:\DATN\dataframe\train_file\86.txt,Kết quả tương ứng :
8553,E:\DATN\dataframe\train_file\86.txt,Level 2
8554,E:\DATN\dataframe\train_file\86.txt,"document.add_heading(""This is a heading 2"", level=2)"
8555,E:\DATN\dataframe\train_file\86.txt,Kết quả tương ứng :
8556,E:\DATN\dataframe\train_file\86.txt,Đoạn văn (paragraph)
8557,E:\DATN\dataframe\train_file\86.txt,"Trong các loại văn bản thông thường, chúng ta có hai cách biểu diễn nội dung của một trang đó là:"
8558,E:\DATN\dataframe\train_file\86.txt,"Layout truyền thống: nội dung được biển diễn từ trên xuống dưới, từ trái sang phải"
8559,E:\DATN\dataframe\train_file\86.txt,Layout dạng cột : Nội dung được tổ chức thành từng cột riêng rẽ với nhau
8560,E:\DATN\dataframe\train_file\86.txt,Layout truyền thống
8561,E:\DATN\dataframe\train_file\86.txt,"Với layout kiểu truyền thống, chúng ta ghi nội dung vào file MS như sau:"
8562,E:\DATN\dataframe\train_file\86.txt,Kết quả tương ứng:
8563,E:\DATN\dataframe\train_file\86.txt,Layout dạng cột
8564,E:\DATN\dataframe\train_file\86.txt,Để tạo ra được các văn bản dạng cột.
8565,E:\DATN\dataframe\train_file\86.txt,Chúng ta cần dùng đến khái niệm Section.
8566,E:\DATN\dataframe\train_file\86.txt,Mỗi section có thể chứa nhiều các đoạn văn.
8567,E:\DATN\dataframe\train_file\86.txt,Mỗi section sẽ tương đương với một page và chúng ta thông qua section để biểu diễn nội dung cho một page.
8568,E:\DATN\dataframe\train_file\86.txt,Tạo layout cột cho section :
8569,E:\DATN\dataframe\train_file\86.txt,from docx.enum.section import WD_SECTION_START
8570,E:\DATN\dataframe\train_file\86.txt,"def set_number_of_columns(section, cols):"
8571,E:\DATN\dataframe\train_file\86.txt,"    """""" sets number of columns through xpath. """""""
8572,E:\DATN\dataframe\train_file\86.txt,"    WNS_COLS_NUM = ""{http://schemas.openxmlformats.org/wordprocessingml/2006/main}num"""
8573,E:\DATN\dataframe\train_file\86.txt,"    section._sectPr.xpath(""./w:cols"")[0].set(WNS_COLS_NUM, str(cols))"
8574,E:\DATN\dataframe\train_file\86.txt,section = document.add_section(WD_SECTION_START.NEW_PAGE)
8575,E:\DATN\dataframe\train_file\86.txt,# col_nb is number of column layout
8576,E:\DATN\dataframe\train_file\86.txt,"set_number_of_columns(section, col_nb)"
8577,E:\DATN\dataframe\train_file\86.txt,Sau đó chúng ta thực hiện thêm đoạn văn giống như kiểu layout truyền thống.
8578,E:\DATN\dataframe\train_file\86.txt,"Đoạn văn sẽ được thêm theo thứ tự các cột, từ trái sang phải."
8579,E:\DATN\dataframe\train_file\86.txt,p = document.add_paragraph(content)
8580,E:\DATN\dataframe\train_file\86.txt,"Ngoài ra, chúng ta cũng có thể thêm phần căn lề (trái, phải, giữa ) cho đoạn văn như sau:"
8581,E:\DATN\dataframe\train_file\86.txt,from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
8582,E:\DATN\dataframe\train_file\86.txt,Căn lề trái
8583,E:\DATN\dataframe\train_file\86.txt,p.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT
8584,E:\DATN\dataframe\train_file\86.txt,Căn lề phải
8585,E:\DATN\dataframe\train_file\86.txt,p.alignment = WD_PARAGRAPH_ALIGNMENT.RIGHT
8586,E:\DATN\dataframe\train_file\86.txt,Căn lề giữa
8587,E:\DATN\dataframe\train_file\86.txt,p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
8588,E:\DATN\dataframe\train_file\86.txt,Căn lề hai bên
8589,E:\DATN\dataframe\train_file\86.txt,p.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY
8590,E:\DATN\dataframe\train_file\86.txt,Thêm câu cho đoạn văn
8591,E:\DATN\dataframe\train_file\86.txt,Thư viện python-docx hỗ trợ chèn thêm câu riêng lẻ vào trong đoạn văn đã được khởi tạo:
8592,E:\DATN\dataframe\train_file\86.txt,# initialize new paragraph
8593,E:\DATN\dataframe\train_file\86.txt,p = document.add_paragraph(content)
8594,E:\DATN\dataframe\train_file\86.txt,# add sentence to initialized paragraph
8595,E:\DATN\dataframe\train_file\86.txt,sentence_element = p.add_run(str(content))
8596,E:\DATN\dataframe\train_file\86.txt,Highlight background
8597,E:\DATN\dataframe\train_file\86.txt,Bạn cũng có thể highlight background cho từng câu bằng các màu yêu thích như sau:(highlight là tên màu )
8598,E:\DATN\dataframe\train_file\86.txt,from docx.enum.text import WD_COLOR_INDEX
8599,E:\DATN\dataframe\train_file\86.txt,if highlight == 'black':
8600,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.BLACK
8601,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'blue':
8602,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.BLUE
8603,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'green':
8604,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.BRIGHT_GREEN
8605,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'dark blue':
8606,E:\DATN\dataframe\train_file\86.txt,   color_element = WD_COLOR_INDEX.DARK_BLUE
8607,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'dark red':
8608,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.DARK_RED
8609,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'dark yellow':
8610,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.DARK_YELLOW
8611,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'dark green':
8612,E:\DATN\dataframe\train_file\86.txt,   color_element = WD_COLOR_INDEX.GREEN
8613,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'pink':
8614,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.PINK
8615,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'red':
8616,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.PINK
8617,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'white':
8618,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.WHITE
8619,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'teal':
8620,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.TEAL
8621,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'yellow':
8622,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.YELLOW
8623,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'violet':
8624,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.VIOLET
8625,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'gray25':
8626,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.GRAY_25
8627,E:\DATN\dataframe\train_file\86.txt,elif highlight == 'gray50':
8628,E:\DATN\dataframe\train_file\86.txt,  color_element = WD_COLOR_INDEX.GRAY_50
8629,E:\DATN\dataframe\train_file\86.txt,"style = document.styles.add_style(""document style"", WD_STYLE_TYPE.CHARACTER)"
8630,E:\DATN\dataframe\train_file\86.txt,style.font.highlight_color = color_element
8631,E:\DATN\dataframe\train_file\86.txt,"sentence_element = p.add_run(str(c), style=self.style)"
8632,E:\DATN\dataframe\train_file\86.txt,"In đậm, nghiêng, gạch chân"
8633,E:\DATN\dataframe\train_file\86.txt,"Bạn cũng có thể thêm highlight cho bằng thêm in đậm, in nghiêng hay gạch chân như khi người sử dụng trực tiếp trên file MS."
8634,E:\DATN\dataframe\train_file\86.txt,"# set bold, italic, underline value which is boolean value True or False"
8635,E:\DATN\dataframe\train_file\86.txt,sentence_element = p.add_run(str(content)
8636,E:\DATN\dataframe\train_file\86.txt,sentence_element.bold = bold
8637,E:\DATN\dataframe\train_file\86.txt,sentence_element.italic = italic
8638,E:\DATN\dataframe\train_file\86.txt,entence_element.underline = underline
8639,E:\DATN\dataframe\train_file\86.txt,Bạn cũng có thể chèn ảnh trưc tiếp vào python-docx bằng đường dẫn tới file ảnh cần chèn hoặc ảnh đã được biểu diễn dạng ma trận.
8640,E:\DATN\dataframe\train_file\86.txt,Bạn cũng có thể điều chỉnh kích thước ảnh phù hợp với văn bản của mình.
8641,E:\DATN\dataframe\train_file\86.txt,import cv2
8642,E:\DATN\dataframe\train_file\86.txt,from docx.shared import Inches
8643,E:\DATN\dataframe\train_file\86.txt,from io import BytesIO
8644,E:\DATN\dataframe\train_file\86.txt,import numpy as np
8645,E:\DATN\dataframe\train_file\86.txt,"def add_picture(document, image_path_or_stream, width):"
8646,E:\DATN\dataframe\train_file\86.txt,"     """"""Add picture to image"""""""
8647,E:\DATN\dataframe\train_file\86.txt,"     if isinstance(image_path_or_stream, str):"
8648,E:\DATN\dataframe\train_file\86.txt,         img = cv2.imread(image_path_or_stream)
8649,E:\DATN\dataframe\train_file\86.txt,         img = np.array(image_path_or_stream)
8650,E:\DATN\dataframe\train_file\86.txt,"     is_success, im_buf_arr = cv2.imencode("".jpg"", img)"
8651,E:\DATN\dataframe\train_file\86.txt,     byte_im = im_buf_arr.tobytes()
8652,E:\DATN\dataframe\train_file\86.txt,     stream = BytesIO(byte_im)
8653,E:\DATN\dataframe\train_file\86.txt,"     document.add_picture(stream, width=Inches(width))"
8654,E:\DATN\dataframe\train_file\86.txt,"add_picture(document, 'example.jpg', 5.0)"
8655,E:\DATN\dataframe\train_file\86.txt,Lời kết
8656,E:\DATN\dataframe\train_file\86.txt,Python-docx là một thư viện hỗ trợ mạnh mẽ về cách tạo lập hay sửa đổi văn bản docx.
8657,E:\DATN\dataframe\train_file\86.txt,Tuy nhiên để có thể tận dụng hết các tính năng của Microsoft Word thì các bạn cần tìm hiểu sâu thêm các api của Mircosoft Word.
8658,E:\DATN\dataframe\train_file\86.txt,Còn nếu bạn chỉ muốn sử dụng tính năng đơn giản thì python-docx vẫn là sự lựa chọn hết sức tuyệt vời.
8659,E:\DATN\dataframe\train_file\86.txt,Cảm ơn các bạn đã theo dõi bài đọc của mình
8660,E:\DATN\dataframe\train_file\87.txt,Trích xuất thông tin từ chứng minh thư
8661,E:\DATN\dataframe\train_file\87.txt,Lời mở đầu
8662,E:\DATN\dataframe\train_file\87.txt,"Gần đây chắc hẳn các bạn đã nghe nhiều tới các khái niệm như định danh điện tử, Ekyc,... Nếu như trước đây, khách hàng muốn mở tài khoản ngân hàng, mở thẻ ATM... sẽ phải đến trực tiếp quầy giao dịch để thực hiện các thủ tục đăng kí, xác minh thông tin, thì giờ đây các thao tác này đều có thể thực hiện qua chiếc điện thoại nhờ giải pháp định danh khách hàng điện tử (eKYC)."
8663,E:\DATN\dataframe\train_file\87.txt,Và bài toán Trích xuất thông tin từ chứng minh thư chính là bài toán nhỏ trong ứng dụng định danh điện từ này.
8664,E:\DATN\dataframe\train_file\87.txt,Hôm nay mình xin giới thiệu các bước giúp các bạn thực hiện bài toán này.
8665,E:\DATN\dataframe\train_file\87.txt,Tuy cách này chưa thực sự là cách giải quyết tốt nhất nhưng qua bài này các bạn mới học về AI cũng có thể học thêm được kiến thức qua bài toán này.
8666,E:\DATN\dataframe\train_file\87.txt,Toàn bộ source code các bạn có thể xem tại .
8667,E:\DATN\dataframe\train_file\87.txt,Các bước xử lý
8668,E:\DATN\dataframe\train_file\87.txt,"Trong bài này, mình đề xuất một hướng xử lý như sau :"
8669,E:\DATN\dataframe\train_file\87.txt,Detect 4 góc chứng minh thư
8670,E:\DATN\dataframe\train_file\87.txt,Xoay chứng minh thư
8671,E:\DATN\dataframe\train_file\87.txt,Detect vùng chữ có trong chứng minh thư
8672,E:\DATN\dataframe\train_file\87.txt,Detect 4 góc chứng minh thư
8673,E:\DATN\dataframe\train_file\87.txt,"Do ảnh đầu vào là ảnh chụp từ điện thoại, có thể ảnh bị nghiêng, bị xoay ngược do đó chúng ta cần bước xoay thẳng lại để có thể dễ dàng xử lý."
8674,E:\DATN\dataframe\train_file\87.txt,"Vì lý do như vậy, nếu chúng ta dùng phương pháp bình thường detect nguyên cả chứng minh thư thì chúng ta khó có thể xoay lại được bằng xử lý ảnh hoặc phải dùng các phương pháp phức tạp hơn."
8675,E:\DATN\dataframe\train_file\87.txt,"Để đơn giản, ở bài này mình đề xuất một phương pháp đó là chúng ta sẽ coi bốn góc của chứng minh thư như là một object chúng ta cần detect sau đó chúng ta sẽ xoay thẳng bằng tọa độ của bốn góc này."
8676,E:\DATN\dataframe\train_file\87.txt,"Nếu như các bạn đã làm quen với các bài toán detect face, bike, car,... , trong đó bike hay car là object thì ở đây bốn góc : bottom left, bottom right, top left, top right chính là 4 object chúng ta cần tìm."
8677,E:\DATN\dataframe\train_file\87.txt,Các bạn có thể thực hiện nhanh chóng bước này bằng cách sử dụng dữ liệu của bản thân kết hợp với mô hình detect đã được cung cấn sẵn bởi Tensorflow API.
8678,E:\DATN\dataframe\train_file\87.txt,Các bạn có thể tìm bài viết hướng dẫn Tensorflow API của mình ở . Ta sẽ có kết quả như hình sau:
8679,E:\DATN\dataframe\train_file\87.txt,Xoay chứng minh thư
8680,E:\DATN\dataframe\train_file\87.txt,Ở đây ta cần bốn góc để xoay nhưng mô hình chúng ta lại chỉ detect được có 3 góc .
8681,E:\DATN\dataframe\train_file\87.txt,Vậy làm thế nào ta có thể tính được ra tọa độ góc còn lại bây giờ ?
8682,E:\DATN\dataframe\train_file\87.txt,"Đơn giản thôi, chúng ta chỉ cần áp dụng một kiến thức hình học cấp hai, ta dễ dàng nội suy ra tọa độ của 3 góc ra tọa độ góc còn lại."
8683,E:\DATN\dataframe\train_file\87.txt,Các bác thử ngâm cứu vẽ vời ra giấy tính toán thử xem.
8684,E:\DATN\dataframe\train_file\87.txt,Còn nếu lười thì dùng luôn code của tôi dưới đây nhé :
8685,E:\DATN\dataframe\train_file\87.txt,Đầu tiên chúng ta cần phải tính ra tọa độ trung tâm của mỗi bouding box hay tọa độ của bốn góc bằng hàm get_center_point().
8686,E:\DATN\dataframe\train_file\87.txt,Hàm này nhận dữ liệu đầu vào là dictionary chứa key là tên góc và value: tọa độ của bounding box tương ứng.
8687,E:\DATN\dataframe\train_file\87.txt,Đẩu ra là một dictionary chứa key là tên góc và value: tọa độ trung tâm bounding box tương ứng hay chính là tọa độ các góc.
8688,E:\DATN\dataframe\train_file\87.txt,def get_center_point(coordinate_dict):
8689,E:\DATN\dataframe\train_file\87.txt,    di = dict()
8690,E:\DATN\dataframe\train_file\87.txt,    for key in coordinate_dict.keys():
8691,E:\DATN\dataframe\train_file\87.txt,"        xmin, ymin, xmax, ymax = coordinate_dict[key]"
8692,E:\DATN\dataframe\train_file\87.txt,        x_center = (xmin + xmax) / 2
8693,E:\DATN\dataframe\train_file\87.txt,        y_center = (ymin + ymax) / 2
8694,E:\DATN\dataframe\train_file\87.txt,"        di[key] = (x_center, y_center)"
8695,E:\DATN\dataframe\train_file\87.txt,    return di
8696,E:\DATN\dataframe\train_file\87.txt,Sau đó chúng ta đưa dictionary thu được bên trên vào hàm calculate_missed_coord_corner để nội suy ra góc còn thiếu và trả dữ liệu dạng dictionary chứa tên và tọa độ bốn góc tương ứng.
8697,E:\DATN\dataframe\train_file\87.txt,"Ở đây hàm này chỉ khắc phục trong trường hợp thiếu một góc, những trường hợp thiếu hai góc không khắc phục được."
8698,E:\DATN\dataframe\train_file\87.txt,Cách khắc phục nhược điểm thiếu nhiều góc là cải thiện model detect trở nên tốt hơn.
8699,E:\DATN\dataframe\train_file\87.txt,def calculate_missed_coord_corner(coordinate_dict):
8700,E:\DATN\dataframe\train_file\87.txt,    thresh = 0
8701,E:\DATN\dataframe\train_file\87.txt,    index = find_miss_corner(coordinate_dict)
8702,E:\DATN\dataframe\train_file\87.txt,    # calculate missed corner coordinate
8703,E:\DATN\dataframe\train_file\87.txt,"    # case 1: missed corner is ""top_left"""
8704,E:\DATN\dataframe\train_file\87.txt,    if index == 0:
8705,E:\DATN\dataframe\train_file\87.txt,"        midpoint = np.add(coordinate_dict['top_right'], coordinate_dict['bottom_left']) / 2"
8706,E:\DATN\dataframe\train_file\87.txt,        y = 2 * midpoint[1] - coordinate_dict['bottom_right'][1] - thresh
8707,E:\DATN\dataframe\train_file\87.txt,        x = 2 * midpoint[0] - coordinate_dict['bottom_right'][0] - thresh
8708,E:\DATN\dataframe\train_file\87.txt,"        coordinate_dict['top_left'] = (x, y)"
8709,E:\DATN\dataframe\train_file\87.txt,"    elif index == 1:  # ""top_right"""
8710,E:\DATN\dataframe\train_file\87.txt,"        midpoint = np.add(coordinate_dict['top_left'], coordinate_dict['bottom_right']) / 2"
8711,E:\DATN\dataframe\train_file\87.txt,        y = 2 * midpoint[1] - coordinate_dict['bottom_left'][1] - thresh
8712,E:\DATN\dataframe\train_file\87.txt,        x = 2 * midpoint[0] - coordinate_dict['bottom_left'][0] - thresh
8713,E:\DATN\dataframe\train_file\87.txt,"        coordinate_dict['top_right'] = (x, y)"
8714,E:\DATN\dataframe\train_file\87.txt,"    elif index == 2:  # ""bottom_left"""
8715,E:\DATN\dataframe\train_file\87.txt,"        midpoint = np.add(coordinate_dict['top_left'], coordinate_dict['bottom_right']) / 2"
8716,E:\DATN\dataframe\train_file\87.txt,        y = 2 * midpoint[1] - coordinate_dict['top_right'][1] - thresh
8717,E:\DATN\dataframe\train_file\87.txt,        x = 2 * midpoint[0] - coordinate_dict['top_right'][0] - thresh
8718,E:\DATN\dataframe\train_file\87.txt,"        coordinate_dict['bottom_left'] = (x, y)"
8719,E:\DATN\dataframe\train_file\87.txt,"    elif index == 3:  # ""bottom_right"""
8720,E:\DATN\dataframe\train_file\87.txt,"        midpoint = np.add(coordinate_dict['bottom_left'], coordinate_dict['top_right']) / 2"
8721,E:\DATN\dataframe\train_file\87.txt,        y = 2 * midpoint[1] - coordinate_dict['top_left'][1] - thresh
8722,E:\DATN\dataframe\train_file\87.txt,        x = 2 * midpoint[0] - coordinate_dict['top_left'][0] - thresh
8723,E:\DATN\dataframe\train_file\87.txt,"        coordinate_dict['bottom_right'] = (x, y)"
8724,E:\DATN\dataframe\train_file\87.txt,    return coordinate_dict
8725,E:\DATN\dataframe\train_file\87.txt,"Sau khi có được tọa độ 4 góc của chứng minh thư, ta xoay thẳng ảnh lại dựa vào kích thước thực tế có chiều dài 500, chiều rộng 300."
8726,E:\DATN\dataframe\train_file\87.txt,"Ở đây, mình dùng PerspectiveTransform của OpenCV:"
8727,E:\DATN\dataframe\train_file\87.txt,"def perspective_transform(image, source_points):"
8728,E:\DATN\dataframe\train_file\87.txt,"    dest_points = np.float32([[0, 0], [500, 0], [500, 300], [0, 300]])"
8729,E:\DATN\dataframe\train_file\87.txt,"    M = cv2.getPerspectiveTransform(source_points, dest_points)"
8730,E:\DATN\dataframe\train_file\87.txt,"    dst = cv2.warpPerspective(image, M, (500, 300))"
8731,E:\DATN\dataframe\train_file\87.txt,    return dst
8732,E:\DATN\dataframe\train_file\87.txt,"Và kết quả cuối cùng, mình sẽ thu được về như sau:"
8733,E:\DATN\dataframe\train_file\87.txt,Detect vùng chữ có trong chứng minh thư
8734,E:\DATN\dataframe\train_file\87.txt,"Tương tự như ý tưởng detect các góc, ở task này chúng ta sẽ sử dụng các mô hình detect có sẵn trong thư viện Tensorflow API như ở bước 1 đã làm để huấn luyện detect ra các chữ có trong ảnh chứng minh thư đã được crop ở bước trên."
8735,E:\DATN\dataframe\train_file\87.txt,Các bạn có thể xem hướng dẫn .
8736,E:\DATN\dataframe\train_file\87.txt,"Mình chia các chữ ra thành 5 class tương ứng với 5 trường thông tin cần thu: id, name, birth, home và add."
8737,E:\DATN\dataframe\train_file\87.txt,Chúng ta sẽ thu được ảnh kết quả trả về như sau:
8738,E:\DATN\dataframe\train_file\87.txt,"Trong ảnh thu được, để tránh hiện tượng cùng một object nhưng có nhiều bouding box đè lên nhau (overlap), chúng ta sử dụng một thuật toán có tên là NMS (Non Maximum Suppression) giúp loại bỏ đi box thừa giữ lại box tốt nhất cho object."
8739,E:\DATN\dataframe\train_file\87.txt," def non_max_suppression_fast(boxes, labels, overlapThresh):"
8740,E:\DATN\dataframe\train_file\87.txt,"  # if there are no boxes, return an empty list"
8741,E:\DATN\dataframe\train_file\87.txt,  if len(boxes) == 0:
8742,E:\DATN\dataframe\train_file\87.txt,"  # if the bounding boxes integers, convert them to floats --"
8743,E:\DATN\dataframe\train_file\87.txt,  # this is important since we'll be doing a bunch of divisions
8744,E:\DATN\dataframe\train_file\87.txt,"  if boxes.dtype.kind == ""i"":"
8745,E:\DATN\dataframe\train_file\87.txt,"      boxes = boxes.astype(""float"")"
8746,E:\DATN\dataframe\train_file\87.txt,  # initialize the list of picked indexes
8747,E:\DATN\dataframe\train_file\87.txt,  # grab the coordinates of the bounding boxes
8748,E:\DATN\dataframe\train_file\87.txt,"  x1 = boxes[:, 1]"
8749,E:\DATN\dataframe\train_file\87.txt,"  y1 = boxes[:, 0]"
8750,E:\DATN\dataframe\train_file\87.txt,"  x2 = boxes[:, 3]"
8751,E:\DATN\dataframe\train_file\87.txt,"  y2 = boxes[:, 2]"
8752,E:\DATN\dataframe\train_file\87.txt,  # compute the area of the bounding boxes and sort the bounding
8753,E:\DATN\dataframe\train_file\87.txt,  # boxes by the bottom-right y-coordinate of the bounding box
8754,E:\DATN\dataframe\train_file\87.txt,  area = (x2 - x1 + 1) * (y2 - y1 + 1)
8755,E:\DATN\dataframe\train_file\87.txt,  idxs = np.argsort(y2)
8756,E:\DATN\dataframe\train_file\87.txt,  # keep looping while some indexes still remain in the indexes
8757,E:\DATN\dataframe\train_file\87.txt,  while len(idxs) > 0:
8758,E:\DATN\dataframe\train_file\87.txt,      # grab the last index in the indexes list and add the
8759,E:\DATN\dataframe\train_file\87.txt,      # index value to the list of picked indexes
8760,E:\DATN\dataframe\train_file\87.txt,      last = len(idxs) - 1
8761,E:\DATN\dataframe\train_file\87.txt,      i = idxs[last]
8762,E:\DATN\dataframe\train_file\87.txt,"      # find the largest (x, y) coordinates for the start of"
8763,E:\DATN\dataframe\train_file\87.txt,"      # the bounding box and the smallest (x, y) coordinates"
8764,E:\DATN\dataframe\train_file\87.txt,      # for the end of the bounding box
8765,E:\DATN\dataframe\train_file\87.txt,"      xx1 = np.maximum(x1[i], x1[idxs[:last]])"
8766,E:\DATN\dataframe\train_file\87.txt,"      yy1 = np.maximum(y1[i], y1[idxs[:last]])"
8767,E:\DATN\dataframe\train_file\87.txt,"      xx2 = np.minimum(x2[i], x2[idxs[:last]])"
8768,E:\DATN\dataframe\train_file\87.txt,"      yy2 = np.minimum(y2[i], y2[idxs[:last]])"
8769,E:\DATN\dataframe\train_file\87.txt,      # compute the width and height of the bounding box
8770,E:\DATN\dataframe\train_file\87.txt,"      w = np.maximum(0, xx2 - xx1 + 1)"
8771,E:\DATN\dataframe\train_file\87.txt,"      h = np.maximum(0, yy2 - yy1 + 1)"
8772,E:\DATN\dataframe\train_file\87.txt,      # compute the ratio of overlap
8773,E:\DATN\dataframe\train_file\87.txt,      overlap = (w * h) / area[idxs[:last]]
8774,E:\DATN\dataframe\train_file\87.txt,      # delete all indexes from the index list that have
8775,E:\DATN\dataframe\train_file\87.txt,"      idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))"
8776,E:\DATN\dataframe\train_file\87.txt,  # return only the bounding boxes that were picked using the
8777,E:\DATN\dataframe\train_file\87.txt,  # integer data type
8778,E:\DATN\dataframe\train_file\87.txt,  final_labels = [labels[idx] for idx in pick]
8779,E:\DATN\dataframe\train_file\87.txt,"  final_boxes = boxes[pick].astype(""int"")"
8780,E:\DATN\dataframe\train_file\87.txt,"  return final_boxes, final_labels"
8781,E:\DATN\dataframe\train_file\87.txt,Các bạn để ý các box ở trường home và add đã ít hơn hẳn so với ảnh trước.
8782,E:\DATN\dataframe\train_file\87.txt,OCR hay nhận dạng kí tự là kĩ thuật nhận dạng chữ có trong ảnh đầu vào.
8783,E:\DATN\dataframe\train_file\87.txt,"Với các box chữ chúng ta thu được từ bước trên, ta crop và đưa qua mô hình OCR để đọc."
8784,E:\DATN\dataframe\train_file\87.txt,"Để giải quyết bài toán nhanh gọn, không mất thời gian các bạn có thể sử dụng  của tác gỉa Phạm Quốc, lý thuyết về Transformer OCR các bạn có thể theo dõi tại  nhé."
8785,E:\DATN\dataframe\train_file\87.txt,Ở đây do tác giả chưa hỗ trợ dự đoán theo batch_size nên các bạn có thể custom lại file  như sau để dự đoán theo theo batch_size nhanh hơn nhé:
8786,E:\DATN\dataframe\train_file\87.txt,"from vietocr.tool.translate import build_model, translate, translate_beam_search, batch_translate_beam_search"
8787,E:\DATN\dataframe\train_file\87.txt,import cv2
8788,E:\DATN\dataframe\train_file\87.txt,import numpy as np
8789,E:\DATN\dataframe\train_file\87.txt,import math
8790,E:\DATN\dataframe\train_file\87.txt,import time
8791,E:\DATN\dataframe\train_file\87.txt,import torch
8792,E:\DATN\dataframe\train_file\87.txt,from collections import defaultdict
8793,E:\DATN\dataframe\train_file\87.txt,class Predictor(object):
8794,E:\DATN\dataframe\train_file\87.txt,"    def __init__(self, config):"
8795,E:\DATN\dataframe\train_file\87.txt,        device = config['device']
8796,E:\DATN\dataframe\train_file\87.txt,"        model, vocab = build_model(config)"
8797,E:\DATN\dataframe\train_file\87.txt,        weights = config['weights']
8798,E:\DATN\dataframe\train_file\87.txt,"        model.load_state_dict(torch.load(weights, map_location=torch.device(device)))"
8799,E:\DATN\dataframe\train_file\87.txt,        self.config = config
8800,E:\DATN\dataframe\train_file\87.txt,        self.model = model
8801,E:\DATN\dataframe\train_file\87.txt,        self.vocab = vocab
8802,E:\DATN\dataframe\train_file\87.txt,"    def predict(self, img):"
8803,E:\DATN\dataframe\train_file\87.txt,        img = img / 255.0
8804,E:\DATN\dataframe\train_file\87.txt,        img = self.preprocess_input(img)
8805,E:\DATN\dataframe\train_file\87.txt,"        img = np.expand_dims(img, axis=0)"
8806,E:\DATN\dataframe\train_file\87.txt,        img = torch.FloatTensor(img)
8807,E:\DATN\dataframe\train_file\87.txt,        img = img.to(self.config['device'])
8808,E:\DATN\dataframe\train_file\87.txt,        if self.config['predictor']['beamsearch']:
8809,E:\DATN\dataframe\train_file\87.txt,"            sent = translate_beam_search(img, self.model)"
8810,E:\DATN\dataframe\train_file\87.txt,            s = sent
8811,E:\DATN\dataframe\train_file\87.txt,"            s = translate(img, self.model)[0].tolist()"
8812,E:\DATN\dataframe\train_file\87.txt,        s = self.vocab.decode(s)
8813,E:\DATN\dataframe\train_file\87.txt,        return s
8814,E:\DATN\dataframe\train_file\87.txt,"    def batch_predict(self, images):"
8815,E:\DATN\dataframe\train_file\87.txt,        param: images : list of ndarray
8816,E:\DATN\dataframe\train_file\87.txt,"        batch_dict, indices = self.batch_process(images)"
8817,E:\DATN\dataframe\train_file\87.txt,        list_keys = [i for i in batch_dict if batch_dict[i] != batch_dict.default_factory()]
8818,E:\DATN\dataframe\train_file\87.txt,        result = list([])
8819,E:\DATN\dataframe\train_file\87.txt,        for width in list_keys:
8820,E:\DATN\dataframe\train_file\87.txt,            batch = batch_dict[width]
8821,E:\DATN\dataframe\train_file\87.txt,            batch = np.asarray(batch)
8822,E:\DATN\dataframe\train_file\87.txt,            batch = torch.FloatTensor(batch)
8823,E:\DATN\dataframe\train_file\87.txt,            batch = batch.to(self.config['device'])
8824,E:\DATN\dataframe\train_file\87.txt,            if self.config['predictor']['beamsearch']:
8825,E:\DATN\dataframe\train_file\87.txt,"                sent = batch_translate_beam_search(batch, model=self.model)"
8826,E:\DATN\dataframe\train_file\87.txt,"                sent = translate(batch, self.model).tolist()"
8827,E:\DATN\dataframe\train_file\87.txt,            batch_text = self.vocab.batch_decode(sent)
8828,E:\DATN\dataframe\train_file\87.txt,        # sort text result to original coordinate
8829,E:\DATN\dataframe\train_file\87.txt,        def get_index(element):
8830,E:\DATN\dataframe\train_file\87.txt,            return element[1]
8831,E:\DATN\dataframe\train_file\87.txt,"        z = zip(result, indices)"
8832,E:\DATN\dataframe\train_file\87.txt,"        sorted_result = sorted(z, key=get_index)"
8833,E:\DATN\dataframe\train_file\87.txt,"        result, _ = zip(*sorted_result)"
8834,E:\DATN\dataframe\train_file\87.txt,        return result
8835,E:\DATN\dataframe\train_file\87.txt,"     def preprocess_input(self, image):"
8836,E:\DATN\dataframe\train_file\87.txt,"        Preprocess input image (resize, normalize)"
8837,E:\DATN\dataframe\train_file\87.txt,"        image: has shape of (H, W, C)"
8838,E:\DATN\dataframe\train_file\87.txt,"        img: has shape (H, W, C)"
8839,E:\DATN\dataframe\train_file\87.txt,"        h, w, _ = image.shape"
8840,E:\DATN\dataframe\train_file\87.txt,"        new_w, image_height = self.resize_v1(w, h, self.config['dataset']['image_height'],"
8841,E:\DATN\dataframe\train_file\87.txt,"        img = cv2.resize(image, (new_w, image_height))"
8842,E:\DATN\dataframe\train_file\87.txt,        img = img / 255.0
8843,E:\DATN\dataframe\train_file\87.txt,"        img = np.transpose(img, (2, 0, 1))"
8844,E:\DATN\dataframe\train_file\87.txt,        return img
8845,E:\DATN\dataframe\train_file\87.txt,"    def batch_process(self, images):"
8846,E:\DATN\dataframe\train_file\87.txt,        batch_img_dict = defaultdict(list)
8847,E:\DATN\dataframe\train_file\87.txt,        image_height = self.config['dataset']['image_height']
8848,E:\DATN\dataframe\train_file\87.txt,        batch_img_li = [self.preprocess_input(img) for img in images]
8849,E:\DATN\dataframe\train_file\87.txt,"        batch_imgs, width_list, indices = self.sort_width(batch_img_li, reverse=False)"
8850,E:\DATN\dataframe\train_file\87.txt,        min_bucket_width = min(width_list)
8851,E:\DATN\dataframe\train_file\87.txt,        max_width = max(width_list)
8852,E:\DATN\dataframe\train_file\87.txt,        thresh = 30
8853,E:\DATN\dataframe\train_file\87.txt,"        max_bucket_width = np.minimum(min_bucket_width + thresh, max_width)"
8854,E:\DATN\dataframe\train_file\87.txt,"        for i, image in enumerate(batch_imgs):"
8855,E:\DATN\dataframe\train_file\87.txt,"            c, h, w = image.shape"
8856,E:\DATN\dataframe\train_file\87.txt,"            # reset min_bucket_width, max_bucket_width"
8857,E:\DATN\dataframe\train_file\87.txt,            if w > max_bucket_width:
8858,E:\DATN\dataframe\train_file\87.txt,                min_bucket_width = w
8859,E:\DATN\dataframe\train_file\87.txt,"                max_bucket_width = np.minimum(min_bucket_width + thresh, max_width)"
8860,E:\DATN\dataframe\train_file\87.txt,            avg_bucket_width = int((max_bucket_width + min_bucket_width) / 2)
8861,E:\DATN\dataframe\train_file\87.txt,"            new_img = self.resize_v2(image, avg_bucket_width, height=image_height)"
8862,E:\DATN\dataframe\train_file\87.txt,"        return batch_img_dict, indices"
8863,E:\DATN\dataframe\train_file\87.txt,"    def sort_width(batch_img, reverse=False):"
8864,E:\DATN\dataframe\train_file\87.txt,        def get_img_width(element):
8865,E:\DATN\dataframe\train_file\87.txt,            img = element[0]
8866,E:\DATN\dataframe\train_file\87.txt,"            c, h, w = img.shape"
8867,E:\DATN\dataframe\train_file\87.txt,            return w
8868,E:\DATN\dataframe\train_file\87.txt,"        batch = list(zip(batch_img, range(len(batch_img))))"
8869,E:\DATN\dataframe\train_file\87.txt,"        sorted_batch = sorted(batch, key=get_img_width, reverse=reverse)"
8870,E:\DATN\dataframe\train_file\87.txt,"        sorted_batch_img, indices = list(zip(*sorted_batch))"
8871,E:\DATN\dataframe\train_file\87.txt,"        return sorted_batch_img, list(map(get_img_width, batch)), indices"
8872,E:\DATN\dataframe\train_file\87.txt,"    def resize_v1(w, h, expected_height, image_min_width, image_max_width):"
8873,E:\DATN\dataframe\train_file\87.txt,        new_w = int(expected_height * float(w) / float(h))
8874,E:\DATN\dataframe\train_file\87.txt,        round_to = 10
8875,E:\DATN\dataframe\train_file\87.txt,        new_w = math.ceil(new_w / round_to) * round_to
8876,E:\DATN\dataframe\train_file\87.txt,"        new_w = max(new_w, image_min_width)"
8877,E:\DATN\dataframe\train_file\87.txt,"        new_w = min(new_w, image_max_width)"
8878,E:\DATN\dataframe\train_file\87.txt,"        return new_w, expected_height"
8879,E:\DATN\dataframe\train_file\87.txt,"    def resize_v2(img, width, height):"
8880,E:\DATN\dataframe\train_file\87.txt,"        new_img = np.transpose(img, (1, 2, 0))"
8881,E:\DATN\dataframe\train_file\87.txt,"        new_img = cv2.resize(new_img, (width, height), cv2.INTER_AREA)"
8882,E:\DATN\dataframe\train_file\87.txt,"        new_img = np.transpose(new_img, (2, 0, 1))"
8883,E:\DATN\dataframe\train_file\87.txt,        return new_img
8884,E:\DATN\dataframe\train_file\87.txt,"Trong bài viết lần này, mình có xây dựng một API bằng thư viện FastApi để các bạn dễ hình dung hơn, các bạn có thể chạy demo bằng cách sau đây:"
8885,E:\DATN\dataframe\train_file\87.txt,git clone https://github.com/buiquangmanhhp1999/extract-information-from-identity-card.git
8886,E:\DATN\dataframe\train_file\87.txt,pip install -r requirement.txt
8887,E:\DATN\dataframe\train_file\87.txt,cd complete
8888,E:\DATN\dataframe\train_file\87.txt,python server.py
8889,E:\DATN\dataframe\train_file\87.txt,Và kết quả API trả về như sau:
8890,E:\DATN\dataframe\train_file\87.txt,"  ""id"": ""174873017"","
8891,E:\DATN\dataframe\train_file\87.txt,"  ""name"": ""NGUYỄN TÀI ĐỨC"","
8892,E:\DATN\dataframe\train_file\87.txt,"  ""birth"": ""10-10-1998"","
8893,E:\DATN\dataframe\train_file\87.txt,"  ""home"": ""TT Lang Chánh Huyện Lang Chánh Thanh Hóa"","
8894,E:\DATN\dataframe\train_file\87.txt,"  ""add"": ""Xã Đông Hòa Huyện Đông Sơn Thanh Hoá"""
8895,E:\DATN\dataframe\train_file\88.txt,Multi Task Learning - Một Số Điều Bạn Nên Biết
8896,E:\DATN\dataframe\train_file\88.txt,Bài đăng này đã không được cập nhật trong 2 năm
8897,E:\DATN\dataframe\train_file\88.txt,"Multi Task Learning ( MTL) là một phương pháp không mới, tuy nhiên mức độ hiệu quả mà nó đem lại thì đã được một số đông những nhà nghiên cứu công nhận."
8898,E:\DATN\dataframe\train_file\88.txt,"Trong bài viết này, tôi sẽ giới thiệu khái quát về học đa nhiệm vụ bao gồm những động lực đằng sau việc sử dụng, lợi ích và một số phương pháp sử dụng Multi Task Learning trong Deep Learning trong đó chúng ta sẽ chỉ tập trung chủ yếu vào các nhiệm vụ phụ trợ - Auxiliary task."
8899,E:\DATN\dataframe\train_file\88.txt,I. Giới Thiệu:
8900,E:\DATN\dataframe\train_file\88.txt,Các phương pháp học máy truyền thống thường tập trung giải quyết một nhiệm vụ với một mô hình duy nhất.
8901,E:\DATN\dataframe\train_file\88.txt,"Điều này có thể khiến chúng ta bỏ qua những thông tin có thể giúp chúng ta thực hiện tốt hơn trên nhiệm vụ chúng ta quan tâm, đến từ những nhiệm vụ khác có liên quan tới nó."
8902,E:\DATN\dataframe\train_file\88.txt,"Lấy một ví dụ đơn giản khi bạn muốn dự đoán giá của một căn nhà dựa vào một số đặc trưng như diện tích, số lượng phòng, số tầng, có gần với các trung tầm thương mại nào hay không,.v..v.. thì rõ ràng việc thêm vào một vài nhiệm vụ như dự đoán căn nhà này thuộc vùng nội thành hay ngoại thành hoặc là biệt thự hay là chung cư sẽ đem lại chúng ta rất nhiều thông tin cho việc dự đoán giá của nó."
8903,E:\DATN\dataframe\train_file\88.txt,"Xét về góc độ chuyên ngành, Multi Task Learning cho phép các nhiệm vụ cùng chia sẻ chung representation của dữ liệu, nhờ vậy mà chúng ta có thể thu được một mô hình có khả năng tổng quát hơn trên nhiệm vụ ban đầu mà chúng ta quan tâm."
8904,E:\DATN\dataframe\train_file\88.txt,"Multi Task Learning còn được biết đến với một số tên gọi như Joint Learning, Learning to Learn, Learning with Auxiriary Task, mỗi khi chúng ta làm việc với một bài toán tối ưu có nhiều hơn một hàm mất mát, chúng ta ngầm định rằng chúng ta đang giải quyết một bài toán liên quan tới Multi Task Learning."
8905,E:\DATN\dataframe\train_file\88.txt,"Về mặt sinh học, học đa nhiệm vụ lấy cảm hứng từ cách con người học hỏi, khi chúng ta cần học để thực hiện một nhiệm vụ mới nào đó, chúng ta thông thường áp dụng những tri thức mà chúng ta đã thu được thông qua việc học từ các nhiệm vụ liên quan."
8906,E:\DATN\dataframe\train_file\88.txt,Ví dụ như một đứa trẻ sẽ học cách nhận biết đâu là khuôn mặt và sau đó có thể áp dụng những tri thức đó cho việc nhận dạng vật thể.
8907,E:\DATN\dataframe\train_file\88.txt,"Ở góc độ sư phạm, chúng ta thường học những kỹ năng mà từ đó cung cấp nền tàng để chúng ta học hỏi những kỹ thuật phức tạp hơn."
8908,E:\DATN\dataframe\train_file\88.txt,"Cuối cùng ở dưới góc độ của học máy, Multi Task Learning cung cấp một inductive bias trong đó sẽ thiên vị những mô hình có thể giải quyết nhiều hơn môt nhiệm vụ."
8909,E:\DATN\dataframe\train_file\88.txt,Hãy giả sử rằng chúng ta có 2 nhiệm vụ có liên quan tới
8910,E:\DATN\dataframe\train_file\88.txt,A và
8911,E:\DATN\dataframe\train_file\88.txt,"B, tôi sẽ đưa ra một số lợi ích của Multi Task Learning khi học đồng thời cả"
8912,E:\DATN\dataframe\train_file\88.txt,A và
8913,E:\DATN\dataframe\train_file\88.txt,Data Augmentation
8914,E:\DATN\dataframe\train_file\88.txt,Học đa nhiệm một cách hiệu quả tăng kích thước tập mẫu chúng ta dùng cho quá trình huấn luyện.
8915,E:\DATN\dataframe\train_file\88.txt,Bởi vì mỗi nhiệm vụ đều chứa nhiễu ( noise ) ở một mức độ nào đó.
8916,E:\DATN\dataframe\train_file\88.txt,Khi huấn luyện mô hình trên nhiệm vụ
8917,E:\DATN\dataframe\train_file\88.txt,"A, mục tiêu của chúng ta là tìm một representation cho A, thứ một cách lý tưởng sẽ là tốt nếu nó tổng quát và độc lập với nhiễu."
8918,E:\DATN\dataframe\train_file\88.txt,"Bởi vì các nhiệm vụ đều có chứa các noise paterns khác nhau, một mô hình học 2 nhiệm vụ đồng thời sẽ có khả năng học được một representation tổng quát hơn."
8919,E:\DATN\dataframe\train_file\88.txt,Việc học
8920,E:\DATN\dataframe\train_file\88.txt,"A sẽ có rủi ro overfitting A, trong khi đó việc học đồng thời cả"
8921,E:\DATN\dataframe\train_file\88.txt,A và
8922,E:\DATN\dataframe\train_file\88.txt,B cho phép mô hình học được một biểu diễn tốt hơn thông qua việc lấy trung bình các noise paterns cũng mỗi nhiệm vụ.
8923,E:\DATN\dataframe\train_file\88.txt,Attention Focusing
8924,E:\DATN\dataframe\train_file\88.txt,"Nếu một nhiệm vụ chứa rất nhiều noise, hoặc dữ liệu bị giới hạn và nằm trong không gian có số chiều cao."
8925,E:\DATN\dataframe\train_file\88.txt,Sẽ là rất khó để mô hình của chúng ta phân biệt được đâu là những đặc trưng liên quan và không liên quan.
8926,E:\DATN\dataframe\train_file\88.txt,"Học đa nhiệm có thể giúp mô hình tập trung sự chú ý của nó vào những đặc trưng quan trọng thật sự, bởi vì các nhiệm vụ khác sẽ cung cấp những thông tin hữu ích cho việc phát hiện đâu là đặc trưng quan trọng và đâu là không quan trọng,"
8927,E:\DATN\dataframe\train_file\88.txt,Một số đặc trưng có thể rất dễ để được học bởi nhiệm vụ
8928,E:\DATN\dataframe\train_file\88.txt,B trong khi lại rất khó để
8929,E:\DATN\dataframe\train_file\88.txt,"A có thể học được nó, điều này sẽ xa khi"
8930,E:\DATN\dataframe\train_file\88.txt,"A tương tác với những đặc trưng đó theo một cách rất phức tạp, hoặc việc học những đặc trưng khác đang ngăn cản khả năng học đặc trưng đó của"
8931,E:\DATN\dataframe\train_file\88.txt,"A. Thông qua MTL, chúng ta có thể học những đặc trưng rất khó để học với"
8932,E:\DATN\dataframe\train_file\88.txt,"A, thông qua"
8933,E:\DATN\dataframe\train_file\88.txt,B. Một cách hữu hiệu để thực hiện đó là chúng ta sẽ trực tiếp huấn luyện mô hinh để dự đoán những đặc trưng quan trọng.
8934,E:\DATN\dataframe\train_file\88.txt,III.4 Representation bias
8935,E:\DATN\dataframe\train_file\88.txt,"MTL thiên vị những representation không chỉ hữu ích trên một nhiệm vụ cụ thể, mà là trên nhiều nhiệm vụ khác nhau."
8936,E:\DATN\dataframe\train_file\88.txt,"Điều này cho phép chúng ta tổng quát hóa trên một lớp các nhiệm vụ, thực hiện tốt trên một tập hợp nhiều nhiệm vụ sẽ cho chúng ta khả năng thực hiện tốt cả trên cả một nhiệm vụ mới trong tương lai, chừng nào các nhiệm vụ này còn chia sẽ chung môi trường."
8937,E:\DATN\dataframe\train_file\88.txt,III.5 Regularization
8938,E:\DATN\dataframe\train_file\88.txt,"MTL có khả năng giảm overfitting nhờ thiên vị các biểu diễn hữu ích trên nhiều nhiều nhiệm vụ, vì vậy khả năng mô hình quá fit vào một nhiệm vụ nào đó sẽ giảm đi."
8939,E:\DATN\dataframe\train_file\88.txt,Multi Task Learning trong Neural Network:
8940,E:\DATN\dataframe\train_file\88.txt,"MTL có rất nhiều cách sử dụng khác nhau, tuy nhiên trong context của Deep Learning, tôi chỉ xin phép giới thiệu 2 phương pháp đó là: Hard Parameter Sharing và Soft Parameter Sharing."
8941,E:\DATN\dataframe\train_file\88.txt,Hard Parameter Sharing.
8942,E:\DATN\dataframe\train_file\88.txt,Hard Sharing là một phương pháp được sử dụng rất nhiều trong Neural Network.
8943,E:\DATN\dataframe\train_file\88.txt,"Nó được thực hiện bằng cách chia sẽ các lớp hidden ở trên tất cả các nhiệm vụ, trong khi chỉ giữ các lớp output layer là khác nhau."
8944,E:\DATN\dataframe\train_file\88.txt,Hard parameter sharing giảm overfitting rất tốt.
8945,E:\DATN\dataframe\train_file\88.txt,"việc chia sẽ các hidden layer giữa các nhiệm vụ sẽ ép buộc mô hình của chúng ta phải học những biểu diễn tổng quát thích hợp ở trên nhiều nhiệm vụ, nhờ vậy mà khả năng overfitting vào một nhiệm vụ cụ thể nào đó sẽ giảm đi rất nhiều."
8946,E:\DATN\dataframe\train_file\88.txt,Soft Parameter Sharing.
8947,E:\DATN\dataframe\train_file\88.txt,"Soft Parameter Sharing thì khác biệt hoàn toàn, mỗi nhiệm vụ sẽ có mô hình riêng, cũng như tham số riêng của nó, tuy nhiên khoảng cách của các tham số giữa các nhiệm vụ sau đó sẽ được ràng buộc để khiến các tham số này có mức độ tương đồng cao giữa các nhiệm vụ."
8948,E:\DATN\dataframe\train_file\88.txt,Ở đây chúng ta có thể sử dụng các Norm để constraint
8949,E:\DATN\dataframe\train_file\88.txt,"Nếu các bạn đã nghe tới Ridge Regression thì phương pháp này có khá nhiều điểm tương đồng với nó, chỉ khác rằng Ridge Regression ràng buộc cường độ tham số, còn Soft Parameter Sharing sẽ ràng buộc khoảng cách."
8950,E:\DATN\dataframe\train_file\88.txt,V. Auxiliary task:
8951,E:\DATN\dataframe\train_file\88.txt,"Trong nhiều trường hợp, chúng ta chỉ quan tâm tới hiệu suất của một nhiệm vụ cụ thể, tuy nhiên chúng ta lại muốn tận dụng được những lợi ích mà MTL mang lại, những trường hợp thế này chúng ta có thể thêm vào một số nhiệm vụ liên quan tới nhiệm vụ chính mà chúng ta quan tâm với mục đích là cải thiện thêm hiệu suất trên nhiệm vụ chính ."
8952,E:\DATN\dataframe\train_file\88.txt,Các nhiệm vụ này được gọi là các nhiệm vụ phụ trợ - Auxiliary task.
8953,E:\DATN\dataframe\train_file\88.txt,"Việc sử dụng các Auxiliary task như thế nào so với Main task là vấn đề đã được nghiên cứu từ lâu, tuy nhiên không có bằng chứng lý thuyết chắc chắn việc sử dụng các Auxiliary task nào sẽ đem lại sự cải thiện cho Main task."
8954,E:\DATN\dataframe\train_file\88.txt,Dưới đây tôi sẽ chỉ ra một vài gợi ý có từ thực nghiệm của các nghiên cứu trước đó liên quan tới cách sử dụng các Auxilirary task như thế nào cho hiệu quả.
8955,E:\DATN\dataframe\train_file\88.txt,Share Layers.
8956,E:\DATN\dataframe\train_file\88.txt,But Share What ?
8957,E:\DATN\dataframe\train_file\88.txt,"Đây là một câu hỏi đã được đặt ra từ lâu, các nghiên cứu trước đó chỉ ra rằng, các low-level task ( như là POS Tagging hay NER) nên được sử dụng tại các layer thấp nhất, ngược lại các high-level task yêu cầu nhiều thông tin hơn có thể được sử dụng ở các layer cao nhất ( như là Chunking, Dependency Parsing hay Relation Extraction)."
8958,E:\DATN\dataframe\train_file\88.txt,Cụ thể là  chỉ ra rằng việc sử dụng POS ở những layer thấp hơn sẽ đem đến những cải thiện trong hiệu suất của Chunking ( cái này mình đã làm để confirm và thấy nó chính xác).
8959,E:\DATN\dataframe\train_file\88.txt,Trong khi đó  xây dựng một mô hình phân tầng theo cấp độ ngôn ngữ học cho một tập hợp các nhiệm vụ NLP khác nhau.
8960,E:\DATN\dataframe\train_file\88.txt,Weighted Loss
8961,E:\DATN\dataframe\train_file\88.txt,"Khi chúng ta làm việc với MTL, tức là khi chúng ta đang làm việc vơi nhiều hơn một loss function, vì hàm mất mát cuối cùng là một weighted sum của các loss function thành phần."
8962,E:\DATN\dataframe\train_file\88.txt,L_{final} = \sum_{i} \lambda_i L_i
8963,E:\DATN\dataframe\train_file\88.txt,Trong đó
8964,E:\DATN\dataframe\train_file\88.txt, là trọng số của mỗi loss function.
8965,E:\DATN\dataframe\train_file\88.txt,Việc chọn trọng số
8966,E:\DATN\dataframe\train_file\88.txt," như thế nào là một công việc quan trọng, đơn giản nhất là các bạn có thể chọn"
8967,E:\DATN\dataframe\train_file\88.txt,\lambda_i = c
8968,E:\DATN\dataframe\train_file\88.txt,=c với
8969,E:\DATN\dataframe\train_file\88.txt,c là một hằng số bất kỳ náo đó có thể được tìm kiếm bằng cross validation.
8970,E:\DATN\dataframe\train_file\88.txt,Một số loại Auxiliary Task thường dùng.
8971,E:\DATN\dataframe\train_file\88.txt,"Các nhiêm vụ phụ trợ cụ thê có thể tùy biến khác nhau, tuy nhiên nhìn chung thì tất cả các Auxiliary Task có thể được phân nhóm thành 4 loại sau đây."
8972,E:\DATN\dataframe\train_file\88.txt,"Statistical: Đây là các nhiệm vụ phụ trợ đơn giản nhất, chúng ta sẽ sử dụng các nhiệm vụ dự đoán các tính chất thống kê của dữ liệu như là Auxiliary Task."
8973,E:\DATN\dataframe\train_file\88.txt,"ví dụ như dụ đoán Log Freqency của một từ, Pos Tag, v..v"
8974,E:\DATN\dataframe\train_file\88.txt,"Selective Unsupervised:: Đây là những nhiệm vụ yêu cầu chúng ta dự đoán một phần của đầu vào, cụ thể như trong Sentiment Analysis ta có thể dự đoán xem khi nào câu chứa một từ Positive Sentiment hay Negative Sentiment Word."
8975,E:\DATN\dataframe\train_file\88.txt,Supervised: Các nhiệm vụ này có thể là các nhiệm vụ kiểu đối đầu ( Adversarial Task ) hoặc các nhiệm vụ nghịch đảo (Inverse Task) hoặc là các nhiệm vụ giám sát có liên quan tới dữ liệu (ví dụ Predict Inputs chảng hạn).
8976,E:\DATN\dataframe\train_file\88.txt,Unsupervised: Đây là những nhiệm vụ liên quan tới dự đoán tất cả các phần của dữ liệu đầu vào.
8977,E:\DATN\dataframe\train_file\88.txt,"Multi Task Learning là một phương pháp không mới, tuy nhiên hiệu quả mà nó đem lại thì thật sự không cần phải bàn cãi."
8978,E:\DATN\dataframe\train_file\88.txt,"Trên đây chỉ là một chút giới thiệu của mình về MTL, các bạn muốn hiểu sâu hơn có thể tham khảo Phd Thesis dưới đây để có thêm những thông tin cụ thể hơn."
8979,E:\DATN\dataframe\train_file\88.txt,"Lần tới có lẽ mình sẽ giới thiệu về một phương pháp khá gần với MTL đó là Sequential Learning, hi vọng các bạn sẽ ủng hộ và theo dõi."
8980,E:\DATN\dataframe\train_file\89.txt,[Deep Learning][Optimization] Neural Network Compression - All essential things You Need!
8981,E:\DATN\dataframe\train_file\89.txt,Bài đăng này đã không được cập nhật trong 2 năm
8982,E:\DATN\dataframe\train_file\89.txt,"Chào mọi người, chúng ta đang sống và làm việc trong sự trỗi dậy rất lớn của AI trong một vài năm trở lại đây, đặc biệt là ở Việt Nam, người người nhà nhà đều AI, các trường đại học cũng mở ra vô số các khoa các nghành mới liên quan đến thuật ngữ này với một tương lai đầy hứa hẹn để thu hút các tân sinh viên."
8983,E:\DATN\dataframe\train_file\89.txt,"Với sự mạnh mẽ của các thuật toán như ML, đặc biệt là Deep Learning,... có những bài toán độ chính xác của máy đã có thể vượt con người trong khả năng nhận diện và tương lai sẽ còn hơn thế nữa."
8984,E:\DATN\dataframe\train_file\89.txt,"Ngay từ hồi đi học mình vẫn rất thường được nghe các thầy của mình nói vui rằng Deep Learning là bộ môn của con nhà giàu, tất nhiên đây chỉ là 1 cách nói biếm họa để chỉ cho thấy sự tốn kém trong việc đầu tư máy móc phục vụ việc nghiên cứu, phát triển các bài toán dạng này, và không phải ai cũng sẵn sàng để chi ra 1 số tiền lớn cho các máy tính kiểu như thế này, đặc biệt là khách hàng của chúng ta những người luôn đặt yếu tố kinh tế lên hàng đầu."
8985,E:\DATN\dataframe\train_file\89.txt,Vậy câu hỏi đặt ra là cơ hội nào cho những mô hình Deep Learning này chạy được trên các ứng dụng đời thường như các ứng dụng chạy trên máy tính CPU (without GPU) or trên các máy điện thoại.
8986,E:\DATN\dataframe\train_file\89.txt,"Đã có những ý tưởng được đưa ra ví dụ như sự cải tiến trong các mô hình deep learning, giúp nó nhẹ hơn, đòi hỏi ít tham số mô hình hơn mà vẫn đạt được độ chính xác cao như MobileNet, SqueezeNet,... hoặc các techniques compress model như Neural Network pruning, quantization,... etc"
8987,E:\DATN\dataframe\train_file\89.txt,"Do vậy, ở bài viết này, mình sẽ cung cấp cho mọi người:"
8988,E:\DATN\dataframe\train_file\89.txt,1 cái nhìn tổng quan nhất về 1 số techniques của models compression
8989,E:\DATN\dataframe\train_file\89.txt,"Giải thích chi tiết cách thức hoạt động của Neural Network Pruning, Neural Network quantization bằng việc cung cấp các kiến thức từ papers"
8990,E:\DATN\dataframe\train_file\89.txt,Cung cấp code implement để mọi người có thể áp dụng được
8991,E:\DATN\dataframe\train_file\89.txt,Cung cấp các tài liệu mà mình đã thu được thành một nguồn để các bạn tham khảo
8992,E:\DATN\dataframe\train_file\89.txt,"Note: Bài viết này được viết dựa trên ý hiểu cá nhân thông qua mình đọc các blog posts và papers, mọi ý kiến đóng góp xin vui lòng write comments down below or send throught email của mình ."
8993,E:\DATN\dataframe\train_file\89.txt,"Nếu nó có ích cho bạn, đừng tiếc 1 upvote cho mình nhé  ."
8994,E:\DATN\dataframe\train_file\89.txt,Ảnh minh họa cho compression model
8995,E:\DATN\dataframe\train_file\89.txt,"Trước khi đi vào chi tiết về cách thức hoạt động, cách implement, chúng ta sẽ cùng nhau tìm hiểu sơ qua Neural Network Compression là gì, và tại sao cần quan tâm đến techniques này nhé."
8996,E:\DATN\dataframe\train_file\89.txt,"Đầu tiên, có thể nói các thuật toán Neural Network Compression là một nhánh nhỏ trong tập thuật toán model optimization, nó được sinh ra với mục đích giúp giải quyết bài toán khi deploy các model Deep Learning trên các thiết bị phần cứng không được mạnh mẽ như (mobile devices, ...)."
8997,E:\DATN\dataframe\train_file\89.txt,"Với một mô hình deep learning, sẽ luôn có 1 câu hỏi thường trực là liệu model này có khả năng ứng dụng thực tế hay không, có khả năng chạy realtime trên một device đời thường để khi deploy lên ai cũng có thể sử dụng được không."
8998,E:\DATN\dataframe\train_file\89.txt,"Thật sự là không dễ dàng gì khi mà chúng ta luôn phải trade-off giữa độ chính xác và tốc độ xử lý của 1 mô hình, thông thường độ chính xác cao như ở 1 số paper SOTA (state-of-the-art) thường chứa 1 lượng tham số rất lớn (chục triệu đến hàng trăm triệu tham số) dẫn đến việc lưu trữ và tính toán trở lên khó khăn hơn rất nhiều nếu không có các thiết bị hỗ trợ (như GPU), còn một số mô hình quá ít tham số thì dẫn đến việc đôi khi lại không đủ sâu để học được hết các features và trả về độ chính xác đủ tốt."
8999,E:\DATN\dataframe\train_file\89.txt,"Vì vậy, các phương pháp optimize model ra đời giúp các model này trở lên gọn nhẹ hơn, nhỏ hơn nhưng vẫn đủ mạnh mẽ như model ban đầu khi đưa chúng chạy trên các ứng dụng thực tế, điều này là rất cần thiết vì không ai trong chúng ta muốn một model tiêu tốn bao công training lại không thể apply vào bất kì ứng dụng nào."
9000,E:\DATN\dataframe\train_file\89.txt,"Hiện nay có khá nhiều các thuật toán model compression, có thể kể đến như: Network Pruning and Quantization, Low-rank Factorization, Transferred/compact convolutional filters or Knowledge distillation, ... Cùng xem qua bảng tổng quan về ý tưởng, ứng dụng của các thuật toán qua ảnh dưới đây:"
9001,E:\DATN\dataframe\train_file\89.txt,Ảnh được copy từ official paper
9002,E:\DATN\dataframe\train_file\89.txt,"Mỗi thuật toán có một nguyên lý hoạt động khác nhau, giờ chúng ta sẽ cùng tìm hiểu chi tiết một số thuật toán thông dụng."
9003,E:\DATN\dataframe\train_file\89.txt,"Ở đây, mình giả sử chúng ta đã train được 1 model đủ tốt, nghĩa là chúng ta hài lòng về độ chính xác, nhưng vì nó quá nặng cả về size lẫn thời gian tính toán, gặp khó khăn khi ta muốn đóng gói và deploy để thử nghiệm."
9004,E:\DATN\dataframe\train_file\89.txt,Do đó chúng ta muốn nén cái model này lại để nó bé và nhanh hơn.
9005,E:\DATN\dataframe\train_file\89.txt,Dưới đây là một vài techniques chúng ta có thể sử dụng:
9006,E:\DATN\dataframe\train_file\89.txt,2.1 Network Pruning
9007,E:\DATN\dataframe\train_file\89.txt,Ảnh minh họa cho Network Pruning
9008,E:\DATN\dataframe\train_file\89.txt,"Đúng với ý nghĩa của từ ""Pruning"", kĩ thuật này dựa trên ý tưởng loại bỏ đi những thành phần dư thừa trên toàn bộ tham số mô hình."
9009,E:\DATN\dataframe\train_file\89.txt,"Trong tổng số những tham số mà mô hình đang lưu trữ, sẽ có những tham số đóng vai trò chính và cũng có những tham số không đóng góp được gì nhiều."
9010,E:\DATN\dataframe\train_file\89.txt,Sự đóng góp này được thể hiện qua giá trị weight mà nó đang lưu trữ.
9011,E:\DATN\dataframe\train_file\89.txt,Giá trị lớn hơn đóng vai trò lớn hơn và ngược lại.
9012,E:\DATN\dataframe\train_file\89.txt,Do đó việc tìm ra một ngưỡng (threshold) để phân loại giữa đâu là weight quan trọng và đâu là weight không quan trọng là cốt lõi của thuật toán này.
9013,E:\DATN\dataframe\train_file\89.txt,Các threshold này có thể là 1 số do ta tự định nghĩa hoặc cũng có thể dynamic theo kiểu là giá trị độ lệch chuẩn (standard deviation) của tập weights.
9014,E:\DATN\dataframe\train_file\89.txt,"Quan sát ảnh phía trên có thể thấy, các connection có giá trị weight nhỏ hơn giá trị threshold này sẽ bị lược bỏ (xét về 0), dẫn đến chúng ta sẽ thu được các sparse weight matrix hay còn gọi là ma trận weight rời rạc."
9015,E:\DATN\dataframe\train_file\89.txt,"Tại thời điểm này, sau khi pruning chất lượng mô hình sẽ không còn được như ban đầu vì nó đã bị cắt đi một vài thành phần."
9016,E:\DATN\dataframe\train_file\89.txt,Do đó chúng ta cần train lại pruned model để các weights params của nó được cập nhật lại các giá trị mới sao cho nó bù lại được những gì nó đã mất.
9017,E:\DATN\dataframe\train_file\89.txt,Kỹ thuật này được gọi là Iterative Pruning.
9018,E:\DATN\dataframe\train_file\89.txt,"Ngoài ra, trong paper , tác giả còn prune cả neurons, không chỉ mỗi weights."
9019,E:\DATN\dataframe\train_file\89.txt,"Note: Tensorflow có cung cấp cho chúng ta 1 module tensorflow-model-optimization giúp giải quyết bài toán này, chúng ta chỉ cần follow theo hướng dẫn tại  là có thể thực hiện được."
9020,E:\DATN\dataframe\train_file\89.txt,"Tuy nhiên, trong phần implementation để hiểu hơn về thuật toán, mình sẽ cùng nhau implement lại từ đầu để hiểu hơn về thuật toán thay vì chỉ biết dùng công cụ có sẵn"
9021,E:\DATN\dataframe\train_file\89.txt,2.2 Network Quantization
9022,E:\DATN\dataframe\train_file\89.txt,Ảnh minh họa cho quantization techniques
9023,E:\DATN\dataframe\train_file\89.txt,"Tại đây, chúng ta quan tâm đến việc tối ưu hóa việc lưu weight như thế nào hơn là tối ưu hóa giá trị weight đang có."
9024,E:\DATN\dataframe\train_file\89.txt,"Quay ngược lại lý thuyết arithmetic operations, hiện ta cần dùng 32bits để biểu diễn mỗi weight (floating-point of 32 bits), do đó ý tưởng chính của quantization là làm sao để giảm số lượng bit cần dùng để biểu diễn này xuống mà vẫn giữ được độ chính xác của mô hình."
9025,E:\DATN\dataframe\train_file\89.txt,Cụ thể hơn là chuyển hoá các floating-point arithmetic thành fixed-point trong các mạng neural networks.
9026,E:\DATN\dataframe\train_file\89.txt,Một số thuật ngữ về quantization chúng ta có thể quan tâm đến như:
9027,E:\DATN\dataframe\train_file\89.txt,"Low precision: biểu thị việc dùng các numeric format như FP16 (half precision floating point), INT8 (fixed point integer of 8 bits),... để biểu diễn weights"
9028,E:\DATN\dataframe\train_file\89.txt,"Mixed precision: dùng cả FP32 và FP16 cho việc lưu trữ, trong đó FP16 giúp giảm 1 nửa memory size, còn FP32 có nhiệm vụ lưu giữ lại những weights quan trọng nhất."
9029,E:\DATN\dataframe\train_file\89.txt,1 số sub-categories của quantization như:
9030,E:\DATN\dataframe\train_file\89.txt,: Neural networks với binary weight
9031,E:\DATN\dataframe\train_file\89.txt,": Neural networks với các giá trị weights trong khoảng +1, 0, -1"
9032,E:\DATN\dataframe\train_file\89.txt,Ví dụ 1 số kiểu kiến trúc áp dụng model quantization (ảnh copy)
9033,E:\DATN\dataframe\train_file\89.txt,"Hiện nay một số frameworks cung cấp cho chúng ta cả các Quantize/Dequantize layers giúp convert input/output thành INT8 trước khi đưa/lấy chúng qua/từ các Convolution/FC layers, về mặt bản chất thì các input/output và model vẫn có dạng format FP32."
9034,E:\DATN\dataframe\train_file\89.txt,Hoặc cũng có 1 số hỗ trợ việc convert cả mô hình sang kiểu INT8 luôn.
9035,E:\DATN\dataframe\train_file\89.txt,Cùng tham khảo hình phía trên.
9036,E:\DATN\dataframe\train_file\89.txt,2.3 Weight-Sharing
9037,E:\DATN\dataframe\train_file\89.txt,Ảnh minh họa: Weight Sharing (Copy từ official paper)
9038,E:\DATN\dataframe\train_file\89.txt,"Tại đây chúng ta cùng tìm hiểu một loại technique mới cũng được áp dụng rất nhiều trong model compression đó là Weight-Sharing, 1 số paper rất hay nói về technique này các bạn có thể đọc tại ."
9039,E:\DATN\dataframe\train_file\89.txt,Ý tưởng chung của thuật toán này đó là việc chia sẻ các tham số weight giữa các phần tử weight trong các matrix weight của mô hình.
9040,E:\DATN\dataframe\train_file\89.txt,"Như các mô hình thông thường, mỗi phần tử trong ma trận weight sẽ có giá trị riêng của chúng, nhưng khi áp dụng weight-sharing, các giá trị weight của ma trận sẽ được tổ chức lại thành các nhóm, các phần tử cùng nhóm sẽ có cùng chỉ số weight."
9041,E:\DATN\dataframe\train_file\89.txt,"Vậy tại sao nó lại tiết kiệm được bộ nhớ, giúp mô hình nhẹ hơn."
9042,E:\DATN\dataframe\train_file\89.txt,"Các bạn cùng quan sát hình phía trên, thay vì nó lưu toàn bộ weight thì giờ đây ta chỉ lưu lại giá trị weight của các nhóm và ma trận chỉ số nhóm cho các phần tử thuộc ma trận weight này."
9043,E:\DATN\dataframe\train_file\89.txt,"Phân tích thêm 1 chút nhé: Lấy ví dụ cách tính toán ở hình trên, đầu tiên ta khởi tạo giá trị các nhóm bằng cách lấy trung bình cộng của các giá trị gần giống nhau và lưu lại các chỉ số nhóm cho các phần tử này."
9044,E:\DATN\dataframe\train_file\89.txt,"Với mỗi lần tính toán gradient, các giá trị gradient của mỗi phần tử tại các nhóm sẽ được tính tổng lại rồi nhân với giá trị learning_rate."
9045,E:\DATN\dataframe\train_file\89.txt,Giờ đây ta sẽ áp dụng gradient descent lên các nhóm này.
9046,E:\DATN\dataframe\train_file\89.txt,"Việc chia sẻ weights như thế này tất nhiên sẽ ảnh hưởng đến độ chính xác của mô hình, do đó sau mỗi lần tính toán weight-sharing ta cần retrain để update và tìm được bộ tham số tốt nhất cho mô hình."
9047,E:\DATN\dataframe\train_file\89.txt,Ngoài ra việc tìm được số nhóm weight tối ưu cũng là rất quan trọng.
9048,E:\DATN\dataframe\train_file\89.txt,Mình sẽ chia sẽ cách thực hiện thuật toán này với tensorflow tại phần implementation.
9049,E:\DATN\dataframe\train_file\89.txt,2.4 Knowledge Distillation (KD)
9050,E:\DATN\dataframe\train_file\89.txt,"Thuật toán đầu tiên được sử dụng với cái tên knowledge transfer để xuất bởi Caruana, về sau được hiểu dưới context của Knowledge Distillation."
9051,E:\DATN\dataframe\train_file\89.txt,Tư tưởng chính của thuật toán là nén một mô hình lớn và sâu hơn dưới dạng một mô hình nhỏ hơn bằng cách cho mô hình nhỏ hơn bắt chước những gì mô hình lớn đã học được thông qua phân phối các output class từ softmax.
9052,E:\DATN\dataframe\train_file\89.txt,"Các mô hình kiểu này được training dựa theo kiểu teacher-student, mô hình lớn sẽ là teacher còn mô hình nhỏ hơn là student."
9053,E:\DATN\dataframe\train_file\89.txt,Các mô hình nhỏ sẽ học dựa trên các label hay soft-label được sinh ra từ mô hình lớn.
9054,E:\DATN\dataframe\train_file\89.txt,"Ngay từ đầu, điểm hạn chế của KD là không hiệu quả với các mô hình con với kiểu kiến trúc quá nông, quá ít tham số."
9055,E:\DATN\dataframe\train_file\89.txt,"Tuy nhiên với sự ra đời của 1 cách tiếp cận mới, FitNets, và các kiểu kiến trúc giúp mô hình nhẹ hơn, ít tham số hơn nhưng vẫn giữ được độ sâu như kiến trúc residual connection, inception, squeeze đã giúp KD trở lên mạnh mẽ hơn rất nhiều."
9056,E:\DATN\dataframe\train_file\89.txt,"Hạn chế của KD là nó chỉ áp dụng được cho các bài toán classification, vì mạng student học qua output lớp softmax của mạng teacher, và so sánh với 1 số thuật toán Model Compression khác, nó cũng tỏ ra kém hiệu quả hơn."
9057,E:\DATN\dataframe\train_file\89.txt,Coding Implementation
9058,E:\DATN\dataframe\train_file\89.txt,"Hiện nay, tensorflow đã cung cấp api giúp việc compress model rất hiệu quả."
9059,E:\DATN\dataframe\train_file\89.txt,"Tuy nhiên, để hiểu rõ bản chất vấn đề và mình cũng muốn biết đâu trong quá trình mày mò implement mình lại ra được ý tưởng gì đó để viết paper (hihi)."
9060,E:\DATN\dataframe\train_file\89.txt,"Ở phần này, mình follow theo tư tưởng của paper , bước 1 sẽ là network pruning, bước 2 là quantization và weight sharing, còn mình bỏ qua bước 3 vì huffman coding là 1 thuật toán riêng biệt và nên được tách ra thành 1 bài cụ thể thì hay hơn."
9061,E:\DATN\dataframe\train_file\89.txt,"Vì code cho toàn bộ quá trình training và các kỹ thuật là khá dài nên mình sẽ chỉ show lên 1 vài function chính nhất, phần source code mình sẽ cung cấp để mọi người tham khảo được kỹ hơn."
9062,E:\DATN\dataframe\train_file\89.txt,Giờ ta sẽ đi chi tiết vào từng phần 1.
9063,E:\DATN\dataframe\train_file\89.txt,3.1 Network pruning
9064,E:\DATN\dataframe\train_file\89.txt,"Ta sẽ tạo 1 class layer, trong đó bao gồm hàm khởi tạo các thông số layer, hàm feed forward, các hàm pruning và quantization."
9065,E:\DATN\dataframe\train_file\89.txt,"Đầu tiên, khởi tạo layers:"
9066,E:\DATN\dataframe\train_file\89.txt,class TrainLayer(object):
9067,E:\DATN\dataframe\train_file\89.txt,"    def __init__(self, input_dims, output_dims, n_clusters, name, kernel_size=(5, 5)):"
9068,E:\DATN\dataframe\train_file\89.txt,        self.name = name
9069,E:\DATN\dataframe\train_file\89.txt,        self.kernel_size = kernel_size
9070,E:\DATN\dataframe\train_file\89.txt,"        if ""conv"" in self.name:"
9071,E:\DATN\dataframe\train_file\89.txt,"            self.w = tf.Variable(initial_value=tf.random.normal((*kernel_size, input_dims, output_dims),"
9072,E:\DATN\dataframe\train_file\89.txt,"        elif ""fc"" in self.name:"
9073,E:\DATN\dataframe\train_file\89.txt,"            self.w = tf.Variable(initial_value=tf.random.normal([input_dims, output_dims],"
9074,E:\DATN\dataframe\train_file\89.txt,"        self.w_PH = tfv.placeholder(tf.float32, shape=self.w.shape)"
9075,E:\DATN\dataframe\train_file\89.txt,"        self.assign_w = tfv.assign(self.w, self.w_PH)"
9076,E:\DATN\dataframe\train_file\89.txt,        self.num_total_weights = np.prod(self.w.shape)
9077,E:\DATN\dataframe\train_file\89.txt,        ### Create mask for pruning weight
9078,E:\DATN\dataframe\train_file\89.txt,"        self.pruning_mask_data = np.ones_like(self.w.shape, dtype=np.float32)"
9079,E:\DATN\dataframe\train_file\89.txt,        ### Number of cluster for quantization
9080,E:\DATN\dataframe\train_file\89.txt,        self.n_clusters = n_clusters
9081,E:\DATN\dataframe\train_file\89.txt,"    def forward(self, x):"
9082,E:\DATN\dataframe\train_file\89.txt,"        if ""conv"" in self.name:"
9083,E:\DATN\dataframe\train_file\89.txt,"            return tf.nn.conv2d(x, self.w, strides=[1, 1, 1, 1], padding=""SAME"")"
9084,E:\DATN\dataframe\train_file\89.txt,"        elif ""fc"" in self.name:"
9085,E:\DATN\dataframe\train_file\89.txt,"            return tf.matmul(x, self.w)"
9086,E:\DATN\dataframe\train_file\89.txt,"Trên đây, chúng ta quan tâm đến w lưu các giá trị weight của layer, w_PH dùng để tính toán các giá trị weight sau khi thay đổi sau đó feed vào hàm assign để gán lại giá trị cho w. pruning_mask_data dùng để lưu vị trí giá trị weights, 0 là đã bị pruning, và 1 là có giá trị."
9087,E:\DATN\dataframe\train_file\89.txt,"Và cuối cùng là clusters, số nhóm dùng cho quantization và weight-sharing."
9088,E:\DATN\dataframe\train_file\89.txt,"Tiếp đến ta sẽ cùng ngó qua hàm pruning, và các hàm update giá trị sau mỗi lần pruning:"
9089,E:\DATN\dataframe\train_file\89.txt,"def prune_weights(self, sess, threshold):"
9090,E:\DATN\dataframe\train_file\89.txt,    w_data = sess.run(self.w)
9091,E:\DATN\dataframe\train_file\89.txt,    self.pruning_mask_data = (w_data >= threshold).astype(np.float32)
9092,E:\DATN\dataframe\train_file\89.txt,"    sess.run(self.assign_w, feed_dict={self.w_PH: self.pruning_mask_data*w_data})"
9093,E:\DATN\dataframe\train_file\89.txt,"def prune_weights_gradient(self, grad):"
9094,E:\DATN\dataframe\train_file\89.txt,    return grad * self.pruning_mask_data
9095,E:\DATN\dataframe\train_file\89.txt,"def prune_weights_update(self, sess):"
9096,E:\DATN\dataframe\train_file\89.txt,    w_data = sess.run(self.w)
9097,E:\DATN\dataframe\train_file\89.txt,"   sess.run(self.assign_w, feed_dict={self.w_PH: self.pruning_mask_data*w_data})"
9098,E:\DATN\dataframe\train_file\89.txt,"Ta sẽ chỉ pruning weight 1 lần sau khi mô hình đã được train đến 1 độ chính xác nhất định, và các bước sau đó là việc train đi train lại để phục hồi được độ chính xác cho mô hình."
9099,E:\DATN\dataframe\train_file\89.txt,"Tuỳ theo từng kiến trúc mô hình và độ sâu, thường thì sau iterative pruning độ chính xác mô hình sẽ giảm đi đôi chút."
9100,E:\DATN\dataframe\train_file\89.txt,"Việc xét ngưỡng để pruning là rất quan trọng, nó ảnh hướng khá nhiều đến độ chính xác, lời khuyên của mình là nên tính toán ra mean, và độ lệch chuẩn của weight để có thể chọn ra được 1 giá trị threshold phù hợp."
9101,E:\DATN\dataframe\train_file\89.txt,3.2 Quantization and Weight-sharing
9102,E:\DATN\dataframe\train_file\89.txt,"Như đã trình bày từ trước, tư tưởng chính của thuật toán này là việc phân cụm cho các giá trị weight."
9103,E:\DATN\dataframe\train_file\89.txt,Cụ thể mọi người có thể đọc lại phần bên trên nhé.
9104,E:\DATN\dataframe\train_file\89.txt,Dưới đây sẽ là example code cho phần này nha:
9105,E:\DATN\dataframe\train_file\89.txt,"def quantize_weights(self, sess):"
9106,E:\DATN\dataframe\train_file\89.txt,    w_data = sess.run(self.w)
9107,E:\DATN\dataframe\train_file\89.txt,    max_val = np.max(w_data)
9108,E:\DATN\dataframe\train_file\89.txt,    min_val = np.min(w_data)
9109,E:\DATN\dataframe\train_file\89.txt,"    self.centroids = np.linspace(min_val, max_val, self.n_clusters)"
9110,E:\DATN\dataframe\train_file\89.txt,"    w_data = np.expand_dims(w_data, 0)"
9111,E:\DATN\dataframe\train_file\89.txt,    centroids_prev = np.copy(self.centroids)
9112,E:\DATN\dataframe\train_file\89.txt,    for i in range(30):
9113,E:\DATN\dataframe\train_file\89.txt,        if 'conv' in self.name:
9114,E:\DATN\dataframe\train_file\89.txt,"            distances = np.abs(w_data - np.reshape(self.centroids, (-1, 1, 1, 1, 1)))"
9115,E:\DATN\dataframe\train_file\89.txt,"            distances = np.transpose(distances, (1, 2, 3, 4, 0))"
9116,E:\DATN\dataframe\train_file\89.txt,        elif 'fc' in self.name:
9117,E:\DATN\dataframe\train_file\89.txt,"            distances = np.abs(w_data - np.reshape(self.centroids, (-1, 1, 1)))"
9118,E:\DATN\dataframe\train_file\89.txt,"            distances = np.transpose(distances, (1, 2, 0))"
9119,E:\DATN\dataframe\train_file\89.txt,"        classes = np.argmin(distances, axis=-1)"
9120,E:\DATN\dataframe\train_file\89.txt,        for i in range(self.n_clusters):
9121,E:\DATN\dataframe\train_file\89.txt,            cluster_mask = (classes == i).astype(np.float32) * self.pruning_mask_data
9122,E:\DATN\dataframe\train_file\89.txt,            num_weights_assigned = np.sum(cluster_mask)
9123,E:\DATN\dataframe\train_file\89.txt,            if num_weights_assigned != 0:
9124,E:\DATN\dataframe\train_file\89.txt,                self.centroids[i] = np.sum(cluster_mask * w_data) / num_weights_assigned
9125,E:\DATN\dataframe\train_file\89.txt,"        if np.array_equal(centroids_prev, self.centroids):"
9126,E:\DATN\dataframe\train_file\89.txt,        centroids_prev = np.copy(self.centroids)
9127,E:\DATN\dataframe\train_file\89.txt,"def quantize_weights_update(self, sess):"
9128,E:\DATN\dataframe\train_file\89.txt,"    w_data_updated = np.zeros(self.w.shape, dtype=np.float32)"
9129,E:\DATN\dataframe\train_file\89.txt,    for i in range(self.n_clusters):
9130,E:\DATN\dataframe\train_file\89.txt,        cluster_mask = self.cluster_masks[i]
9131,E:\DATN\dataframe\train_file\89.txt,        centroid = self.centroids[i]
9132,E:\DATN\dataframe\train_file\89.txt,        w_data_updated = w_data_updated + cluster_mask * centroid
9133,E:\DATN\dataframe\train_file\89.txt,"    sess.run(self.assign_w, feed_dict={self.w_PH: self.pruning_mask_data * w_data_updated})"
9134,E:\DATN\dataframe\train_file\89.txt,"def quantize_centroids_update(self, sess):"
9135,E:\DATN\dataframe\train_file\89.txt,    w_data = sess.run(self.w)
9136,E:\DATN\dataframe\train_file\89.txt,    for i in range(self.n_clusters):
9137,E:\DATN\dataframe\train_file\89.txt,        cluster_mask = self.cluster_masks[i]
9138,E:\DATN\dataframe\train_file\89.txt,        cluster_count = np.sum(cluster_mask)
9139,E:\DATN\dataframe\train_file\89.txt,        if cluster_count != 0:
9140,E:\DATN\dataframe\train_file\89.txt,            self.centroids[i] = np.sum(cluster_mask * w_data) / cluster_count
9141,E:\DATN\dataframe\train_file\89.txt,"def group_and_reduce_gradient(self, grad):"
9142,E:\DATN\dataframe\train_file\89.txt,"    grad_out = np.zeros(self.w.shape, dtype=np.float32)"
9143,E:\DATN\dataframe\train_file\89.txt,    for i in range(self.n_clusters):
9144,E:\DATN\dataframe\train_file\89.txt,        cluster_mask = self.cluster_masks[i]
9145,E:\DATN\dataframe\train_file\89.txt,        centroid_grad = np.sum(grad * cluster_mask)
9146,E:\DATN\dataframe\train_file\89.txt,        grad_out = grad_out + cluster_mask * centroid_grad
9147,E:\DATN\dataframe\train_file\89.txt,    return grad_out
9148,E:\DATN\dataframe\train_file\89.txt,"Đầu tiên ta cần tìm ra các điểm là trung tâm (centroid) của các cụm này, và các mask chỉ số biểu thị cho các các phần tử ma trận thuộc về từng class, số lượng các mask sẽ tương tự với số centroid và số lượng clusters."
9149,E:\DATN\dataframe\train_file\89.txt,"Để tìm được giá trị centroid, các cluster_mask tốt nhất, ta thực hiện 1 số vòng lặp nhất định , với mỗi vòng lặp tính toán khoảng cách từ centroid đến từng điểm weight của matrix weight, cluster mask tương ứng sẽ là các vị trí mà tại đó giá trị khoảng cách là nhỏ nhất."
9150,E:\DATN\dataframe\train_file\89.txt,"Sau mỗi lần lặp, giá trị centroid của từng cluster cũng sẽ được cập nhật lại bằng trung bình các giá trị weight được assign cho mỗi cluster (dựa vào cluster mask, ta sẽ biết được đâu là điểm được assign)."
9151,E:\DATN\dataframe\train_file\89.txt,"Cuối cùng sau khi tìm được các giá trị tối ưu, ta thực hiện việc update nó cho ma trận weight của layer."
9152,E:\DATN\dataframe\train_file\89.txt,"Ta cũng chỉ quantize và weight-sharing 1 lần duy nhất sau khi quá trình pruning hoàn tất, tương tự pruning, độ chính xác của mô hình sẽ bị ảnh hưởng khá nhiều sau khi thực hiện quantize và sharing weight, do đó ta lại cần train tiếp để giúp mô hình có khả năng lấy lại được những gì nó vừa thay đổi."
9153,E:\DATN\dataframe\train_file\89.txt,"Theo paper , việc apply network pruning cho l2 regularization sẽ cho kết quả tốt hơn, các chỉ số dropout để retrain cũng sẽ thay đổi so với ban đầu để có thể thu được độ chính xác tốt hơn sau khi đã bị pruning đi 1 vài connections."
9154,E:\DATN\dataframe\train_file\89.txt,"Sau khi pruning, quantization và share weight, quá trình retrain lại sẽ mất khá nhiều thời gian, tuy nhiên đánh đổi với nó là ta thu được một mô hình có độ chính xác tương đương nhưng thời gian tính toán và kích thước mô hình lại nhẹ hơn rất nhiều."
9155,E:\DATN\dataframe\train_file\89.txt,"=> Ok ngon rồi, giờ cùng qua phần conclusion nhé."
9156,E:\DATN\dataframe\train_file\89.txt,Tại bài này mình đã cung cấp cho mọi người những kỹ thuật phổ biến nhất của Model Compression và code minh hoạ cho những kỹ thuật này.
9157,E:\DATN\dataframe\train_file\89.txt,"Các kỹ thuật này tuy không còn mới, tuy nhiên hiểu biết về nó cung cấp cho chúng ta một cách sâu hơn trong việc tính toán, custom weights cũng như một lĩnh vực nghiên cứu mới."
9158,E:\DATN\dataframe\train_file\89.txt,"Cảm ơn mọi người đã đọc đến đây, mọi người có thể kham khảo source code của mình dưới đây."
9159,E:\DATN\dataframe\train_file\89.txt,Mình sẽ chia sẻ sớm nhất ngay sau khi mình cần refactor lại source code.
9160,E:\DATN\dataframe\train_file\89.txt,Cảm ơn mọi người.
9161,E:\DATN\dataframe\train_file\9.txt,Guidance for Web Store on AWS
9162,E:\DATN\dataframe\train_file\9.txt,"The architecture describes a pattern to build a headless e-commerce web application, using the native services offered by AWS to implement core capabilities – including search, personalization, marketing, fraud detection, customer authentication, location services, and chatbots."
9163,E:\DATN\dataframe\train_file\9.txt,It is designed to enrich the customer experience and provide a solution that is both scalable and cost effective.
9164,E:\DATN\dataframe\train_file\9.txt,Customers access the web application through different channels.
9165,E:\DATN\dataframe\train_file\9.txt,"Amazon Route 53, the Domain Name System (DNS) enables front-end clients to resolve the website hostname to the AWS content delivery network (Amazon CloudFront)."
9166,E:\DATN\dataframe\train_file\9.txt,"Amazon CloudFront takes care to route the web requests to origin servers, caches the static content & assets served from Amazon S3 and Origin servers."
9167,E:\DATN\dataframe\train_file\9.txt,"It also secures the application traffic using AWS WAF (a web application firewall), which helps protect the application against common exploits and bots."
9168,E:\DATN\dataframe\train_file\9.txt,"The web application uses Amazon Cognito to perform authentication (user sign-up, sign-in) and authorization of backend APIs."
9169,E:\DATN\dataframe\train_file\9.txt,Amazon Simple Storage Service (Amazon S3) is a highly available and durable object storage service that stores and serves the static assets (images and videos).
9170,E:\DATN\dataframe\train_file\9.txt,"Application Load Balancer (ALB) serves the front-end web requests by automatically distributing the incoming traffic across multiple web tier targets, deployed in multiple Availability Zones."
9171,E:\DATN\dataframe\train_file\9.txt,Amazon API Gateway is a fully managed service that interfaces the backend micro-services to access data and execute the business logic.
9172,E:\DATN\dataframe\train_file\9.txt,These micro-services are exposed as Restful APIs for consumption by Web Tier and the Mobile App.
9173,E:\DATN\dataframe\train_file\9.txt,"eCommerce frontend/Web Tier is a headless and responsive web UI, built on your choice of frontend technologies (like ReactJS, VueJS, AngularJS, NodeJS, etc.)"
9174,E:\DATN\dataframe\train_file\9.txt,and deployed on AWS Fargate (serverless compute service).
9175,E:\DATN\dataframe\train_file\9.txt,This Web Tier uses Amazon Elastic Cache to cache static content and orchestrated backend API responses; and Amazon DynamoDB table to persist the user sessions and frontend application configurations (e.g.
9176,E:\DATN\dataframe\train_file\9.txt,Feature flags).
9177,E:\DATN\dataframe\train_file\9.txt,eCommerce Backend Services (App Tier) is a set of stateless Restful micro-services built to access the data and also execute specific business logic (such as OrderMx for cart and checkout as well as PaymentMx for handling payments).
9178,E:\DATN\dataframe\train_file\9.txt,These micro-services are deployed on the serverless compute services (AWS Fargate and AWS Lambda).
9179,E:\DATN\dataframe\train_file\9.txt,Amazon DynamoDB in the App Tier provide the ecommerce application data store.
9180,E:\DATN\dataframe\train_file\9.txt,"It holds products, customer and customer transaction data (such as orders and shopping carts)."
9181,E:\DATN\dataframe\train_file\9.txt,"DynamoDB DAX caches the database query results, while Amazon ElastiCache caches the transformed response of individual microservices."
9182,E:\DATN\dataframe\train_file\9.txt,Amazon EventBridge is a serverless event bus used by both Web and App Tiers to emit events that will be consumed asynchronously by the micro-services in the App Tier and/or other supported sources to perform specific actions.
9183,E:\DATN\dataframe\train_file\9.txt,"As an example, a Customer Consent sign-up action on the front-end triggers an event to Amazon EventBridge, which in response invokes multiple backend micro-services to execute independent business logic and update isolated applications/datastores such as DynamoDB, Amazon Pinpoint as well as third-party CMS and marketing systems."
9184,E:\DATN\dataframe\train_file\9.txt,"Both the Web and App Tiers use Amazon Elastic File System (EFS) to share common code and files such as properties/configurations, JavaScript, CSS and JSON templates."
9185,E:\DATN\dataframe\train_file\9.txt,A set of AWS services delivering core ecommerce business capabilities.
9186,E:\DATN\dataframe\train_file\9.txt,"Amazon Open Search for intelligent search and filtering or products, Amazon Personalize for AI/ML powered product and offer recommendations, Amazon Pinpoint for marketing campaigns and push notifications, Amazon Location Service for Maps, store locator, delivery tracking, etc."
9187,E:\DATN\dataframe\train_file\9.txt,"Amazon Fraud Detector to detect fraudulent transactions (such as malicious attempts of customer login and payment), Amazon Lex for AI/ML powered chatbot."
9188,E:\DATN\dataframe\train_file\9.txt,"Amazon Simple Queue Service (Amazon SQS) first in, first out (FIFO) is used to publish the order messages for the orders placed by customers using the eCommerce application, to the Order Management System (OMS) for processing and fulfillment."
9189,E:\DATN\dataframe\train_file\9.txt,"Amazon Managed Streaming for Apache Kafka (MSK) is used to perform the ETL (Extract, Transform and Load) activities at scale (such as importing data feeds into eCommerce data stores."
9190,E:\DATN\dataframe\train_file\9.txt,"These include data feeds such as product/catalog data from the PIM, near real-time inventory and order status updates from Supply Chain Systems."
9191,E:\DATN\dataframe\train_file\9.txt,"Some of the key third party services and applications, which integrate with the ecommerce application to deliver business capabilities."
9192,E:\DATN\dataframe\train_file\90.txt,Nhận dạng tiếng Việt cùng với Transformer OCR
9193,E:\DATN\dataframe\train_file\90.txt,Bài đăng này đã không được cập nhật trong 2 năm
9194,E:\DATN\dataframe\train_file\90.txt,Lời nói đầu
9195,E:\DATN\dataframe\train_file\90.txt,"Nếu các bạn đã quá ngán ngẩm xử lý bằng RNN, LSTM vì thời gian training quá lâu và đôi khi không hiệu quả đối với những câu dài đòi hỏi phụ thuộc (long-range dependencies), thì chúc mừng Transformer chính là câu trả lời cho bạn."
9196,E:\DATN\dataframe\train_file\90.txt,"Xuất phát ý tưởng từ , Transformer đã thực sự tạo nên một kiến trúc đột phá giúp giải quyết nhiều vấn đề tồn tại trong việc xử lý ngôn ngữ tự nhiên và gần đây đã mở rộng nhiều lĩnh vực trong đó có Computer Vision."
9197,E:\DATN\dataframe\train_file\90.txt,"Hôm nay, mình sẽ cùng các bạn tìm hiểu về lý thuyết cũng như ứng dụng Transformer trong nhận dạng tiếng Việt qua thư viện ."
9198,E:\DATN\dataframe\train_file\90.txt,Vấn đề của RNN ?
9199,E:\DATN\dataframe\train_file\90.txt,"Khi bắt đầu học về NLP, chắc hẳn các bạn đã quen với các lớp quen thuộc như RNN hay LSTM."
9200,E:\DATN\dataframe\train_file\90.txt,Tuy nhiên những lớp đó lại có những nhược điểm như sau :
9201,E:\DATN\dataframe\train_file\90.txt,Thời gian huấn luyện lâu : Khi bạn xử lý một câu văn bằng RNN thì mô hình xử lý câu văn một cách tuần tự theo từng timestep do đó hidden state sau phải phụ thuộc vào hidden state trước thực hiện xong mới tính toán được.
9202,E:\DATN\dataframe\train_file\90.txt,"Điều này khiến mô hình không thể thực hiện tính toán song song, không tận dụng được khả năng tính toán của GPU khiến thời gian training lâu hơn nhiều so với cấu trúc như CNN."
9203,E:\DATN\dataframe\train_file\90.txt,Khả năng ghi nhớ kém : Đây là vấn đề muôn thuở đối với mạng có kiến trúc tuần tự như RNN.
9204,E:\DATN\dataframe\train_file\90.txt,"Nói đơn giản là mô hình sẽ chỉ học được các từ ở đầu câu, càng về sau những đặc trưng học được càng ít do gradient biến mất (vanishing gradient)."
9205,E:\DATN\dataframe\train_file\90.txt,Kể cả kiến trúc LSTM hay GRU được giới thiệu là giải quyết được điều này nhờ kiến trúc đặc biệt tuy nhiên việc học được những câu dài luôn luôn là một thách thức.
9206,E:\DATN\dataframe\train_file\90.txt,"Khả năng chú ý kém : Các lớp RNN học các đặc trưng theo từng timstep sau đó sẽ mã hóa (encode) input sequence đó thành một context vector, tuy nhiên trong context vector đó từ nào cũng giống từ nào ."
9207,E:\DATN\dataframe\train_file\90.txt,Nhưng trong một câu xét về mặt ngữ nghĩa có những từ có vai trò quan trọng có những từ ít quan trọng hơn do đó việc coi các từ giống nhau sẽ làm giảm độ chính xác của mô hình.
9208,E:\DATN\dataframe\train_file\90.txt,"Trong mô hình xử lý ngôn ngữ, có ba loại quan hệ cần chú ý:"
9209,E:\DATN\dataframe\train_file\90.txt,Quan hệ giữa các token giữa input và output
9210,E:\DATN\dataframe\train_file\90.txt,Quan hệ giữa các token ở input
9211,E:\DATN\dataframe\train_file\90.txt,Quan hệ giữa các token ở output
9212,E:\DATN\dataframe\train_file\90.txt,"Cơ chế attention truyền thống đánh lại trọng số (reweight) của context vector( còn được gọi là attention weight) nhờ đó giúp phần giải mã biết timestep nào cần được chú ý (attention), mô hình hóa được mối quan hệ ngữ nghĩa giữa input và output."
9213,E:\DATN\dataframe\train_file\90.txt,Attention weight bản chất chính là độ liên quan của các encoder hidden states trong khi giải mã decoder hidden state.
9214,E:\DATN\dataframe\train_file\90.txt,Các bạn có thể tìm hiểu thêm về cơ chế Attention qua bài viết  của tác giả Huy Hoàng.
9215,E:\DATN\dataframe\train_file\90.txt,Vậy có một ý tưởng là Tại sao không để input/output attention đến chính nó?
9216,E:\DATN\dataframe\train_file\90.txt,Và Transformer chính là câu trả lời cho câu trả lời này.
9217,E:\DATN\dataframe\train_file\90.txt,Tại sao lại là Transformer ?
9218,E:\DATN\dataframe\train_file\90.txt,Transformer giải quyết được nhược điểm của mô hình tuần tự truyền thống nhờ chủ yếu vào hai cấu trúc là Multi-head attention & Positional encoding
9219,E:\DATN\dataframe\train_file\90.txt,"Nói sơ qua một chút, kiến trúc transformer cũng giống với các mô hình sequence-to-sequence bao gồm hai phần encoder ( trái ) và decoder (phải )."
9220,E:\DATN\dataframe\train_file\90.txt,"Phần Encoder, Gồm N block, mỗi block bao gồm hai sub-layer: Multi-Head Attention và Feed forward network."
9221,E:\DATN\dataframe\train_file\90.txt,Tác giả dùng một residual connection ở mỗi sub-layer này.
9222,E:\DATN\dataframe\train_file\90.txt,Theo sau mỗi sub-layer đó là một lớp Layer Norm có ý nghĩa tương tự như lớp Batch Norm trong CNN.
9223,E:\DATN\dataframe\train_file\90.txt,"Residual connection cũng góp phần giúp mô hình có thể sâu hơn , deep hơn nhờ giảm tác động của vanishing gradient."
9224,E:\DATN\dataframe\train_file\90.txt,"Phần Decoder cũng tương tự như encoder gồm N block, mỗi block gồm 2 sub-layer."
9225,E:\DATN\dataframe\train_file\90.txt,"Tuy nhiên, nó có một lớp Masked Multi-Head Attention."
9226,E:\DATN\dataframe\train_file\90.txt,Lớp này chính là lớp Multi-Head Attention.
9227,E:\DATN\dataframe\train_file\90.txt,Nó có chức năng chú ý đến toàn bộ những decoder hidden state trước.
9228,E:\DATN\dataframe\train_file\90.txt,"Lý do mà nó lại được đặt tên như vậy là khi huấn luyện Transformer, ta đưa toàn bộ câu vào cùng một lúc nên nếu ta đưa toàn bộ target sentence cho decoder trước thì mô hình sẽ chẳng học được gì cả (biết hết rồi ai học làm gì ) Do đó phải che (mask) bớt một phần token ở decoder hidden state sau trong quá trình decode."
9229,E:\DATN\dataframe\train_file\90.txt,"Tại bài viết này, mình không bàn sâu về encoder và decoder mà tập trung hai cấu trúc chính là Multi-head attention & Positional encoding."
9230,E:\DATN\dataframe\train_file\90.txt,Các bạn muốn tìm hiểu sâu hơn có thể xem một bài viết rất hay của tác giả Việt Anh theo .
9231,E:\DATN\dataframe\train_file\90.txt,3.1 Multi-Head Attention
9232,E:\DATN\dataframe\train_file\90.txt,"Từ đầu bài viết đến rồi, ta liên tục nhấc Attention, Attention, Attention!."
9233,E:\DATN\dataframe\train_file\90.txt,"Vậy thực sự Attention trong Transformer là gì input sentences sẽ được nhân tuyến tính với ba ma trận để sinh ra ba giá trị keys, values, queries."
9234,E:\DATN\dataframe\train_file\90.txt,Keys và Queries gần giống nhau.
9235,E:\DATN\dataframe\train_file\90.txt,Values chính là giá trị của keys.
9236,E:\DATN\dataframe\train_file\90.txt,"Ta có thể ví dụ, keys là mã một từ, queries là truy vấn để tìm mã từ đó (keys) và values chính là nghĩa của từ."
9237,E:\DATN\dataframe\train_file\90.txt,"Dựa trên ba giá trị này, ta tính attention_score."
9238,E:\DATN\dataframe\train_file\90.txt,Attention score thể hiện mức liên quan giữa các values với nhau hay các nghĩa của từ với nhau.
9239,E:\DATN\dataframe\train_file\90.txt,"Nếu Trong mô hình, các giá trị được kí hiệu lần lượt là: {Values: V, Keys: K, Query: Q}"
9240,E:\DATN\dataframe\train_file\90.txt,Có một khó khăn trong các mô hình truyền thống đó là rất khó khái quát được input sentences theo nhiều góc độ khác nhau vì chỉ có duy nhất một cơ chế attention.
9241,E:\DATN\dataframe\train_file\90.txt,"Ví dụ xử lý một câu ""The animal didn't cross the street because it was too tired""."
9242,E:\DATN\dataframe\train_file\90.txt,"Nếu ta chỉ có duy nhất một attention weights, attention có khả năng chỉ chú ý đến ""animal"" hay ""street""."
9243,E:\DATN\dataframe\train_file\90.txt,"Tuy nhiên , ""it"" trong câu là để chỉ ""animal"" hay ""street""."
9244,E:\DATN\dataframe\train_file\90.txt,"Do đó để nắm bắt đa chú ý, Transformer thay vì sử dụng self-attetion (1 head) đã sử dụng nhiều linear attention cùng một lúc (multi-head) để học được nhiều attention weight khác nhau giúp chú ý đến nhiều chỗ khác nhau trong cùng một câu."
9245,E:\DATN\dataframe\train_file\90.txt,"Các giá trị V, K, Q cùng một lúc được biến đổi tuyến tính sau đó ta dùng một cơ chế attention có tên là Scaled Dot-Product Attention để tổng hợp attention weight của cả V, Q, K. Công thức tính của Scaled Dot-Product Attention như sau:"
9246,E:\DATN\dataframe\train_file\90.txt,trong đó dk chính là kích thước của K và V.
9247,E:\DATN\dataframe\train_file\90.txt,Ý tưởng đằng sau công thức này đơn giản chỉ là nhân query với key.
9248,E:\DATN\dataframe\train_file\90.txt,Kết quả sẽ cho ra độ liên quan giữa các từ với nhau.
9249,E:\DATN\dataframe\train_file\90.txt,Tuy nhiên kết quả này sẽ tăng phi mã theo kích thước (dimension) của query và key.
9250,E:\DATN\dataframe\train_file\90.txt,Do đó cần phải chia cho căn bậc hai kích thước của keys để ngăn chặn hiện tượng số quá lớn.
9251,E:\DATN\dataframe\train_file\90.txt,Hàm softmax để tính phân bố xác suất liên quan giữa các từ.
9252,E:\DATN\dataframe\train_file\90.txt,Cuối cùng ta nhân thêm value để loại bỏ những từ không cần thiết trong câu (có xác suất qua hàm softmax nhỏ).
9253,E:\DATN\dataframe\train_file\90.txt,"Sau khi tính từng attention weight bằng cơ chế Scaled Dot-Product Attention, chúng ta dùng concat chúng lại với nhau thành một ma trận rồi nhân tuyến tính với một ma trận đưa ra output cuối cùng."
9254,E:\DATN\dataframe\train_file\90.txt,3.2 Positional Encoding (Mã hóa vị trí )
9255,E:\DATN\dataframe\train_file\90.txt,Vị trí và thứ tự của các từ trong một câu là điều cần thiết đối với mọi mô hình ngôn ngữ kể cả trong NLP hay CV.
9256,E:\DATN\dataframe\train_file\90.txt,Các mô hình như RNN hay LSTM sử dụng tính tuần tự để học được vị trí của các câu trong văn bản.
9257,E:\DATN\dataframe\train_file\90.txt,"Nhưng như mình đã vừa đề cập ở trên, để khắc phục thời gian huấn luyện quá lâu do tính tuần tự gây ra, Transfomer đã hoàn toàn loại bỏ điều này."
9258,E:\DATN\dataframe\train_file\90.txt,Vậy làm thế nào để mô hình có thể học được thông tin về vị trí ?
9259,E:\DATN\dataframe\train_file\90.txt,Đó chính là mã hóa thêm thông tin biểu diễn vị trí vào từng từ câu.
9260,E:\DATN\dataframe\train_file\90.txt,Và người ta gọi đó là Positional Encoding.
9261,E:\DATN\dataframe\train_file\90.txt,Một positional encoding tốt được đánh giá dựa trên những tiêu chí sau:
9262,E:\DATN\dataframe\train_file\90.txt,Mỗi time-step phải có một mã hóa (encoding) duy nhất: Nếu hai time-step khác nhau mà có cùng một mã hóa sẽ gây ra nhầm lẫn vị trí giữa các từ với nhau.
9263,E:\DATN\dataframe\train_file\90.txt,Khoảng cách giữa hai vị trí được embedding của hai time-step giữa hai câu có độ dài khác nhau phải bằng nhau
9264,E:\DATN\dataframe\train_file\90.txt,Có khả năng biểu diễn được vị trí cho những câu dài hơn khi huấn luyện
9265,E:\DATN\dataframe\train_file\90.txt,"Và cách mà transformer mã hóa vị trí thật tuyệt vời, nó đáp ứng được hết tất cả những điều mà ta mong đợi của một positional encoding."
9266,E:\DATN\dataframe\train_file\90.txt,"Công thức mà trong paper, tác giả đã đề xuất như sau:"
9267,E:\DATN\dataframe\train_file\90.txt,"trong đó pos là vị trí hiện tại, dmodel là kích thước cố định của mô hình, i là vị trí trong dmodel."
9268,E:\DATN\dataframe\train_file\90.txt,Đặt w =
9269,E:\DATN\dataframe\train_file\90.txt,2i
9270,E:\DATN\dataframe\train_file\90.txt,", ta có"
9271,E:\DATN\dataframe\train_file\90.txt,"PE[pos, 2i] = sin(w * pos)"
9272,E:\DATN\dataframe\train_file\90.txt,"PE[pos, 2i + 1] = cos(w * pos)"
9273,E:\DATN\dataframe\train_file\90.txt,Nào chúng ta cùng xét những tiêu chí ta đặt ra ở bên trên:
9274,E:\DATN\dataframe\train_file\90.txt,"Mỗi time-step phải có một mã hóa (encoding) duy nhất: Khi giá trị i càng lớn, càng sâu thì giá trị w giảm dần, dần dần tiến về 0."
9275,E:\DATN\dataframe\train_file\90.txt,"Do đó mỗi vị trí i sẽ có một cách biểu diễn khác nhau do pos khác nhau và mặc dù là các hàm sin, cos có chu kỳ nhưng w giảm dần không phải cố đinh nên ta sẽ nhận được giá trị khác nhau đối với mỗi giá trị i. Hơn nữa, nếu pos giống nhau trong hai câu có độ dài khác nhau vẫn có vị trí trong embeddding giống nhau."
9276,E:\DATN\dataframe\train_file\90.txt,Khoảng cách giữa hai vị trí được embedding của hai time-step giữa hai câu có độ dài khác nhau phải bằng nhau: Bởi vì mỗi vị trí i có vị trí embedding khác nhau trong cùng một câu và giống nhau trong hai câu có độ dài khác nhau nên khoảng cách giữa chúng sẽ bằng nhau không phụ thuộc độ dài câu.
9277,E:\DATN\dataframe\train_file\90.txt,"Có khả năng biểu diễn được vị trí cho những câu dài hơn khi huấn luyện: Do hàm sin, cos là hai hàm lượng giác có chu kì 2kΠ mà chúng ta có thể dễ dàng được w và xác định giá trị pos nên có khả năng biểu diễn được những vị trí xa hơn kể cả chưa được huấn luyện"
9278,E:\DATN\dataframe\train_file\90.txt,Các bạn có thể quan sát hình sau xem vị trí sau khi positional encoding:
9279,E:\DATN\dataframe\train_file\90.txt,"Khi giá trị i càng deep, càng lớn thì giá trị hàm sin và cos tiến đến 0 và 1nên các vị trí embedding sẽ gần giống nhau."
9280,E:\DATN\dataframe\train_file\90.txt,"Do đó càng về sau, các cột màu đều một màu, không có sự khác nhau lớn."
9281,E:\DATN\dataframe\train_file\90.txt,Nhận dạng tiếng Việt cùng với Transformer OCR
9282,E:\DATN\dataframe\train_file\90.txt,"Sau khi ngâm cứu những điều tuyệt vời của kiến trúc Transformer, bây giờ mình cùng thử xem sức mạnh của nó thực tế sẽ như nào ?"
9283,E:\DATN\dataframe\train_file\90.txt,"Ở trong bài lần này, mình giới thiệu cho các bạn một pretrained ngon ghẻ từ  của anh Phạm Quốc."
9284,E:\DATN\dataframe\train_file\90.txt,"Pretrained weight đã được huấn luyện với 10 triệu ảnh, một số lượng rất lớn nên mình khuyên các bạn không nên huấn luyện lại mà mình sẽ dùng pretrained đó và custom lại với dữ liệu của mình."
9285,E:\DATN\dataframe\train_file\90.txt,Let's go
9286,E:\DATN\dataframe\train_file\90.txt,"Đầu tiên, bạn cần cài đặt thư viện VietOCR và môi trường theo câu lệnh sau:"
9287,E:\DATN\dataframe\train_file\90.txt,pip install --quiet vietocr==0.3.2
9288,E:\DATN\dataframe\train_file\90.txt,pip install torch
9289,E:\DATN\dataframe\train_file\90.txt,pip install torchvision
9290,E:\DATN\dataframe\train_file\90.txt,Download pretrain weight  Hoặc sử dụng câu lệnh
9291,E:\DATN\dataframe\train_file\90.txt,gdown https://drive.google.com/uc?id=13327Y1tz1ohsm5YZMyXVMPIOjoOA0OaA
9292,E:\DATN\dataframe\train_file\90.txt,4.1 Train model
9293,E:\DATN\dataframe\train_file\90.txt,"Chọn mô hình là VGG Transformer, tức là mô hình gồm phần backbone là mạng VGG-19 kết hợp với Transformer."
9294,E:\DATN\dataframe\train_file\90.txt,Các cấu hình của model sẽ được lưu vào biến config.
9295,E:\DATN\dataframe\train_file\90.txt,Lưu ý là các mô hình khác chưa có pretrained weight đâu nhé
9296,E:\DATN\dataframe\train_file\90.txt,from vietocr.tool.config import Cfg
9297,E:\DATN\dataframe\train_file\90.txt,from vietocr.model.trainer import Trainer
9298,E:\DATN\dataframe\train_file\90.txt,config = Cfg.load_config_from_name('vgg_transformer')
9299,E:\DATN\dataframe\train_file\90.txt,Sau đó các bạn chỉnh config phù hợp với bài tóan của mình.
9300,E:\DATN\dataframe\train_file\90.txt,Trong đó cần lưu ý :
9301,E:\DATN\dataframe\train_file\90.txt,data_root : chỉ thư mục cha chứa file có chứa label là train_annotation.txt và test_annotation.txt
9302,E:\DATN\dataframe\train_file\90.txt,checkpoint: đường dẫn tới file checkpoint mà bạn định lưu
9303,E:\DATN\dataframe\train_file\90.txt,export: đường dẫn tới pretrained weight
9304,E:\DATN\dataframe\train_file\90.txt,device: chỉ thiết bị bạn dùng huấn luyện mô hình.
9305,E:\DATN\dataframe\train_file\90.txt,"Nếu dùng GPU, đặt là cuda:0."
9306,E:\DATN\dataframe\train_file\90.txt,"Nếu là CPU, đặt là cpu."
9307,E:\DATN\dataframe\train_file\90.txt,"          'metrics': 10000,"
9308,E:\DATN\dataframe\train_file\90.txt,          'batch_size': 64
9309,E:\DATN\dataframe\train_file\90.txt,"              'init_lr': 0.01,"
9310,E:\DATN\dataframe\train_file\90.txt,              'n_warmup_steps': 4000
9311,E:\DATN\dataframe\train_file\90.txt,config['device'] = 'cuda:0'
9312,E:\DATN\dataframe\train_file\90.txt,Cuối cùng ta tiến hành train và chờ kết quả thôi nào
9313,E:\DATN\dataframe\train_file\90.txt,"trainer = Trainer(config, pretrained=True)"
9314,E:\DATN\dataframe\train_file\90.txt,4.2 Test
9315,E:\DATN\dataframe\train_file\90.txt,"Sau khi train xong model, bạn sẽ thu được file weight của mô hình."
9316,E:\DATN\dataframe\train_file\90.txt,Hoặc bạn nào ngại train thì có thể tại trực tiếp pretrained weight dùng thử vì nó cũng tương đối ngon rồi.
9317,E:\DATN\dataframe\train_file\90.txt,Ảnh đầu vào có tên image.png:
9318,E:\DATN\dataframe\train_file\90.txt,from vietocr.tool.predictor import Predictor
9319,E:\DATN\dataframe\train_file\90.txt,from vietocr.tool.config import Cfg
9320,E:\DATN\dataframe\train_file\90.txt,import cv2
9321,E:\DATN\dataframe\train_file\90.txt,# load pretrained weight
9322,E:\DATN\dataframe\train_file\90.txt,config['weights'] = 'https://drive.google.com/uc?id=13327Y1tz1ohsm5YZMyXVMPIOjoOA0OaA'
9323,E:\DATN\dataframe\train_file\90.txt,# set device to use cpu
9324,E:\DATN\dataframe\train_file\90.txt,config['device'] = 'cpu'
9325,E:\DATN\dataframe\train_file\90.txt,detector = Predictor(config)
9326,E:\DATN\dataframe\train_file\90.txt,img = cv2.ỉmread('image.png')
9327,E:\DATN\dataframe\train_file\90.txt,result = detector.predict(img)
9328,E:\DATN\dataframe\train_file\90.txt,Transformer hiện đang được ứng dụng trong nhiều lĩnh vực hiện nay trong đó có cả Computer Vision.
9329,E:\DATN\dataframe\train_file\90.txt,Mong bài viết của mình một phần giúp các bạn hiểu thêm về một kiến trúc tuyệt vời này.
9330,E:\DATN\dataframe\train_file\90.txt,Cảm ơn các bạn đã theo dõi bài viết của mình.
9331,E:\DATN\dataframe\train_file\90.txt,Hãy ấn like và share nếu bạn thấy bài viết có ích nhé
9332,E:\DATN\dataframe\train_file\91.txt,Chúng ta bảo vệ các mô hình Deep learning như thế nào?
9333,E:\DATN\dataframe\train_file\91.txt,Bài đăng này đã không được cập nhật trong 2 năm
9334,E:\DATN\dataframe\train_file\91.txt,"Chào mọi người, bài viết này là một bài viết tổng hợp lại những kiến thức cơ sở và một vài nghiên nghiên cứu gần đây về một bài toán mà mình đang tìm hiểu, có thể nó sẽ là một bài toán lạ đối với khá nhiều người và cũng có thể nó không mang lại cho bạn quá nhiều hứng thú, nhưng hãy cùng tìm hiểu xem bài toán đó là gì và để lại bình luận của bạn ở ngay dưới bài viết này."
9335,E:\DATN\dataframe\train_file\91.txt,Xin cảm ơn.
9336,E:\DATN\dataframe\train_file\91.txt,Bài viết được lấy cảm hứng từ loạt bài về watermark của tác giả .
9337,E:\DATN\dataframe\train_file\91.txt,Bạn có thể tìm hiểu nhiều hơn trong loạt bài của anh ấy .
9338,E:\DATN\dataframe\train_file\91.txt,Đặt vấn đề
9339,E:\DATN\dataframe\train_file\91.txt,"Như các bạn đã biết, với sự phát triển mạnh mẽ của các nền tảng phần cứng như GPU, TPU đi kèm với sự dồi dào về nguồn dữ liệu, lĩnh vực nghiên cứu trí tuệ nhân tạo (AI) đang có những bước tiến không ngừng, cho thấy sự tuyệt vời của nó trong việc thực hiện các nhiệm vụ khác nhau để thay thế việc xử lí thủ công của con người như các bài toán liên quan tới xử lý ảnh và xử lý ngôn ngữ tự nhiên, phân tích và nhận dạng giọng nói, tín hiệu."
9340,E:\DATN\dataframe\train_file\91.txt,Và đứng sau sự thành công tuyệt vời ấy của trí tuệ nhân tạo chính là một lĩnh vực nghiên cứu nhỏ cực kỳ thú vị - Deep learning.
9341,E:\DATN\dataframe\train_file\91.txt,Để xây dựng được một mô hình học sâu hay còn gọi là deep learning model để đưa vào các sản phẩm thực tế không phải là một chuyện đơn giản và dễ dàng.
9342,E:\DATN\dataframe\train_file\91.txt,"Để có được mô hình tốt, các mô hình đòi hỏi một lượng lớn dữ liệu huấn luyện(do con người gán nhãn, chuẩn bị trước), một tài nguyên tính toán đủ lớn và đủ nhanh(thường là GPU) và những điều đó thôi là chưa đủ, nó còn đòi hỏi chuyên môn, kinh nghiệm thực thi của các nhà phát triển."
9343,E:\DATN\dataframe\train_file\91.txt,"Chính vì thế, một bài toán khác lại đặt ra, sau khi huấn luyện xong mô hình, chúng ta phân phối chúng như thế nào để có thể bảo vệ bản quyền, quyền sở hữu của một thứ mà ta không hề dễ dàng có được nó."
9344,E:\DATN\dataframe\train_file\91.txt,"Liệu sau khi phân phối có phát sinh các trường hợp phân phối lại bất hợp pháp, vi phạm bản quyền và ảnh hưởng tới lợi ích của người/công ty bỏ công sức ra nghiên cứu và phát triển mô hình học sâu đó."
9345,E:\DATN\dataframe\train_file\91.txt,"Đây là vấn đề quan trọng giúp các nhà phát triển, các doanh nghiệp tự tin hơn khi phân phối mô hình đã huấn luyện của mình cho khách hàng, nhóm các nhà nghiên cứu dễ dàng chia sẻ những kết quả mình đạt được mà không bị lo sợ quyền lợi bị ảnh hướng."
9346,E:\DATN\dataframe\train_file\91.txt,"Do đó, để giải quyết vấn đề này, điều cần thiết phải nghiên cứu lúc này là một kỹ thuật để bảo vệ được quyền sở hữu các mô hình Deep learning của tác giả, cho pháp xác minh/trích xuất quyền sở hữu của mô hình."
9347,E:\DATN\dataframe\train_file\91.txt,"Và trong bài viết này, chúng ta sẽ nghiên cứu về một kỹ thuật mang tên digital watermarking, một kỹ thuật đã quen thuộc nhằm xác minh quyền sở hữu trí tuệ cho các sản phẩm đa phương tiện nhưng với một đối tượng khác, các mô hình học sâu."
9348,E:\DATN\dataframe\train_file\91.txt,Yêu cầu khi sử dụng Watermark
9349,E:\DATN\dataframe\train_file\91.txt,Việc áp dụng kỹ thuật watermark trong việc bảo vệ các mô hình học sâu sẽ được tìm hiểu sau.
9350,E:\DATN\dataframe\train_file\91.txt,"Tuy nhiên, như quy trình phát triển, nghiên cứu các dự án phần mềm khác, trước khi bắt tay vào thực hiện, chúng ta nên định nghĩa ra các tiêu chuẩn đánh giá về tính khả thi và hợp lệ của phương pháp trước, để từ đó về sau có thể xác định được luôn phương pháp nào khả thi, phương pháp nào không."
9351,E:\DATN\dataframe\train_file\91.txt,"Vậy, các yêu cầu khi sử dụng watermark là gì?"
9352,E:\DATN\dataframe\train_file\91.txt,Bảo toàn chất lượng
9353,E:\DATN\dataframe\train_file\91.txt,"Các kỹ thuật watermark đã được sử dụng rất nhiều cho các loại dữ liệu đa phương tiện như hình ảnh, video, audio."
9354,E:\DATN\dataframe\train_file\91.txt,"Và tương tự như với các loại dữ liệu này, với việc áp dụng với các mô hình học sâu cũng có một yêu cầu tương tự Sau khi gắn thêm watermark, chất lượng của dữ liệu phải được bảo toàn."
9355,E:\DATN\dataframe\train_file\91.txt,"Ở đây, với hình ảnh, chất lượng dữ liệu được bảo toàn có nghĩa là sự cảm nhận của con người về hình ảnh vẫn còn nguyên vẹn, không hoặc ít bị thay đổi."
9356,E:\DATN\dataframe\train_file\91.txt,"Còn đối với các mô hình DNNs, chất lượng, hiệu năng của model cũng vẫn phải được bảo toàn, mà độ đo ta hay nhắc đến nhất chính là độ chính xác - accurancy."
9357,E:\DATN\dataframe\train_file\91.txt,Độ mạnh mẽ của watermark
9358,E:\DATN\dataframe\train_file\91.txt,"Luôn nhớ rằng, mục đích của chúng ta khi giấu watermark là để bảo vệ quyền sở hữu của mình với dữ liệu."
9359,E:\DATN\dataframe\train_file\91.txt,"Vậy nên, một trong những yêu cầu bắt buộc đối với bài toán này là độ mạnh mẽ của watermark, liệu watermark có được duy trì với các phương thức xử lý, tấn công khác nhau của kẻ thứ 3."
9360,E:\DATN\dataframe\train_file\91.txt,"Đối với các mạng DNN, các phương thức xử lý gây tác động nhiều nhất là fine-tuning hay transfer learning."
9361,E:\DATN\dataframe\train_file\91.txt,Watermark cần phải được duy trì ngay cả khi mô hình DNNs phải chịu tác động của các phương xử lý này.
9362,E:\DATN\dataframe\train_file\91.txt,"Ngoài ra, một vài yêu cầu không bắt buộc khác đối với các phương pháp watermark là các phương pháp phải nhúng được một lượng lớn thông tin(đủ để xác thực bản quyển và khó giả mạo), các watermark phải khó bị truy cập và sửa đổi, ghi đè, quá trình nhúng và trích xuất watermark phải nhanh, không quá phức tạp."
9363,E:\DATN\dataframe\train_file\91.txt,Các trường hợp có thể áp dụng watermark
9364,E:\DATN\dataframe\train_file\91.txt,"Vậy ta có thể sử dụng watermark trong những trường hợp nào trong các giai đoạn phát triển mô hình, điều này cũng cần được định nghĩa và làm rõ."
9365,E:\DATN\dataframe\train_file\91.txt,Có 3 giai đoạn được đặt ra có thể trở thành 3 giai đoạn nhúng watermark:
9366,E:\DATN\dataframe\train_file\91.txt,"Train-to-embed: Đây là trường hợp tiêu chuẩn nhất, khi dữ liệu có nhãn được cung cấp, các nhà phát triển sẽ nhúng watermark vào model ngày từ giai đoạn đầu tiên huấn luyện mô hình."
9367,E:\DATN\dataframe\train_file\91.txt,"Fine-tune-to-embed: Đối với các trường hợp model đã được huấn luyện sẵn, các phương pháp gán watermark cũng cần được xây dựng để có khả năng gán watermark vào mô hình trong quá trình fine-tune model."
9368,E:\DATN\dataframe\train_file\91.txt,"Việc nhúng watermark trong quá trình fine-tune model cũng có một ứng dụng tốt hơn Train-to-embed là nhà phát triển có thể nhúng các watermark khác nhau và cùng một model gốc, từ đó dễ dàng kiểm soát được hoạt động phân phối của từng model."
9369,E:\DATN\dataframe\train_file\91.txt,Distill-to-embed: Đây là cũng là một trường hợp cực kỳ hay khi nhúng watermark.
9370,E:\DATN\dataframe\train_file\91.txt,"Trong hai trường hợp ở trên, tác giả hay nhà phát triển mô hình chính là người gán watermark cho mô hình và họ đã phải có một lượng dữ liệu có nhãn nhất định cho việc huấn luyện mô hình."
9371,E:\DATN\dataframe\train_file\91.txt,"Còn trong trường hợp này, chúng ta giấu watermark vào trong mô hình khi hoàn toàn không có một chút dữ liệu có nhãn nào."
9372,E:\DATN\dataframe\train_file\91.txt,"Đây cũng là ứng dụng có thể nhìn thấy được như một trung tâm bảo vệ bản quyền cho model, thay mặt các tác giả model gán watermark cho các DNNs của họ."
9373,E:\DATN\dataframe\train_file\91.txt,Bảo vệ watermark khỏi tấn công
9374,E:\DATN\dataframe\train_file\91.txt,Tiếp đến một vấn đề ta phải quan tâm tới trước khi đi sâu vào chi tiết kỹ thuật của bài toán này đó là cách bảo vệ watermark trước những tấn công xấu của đối thủ.
9375,E:\DATN\dataframe\train_file\91.txt,"Ở đây, chúng ta định nghĩa ra các kiểu tấn công chính/ các phương pháp phá watermark có thể có với các mô hình DNNs."
9376,E:\DATN\dataframe\train_file\91.txt,Hai phương pháp pháp watermark chính có thể kể đến như fine-tuning và model compression.
9377,E:\DATN\dataframe\train_file\91.txt,Fine-tuning: Đây là phương pháp tấn công khả thi nhất khi đối thủ có một phần dữ liệu có nhãn.
9378,E:\DATN\dataframe\train_file\91.txt,Fine-tune sẽ làm cho các tham số của mô hình thay đổi và watermark phải đủ mạnh mẽ để duy trì sau những biến đổi này.
9379,E:\DATN\dataframe\train_file\91.txt,: Đây là bước vô cùng quan trọng khi ta triển khai các mô hình DNNs vào các hệ thống thực tế đặc biệt là các hệ thống phần cứng yếu vì nó có thể làm giảm đáng kể bộ nhớ và chi phí tính toán.
9380,E:\DATN\dataframe\train_file\91.txt,"Tuy nhiên, điều này cũng là các tham số của mô hình có sự biến đổi và dĩ nhiên điều này làm ảnh hưởng không nhỏ đến các watermark."
9381,E:\DATN\dataframe\train_file\91.txt,"Để hiểu hơn về model compression, mời bạn đọc lại bài viết trước đây của mình ."
9382,E:\DATN\dataframe\train_file\91.txt,Vậy là chúng ta đã tìm hiểu sơ qua và có cái nhìn khái quát về về yêu cầu kỹ thuật cũng như đặc điểm của bài toán này.
9383,E:\DATN\dataframe\train_file\91.txt,"Tiếp theo, chúng ta sẽ cùng lần lượt tìm hiểu các bài báo nghiên cứu về watermark gần đây, để xem quá trình phát triển, xây dựng các kỹ thuật bảo vệ quyền sở hữu cho các mô hình Deep learning như thế nào?"
9384,E:\DATN\dataframe\train_file\91.txt,Các paper nghiên cứu về kỹ thuật watermarking được nghiên cứu gần đây
9385,E:\DATN\dataframe\train_file\91.txt,Embedding Watermarks into Deep Neural Networks (2017)
9386,E:\DATN\dataframe\train_file\91.txt,"Năm 2017, Yusuke Uchida và cộng sự đã đề xuất việc sử dụng kỹ thuật watermarking để bảo vệ quyền sở hữu trí tuệ và phát hiện vi phạm sở hữu trí tuệ trong việc sử dụng các mô hình được đào tạo và phân phối bằng việc cố gắng nhúng watermark vào trong các mạng DNNs."
9387,E:\DATN\dataframe\train_file\91.txt,"Trong bài báo, nhóm đã đề xuất 1 framework để nhúng watermark vào trong chính tham số của mô hình, sử dụng parameter regularizer."
9388,E:\DATN\dataframe\train_file\91.txt,Framework này đã được public tại .
9389,E:\DATN\dataframe\train_file\91.txt,"Watermark được nhúng vào tham số của mạng trong quá trình đào tạo, do đó nó không làm ảnh hưởng tới hiệu suất của mô hình."
9390,E:\DATN\dataframe\train_file\91.txt,"Theo như kết quả được công bố tại bài báo, framework mà họ cung cấp đã có khả năng nhúng được các watermark vào trong các mạng DNNs cả trong 3 giai đoạn, training from scratch, fine-tuning và distilling mà không làm ảnh hướng đến hiệu suất của mô hình."
9391,E:\DATN\dataframe\train_file\91.txt,Watermark không bị biến mất ngay cả khi bị tinh chỉnh hay 65% tham số bị cắt tỉa khi bị tấn công pruning.
9392,E:\DATN\dataframe\train_file\91.txt,Cho một mô hình neural network có hoặc không có pre-trained weights.
9393,E:\DATN\dataframe\train_file\91.txt,Nhiệm vụ cần thực hiện là nhúng
9394,E:\DATN\dataframe\train_file\91.txt,"T−bits vào trong các tham số của mô hình đó ở một hoặc nhiều layer khác nhau mà trong bài báo này, nhóm tác giải tập trung vào các layer CNNs."
9395,E:\DATN\dataframe\train_file\91.txt,Chi tiết về phương pháp
9396,E:\DATN\dataframe\train_file\91.txt,"Trong nghiên cứu này, một watermark được giả định sẽ nhúng vào một convolutional layers của mạng DCNN."
9397,E:\DATN\dataframe\train_file\91.txt,Giả định lớp convolution này có kernel size là
9398,E:\DATN\dataframe\train_file\91.txt,"(S, S)"
9399,E:\DATN\dataframe\train_file\91.txt,"(S,S), input đầu vào cho layer này có số channel là"
9400,E:\DATN\dataframe\train_file\91.txt,D là số filters của layer hiện tại là
9401,E:\DATN\dataframe\train_file\91.txt,"L. Khi đó, số parameters của layer này sẽ là một tensor"
9402,E:\DATN\dataframe\train_file\91.txt,W^{(S\times S\times D\times L)}
9403,E:\DATN\dataframe\train_file\91.txt,(S×S×D×L)
9404,E:\DATN\dataframe\train_file\91.txt, (không xét đến
9405,E:\DATN\dataframe\train_file\91.txt,Watermark ở đây sẽ là một vector
9406,E:\DATN\dataframe\train_file\91.txt,"T−bits,"
9407,E:\DATN\dataframe\train_file\91.txt,"b\in\{0, 1\}^T"
9408,E:\DATN\dataframe\train_file\91.txt,"b∈{0,1}"
9409,E:\DATN\dataframe\train_file\91.txt,", vector này sẽ cố gắng để nhúng vào"
9410,E:\DATN\dataframe\train_file\91.txt,Có thể nhúng watermark
9411,E:\DATN\dataframe\train_file\91.txt,b vào
9412,E:\DATN\dataframe\train_file\91.txt,W bằng cách sửa đổi luôn giá trị các phần tử trong
9413,E:\DATN\dataframe\train_file\91.txt,"W, điều này là khả thi tuy nhiên nó ảnh hưởng nghiêm trọng tới độ chính xác cũng như hiệu năng của mạng DCNN ban đầu."
9414,E:\DATN\dataframe\train_file\91.txt,"Thay vào đó, nhóm tác giả quyết định nhúng"
9415,E:\DATN\dataframe\train_file\91.txt,b vào không gian
9416,E:\DATN\dataframe\train_file\91.txt,W trong quá trình training model thông qua parameter regularizer- là một thuật ngữ bổ sung cho cost function của nhiệm vụ training bạn đầu.
9417,E:\DATN\dataframe\train_file\91.txt,Hàm lỗi hay còn gọi là cost function
9418,E:\DATN\dataframe\train_file\91.txt,E(w) được xác định với regularizer như sau:
9419,E:\DATN\dataframe\train_file\91.txt,E(w) = E_0(w) + λE_R(w)
9420,E:\DATN\dataframe\train_file\91.txt,"Trong đó,"
9421,E:\DATN\dataframe\train_file\91.txt,(w) có thể là L2 regularization.
9422,E:\DATN\dataframe\train_file\91.txt,E_R(w) = ||w||^2_2
9423,E:\DATN\dataframe\train_file\91.txt,(w)=∣∣w∣∣
9424,E:\DATN\dataframe\train_file\91.txt,"Khi các bạn học về Machine learning, ý nghĩa của biểu thức trên là gì và nó có ảnh hưởng như thế nào với quá trình đào tạo thì các bạn đã quá quen thuộc rồi, mình không giải thích lại."
9425,E:\DATN\dataframe\train_file\91.txt,Bạn có thể đọc lại tại .
9426,E:\DATN\dataframe\train_file\91.txt,"Khác với các chức năng regularizer tiêu chuẩn như L1/L2 regularization, nhóm tác giả đề xuất một khái niệm gọi là"
9427,E:\DATN\dataframe\train_file\91.txt,embedding\ regularizer
9428,E:\DATN\dataframe\train_file\91.txt,embedding regularizer.
9429,E:\DATN\dataframe\train_file\91.txt,(w) được gọi là một embedding loss function kết hợp với loss function ban đầu là
9430,E:\DATN\dataframe\train_file\91.txt,(w) để trở thành loss function mới của mạng.
9431,E:\DATN\dataframe\train_file\91.txt,Để có thể nhúng vector
9432,E:\DATN\dataframe\train_file\91.txt,"T−bits,"
9433,E:\DATN\dataframe\train_file\91.txt,"b\in\{0, 1\}^T"
9434,E:\DATN\dataframe\train_file\91.txt,"b∈{0,1}"
9435,E:\DATN\dataframe\train_file\91.txt," vào mô hình, chúng ta cần định nghĩa một ma trận embedding gọi là"
9436,E:\DATN\dataframe\train_file\91.txt,"X, X ∈ R^{T×M}"
9437,E:\DATN\dataframe\train_file\91.txt,"X,X∈R"
9438,E:\DATN\dataframe\train_file\91.txt,T×M
9439,E:\DATN\dataframe\train_file\91.txt,Ma trận này là cố định và được khởi tạo một lần duy nhất và cần được lưu lại cho quá trình trích xuất watermark khi muốn xác định chủ sở hữu mô hình.
9440,E:\DATN\dataframe\train_file\91.txt,(w) được định nghĩa như sau:
9441,E:\DATN\dataframe\train_file\91.txt,"Khi đó, bằng việc mô hình được học dựa trên loss function mới, mô hình sẽ cố gắng cập nhật các trọng số cần học của mạng là"
9442,E:\DATN\dataframe\train_file\91.txt,w sao cho
9443,E:\DATN\dataframe\train_file\91.txt,- giá trị bit thứ j của vector nhúng và các giá trị
9444,E:\DATN\dataframe\train_file\91.txt, là tiệm cận về mặt giá trị với nhau vì các giá trị
9445,E:\DATN\dataframe\train_file\91.txt, được thiết kế cơ bản là đầu ra của một mạng perceptron đơn giản với tham số học được chính là
9446,E:\DATN\dataframe\train_file\91.txt, với tham số cố định là
9447,E:\DATN\dataframe\train_file\91.txt,"Như vậy, khi mô hình được tối ưu dựa trên loss mới, dựa vào bộ trọng số của mô hình và ma trận"
9448,E:\DATN\dataframe\train_file\91.txt,"X định trước, ta dễ dàng xác định lại được vector watermark"
9449,E:\DATN\dataframe\train_file\91.txt,T như cách tính của
9450,E:\DATN\dataframe\train_file\91.txt, ở trên.
9451,E:\DATN\dataframe\train_file\91.txt,"Nếu nhìn sơ qua, cách xây dựng này có thể làm giảm hiệu suất của mạng do thay vì chỉ cập nhật trọng số của mạng để đạt được nhiệm vụ ban đầu mà còn phải biến đổi sao cho phù hợp với watermark."
9452,E:\DATN\dataframe\train_file\91.txt,Đôi khi vì quá tập trung vào cập nhật cho phù hợp với watermark mà mạng mất đi hiệu suất cho nhiệm vụ ban đầu.
9453,E:\DATN\dataframe\train_file\91.txt,"Tuy nhiên, bằng việc thực nghiệm của mình, nhóm nghiên cứu đã chỉ ra rằng đề xuất này không làm giảm hiệu suất của nhiệm vụ ban đầu mà còn giúp mô hình dễ dàng chống được overfit- một hiện tượng thường gặp của các mạng DNNs."
9454,E:\DATN\dataframe\train_file\91.txt,"This approach does not impair the performance of the host network in the original task as confirmed in experiments, because deep neural networks are typically overparameterized."
9455,E:\DATN\dataframe\train_file\91.txt,"It is well-known that deep neural networks have many local minima, and that all local minima are likely to have an error very close to that of the global minimum [, ]."
9456,E:\DATN\dataframe\train_file\91.txt,"Therefore, the embedding regularizer only needs to guide model parameters to one of a number of good local minima so that the final model parameters have an arbitrary watermark."
9457,E:\DATN\dataframe\train_file\91.txt,"Trong bài báo, nhóm tác giả của đề xuất và thí nghiệm 3 phương pháp sinh ma trận embedding"
9458,E:\DATN\dataframe\train_file\91.txt,X. Đây là có thể coi là một secret key với
9459,E:\DATN\dataframe\train_file\91.txt,X có vai trò để nhúng và phát hiện lại watermark.
9460,E:\DATN\dataframe\train_file\91.txt,"X ở đây có thể là các ma trận bất kì, được sinh ngẫu nhiên, tuy nhiên, vì nó sẽ ảnh hưởng đến quá trình nhúng watermark và có thể ảnh hưởng đến hiệu suất của mạng ban đầu nên một số đề xuất đã được xem xét bao gồm"
9461,E:\DATN\dataframe\train_file\91.txt,Kết quả thí nghiệm các bạn có thể xem chi tiết tại bài báo.
9462,E:\DATN\dataframe\train_file\91.txt,Toàn bộ code cho thử nghiệm được public tại đây .
9463,E:\DATN\dataframe\train_file\91.txt,"Nhìn chung, với cảm nhận cá nhân mình thấy cách nhúng watermark của nhóm tác giả này khá hay và có phần mới lạ."
9464,E:\DATN\dataframe\train_file\91.txt,Nhóm tác giả cũng chứng minh được rằng watermark này mạnh mẽ trước các loại tấn cấn như fine-tuning hay model compression.
9465,E:\DATN\dataframe\train_file\91.txt,"Tuy nhiên, nếu ma trận"
9466,E:\DATN\dataframe\train_file\91.txt,X bị lộ sẽ dễ dàng bị tấn công ghi đè để xóa watermark.
9467,E:\DATN\dataframe\train_file\91.txt,Protecting Intellectual Property of Deep Neural Networks with Watermarking (2018)
9468,E:\DATN\dataframe\train_file\91.txt,Một trong những hướng đi khác để bảo vệ mô hình DNN là tạo fingerprint cho mô hình.
9469,E:\DATN\dataframe\train_file\91.txt,"Paper này được viết bởi Jialong Zhang và các cộng sự của mình, nhóm nghiên cứu thuộc IBM research và được công bố tại hội thảo ASIACCS năm 2018."
9470,E:\DATN\dataframe\train_file\91.txt,"Trong paper này, nhóm nghiên cứu đã đề xuất một phương pháp nhúng các watermark vào các mô hình DNN sau đó thiết kế một cơ chế xác thực từ xa để xác định quyền sở hữu của mô hình."
9471,E:\DATN\dataframe\train_file\91.txt,"Với việc giả định rằng điều kiện khi xác định quyền sở hữu của mô hình không cho phép người kiểm tra có thể xem xét toàn bộ kiến trúc cũng như trọng số của mô hình, nhóm nghiên cứu đã xây dựng một phương pháp xác thực từ xa."
9472,E:\DATN\dataframe\train_file\91.txt,Điều này hiểu đơn giản như việc bạn nghi ngờ công ty A đang sử dụng mô hình của mình khi chưa được cấp phép nhưng cái bạn có duy nhất chỉ là một web site hay một ứng dụng mà công ty đó public có sử dụng mô hình này.
9473,E:\DATN\dataframe\train_file\91.txt,Thực chất bạn chỉ đang nghi ngờ mà không biết họ có đang sử dụng mô hình của mình hay không.
9474,E:\DATN\dataframe\train_file\91.txt,"Như chúng ta đã biết, các mạng học sâu DNNs hay như CNN có một đặc điểm cũng là ưu và nhược đó là rất dễ học được và ghi nhớ những mẫu có trong dữ liệu học."
9475,E:\DATN\dataframe\train_file\91.txt,Đây chính là hiện tượng khiến cho các mô hình dễ dàng bị overfit vào các bộ dữ liệu huấn luyện khi bị học quá lâu.
9476,E:\DATN\dataframe\train_file\91.txt,"Điều này cũng gợi ý cho ta về một ý tưởng đó là ta có thể cài một tập các mẫu ""nhiễu"" có chứa watermark vào mô hình để mô hình có thể học được và ghi nhớ chúng trong quá trình huấn luyện."
9477,E:\DATN\dataframe\train_file\91.txt,"Khi kiểm tra, xác minh quyền sở hữu, ta chỉ việc kiểm tra xem các mô hình đã có nhận ra được các watermark này nữa hay không."
9478,E:\DATN\dataframe\train_file\91.txt,Và đây cũng là đề xuất trong bài báo mà mình đang nói tới.
9479,E:\DATN\dataframe\train_file\91.txt,Nhóm tác giả đã đề xuất việc tạo ra các đầu vào đặc biệt làm watermark để kiểm tra các mô hình như các blackbox của mình.
9480,E:\DATN\dataframe\train_file\91.txt,Hình dưới đây chính là work flow được đề xuất trong bài báo.
9481,E:\DATN\dataframe\train_file\91.txt,"Như hình trên thể hiện rõ cách làm của tác giả, đơn giản và vô cùng dễ thực hiện."
9482,E:\DATN\dataframe\train_file\91.txt,"Trong dữ liệu training chúng ta có một ảnh là ""automobile"", chúng ta vẫn cho mô hình học được đó là hình ảnh của một automobile, tuy nhiên, song song với đó ta thực hiện nhúng watermark vào ảnh đó là bảo mô hình đó là một ""airplane""."
9483,E:\DATN\dataframe\train_file\91.txt,Mô hình sẽ học và nhận ra được đâu là hình ảnh có chưa watermark và đưa ra một dự đoán sai.
9484,E:\DATN\dataframe\train_file\91.txt,"Trong paper, nhóm tác giả đề xuất 3 phương pháp nhúng watermark vào dữ liệu huấn luyện."
9485,E:\DATN\dataframe\train_file\91.txt,Meaningful content embedded in original training data as watermarks: Phương pháp này chính là phương pháp vừa mình trình bày ở trên.
9486,E:\DATN\dataframe\train_file\91.txt,Một watermark xác định được nhúng vào trong một vài dữ liệu của một class và cho mô hình học được rằng đó là một class khác.
9487,E:\DATN\dataframe\train_file\91.txt,(ô tô + watermark == máy bay)
9488,E:\DATN\dataframe\train_file\91.txt,"Independent training data with unrelated classes as watermarks: Phương pháp này chỉ tận dụng khả năng ghi nhớ dữ liệu của mô hình, không cần mô hình phải nhận ra các pattern watermark có trong dữ liệu vì các watermark độc lập với dữ liệu huấn luyện."
9489,E:\DATN\dataframe\train_file\91.txt,Chúng ta cho mô hình học các dữ liệu không liên quan nhưng mô hình vẫn phải dự đoán đó là các class định sẵn.
9490,E:\DATN\dataframe\train_file\91.txt,Như việc ta xây dựng một mô hình phân loại cho mèo nhưng cho mô hình huấn luyện trên 10 ảnh con voi mà vẫn bắt nó dự đoán đó là con mèo.
9491,E:\DATN\dataframe\train_file\91.txt,"Pre-specified Noise as watermarks: Phương pháp này thì khá tương tự như phương pháp đầu tiên, nhưng thay vì gán các watermark định sẵn, chúng ta thêm nhiễu vào các sample của 1 class cần mô hình nhận dạng và bắt mô hình dự đoán đó thuộc về một class khác."
9492,E:\DATN\dataframe\train_file\91.txt,3 phương pháp được đề xuất được thể hiện như hình bên dưới đây.
9493,E:\DATN\dataframe\train_file\91.txt,"Dễ dàng nhận thấy những đề xuất này hiệu quả ở việc rất khó để mô hình có thể quên đi các mẫu watermark đã được huấn luyện kể cả mô hình bị tấn công watermark bằng fine-tuning hay model compression như pruning, quantization."
9494,E:\DATN\dataframe\train_file\91.txt,Một khi mô hình đã học được các mẫu watermark thì không thể xóa chúng trừ khi bên công có được cách thức nhúng watermark và bộ dữ liệu chứa watermark dùng để chứng minh quyền sở hữu.
9495,E:\DATN\dataframe\train_file\91.txt,Việc xác thực sở hữu hoàn toàn là việc cho mô hình dự đoán lại các mẫu dữ liệu chứa watermark mà không cần kiểm tra kiến trúc hay trọng số của mô hình.
9496,E:\DATN\dataframe\train_file\91.txt,Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring (2018)
9497,E:\DATN\dataframe\train_file\91.txt,How to Prove Your Model Belongs to You: A Blind-Watermark based Framework to Protect Intellectual Property of DNN (2018)
9498,E:\DATN\dataframe\train_file\91.txt,DeepSigns: A Generic Watermarking Framework for Protecting the Ownership of Deep Learning Models (2018)
9499,E:\DATN\dataframe\train_file\92.txt,Semantic Versioning
9500,E:\DATN\dataframe\train_file\92.txt,Bài viết xuất phát từ một lần tò mò xem change log của một extention khá quen thuộc là .
9501,E:\DATN\dataframe\train_file\92.txt,Khi xem change log ở repo này mình thấy quy tắc đánh version khá linh tinh.
9502,E:\DATN\dataframe\train_file\92.txt,Ví dụ như đang ở 5.6.3 nhảy lên luôn 5.7.0 mà không phải là 5.6.4.
9503,E:\DATN\dataframe\train_file\92.txt,Sau một thời gian tìm tòi cũng như hỏi ngu thì mình được một người anh chỉ cho keyword Semantic versioning để giải thích cách đặt version cho mỗi lần release.
9504,E:\DATN\dataframe\train_file\92.txt,"Nhưng trước khi giải thích ""công thức"" đánh version kia thì chúng ta tìm hiểu trước một chút về Semantic versioning xem chúng là gì ?"
9505,E:\DATN\dataframe\train_file\92.txt,và giải quyết mục đích gì đã nhé.
9506,E:\DATN\dataframe\train_file\92.txt,Semantic versioning ra đời như thế nào ?
9507,E:\DATN\dataframe\train_file\92.txt,"Chuyện rằng trong một ngày đẹp trời, mình cần thực hiện việc lấy ra thông tin của các ca sĩ sao hạng A để phục vụ mục đích hiện thị trên trang web của mình."
9508,E:\DATN\dataframe\train_file\92.txt,"Thật may là sau một thời gian tìm kiếm thì cũng có một dịch vụ, mình tạm gọi là dịch vụ X có cung cấp một API hiển thị toàn bộ danh sách thông tin của các ca sĩ này."
9509,E:\DATN\dataframe\train_file\92.txt,Khi thông tin của API này thì mình có thể liệt kê ra một vài thành phần đánh chú ý như sau:
9510,E:\DATN\dataframe\train_file\92.txt,URL API:
9511,E:\DATN\dataframe\train_file\92.txt,METHOD: GET
9512,E:\DATN\dataframe\train_file\92.txt,"  ""id"": 1,"
9513,E:\DATN\dataframe\train_file\92.txt,"  ""name"": ""Ưng Hoàng Hôn"","
9514,E:\DATN\dataframe\train_file\92.txt,"  ""company"": ""XXX"""
9515,E:\DATN\dataframe\train_file\92.txt,"  ""id"": 2,"
9516,E:\DATN\dataframe\train_file\92.txt,"  ""name"": ""Sơn Tường MTP"","
9517,E:\DATN\dataframe\train_file\92.txt,"  ""company"": ""YYY"""
9518,E:\DATN\dataframe\train_file\92.txt,"  ""id"": 3,"
9519,E:\DATN\dataframe\train_file\92.txt,"  ""name"": ""Chi Peo"","
9520,E:\DATN\dataframe\train_file\92.txt,"  ""company"": ""ZZZ"""
9521,E:\DATN\dataframe\train_file\92.txt,Vậy là trong code của mình chỉ việc tiến hành call API về gán vào một biến có tên singers
9522,E:\DATN\dataframe\train_file\92.txt,   $client = new \GuzzleHttp\Client();
9523,E:\DATN\dataframe\train_file\92.txt,    $request = $client->get('https://xxx/list-singer');
9524,E:\DATN\dataframe\train_file\92.txt,    $singers = $request->getBody();
9525,E:\DATN\dataframe\train_file\92.txt,    Ở ngoài view hiển thị dữ liệu dạng
9526,E:\DATN\dataframe\train_file\92.txt,    @foreach($singers as $singer)
9527,E:\DATN\dataframe\train_file\92.txt,        <td>{{ $singer->name }}</td>
9528,E:\DATN\dataframe\train_file\92.txt,        <td>{{ $singer->company }}</td>
9529,E:\DATN\dataframe\train_file\92.txt,"Vậy là ngon, mình đã hoàn thành việc liệt kê ra các ca sĩ dựa trên một API được public."
9530,E:\DATN\dataframe\train_file\92.txt,"Nhưng sau một thời gian sau, vào trang web mình tự nhiên thấy xuất hiện lỗi dạng name undefined."
9531,E:\DATN\dataframe\train_file\92.txt,Sau một hồi debug thì mình phát hiện ra đầu API kia đã thay đổi format response trả về.
9532,E:\DATN\dataframe\train_file\92.txt,"  ""id"": 1,"
9533,E:\DATN\dataframe\train_file\92.txt,"  ""name"": ""Ưng Hoàng Hôn"","
9534,E:\DATN\dataframe\train_file\92.txt,"  ""company"": ""XXX"""
9535,E:\DATN\dataframe\train_file\92.txt,"      ""id"": 1,"
9536,E:\DATN\dataframe\train_file\92.txt,"      ""name"": ""Ưng Hoàng Hôn"","
9537,E:\DATN\dataframe\train_file\92.txt,"      ""company"": ""XXX"""
9538,E:\DATN\dataframe\train_file\92.txt,"status: 200,"
9539,E:\DATN\dataframe\train_file\92.txt,"Vậy là mình vừa sửa bug vừa viết email chửi bên cung cấp, rằng tại sao mày lại thay đổi reponse code dẫn đến hệ thống của tao bị lỗi."
9540,E:\DATN\dataframe\train_file\92.txt,"Và được bên cung cấp rằng trong quá trình vận hành, có một bên client cần cung cấp thêm status code và vài thứ khác nên đội dev đã phải tiến hành thay đổi response."
9541,E:\DATN\dataframe\train_file\92.txt,Dựa trên câu chuyện không có thật ở trên ta có thể nhận ra 2 vấn đề về cách phát triển một API như sau.
9542,E:\DATN\dataframe\train_file\92.txt,"Phía client, cụ thể là nhà phát triển phải phụ thuộc vào response của API dẫn đến khi API thay đổi, client cũng thay đổi theo."
9543,E:\DATN\dataframe\train_file\92.txt,"Chúng ta thử tưởng tượng một service của chúng ta cần gọi tới 100 bên vendor cung cấp API, vậy là công việc của dev là chỉ ăn và sửa code theo response của các API."
9544,E:\DATN\dataframe\train_file\92.txt,Vẫn đề này gọi là Dependency hell - Phụ thuộc một cách bị động
9545,E:\DATN\dataframe\train_file\92.txt,"Về phía vendor cung cấp API, họ sẽ phải cẩn thận hơn trong quá trình thay đổi response trả về, làm sao để dù có thêm response - như câu chuyện trên là status thì không ảnh hưởng tới logic code của các bên client."
9546,E:\DATN\dataframe\train_file\92.txt,"Nhưng thật khó để có thể chiều lòng tất cả các bên vendor nên có một số bên cung cấp API họ đành lựa chọn cách không cải thiện response gì thêm, đúng với tiêu chí: Nếu nó đang hoạt động, đừng sửa nó."
9547,E:\DATN\dataframe\train_file\92.txt,Vẫn đề này gọi là version lock - Không phát triển được thêm.
9548,E:\DATN\dataframe\train_file\92.txt,"Để giải quyết vấn đề trên, các nhà phát triển trên họ đã nghĩ đến việc đánh version cho những lần thay đổi."
9549,E:\DATN\dataframe\train_file\92.txt,"Làm sao để mỗi lần có một thay đổi response, ở đây tạm coi là một lần release, họ sẽ cung cấp thêm một version mới để đảm bảo việc sẽ không ảnh hưởng bở version cũ."
9550,E:\DATN\dataframe\train_file\92.txt,Ví dụ như ở trên đầu bài chúng là có
9551,E:\DATN\dataframe\train_file\92.txt,URL API:
9552,E:\DATN\dataframe\train_file\92.txt,Bây giờ sau khi đánh version cho các lần release thì URL sẽ thay đổi theo dạng v1
9553,E:\DATN\dataframe\train_file\92.txt,URL API:
9554,E:\DATN\dataframe\train_file\92.txt,Khi có sự thay đổi sẽ cung cấp thêm một version nữa v2 chẳng hạn
9555,E:\DATN\dataframe\train_file\92.txt,URL API:  Để không ảnh hưởng tới việc gọi API của các client cũ mà vừa có thể phát triển được version mới.
9556,E:\DATN\dataframe\train_file\92.txt,Hoặc khi chúng ta install một package dạng
9557,E:\DATN\dataframe\train_file\92.txt,"""laravelcollective/html"": ""5.8.0"","
9558,E:\DATN\dataframe\train_file\92.txt,Sau khi nhà phát triển phát hành version 5.9.0 thì cũng không ảnh hưởng tới version hiện tại đang dùng.
9559,E:\DATN\dataframe\train_file\92.txt,Quy tắc đánh version
9560,E:\DATN\dataframe\train_file\92.txt,Ở phần trước chúng ta đã nói đến việc cần thiết phải đánh version nhưng chưa có một quy tắc cụ thể nào cả.
9561,E:\DATN\dataframe\train_file\92.txt,"Việc không có quy tắc sẽ gặp một vài vấn đề nhỏ, ví dụ như khi trong quá trình maintain, việc sửa một số logic nhỏ nhưng không ảnh hưởng đến logic cũ thì có cần thiết phải nâng version hay không."
9562,E:\DATN\dataframe\train_file\92.txt,"Quy tắc đánh version đầu tiên do  tạo ra, anh ấy cũng là người phát minh ra Gravatar và đồng chủ sở hữu GitHub."
9563,E:\DATN\dataframe\train_file\92.txt,                                     Ảnh: wikipedia
9564,E:\DATN\dataframe\train_file\92.txt,"Quy tắc này dựa trên 3 con số chính MAJOR, MINOR, PATCH."
9565,E:\DATN\dataframe\train_file\92.txt,Nó tương ứng với 3 con số trong việc định nghĩa version của 1 API hoặc 1 package.
9566,E:\DATN\dataframe\train_file\92.txt,Để giải thích cho 3 keyword trên chúng ta đi vào ví dụ cụ thể sau.
9567,E:\DATN\dataframe\train_file\92.txt,"Phiên bản đầu tiên /v1/users/:id, chúng ta viết một api trả về dữ liệu như sau:"
9568,E:\DATN\dataframe\train_file\92.txt,"   ""id"": 1,"
9569,E:\DATN\dataframe\train_file\92.txt,"   ""name"": ""sunh"""
9570,E:\DATN\dataframe\train_file\92.txt,"Sau đó chúng ta cần thêm một thông tin về tuổi chẳng hạn, ta cập nhật lại thành."
9571,E:\DATN\dataframe\train_file\92.txt,"  ""id"": 1,"
9572,E:\DATN\dataframe\train_file\92.txt,"  ""name"": ""sunh"","
9573,E:\DATN\dataframe\train_file\92.txt,"  ""age"": ""24"""
9574,E:\DATN\dataframe\train_file\92.txt,"=> Bản api mới này chỉ thêm trường ""age"", còn 2 trường cũ vẫn tương thích với bản trước đó nên đây gọi là MINOR change , đại loại là những thay đổi không làm ảnh hưởng đến phần cũ đang hoạt động."
9575,E:\DATN\dataframe\train_file\92.txt,"Và như vậy, api version vẫn giữ nguyên là v1."
9576,E:\DATN\dataframe\train_file\92.txt,"Sau đó, ta nhận thấy trả về tuổi kiểu string là một lỗi, ta sửa lại nó thành số."
9577,E:\DATN\dataframe\train_file\92.txt,"=> Bản api mới này chỉ sửa lại kiểu dữ liệu, sửa một lỗi nhỏ, không thêm gì mới và vẫn tương thích với bản trước đó nên gọi đây là PATCH (bản vá)."
9578,E:\DATN\dataframe\train_file\92.txt,Và như vậy api version vẫn giữ nguyên là v1.
9579,E:\DATN\dataframe\train_file\92.txt,"Đến một lúc nào đấy, chúng ta thấy api mình cần trả nhiều thông tin khác hơn là chỉ thông tin người dùng."
9580,E:\DATN\dataframe\train_file\92.txt,"  ""data"": { ""id"": 1, ""name"": ""sunh"", ""age"": 24 },"
9581,E:\DATN\dataframe\train_file\92.txt,"     ""source"": ""foobar"""
9582,E:\DATN\dataframe\train_file\92.txt,"=> Bản api mới này hoàn toàn khác với v1 đang chạy, nếu chúng ta sửa code, các phần các đang gọi sẽ oẳng."
9583,E:\DATN\dataframe\train_file\92.txt,Vậy nên chúng ta phải viết một api mới đánh đấu là /v2/users/:id.
9584,E:\DATN\dataframe\train_file\92.txt,"Đây là MAJOR hay breaking change, thay đổi không tương thích với bản cũ."
9585,E:\DATN\dataframe\train_file\92.txt,Vậy túm lại là
9586,E:\DATN\dataframe\train_file\92.txt,"MAJOR: Đại diện cho việc thay đổi lớn, không tương thích với bản cũ."
9587,E:\DATN\dataframe\train_file\92.txt,"PATCH: Đại diện cho những thay đổi nhỏ, vẫn tương thích với bản cũ, thường thay đổi sẽ là update gì đó."
9588,E:\DATN\dataframe\train_file\92.txt,"Nó làm mình liên tường đến PUT, PATCH trong Http request methods."
9589,E:\DATN\dataframe\train_file\92.txt,"MINOR: Đai diện cho những thay đổi nhỏ, vẫn tương thích với bản cũ, nó sẽ khác với PATCH là thay vì update một cái gì đó sẽ thành create một cái gì đó."
9590,E:\DATN\dataframe\train_file\92.txt,"Dựa vào việc giải thích trên, chúng ta có thể hoàn toàn dựa vào hoàn cảnh của từng lần release khác nhau để quyết định tăng MAJOR, PATCH hay MINOR."
9591,E:\DATN\dataframe\train_file\92.txt,Một số lưu ý trong việc sử dụng Semantic versioning
9592,E:\DATN\dataframe\train_file\92.txt,Một số lưu ý đánh version được định nghĩa trong .
9593,E:\DATN\dataframe\train_file\92.txt,Mình xin phép lược dịch lại.
9594,E:\DATN\dataframe\train_file\92.txt,Phần mềm sử dụng Semantic versioning(semver) phải là một public API.
9595,E:\DATN\dataframe\train_file\92.txt,Tuy nhiên với các internal api mình nghĩ các bạn cũng nên đánh version để khi deploy zero time nếu bạn xây dựng BE và FE ở 2 repo riêng biệt.
9596,E:\DATN\dataframe\train_file\92.txt,Cái này nói ra cũng hơi dài.
9597,E:\DATN\dataframe\train_file\92.txt,Nên bạn nào muốn tìm hiểu thêm thì comment xuống dưới mình giải thích nhé.
9598,E:\DATN\dataframe\train_file\92.txt,"Một version định nghĩa đúng phải bao gồm 3 số X.Y.Z tương ứng với MAJOR, PATCH, MINOR."
9599,E:\DATN\dataframe\train_file\92.txt,Mỗi phần tử phải tăng dần 1.9.0 -> 1.10.0 -> 1.11.0.
9600,E:\DATN\dataframe\train_file\92.txt,"Từ giờ khi gọi X, Y, Z chúng tầm nhầm hiểu là các con số bên trên."
9601,E:\DATN\dataframe\train_file\92.txt,Những con số này phải là số nguyên dương và không có số 0 đằng trước.
9602,E:\DATN\dataframe\train_file\92.txt,Khi một package đã được release.
9603,E:\DATN\dataframe\train_file\92.txt,"Không được phép tiến hành thay đổi nội dung trong version đó, mà phải release ở một version khác."
9604,E:\DATN\dataframe\train_file\92.txt,Dù sự thay đổi là nhỏ nhất.
9605,E:\DATN\dataframe\train_file\92.txt,Major version zero(0.y.z) dành cho việc phát triển.
9606,E:\DATN\dataframe\train_file\92.txt,Đây không được coi là một bản ổn định cho việc sử dụng.
9607,E:\DATN\dataframe\train_file\92.txt,Version 1.0.0 định nghĩa cho việc release lần đầu tiên.
9608,E:\DATN\dataframe\train_file\92.txt,"Việc quyết định X, Y, Z sẽ tăng lên trong những lần release tiếp theo phụ thuộc vào các hoàn cảnh khác nhau."
9609,E:\DATN\dataframe\train_file\92.txt,Patch version Z (x.y.Z | x > 0) phải được tăng lên cho mỗi lần sửa lỗi.
9610,E:\DATN\dataframe\train_file\92.txt,Cái này mình có nói ở phần trên rồi.
9611,E:\DATN\dataframe\train_file\92.txt,"Minor version Y (x.Y.z | x > 0) phải được tăng lên nếu có gì đó mới, mà tương thích với bản cũ."
9612,E:\DATN\dataframe\train_file\92.txt,Nó cũng phải được tăng lên nếu một chức năng nào đó trong API không dùng đến.
9613,E:\DATN\dataframe\train_file\92.txt,Nó có thể được tăng nên nếu có cải tiến trong code.
9614,E:\DATN\dataframe\train_file\92.txt,Patch version phải reset về 0 nếu Minor version tăng lên.
9615,E:\DATN\dataframe\train_file\92.txt,"Major version X (X.y.z | X > 0) phải được tăng lên nếu có sự thay đổi lớn, không tương thích với bản cũ."
9616,E:\DATN\dataframe\train_file\92.txt,"Nó có thể bao gồm cả sự thay đổi của Y, Z. Patch và minor phải được reset về 0 nếu X được tăng lên."
9617,E:\DATN\dataframe\train_file\92.txt,Các bản pre-release có thể biểu diễn thêm bằng cách thêm kí tự gạch ngang (-) đi kèm với kí tự ASCII.
9618,E:\DATN\dataframe\train_file\92.txt,Bản pre-release báo hiệu rằng đây không phải là một version hoàn chỉnh.
9619,E:\DATN\dataframe\train_file\92.txt,"Ví dụ như 1.0.0-alpha, 1.0.0-alpha.1, 1.0.0-0.3.7, 1.0.0-x.7.z.92, 1.0.0-x-y-z.–.."
9620,E:\DATN\dataframe\train_file\92.txt,Mức độ ưu tiên của các phần mềm sử dụng semver được định nghĩa như sau
9621,E:\DATN\dataframe\train_file\92.txt,"Mức độ ưu tiên phụ thuộc vào độ lớn của X, Y, Z từ trái qua phải."
9622,E:\DATN\dataframe\train_file\92.txt,Ví dụ 1.0.0 <2.0.0 <2.1.0 <2.1.1
9623,E:\DATN\dataframe\train_file\92.txt,Mức độ ưu tiên của version release được ưu tiên hơn so với phiên bản pre-release.
9624,E:\DATN\dataframe\train_file\92.txt,Ví dụ 1.0.0-alpha < 1.0.0
9625,E:\DATN\dataframe\train_file\92.txt,"Mức độ ưu tiên của các version pre-release cũng được đánh giá từ trái qua phải, số với số, chữ với chữ."
9626,E:\DATN\dataframe\train_file\92.txt,Ví dụ như 1.0.0-alpha < 1.0.0-alpha.1 < 1.0.0-alpha.beta < 1.0.0-beta < 1.0.0-beta.2 < 1.0.0-beta.11 < 1.0.0-rc.1 < 1.0.0
9627,E:\DATN\dataframe\train_file\92.txt,Trên đây mình đã giới thiệu cho các bạn tại sao phải đánh version cho từng lần release và sử dụng Semantic versioning.
9628,E:\DATN\dataframe\train_file\92.txt,Khi đã có am hiểu về việc đánh version chúng ta sẽ tránh mắc phải những sai xót trong những lần release.
9629,E:\DATN\dataframe\train_file\92.txt,Đánh giá được những sự thay đổi có ảnh hưởng đến logic hay không.
9630,E:\DATN\dataframe\train_file\92.txt,"Semantic cũng không phải là nguyên tắc đánh version duy nhất, ngoài ra nó còn kiểu đánh toàn number, gồm 4 phần nữa : Major.Minor.Revision.Build."
9631,E:\DATN\dataframe\train_file\92.txt,Các bạn có thể tìm hiểu thêm nhé.
9632,E:\DATN\dataframe\train_file\92.txt,"Dựa trên kiến thức của bài viết, chúng ta cũng phần nào giải thích được tại sao chat++ đang ở 5.6.3 nhảy lên luôn 5.7.0 mà không phải là 5.6.4 rồi đúng không."
9633,E:\DATN\dataframe\train_file\92.txt,"Cảm ơn các bạn đã theo dõi bài viết, nếu bài viết hữu ích các bạn ấn upvote để ủng hộ mình và follow để nhận thông báo mỗi khi mình có bài viết mới nhé"
9634,E:\DATN\dataframe\train_file\92.txt,Donate cho tác giả :
9635,E:\DATN\dataframe\train_file\92.txt,"Bài viết của mình bao gồm cả sự tìm hiểu, đóng góp ý kiến của các thành viên trong Avengers Groupđể bài viết hoàn thiện hơn."
9636,E:\DATN\dataframe\train_file\92.txt,Ngoài ra cũng được tham khảo từ tài liệu chính thức .
9637,E:\DATN\dataframe\train_file\92.txt,Các bạn có thể lên đó đọc thêm.
9638,E:\DATN\dataframe\train_file\93.txt,Tính toán và xử lí ngày tháng bằng câu lệnh SQL
9639,E:\DATN\dataframe\train_file\93.txt,Bài đăng này đã không được cập nhật trong 3 năm
9640,E:\DATN\dataframe\train_file\93.txt,Vừa qua mình vừa có 1 task liên quan đến việc tính toán và xử lí ngày tháng bằng câu lệnh SQL.
9641,E:\DATN\dataframe\train_file\93.txt,"Trong quá trình tìm hiểu và thực hiền mình có rút ra 1 chút kinh nghiệm hay hay nên hôm nay muốn chia sẽ cùng mọi người, mong có thế giúp các bạn khi cần thiết"
9642,E:\DATN\dataframe\train_file\93.txt,Kiểu dữ liệu ngày SQL.
9643,E:\DATN\dataframe\train_file\93.txt,MySQL có các loại dữ liệu sau cho một ngày hoặc giá trị ngày / thời gian trong cơ sở dữ liệu:
9644,E:\DATN\dataframe\train_file\93.txt,Date - format YYYY-MM-DD
9645,E:\DATN\dataframe\train_file\93.txt,DATETIME - format: YYYY-MM-DD HH:MI:SS
9646,E:\DATN\dataframe\train_file\93.txt,TIMESTAMP - format: YYYY-MM-DD HH:MI:SS
9647,E:\DATN\dataframe\train_file\93.txt,YEAR - format YYYY hoặc YY
9648,E:\DATN\dataframe\train_file\93.txt,Sql server có các loại dữ liệu sau cho một ngày hoặc giá trị ngày / thời gian trong cơ sở dữ liệu:
9649,E:\DATN\dataframe\train_file\93.txt,DATE - format YYYY-MM-DD
9650,E:\DATN\dataframe\train_file\93.txt,DATETIME - format: YYYY-MM-DD HH:MI:SS
9651,E:\DATN\dataframe\train_file\93.txt,SMALLDATETIME - format: YYYY-MM-DD HH:MI:SS
9652,E:\DATN\dataframe\train_file\93.txt,TIMESTAMP - format: 1 số duy nhất
9653,E:\DATN\dataframe\train_file\93.txt,Các funtion thường sử dụng.
9654,E:\DATN\dataframe\train_file\93.txt,....... Ngoài ra còn rất nhiều hàm khác nhưng mình xin phép trình bày một số hàm mà chúng ta hay sử dụng như trên.
9655,E:\DATN\dataframe\train_file\93.txt,3.1 Còn bao nhiêu ngày nữa ?
9656,E:\DATN\dataframe\train_file\93.txt,Câu hỏi này chắc chắn chạy qua đầu của chúng ta ít nhất là hàng tuần nếu không nói là hàng ngày
9657,E:\DATN\dataframe\train_file\93.txt,MySQL giải quyết loại câu hỏi này với hàm DATEDIFF()
9658,E:\DATN\dataframe\train_file\93.txt,DATEDIFF() trừ hai giá trị ngày và trả về số ngày giữa chúng.
9659,E:\DATN\dataframe\train_file\93.txt,"SELECT DATEDIFF(CURDATE(), birthday) AS days_difference"
9660,E:\DATN\dataframe\train_file\93.txt,     FROM friends
9661,E:\DATN\dataframe\train_file\93.txt,    LIMIT 5;
9662,E:\DATN\dataframe\train_file\93.txt,và kết quả là đây :
9663,E:\DATN\dataframe\train_file\93.txt,"sau khi lấy được số ngày, bạn muốn xem người đó năm nay bao nhiêu tuổi bạn chỉ cần chia cho 365 ngày là ra kết quả số tuổi."
9664,E:\DATN\dataframe\train_file\93.txt,"SELECT ROUND(DATEDIFF(CURDATE(), birthday) / 365, 0) AS years"
9665,E:\DATN\dataframe\train_file\93.txt,    FROM friends
9666,E:\DATN\dataframe\train_file\93.txt,   LIMIT 5;
9667,E:\DATN\dataframe\train_file\93.txt,Hàm ROUND()toán học được sử dụng để làm tròn kết quả thành một số nguyên.
9668,E:\DATN\dataframe\train_file\93.txt,Bạn cũng có thể tính toán tuổi của friends bằng cách sau
9669,E:\DATN\dataframe\train_file\93.txt,"    (YEAR(CURDATE()) - YEAR(birthday)) - (RIGHT(CURDATE(), 5) < RIGHT(birthday, 5)) AS years"
9670,E:\DATN\dataframe\train_file\93.txt,Giải thích 1 chút :
9671,E:\DATN\dataframe\train_file\93.txt,"Hàm CURDATE () trả về ngày hiện tại của máy tính, hàm YEAR () trả về năm của ngày đã chỉ định, hàm MONTH () trả về tháng của ngày đã chỉ định, hàm DAY () trả về ngày của ngày được chỉ định Hàm RIGHT () trả về số lượng ký tự như được chỉ định trong hàm từ chuỗi hoặc ngày đã cho."
9672,E:\DATN\dataframe\train_file\93.txt,Phần của biểu thức so sánh các trả về từ hàm RIGHT () ước tính 1 hoặc 0. kết quả là :
9673,E:\DATN\dataframe\train_file\93.txt,Sau khi select được số tuổi của các friend trong khoa trong list friend của mình bạn muốn sắp xếp số tuổi theo thứ tự giảm dần hoặc tăng dần thì chúng ta chỉ cần
9674,E:\DATN\dataframe\train_file\93.txt,ORDER BY age ASC; //sắp xếp tăng dần
9675,E:\DATN\dataframe\train_file\93.txt,ORDER BY age DESC; // sắp xếp giảm dần
9676,E:\DATN\dataframe\train_file\93.txt,vào cuối mệnh đề trên.
9677,E:\DATN\dataframe\train_file\93.txt,3.2 Chúng ta không bao giờ quên sinh nhật phải không?
9678,E:\DATN\dataframe\train_file\93.txt,Giả sử chúng ta muốn biết ngày trong tuần là sinh nhật của một người bạn.
9679,E:\DATN\dataframe\train_file\93.txt,"Có lẽ chúng tôi nhìn vào friends bàn mỗi tuần và biết được ai sẽ sinh nhật, nếu có, và ghi chú ngày hôm nay là ngày gì."
9680,E:\DATN\dataframe\train_file\93.txt,Các DAYOFWEEK()hàm trả về một giá trị số cho tham số giá trị ngày tháng.
9681,E:\DATN\dataframe\train_file\93.txt,Những con số đó đại diện cho:
9682,E:\DATN\dataframe\train_file\93.txt,"1 = Chủ nhật,"
9683,E:\DATN\dataframe\train_file\93.txt,"2 = Thứ hai, v.v."
9684,E:\DATN\dataframe\train_file\93.txt,Chúng ta có thể đặt một CASE biểu thức để sử dụng ở đây.
9685,E:\DATN\dataframe\train_file\93.txt,        WHEN DAYOFWEEK(birthday) = '1' THEN 'Sunday'
9686,E:\DATN\dataframe\train_file\93.txt,        WHEN DAYOFWEEK(birthday) = '2' THEN 'Monday'
9687,E:\DATN\dataframe\train_file\93.txt,        WHEN DAYOFWEEK(birthday) = '3' THEN 'Tuesday'
9688,E:\DATN\dataframe\train_file\93.txt,        WHEN DAYOFWEEK(birthday) = '4' THEN 'Wednesday'
9689,E:\DATN\dataframe\train_file\93.txt,        WHEN DAYOFWEEK(birthday) = '5' THEN 'Thursday'
9690,E:\DATN\dataframe\train_file\93.txt,        WHEN DAYOFWEEK(birthday) = '6' THEN 'Friday'
9691,E:\DATN\dataframe\train_file\93.txt,        WHEN DAYOFWEEK(birthday) = '7' THEN 'Saturday'
9692,E:\DATN\dataframe\train_file\93.txt,        ELSE 'not a day of week'
9693,E:\DATN\dataframe\train_file\93.txt,    END AS day_of_week
9694,E:\DATN\dataframe\train_file\93.txt,LIMIT 10
9695,E:\DATN\dataframe\train_file\93.txt,Điều đó hoạt động hoàn hảo.
9696,E:\DATN\dataframe\train_file\93.txt,Nhưng nó khá dài để lấy tên 1 ngày trong tuần.
9697,E:\DATN\dataframe\train_file\93.txt,MySQL có một function DAYNAME() phù hợp cho việc này.
9698,E:\DATN\dataframe\train_file\93.txt,Đơn giản chỉ cần cung cấp cho nó một giá trị ngày và bạn là vàng.
9699,E:\DATN\dataframe\train_file\93.txt,"    first_name, last_name, DAYNAME(birthday)"
9700,E:\DATN\dataframe\train_file\93.txt,LIMIT 10
9701,E:\DATN\dataframe\train_file\93.txt,3.3 Xử lí tháng
9702,E:\DATN\dataframe\train_file\93.txt,Các hàm MONTH() được sử dụng để lấy các giá trị số theo tháng từ một giá trị ngày tháng cung cấp.
9703,E:\DATN\dataframe\train_file\93.txt,Như trong 1 nghĩa (tháng 1) và 12 cho (tháng 12) với mọi thứ khác ở giữa.
9704,E:\DATN\dataframe\train_file\93.txt,"    (MONTH(birthday)) AS month, COUNT(*) AS number_of_birthdays"
9705,E:\DATN\dataframe\train_file\93.txt,GROUP BY month
9706,E:\DATN\dataframe\train_file\93.txt,ORDER BY month ASC
9707,E:\DATN\dataframe\train_file\93.txt,"Trong truy vấn này, hàm COUNT() đến số người có ngày sinh trong mỗi tháng :Vậy liệu chúng ta có thể lấy tên của tháng không ?"
9708,E:\DATN\dataframe\train_file\93.txt,câu trả lởi chắc chắn là có rồi
9709,E:\DATN\dataframe\train_file\93.txt,"Sử dụng hàm MONTHNAME(), lấy tên của Tháng thực tế từ giá trị ngày đã qua, so với số Tháng qua MONTH()."
9710,E:\DATN\dataframe\train_file\93.txt,SELECT DISTINCT
9711,E:\DATN\dataframe\train_file\93.txt,"    (MONTHNAME(birthday)) AS month,"
9712,E:\DATN\dataframe\train_file\93.txt,    COUNT(*) AS number_of_birthdays
9713,E:\DATN\dataframe\train_file\93.txt,GROUP BY month
9714,E:\DATN\dataframe\train_file\93.txt,3.4 Xử lí ngày
9715,E:\DATN\dataframe\train_file\93.txt,"Khi bạn có thêm 1 người bạn mới, bạn vui vẻ nhập thông tin người bạn ấy vào Nhưng, ngày sinh nhật ở dạng chuỗi như 'ngày 10tháng 08 năm 2017'."
9716,E:\DATN\dataframe\train_file\93.txt,"SELECT STR_TO_DATE(""August 10 2017"", ""%M %d %Y"")"
9717,E:\DATN\dataframe\train_file\93.txt,Giải thích một chút nào
9718,E:\DATN\dataframe\train_file\93.txt,"%M %d,%Y được định dạng là %M - Tên tháng."
9719,E:\DATN\dataframe\train_file\93.txt,%d - Số ngày trong tháng.
9720,E:\DATN\dataframe\train_file\93.txt,%Y - 4 chữ số năm.
9721,E:\DATN\dataframe\train_file\93.txt,3.5 Ngày có giá trị NOT NULL
9722,E:\DATN\dataframe\train_file\93.txt,để kiểm tra nếu giá trị ngày không phải là NULL.
9723,E:\DATN\dataframe\train_file\93.txt,"    first_name, last_name, birthday"
9724,E:\DATN\dataframe\train_file\93.txt,    birthday IS NOT NULL;
9725,E:\DATN\dataframe\train_file\93.txt,Câu lệnh MySQL ở trên sẽ lọc các hàng có ngày birthday KHÔNG phải là NULL.
9726,E:\DATN\dataframe\train_file\93.txt,3.5 Lấy ra những ngày trong khoảng ngày từ ngày... đến ngày ...
9727,E:\DATN\dataframe\train_file\93.txt,    birthday BETWEEN '1996-10-05 00:00:00' AND '1996-12-25 23:59:59'
9728,E:\DATN\dataframe\train_file\93.txt,"Thông qua các ví dụ thực tế trên, mong có thể giúp chúng ta có cái nhìn rõ hơn với việc xử lí ngày tháng bằng câu lệnh SQL."
9729,E:\DATN\dataframe\train_file\93.txt,Bài viết của mình vẫn còn nhiều thiếu sót rất mong nhận được sự góp ý đóng góp của các bạn để bài viết được hoàn thiện hơn
9730,E:\DATN\dataframe\train_file\93.txt,Tài liệu tham khảo :
9731,E:\DATN\dataframe\train_file\94.txt,UI UX là gì?
9732,E:\DATN\dataframe\train_file\94.txt,"UI, UX design là gì?"
9733,E:\DATN\dataframe\train_file\94.txt,Bài đăng này đã không được cập nhật trong 3 năm
9734,E:\DATN\dataframe\train_file\94.txt,"Công nghệ thiết kế UI, UX là một trong các công nghệ thiết kế web phổ biến được nhiều công ty, sử dụng để làm web cho các doanh nghiệp."
9735,E:\DATN\dataframe\train_file\94.txt,Đây cũng là xu hướng thiết kế web được đánh giá sẽ tiếp tục được ưa chuộng và phát triển trong năm 2018.
9736,E:\DATN\dataframe\train_file\94.txt,UI UX là gì?
9737,E:\DATN\dataframe\train_file\94.txt,Khái niệm UI
9738,E:\DATN\dataframe\train_file\94.txt,UI là viết tắt của từ User Interface có nghĩa là giao diện người dùng.
9739,E:\DATN\dataframe\train_file\94.txt,"Hiểu một cách đơn giản nhất thì UI bao gồm tất cả những gì người dùng có thể nhìn thấy như: màu sắc web, bố cục sắp xếp như thế nào, web/app sử dụng fonts chữ gì, hình ảnh trên web có hấp dẫn hay không,..."
9740,E:\DATN\dataframe\train_file\94.txt,"Trong thiết kế thì UI đóng vai trò là yếu tố truyền tải thông điệp từ người thiết kế, nhà cung cấp dịch vụ, sản phẩm tới người dùng."
9741,E:\DATN\dataframe\train_file\94.txt,Đơn giản hơn thì nhà thiết kế đóng vai trò như 1 lập trình viên hoặc nhà xây dựng để bất cứ ai cũng có thể hiểu và sử dụng được sản phẩm của họ .
9742,E:\DATN\dataframe\train_file\94.txt,"Ví dụ: Trên cương vị là một người thợ mộc khi bạn đóng một cái giường thì trước tiên sản phẩm bạn làm ra phải giống một cái giường đã, không thể cái giường lại giống 1 cái bàn được đúng không nào?"
9743,E:\DATN\dataframe\train_file\94.txt,Thì ở đây UI cũng được hiểu tương tự như vậy.
9744,E:\DATN\dataframe\train_file\94.txt,Khái niệm UX
9745,E:\DATN\dataframe\train_file\94.txt,UX là viết tắt của từ User Experience có nghĩa là trải nghiệm người dùng.
9746,E:\DATN\dataframe\train_file\94.txt,Đơn giản hơn thì UX là những đánh giá của người dùng khi sử dụng sản phẩm.
9747,E:\DATN\dataframe\train_file\94.txt,"như: Website hay App của bạn có dễ sử dụng hay không, có thân việc bố trí sắp xếp bố cục như vậy đã được hay chưa?"
9748,E:\DATN\dataframe\train_file\94.txt,sản phẩm đó có đạt được mục đích đề ra không.
9749,E:\DATN\dataframe\train_file\94.txt,Người làm về UX hay còn gọi là UX Designer.
9750,E:\DATN\dataframe\train_file\94.txt,UX Designer sẽ nghiên cứu và đánh giá về thói quen và cách mà khách hàng sử dụng rồi đánh giá về sản phẩm website/App nào đó.
9751,E:\DATN\dataframe\train_file\94.txt,"Sử dụng và đánh giá ở đây đơn giản là những vấn đề: tính dễ sử dụng, sự tiện ích, sự hiệu quả khi hệ thống hoạt động."
9752,E:\DATN\dataframe\train_file\94.txt,"Ví dụ: Hiện tại các bạn đang xem bài viết này trên website , các bạn đang cần tìm kiếm thông tin, kiến thức nào đó về website, nhưng nếu Tất Thành chèn quá nhiều quảng cáo gây khó chịu ảnh hưởng đến việc tìm kiếm thông tin của bạn, làm bạn mất tập chung như vậy thì có thể nói là UX hay trải nghiệm người dùng trên web  chưa được tốt."
9753,E:\DATN\dataframe\train_file\94.txt,Vì vậy Tất Thành luôn cố gắng cân bằng giữa UI/UX để bạn đọc có được một trải nghiệm trên website  một cách tốt nhất.
9754,E:\DATN\dataframe\train_file\94.txt,| Tóm lại: UI là cái người dùng nhìn thấy.
9755,E:\DATN\dataframe\train_file\94.txt,UX là cách người dùng sử dụng website/app đó.
9756,E:\DATN\dataframe\train_file\94.txt,1 website/app có thể có UI đẹp nhưng UX tệ.
9757,E:\DATN\dataframe\train_file\94.txt,UI UX design là gì?
9758,E:\DATN\dataframe\train_file\94.txt,UI/UX Designer là những người chuyên đi thiết kế giao diện/trải nghiệm người dùng cho sản phẩm.
9759,E:\DATN\dataframe\train_file\94.txt,Nó có thể là giao diện của một website hoặc một app điện thoại.
9760,E:\DATN\dataframe\train_file\94.txt,Nhiệm vụ chính là đảm bảo tính thẫm mỹ và sự tiện dụng của nó.
9761,E:\DATN\dataframe\train_file\94.txt,Công việc của UI Designer
9762,E:\DATN\dataframe\train_file\94.txt,Xem xét và cảm nhận:
9763,E:\DATN\dataframe\train_file\94.txt,Phân tích khách hàng.
9764,E:\DATN\dataframe\train_file\94.txt,Nghiên cứu thiết kế.
9765,E:\DATN\dataframe\train_file\94.txt,Xây dựng thương hiệu và phát triển đồ họa.
9766,E:\DATN\dataframe\train_file\94.txt,Xây dựng hướng dẫn sử dụng / Cốt truyện.
9767,E:\DATN\dataframe\train_file\94.txt,Sự đáp ứng và tương tác:
9768,E:\DATN\dataframe\train_file\94.txt,Xây dựng sản phẩm mẫu.
9769,E:\DATN\dataframe\train_file\94.txt,Sự tương tác và hoạt hình.
9770,E:\DATN\dataframe\train_file\94.txt,Sự thích ứng với tất cả các kích cỡ của màn hình thiết bị.
9771,E:\DATN\dataframe\train_file\94.txt,Thực hiện với nhà phát triển.
9772,E:\DATN\dataframe\train_file\94.txt,"Vai trò của giao diện người dùng là rất quan trọng đối với mọi giao diện kỹ thuật số, và là một yếu tố quan trọng mang lại sự tin tưởng vào một thương hiệu."
9773,E:\DATN\dataframe\train_file\94.txt,Các nhà thiết kế giao diện người dùng cần thể hiện rõ thương hiệu trên chính sản phẩm của họ.
9774,E:\DATN\dataframe\train_file\94.txt,Công việc của UX Designer
9775,E:\DATN\dataframe\train_file\94.txt,Chiến lược và nội dung:
9776,E:\DATN\dataframe\train_file\94.txt,Phân tích đối thủ cạnh tranh
9777,E:\DATN\dataframe\train_file\94.txt,Phân tích khách hàng
9778,E:\DATN\dataframe\train_file\94.txt,Cơ cấu / Chiến lược sản phẩm
9779,E:\DATN\dataframe\train_file\94.txt,Phát triển nội dung
9780,E:\DATN\dataframe\train_file\94.txt,Xây dựng dụng cụ trực quan và sản phẩm mẫu:
9781,E:\DATN\dataframe\train_file\94.txt,Xây dựng dụng cụ trực quan và sản phẩm mẫu
9782,E:\DATN\dataframe\train_file\94.txt,Kiểm tra / Lặp lại
9783,E:\DATN\dataframe\train_file\94.txt,Lên kế hoạch phát triển
9784,E:\DATN\dataframe\train_file\94.txt,Thực hiện và Phân tích
9785,E:\DATN\dataframe\train_file\94.txt,Phối hợp với nhà thiết kế giao diện người dùng
9786,E:\DATN\dataframe\train_file\94.txt,Phối hợp với các nhà phát triển
9787,E:\DATN\dataframe\train_file\94.txt,Theo dõi mục tiêu
9788,E:\DATN\dataframe\train_file\94.txt,Phân tích và lặp lại
9789,E:\DATN\dataframe\train_file\94.txt,Vậy giữa UI và UX cái nào quan trọng hơn?
9790,E:\DATN\dataframe\train_file\94.txt,Thực tế để phân biệt hai khái niệm UI và UX là điều khác khó khăn vì chúng có mối liên quan chặt chẽ với nhau.
9791,E:\DATN\dataframe\train_file\94.txt,Có không ít cuộc tranh luận rằng UX quan trọng hơn UI hoặc ngược lại UI quan trọng hơn UX.
9792,E:\DATN\dataframe\train_file\94.txt,"Tuy nhiên khi bạn đã hiểu rõ ràng về hai khái niệm này bạn có thể dễ dàng nhận điểm chung đó là cả UI và UX đều mang một mục đích đó là tạo sự thoải mái cho người dùng, từ đó ta có thể thấy chúng có vái trò quan trọng như nhau."
9793,E:\DATN\dataframe\train_file\94.txt,"Ví dụ: Một sản phẩm website/App có thiết kế bắt mắt, màu sắc đẹp thu hút người nhìn tuy nhiên nó lại khó khăn trong việc sử dụng, hay ngược lại một sản phẩm website/App rất dễ sử dụng và rất có ích nhưng nó khoác trên mình một vẻ ngoài khủng khiếp; rõ ràng chúng ta chẳng ai muốn dùng những sản phẩm như thế."
9794,E:\DATN\dataframe\train_file\94.txt,“Trải nghiệm người dùng (UX) và giao diện người dùng (UI) là một số thuật ngữ gây bối rối và dễ bị lầm lẩn nhất trong lĩnh vực của chúng tôi.
9795,E:\DATN\dataframe\train_file\94.txt,Một giao diện người dùng mà bỏ qua các vấn đề về trải nghiệm người dùng cũng giống như một họa sĩ sơn bừa bãi vào mặt vải/giấy một cách không chủ đích; trong khi UX không có UI thì chỉ giống như 1 khung tranh mà không hề có vải hay giấy trên đó.
9796,E:\DATN\dataframe\train_file\94.txt,trải nghiệm sản phẩm tuyệt vời được thực hiện bắt đầu từ UX tiếp theo sau đó là UI.
9797,E:\DATN\dataframe\train_file\94.txt,"Cả hai đều cần thiết cho sự thành công của sản phẩm.” - Rahul Varshney, Co-creator of  - UX và UI, cả hai thành phần đều có vai trò quan trọng trong việc thành công của sản phẩm."
9798,E:\DATN\dataframe\train_file\94.txt,“Một giao diện đẹp nhưng khó sử dụng là một ví dụ UI tốt và UX tồi.
9799,E:\DATN\dataframe\train_file\94.txt,"Trái lại, một sản phẩm dễ sử dụng với giao diện xấu lại là ví dụ cho UX tốt và UI tồi.” Nhà chuyên gia Helga Moreno, tác giả bài viết The Gap Between UX And UI Design đã đưa ra khẳng định chắc nịch: “Vì vậy, bạn có thể thấy, chúng đều rất quan trọng."
9800,E:\DATN\dataframe\train_file\94.txt,"Có tới hàng triệu ví dụ về các sản phẩm tuyệt vời với chỉ một yếu tố, vậy thì hãy tưởng tượng xem sẽ thành công như thế nào khi có cả hai yếu tố này?”"
9801,E:\DATN\dataframe\train_file\94.txt,Nguồn thao khảo
9802,E:\DATN\dataframe\train_file\95.txt,Context và Memory Leak trong Android
9803,E:\DATN\dataframe\train_file\95.txt,Context là trạng thái của ứng dụng tại một thời điểm nhất định.
9804,E:\DATN\dataframe\train_file\95.txt,"Context là 1 lớp cơ bản chứa hầu hết các thông tin về môi trường ứng dụng của android, tức là mọi thao tác, tương tác với hệ điều hành đều phải thông qua lớp này."
9805,E:\DATN\dataframe\train_file\95.txt,"Context là 1 abstract class, nó cung cấp cho các lớp triển khai các phương thức truy cập vào tài nguyên của ứng dụng và hệ thống."
9806,E:\DATN\dataframe\train_file\95.txt,"Ví dụ như nó có thể khởi tạo và chạy các activities, broadcast, các intents...."
9807,E:\DATN\dataframe\train_file\95.txt,"Sở dĩ hầu hết các lớp liên quan đến UI (layout, button, textview...) đều phải super context vì bản thân chúng đảm nhận việc truy cập resource(, R.layout...)."
9808,E:\DATN\dataframe\train_file\95.txt,Nếu chúng ta không tham chiếu đến Context thì sẽ không dùng được các resource mà chúng ta đã tạo ra.
9809,E:\DATN\dataframe\train_file\95.txt,Hệ thống cấp bậc Context:
9810,E:\DATN\dataframe\train_file\95.txt,| — ContextWrapper
9811,E:\DATN\dataframe\train_file\95.txt,| — — Application
9812,E:\DATN\dataframe\train_file\95.txt,| — — ContextThemeWrapper
9813,E:\DATN\dataframe\train_file\95.txt,| — — — Activity
9814,E:\DATN\dataframe\train_file\95.txt,| — — Service
9815,E:\DATN\dataframe\train_file\95.txt,| — — — IntentService
9816,E:\DATN\dataframe\train_file\95.txt,| — MockContext
9817,E:\DATN\dataframe\train_file\95.txt,"Thông thường, bạn hay sử dụng 2 loại context là Application và Activity:"
9818,E:\DATN\dataframe\train_file\95.txt,Application context: gắn liền với vòng đời của ứng dụng và luôn luôn giống nhau xuyên suốt vòng đời ứng dụng.
9819,E:\DATN\dataframe\train_file\95.txt,"getApplication(), getApplicationContext()."
9820,E:\DATN\dataframe\train_file\95.txt,Activity context: gắn liền với vòng đời của Activity và nó sẽ bị hủy khi activity bị hủy.
9821,E:\DATN\dataframe\train_file\95.txt,"getBaseContext(), Activity.this."
9822,E:\DATN\dataframe\train_file\95.txt,"Tips: Bất cứ khi nào bạn cần thao tác với Views hãy sử dụng Activity context, còn không sử dụng Application context là đủ."
9823,E:\DATN\dataframe\train_file\95.txt,"Ví dụ: khi bạn sử dụng Toast, bạn có thể sử dụng 1 trong 2 loại contex trên, nhưng vì nó có thể được show lên từ bất cứ nơi đâu trong ứng dụng, vì vậy bạn nên sử dụng Application context là hợp lý (Trong head-first android họ cũng sử dụng getApplicationContext());"
9824,E:\DATN\dataframe\train_file\95.txt,Tránh sử dụng getBaseContext() - lớp này được triển khai khi 1 class extends từ ContextWrapper.
9825,E:\DATN\dataframe\train_file\95.txt,Mà lớp này lại có khoảng 40 lớp con trực tiếp và không trực tiếp.
9826,E:\DATN\dataframe\train_file\95.txt,"Vì vậy, nên gọi trực tiếp đến getContext, Activity, Fragment... để tránh gây ra memory leak."
9827,E:\DATN\dataframe\train_file\95.txt,getApplicationContext() là 1 instance của class Application - được dùng để duy trì trạng thái global cho app.
9828,E:\DATN\dataframe\train_file\95.txt,Lỗi mà mọi người hay gặp khi sử dụng context là Memory Leak.
9829,E:\DATN\dataframe\train_file\95.txt,Memory leak
9830,E:\DATN\dataframe\train_file\95.txt,"Memory leak là rò rỉ bộ nhớ, xảy ra khi bộ nhớ được cấp phát nhưng không bao giờ được giải phóng."
9831,E:\DATN\dataframe\train_file\95.txt,"Trong khi làm việc với Android, đối tượng context rất hay được sử dụng, vì nó thường được sử dụng để load và truy cập vào resource."
9832,E:\DATN\dataframe\train_file\95.txt,Leak: được hiểu là việc bạn giữ 1 tham chiếu tới context và nó ngăn cản việc GC(Garbage Collection - trình thu gom rác) thu gom nó.
9833,E:\DATN\dataframe\train_file\95.txt,"Khi xảy ra sự kiện xoay màn hình, activity sẽ bị destroy và recreate lại nhưng trạng thái của activity vẫn được giữ lại."
9834,E:\DATN\dataframe\train_file\95.txt,Như vậy hệ thống sẽ load lại UI của ứng dụng từ resource.
9835,E:\DATN\dataframe\train_file\95.txt,Trong trường hợp bạn cần load 1 cái gì đó nặng và không muốn phải load lại khi xoay màn hình thì bạn sẽ để nó là static.
9836,E:\DATN\dataframe\train_file\95.txt,Ví dụ mình có đoạn code như sau:
9837,E:\DATN\dataframe\train_file\95.txt,private statis Drawable sBackground;
9838,E:\DATN\dataframe\train_file\95.txt,protected void onCreate(Bundle state){
9839,E:\DATN\dataframe\train_file\95.txt,    TextView label = new TextView(this);
9840,E:\DATN\dataframe\train_file\95.txt,"    label.setText(""Leak is bad!"
9841,E:\DATN\dataframe\train_file\95.txt,    if(sBackground == null) {
9842,E:\DATN\dataframe\train_file\95.txt,        sBackground = getDrawable(R.drawable.bit_map);
9843,E:\DATN\dataframe\train_file\95.txt,"Đoạn code trên có vẻ khá nhanh, nhưng lại thực sự sai."
9844,E:\DATN\dataframe\train_file\95.txt,"Lúc này drawable sẽ giữ 1 tham chiếu đến TextView, mà chính nó lại có 1 tham chiếu đến context (activity)."
9845,E:\DATN\dataframe\train_file\95.txt,"Đây là trường hợp đơn giản nhất dẫn đến memory leak, còn nhiều trường hợp nữa sẽ dẫn đến memory leak nhiều hơn và gây ra out of memory nhanh hơn(inner class)."
9846,E:\DATN\dataframe\train_file\95.txt,Có 2 cách đơn giản để tránh memory leak trong trường hợp này:
9847,E:\DATN\dataframe\train_file\95.txt,Tránh thoát khỏi context trong phạm vi
9848,E:\DATN\dataframe\train_file\95.txt,Sử dụng Application context: context này sẽ sống khi ứng dụng sống và nó không phụ thuộc vào vòng đời của activity.
9849,E:\DATN\dataframe\train_file\95.txt,Nếu bạn cần giữ 1 đối tượng lâu dài mà cần đến context thì nên dùng application context.
9850,E:\DATN\dataframe\train_file\95.txt,Tóm lại để tránh memory leak nên làm theo 1 số bước sau:
9851,E:\DATN\dataframe\train_file\95.txt,Không giữ reference đến context trong thời gian dài(1 reference nên đi cùng với vòng đời của activity)
9852,E:\DATN\dataframe\train_file\95.txt,Cố gắng sử dụng application context thay vì activity context
9853,E:\DATN\dataframe\train_file\95.txt,Nên để inner class là static và sử dụng WeakReference
9854,E:\DATN\dataframe\train_file\95.txt,Không khai báo biến static cho view hoặc activity
9855,E:\DATN\dataframe\train_file\95.txt,"Nhớ rằng luôn unregister broadcast, timer trong activity."
9856,E:\DATN\dataframe\train_file\95.txt,"Cancel asyncTask, thread trong onDestroy"
9857,E:\DATN\dataframe\train_file\95.txt,Sử dụng weakReference khi cần
9858,E:\DATN\dataframe\train_file\95.txt,Một Garbage collector không chống lại được memory leak.
9859,E:\DATN\dataframe\train_file\95.txt,Cách tránh memory leak
9860,E:\DATN\dataframe\train_file\95.txt,Có một số cách cụ thể để tránh Memory Leak như sau:
9861,E:\DATN\dataframe\train_file\95.txt,Broadcast receiver
9862,E:\DATN\dataframe\train_file\95.txt,Nếu đăng ký ở onStart() thì nên hủy đăng ký ở onStop().
9863,E:\DATN\dataframe\train_file\95.txt,Nếu đăng ký ở onResume() thì nên hủy đăng ký ở onPause()
9864,E:\DATN\dataframe\train_file\95.txt,Và nên hủy đăng ký ở onDestroy
9865,E:\DATN\dataframe\train_file\95.txt,b. Static Activity and View Reference
9866,E:\DATN\dataframe\train_file\95.txt,Nếu bạn khai báo view hoặc activity là static thì sẽ ngăn GC không thu hồi được bộ nhớ khi activity bị destroy.
9867,E:\DATN\dataframe\train_file\95.txt,Vì vậy đừng bao giờ khai báo chúng là static.
9868,E:\DATN\dataframe\train_file\95.txt,c. Singleton class reference
9869,E:\DATN\dataframe\train_file\95.txt,"Không nên truyền activity context vào class singleton, thay vào đó là truyền application context."
9870,E:\DATN\dataframe\train_file\95.txt,Hủy singleton trong onDestroy.
9871,E:\DATN\dataframe\train_file\95.txt,Nếu bạn truyền activity context vào trong class singleton thì hãy đảm bảo nó được set về null.
9872,E:\DATN\dataframe\train_file\95.txt,Inner class reference
9873,E:\DATN\dataframe\train_file\95.txt,"Như đã đề cập ở trên, đừng bao giờ khai báo static cho biến inner class"
9874,E:\DATN\dataframe\train_file\95.txt,Nên khai báo inner class là static class
9875,E:\DATN\dataframe\train_file\95.txt,"Hoặc là sử dụng weakReference cho view/activity, vì GC có thể thu gom chúng."
9876,E:\DATN\dataframe\train_file\95.txt,d. Anonymous class reference
9877,E:\DATN\dataframe\train_file\95.txt,Tương tự ý trên
9878,E:\DATN\dataframe\train_file\95.txt,e. AsyncTask reference
9879,E:\DATN\dataframe\train_file\95.txt,Luôn cancel asyncTask trong onDestroy
9880,E:\DATN\dataframe\train_file\95.txt,Nếu class AsyncTask được khai báo trong activity thì nó nên để static class (như ý trên).
9881,E:\DATN\dataframe\train_file\95.txt,Có thể sử dụng weakReference
9882,E:\DATN\dataframe\train_file\95.txt,f. Thread reference
9883,E:\DATN\dataframe\train_file\95.txt,Gọi thread.interrupt trong onDestroy.
9884,E:\DATN\dataframe\train_file\95.txt,g. TimerTask reference
9885,E:\DATN\dataframe\train_file\95.txt,Cancel timer trong onDestroy.
9886,E:\DATN\dataframe\train_file\95.txt,"Trên đây là một số cách tránh Memory Leak, mọi người tham khảo nhé."
9887,E:\DATN\dataframe\train_file\95.txt,Chúc mọi người code vui vẻ.
9888,E:\DATN\dataframe\train_file\96.txt,"Nét code nết người, Những cách giúp code của bạn sạch hơn"
9889,E:\DATN\dataframe\train_file\96.txt,"Viết code không hề khó, nhưng viết code “Sạch” lại không hề dễ dàng."
9890,E:\DATN\dataframe\train_file\96.txt,Code “Sạch” là gì?
9891,E:\DATN\dataframe\train_file\96.txt,"Những lập trình viên vừa bước chân vào nghề, hay những lập trình viên “Gà” thường Code cho xong mà không cần nghĩ tới tương lai của dự án, có bao giờ bạn mở lại đống code của bạn mà bạn viết cách đây khoảng 1 năm, và bạn đọc nó và thấy mình chả viết nó là cái gì Điển hình như việc sinh viên hay code thuật toán, đặt tên biến là a,b,c… xong đọc lại chả nhớ a,b,c là cái vẹo gì."
9892,E:\DATN\dataframe\train_file\96.txt,"Code sạch là code mà bạn viết ra trước hết là chính bạn có thể đọc, sau đó là người khác đọc vào, biết bạn đang code cái gì."
9893,E:\DATN\dataframe\train_file\96.txt,"Người viết code sạch thì sẽ không lạm dụng comment, mà ngươi khác vẫn hiểu những gì bạn viết."
9894,E:\DATN\dataframe\train_file\96.txt,Sử dụng IDE “Ngon”
9895,E:\DATN\dataframe\train_file\96.txt,"Đầu tiên hãy lựa chọn IDE phù hợp với ngôn ngữ của mình, và “ngon”."
9896,E:\DATN\dataframe\train_file\96.txt,"Ví dụ hồi trước mình có code java trên NetBean, Eclipse, sau khi chuyển qua Intelliji thì nó như 1 bầu trời mới vậy."
9897,E:\DATN\dataframe\train_file\96.txt,"Tất nhiên IDE cũng chỉ là 1 phần, đối với những lập trình viên mới thì chọn IDE tốt sẽ giúp tránh đc các lỗi vặt, đảm bảo tốt được hiệu năng"
9898,E:\DATN\dataframe\train_file\96.txt,"Một số IDE mình đang dùng: Visual Studio (.NET), Visual Studio Code (Front end), DbForge (Database) (bạn có thể dùng DataGrib, cũng cực ngon luôn), Visual Paradigm (Phân tích thiết kế), PostMan (Call API),…"
9899,E:\DATN\dataframe\train_file\96.txt,Đặt tên phải có Ý nghĩa
9900,E:\DATN\dataframe\train_file\96.txt,"Đặt tên biến luôn là một vấn đề khá là khó khăn, tuy nhiên hãy cố đặt nó theo cách dễ hiểu nhất"
9901,E:\DATN\dataframe\train_file\96.txt,Code tồi
9902,E:\DATN\dataframe\train_file\96.txt,int a;
9903,E:\DATN\dataframe\train_file\96.txt,Code Xịn
9904,E:\DATN\dataframe\train_file\96.txt,int daysToAppocalypse;
9905,E:\DATN\dataframe\train_file\96.txt,Sử dụng Camel/Pascal Case
9906,E:\DATN\dataframe\train_file\96.txt,Camel Case
9907,E:\DATN\dataframe\train_file\96.txt,"Về cơ bản, chữ cái đầu tiên của từ đầu sẽ viết thường, chữ cái đầu của từ tiếp theo sẽ viết hoa"
9908,E:\DATN\dataframe\train_file\96.txt,Code tồi
9909,E:\DATN\dataframe\train_file\96.txt,int RandomInteger;
9910,E:\DATN\dataframe\train_file\96.txt,string FirstName;
9911,E:\DATN\dataframe\train_file\96.txt,Code Xịn
9912,E:\DATN\dataframe\train_file\96.txt,int randomInteger;
9913,E:\DATN\dataframe\train_file\96.txt,string firstName;
9914,E:\DATN\dataframe\train_file\96.txt,Pascal Case
9915,E:\DATN\dataframe\train_file\96.txt,Các chữ cái đầu của từ sẽ được viết hoa (Áp dụng cho class và function)
9916,E:\DATN\dataframe\train_file\96.txt,Code tồi
9917,E:\DATN\dataframe\train_file\96.txt,class program
9918,E:\DATN\dataframe\train_file\96.txt,    static void main(string[] args)
9919,E:\DATN\dataframe\train_file\96.txt,"        Console.WriteLine(""Hello World!"
9920,E:\DATN\dataframe\train_file\96.txt,Code Xịn
9921,E:\DATN\dataframe\train_file\96.txt,class Program
9922,E:\DATN\dataframe\train_file\96.txt,    static void Main(string[] args)
9923,E:\DATN\dataframe\train_file\96.txt,"        Console.WriteLine(""Hello World!"
9924,E:\DATN\dataframe\train_file\96.txt,Chú ý định dạng code
9925,E:\DATN\dataframe\train_file\96.txt,Code tồi
9926,E:\DATN\dataframe\train_file\96.txt,class Program
9927,E:\DATN\dataframe\train_file\96.txt,{static void Main(string[] args)
9928,E:\DATN\dataframe\train_file\96.txt,"    {Console.WriteLine(""Hello World!"
9929,E:\DATN\dataframe\train_file\96.txt,"Lựa chọn IDE ngon sẽ giúp bạn format code tự động, như này chẳng hạn"
9930,E:\DATN\dataframe\train_file\96.txt,Thêm Comment vào những chỗ Cần Thiết
9931,E:\DATN\dataframe\train_file\96.txt,"Hãy sử dụng comment vào những chỗ “Cần thiết”, đừng lạm dụng quá."
9932,E:\DATN\dataframe\train_file\96.txt,"Ông nào code thì cũng lười comment cả thôi, nhưng cố mà thêm vào để sau đọc lại còn hiểu"
9933,E:\DATN\dataframe\train_file\96.txt,"Như mình dùng VS, sau khi comment, lúc gọi tới hàm, chỉ vào là thấy hàm này làm gì"
9934,E:\DATN\dataframe\train_file\96.txt,"Hãy thêm comment khi code của bạn muốn giải thích chuyên sâu, rõ ràng, không nên lạm dụng comment"
9935,E:\DATN\dataframe\train_file\96.txt,Code phải được Tái sử dụng
9936,E:\DATN\dataframe\train_file\96.txt,Viết code có thể được sử dụng lại là điều khá quan trọng.
9937,E:\DATN\dataframe\train_file\96.txt,Nó có thể làm giảm các dòng code tổng thể trong dự án của bạn và làm cho nó có hiệu quả cao.
9938,E:\DATN\dataframe\train_file\96.txt,Bạn không muốn sao chép-dán một hàm qua nhiều file/class.
9939,E:\DATN\dataframe\train_file\96.txt,"Thay vào đó, tạo một function chung, sau đó gọi tới ở những nơi cần."
9940,E:\DATN\dataframe\train_file\96.txt,"Và, nếu có bất kỳ sửa đổi nào cần thiết, bạn sẽ chỉ phải thay đổi code trong hàm đó, không phải ở mọi nơi."
9941,E:\DATN\dataframe\train_file\96.txt,"Xịn hơn, bạn có thể dùng Generic và Dynamic"
9942,E:\DATN\dataframe\train_file\96.txt,Đừng để 1 Class/ Function quá Phình To
9943,E:\DATN\dataframe\train_file\96.txt,"Theo SOLID Principles, trong 1 class / function không code quá nhiều dòng, mỗi class nên là 1 chức năng nào đó nhất định, nếu dài quá, hãy tách ra 1 class / function khác"
9944,E:\DATN\dataframe\train_file\96.txt,Sử dụng Design pattern
9945,E:\DATN\dataframe\train_file\96.txt,Lựa chọn Design Pattern tốt sẽ giúp code của bạn quản lý tốt hơn
9946,E:\DATN\dataframe\train_file\96.txt,Sắp xếp các thư mục / Project tốt
9947,E:\DATN\dataframe\train_file\96.txt,"Việc phân chia bố cục của project, gồm những Folder nào thực hiện chức năng nào sẽ giúp bạn quản lý tốt hơn"
9948,E:\DATN\dataframe\train_file\96.txt,"Tất nhiên là vẫn có thể ném hết tất cả code vào 1 file hoặc tất cả file vào 1 folder, nhưng đến lúc nó phình to thì việc mở rộng là cực kỳ khó, mất thời gian và người khác đọc thì chắc chắn rồi, k hiểu gì cả"
9949,E:\DATN\dataframe\train_file\96.txt,Tránh việc sử dụng chuỗi / số fix cứng
9950,E:\DATN\dataframe\train_file\96.txt,Code tồi
9951,E:\DATN\dataframe\train_file\96.txt,"if(userRole == ""Admin"")"
9952,E:\DATN\dataframe\train_file\96.txt,    //logic here
9953,E:\DATN\dataframe\train_file\96.txt,Code xịn
9954,E:\DATN\dataframe\train_file\96.txt,"const string ADMIN_ROLE = ""Admin"""
9955,E:\DATN\dataframe\train_file\96.txt,if(userRole == ADMIN_ROLE )
9956,E:\DATN\dataframe\train_file\96.txt,//logic here
9957,E:\DATN\dataframe\train_file\96.txt,"Ngoài ra, bạn cũng có thể tạo 1 Enum để lưu các giá trị đc hard code"
9958,E:\DATN\dataframe\train_file\96.txt,"11, Xoá những đoạn Code thừa"
9959,E:\DATN\dataframe\train_file\96.txt,"Bạn cần xoá những dòng code thừa trong quá trình code, những người viết javascript thường hay Console.log để xem kết quả, đôi khi họ cứ để đấy mãi"
9960,E:\DATN\dataframe\train_file\96.txt,Sử dụng Async/Await
9961,E:\DATN\dataframe\train_file\96.txt,"Lập trình bất đồng bộ sẽ giúp code của bạn chạy nhanh hơn, tuy nhiên vấn đề quản lý task chưa bao giờ là dễ dàng"
9962,E:\DATN\dataframe\train_file\96.txt,Không sử dụng ‘throw ex’
9963,E:\DATN\dataframe\train_file\96.txt,Code tồi
9964,E:\DATN\dataframe\train_file\96.txt,    // Do something..
9965,E:\DATN\dataframe\train_file\96.txt,catch (Exception ex)
9966,E:\DATN\dataframe\train_file\96.txt,    throw ex;
9967,E:\DATN\dataframe\train_file\96.txt,Code xịn
9968,E:\DATN\dataframe\train_file\96.txt,    // Do something..
9969,E:\DATN\dataframe\train_file\96.txt,catch (Exception ex)
9970,E:\DATN\dataframe\train_file\96.txt,Sử dụng toán tử 3 ngôi
9971,E:\DATN\dataframe\train_file\96.txt,Code tồi
9972,E:\DATN\dataframe\train_file\96.txt,public string SomeMethod(int value)
9973,E:\DATN\dataframe\train_file\96.txt,    if(value == 10)
9974,E:\DATN\dataframe\train_file\96.txt,"        return ""Value is 10"";"
9975,E:\DATN\dataframe\train_file\96.txt,"        return ""Value is not 10"";"
9976,E:\DATN\dataframe\train_file\96.txt,Code xịn
9977,E:\DATN\dataframe\train_file\96.txt,public string SomeMethod(int value)
9978,E:\DATN\dataframe\train_file\96.txt,    return value == 10 ?
9979,E:\DATN\dataframe\train_file\96.txt,"""Value is 10"" : ""Value is not 10"";"
9980,E:\DATN\dataframe\train_file\96.txt,Đừng cộng chuỗi
9981,E:\DATN\dataframe\train_file\96.txt,"Cộng chuỗi cũng oke đấy, nhưng nhìn sẽ rất rối"
9982,E:\DATN\dataframe\train_file\96.txt,Code tồi
9983,E:\DATN\dataframe\train_file\96.txt,public string SomeMethod(Student student)
9984,E:\DATN\dataframe\train_file\96.txt,"    return ""Student Name is "" + student.Name + ""."
9985,E:\DATN\dataframe\train_file\96.txt,"Age is "" + student.Age;"
9986,E:\DATN\dataframe\train_file\96.txt,Code xịn
9987,E:\DATN\dataframe\train_file\96.txt,public string SomeMethod(Student student)
9988,E:\DATN\dataframe\train_file\96.txt,"    return $""Student Name is {student.Name}."
9989,E:\DATN\dataframe\train_file\96.txt,"Age is {student.Age}"";"
9990,E:\DATN\dataframe\train_file\96.txt,Sử dụng quá nhiều Parameter trong hàm
9991,E:\DATN\dataframe\train_file\96.txt,Thay vào đó hãy nhóm chúng thành 1 class cho gọn
9992,E:\DATN\dataframe\train_file\96.txt,Code tồi
9993,E:\DATN\dataframe\train_file\96.txt,"public Student SomeMethod(string name, string city, int age, string section, DateTime dateOfBirth)"
9994,E:\DATN\dataframe\train_file\96.txt,    return new Student()
9995,E:\DATN\dataframe\train_file\96.txt,"        Age = age,"
9996,E:\DATN\dataframe\train_file\96.txt,"        Name = name,"
9997,E:\DATN\dataframe\train_file\96.txt,        //Other parameters too
9998,E:\DATN\dataframe\train_file\96.txt,Code xịn
9999,E:\DATN\dataframe\train_file\96.txt,public Student SomeMethod(Student student)
10000,E:\DATN\dataframe\train_file\96.txt,    return student;
10001,E:\DATN\dataframe\train_file\96.txt,Đừng bỏ trống catch
10002,E:\DATN\dataframe\train_file\96.txt,Code tồi
10003,E:\DATN\dataframe\train_file\96.txt,public void SomeMethod()
10004,E:\DATN\dataframe\train_file\96.txt,Code xịn
10005,E:\DATN\dataframe\train_file\96.txt,public void SomeMethod()
10006,E:\DATN\dataframe\train_file\96.txt,    catch (Exception ex)
10007,E:\DATN\dataframe\train_file\96.txt,Sử dụng Multiple catch
10008,E:\DATN\dataframe\train_file\96.txt,Code tồi
10009,E:\DATN\dataframe\train_file\96.txt,    // Do something..
10010,E:\DATN\dataframe\train_file\96.txt,catch (Exception ex)
10011,E:\DATN\dataframe\train_file\96.txt,    if (ex is TaskCanceledException)
10012,E:\DATN\dataframe\train_file\96.txt,        // Take action for TaskCanceledException
10013,E:\DATN\dataframe\train_file\96.txt,    else if (ex is TaskSchedulerException)
10014,E:\DATN\dataframe\train_file\96.txt,        // Take action for TaskSchedulerException
10015,E:\DATN\dataframe\train_file\96.txt,Code xịn
10016,E:\DATN\dataframe\train_file\96.txt,    // Do something..
10017,E:\DATN\dataframe\train_file\96.txt,catch (TaskCanceledException ex)
10018,E:\DATN\dataframe\train_file\96.txt,    // Take action for TaskCanceledException
10019,E:\DATN\dataframe\train_file\96.txt,catch (TaskSchedulerException ex)
10020,E:\DATN\dataframe\train_file\96.txt,    // Take action for TaskSchedulerException
10021,E:\DATN\dataframe\train_file\96.txt,Don't Repeat Yourself (DRY)
10022,E:\DATN\dataframe\train_file\96.txt,Code tồi
10023,E:\DATN\dataframe\train_file\96.txt,public List ShowDeveloperList(Developers developers)
10024,E:\DATN\dataframe\train_file\96.txt,    foreach (var developers in developer)
10025,E:\DATN\dataframe\train_file\96.txt,        var expectedSalary = developer.CalculateExpectedSalary();
10026,E:\DATN\dataframe\train_file\96.txt,        var experience = developer.GetExperience();
10027,E:\DATN\dataframe\train_file\96.txt,        var githubLink = developer.GetGithubLink();
10028,E:\DATN\dataframe\train_file\96.txt,        var data = new[] {
10029,E:\DATN\dataframe\train_file\96.txt,public List ShowManagerList(Manager managers)
10030,E:\DATN\dataframe\train_file\96.txt,    foreach (var manager in managers)
10031,E:\DATN\dataframe\train_file\96.txt,        var expectedSalary = manager.CalculateExpectedSalary();
10032,E:\DATN\dataframe\train_file\96.txt,        var experience = manager.GetExperience();
10033,E:\DATN\dataframe\train_file\96.txt,        var githubLink = manager.GetGithubLink();
10034,E:\DATN\dataframe\train_file\96.txt,        var data =
10035,E:\DATN\dataframe\train_file\96.txt,Code xịn
10036,E:\DATN\dataframe\train_file\96.txt,public List ShowList(Employee employees)
10037,E:\DATN\dataframe\train_file\96.txt,    foreach (var employee in employees)
10038,E:\DATN\dataframe\train_file\96.txt,        var expectedSalary = employees.CalculateExpectedSalary();
10039,E:\DATN\dataframe\train_file\96.txt,        var experience = employees.GetExperience();
10040,E:\DATN\dataframe\train_file\96.txt,        var githubLink = employees.GetGithubLink();
10041,E:\DATN\dataframe\train_file\96.txt,        var data =
10042,E:\DATN\dataframe\train_file\96.txt,Code cực xịn
10043,E:\DATN\dataframe\train_file\96.txt,public List ShowList(Employee employees)
10044,E:\DATN\dataframe\train_file\96.txt,    foreach (var employee in employees)
10045,E:\DATN\dataframe\train_file\96.txt,"Bạn hãy tìm hiểu về các quy tắc này, nó sẽ giúp íchh cho bạn rất nhiều"
10046,E:\DATN\dataframe\train_file\96.txt,Tài liệu tham khảo:
10047,E:\DATN\dataframe\train_file\97.txt,Câu chuyện muôn thuở của SQL và NoSQL
10048,E:\DATN\dataframe\train_file\97.txt,Bài viết nằm trong series .
10049,E:\DATN\dataframe\train_file\97.txt,"SQL và NoSQL là chủ đề không còn xa lạ trong thời buổi hiện nay khi mà đi đâu cũng nghe bàn tán xôn xao MongoDB, Cassandra, CouchDB hay BigTable, DynamoDB..."
10050,E:\DATN\dataframe\train_file\97.txt,"Postgres, MySQL, MSSQL là SQL."
10051,E:\DATN\dataframe\train_file\97.txt,"Còn MongoDB, Cassandra là NoSQL..."
10052,E:\DATN\dataframe\train_file\97.txt,"NoSQL nhanh hơn SQL đấy, sao không dùng?"
10053,E:\DATN\dataframe\train_file\97.txt,"MySQL lỗi thời rồi, chuyển sang MongoDB đi."
10054,E:\DATN\dataframe\train_file\97.txt,"Khi nào thì nên dùng NoSQL nhỉ, nếu SQL lỗi thời rồi thì sao vẫn còn được dùng ở rất rất nhiều các project?"
10055,E:\DATN\dataframe\train_file\97.txt,"Và vô vàn các câu hỏi hay lập luận, khẳng định đanh thép từ giới chuyên gia về vấn đề gây tranh cãi này."
10056,E:\DATN\dataframe\train_file\97.txt,Còn mình thì nghĩ rằng.. thực ra chẳng có gì để phải tranh cãi nếu chúng ta hiểu đúng về SQL và NoSQL.
10057,E:\DATN\dataframe\train_file\97.txt,Nếu bạn chưa hiểu rõ về SQL và NoSQL thì hãy tiếp tục.
10058,E:\DATN\dataframe\train_file\97.txt,"Còn nếu bạn đã nắm chắc như lòng bàn tay thì.. cũng hãy đọc tiếp để góp ý, bổ sung cho mình nhé."
10059,E:\DATN\dataframe\train_file\97.txt,Let's begin.
10060,E:\DATN\dataframe\train_file\97.txt,Bất kì project nào cũng cần sử dụng đến database và một câu hỏi luôn thường trực mỗi khi chúng ta bắt đầu là nên chọn SQL hay NoSQL hay chơi cả 2 cho máu?
10061,E:\DATN\dataframe\train_file\97.txt,"Muốn trả lời được ta cần hiểu rất rõ 2 loại này là gì, hoạt động thế nào, ưu nhược điểm ra sao để có thể áp dụng một cách linh hoạt và phù hợp nhất."
10062,E:\DATN\dataframe\train_file\97.txt,NOTE: tranh thủ kiếm tìm talent về với team mình.
10063,E:\DATN\dataframe\train_file\97.txt,Nếu bạn đang cân nhắc một cơ hội mới với 2 mục tiêu:
10064,E:\DATN\dataframe\train_file\97.txt,"Job remote full time, không quản thúc thời gian hay địa điểm."
10065,E:\DATN\dataframe\train_file\97.txt,"Bạn hoàn toàn có thể vừa nhâm nhi li cocktail bên bãi biễn, vừa fix bug và trò chuyện với crush."
10066,E:\DATN\dataframe\train_file\97.txt,"Package hàng năm lên tới 50k USD (chưa tính thưởng + bonus), tất nhiên nó còn tùy thuộc vào sự chai lì của bạn."
10067,E:\DATN\dataframe\train_file\97.txt,Đừng ngại ngần contact với mình nếu có nhu cầu nhé.
10068,E:\DATN\dataframe\train_file\97.txt,"Mà thời buổi này ngại chỉ có thiệt thân thôi, good luck!"
10069,E:\DATN\dataframe\train_file\97.txt,1) SQL
10070,E:\DATN\dataframe\train_file\97.txt,1.1) SQL là gì?
10071,E:\DATN\dataframe\train_file\97.txt,"Đầu tiên là SQL, một LƯU Ý RẤT TO mình để ở đây là:"
10072,E:\DATN\dataframe\train_file\97.txt,SQL không phải là một thứ gì đó nói về database và càng không phải là database.
10073,E:\DATN\dataframe\train_file\97.txt,SQL là Structure Query Language: dịch sang tiếng Việt nghĩa là ngôn ngữ... mà thôi đừng dịch làm gì.
10074,E:\DATN\dataframe\train_file\97.txt,"Cụ thể hơn, SQL là ngôn ngữ cho phép chúng ta viết các câu lệnh để thao tác với dữ liệu trong database:"
10075,E:\DATN\dataframe\train_file\97.txt,"SELECT id, name FROM product"
10076,E:\DATN\dataframe\train_file\97.txt,DELETE FROM product WHERE id = 10
10077,E:\DATN\dataframe\train_file\97.txt,"Không chỉ SELECT, DELETE mà còn kha khá các câu lệnh khác nhưng tựu chung lại là trông nó sẽ giống như dưới: bao gồm nhiều keywords, syntax này nọ và các parameters."
10078,E:\DATN\dataframe\train_file\97.txt,Túm cái váy lại SQL là một ngôn ngữ vô cùng powerful để tương tác (insert/update/delete/join...) với data trong database.
10079,E:\DATN\dataframe\train_file\97.txt,Khi nói đến SQL vs NoSQL chúng ta ngầm hiểu đó là nói về 2 loại DBMS khác nhau.
10080,E:\DATN\dataframe\train_file\97.txt,"Relational database: MySQL, MSSQL, Postgres... Đây là những database thường sử dụng để lưu trữ dữ liệu có cấu trúc rõ ràng, có tính quan hệ với nhau và quan trọng nhất là sử dụng SQL để truy vấn data."
10081,E:\DATN\dataframe\train_file\97.txt,"Non-relational database:: MongoDB, Cassandra, DynamoDB... Hiểu một cách đơn giản nó ngược lại so với SQL."
10082,E:\DATN\dataframe\train_file\97.txt,"Đây là những database có khả năng lưu trữ dữ liệu phi cấu trúc, không cần thể hiện quan hệ ràng buộc với nhau, không sử dụng SQL để truy vấn data."
10083,E:\DATN\dataframe\train_file\97.txt,1.2) Database structure
10084,E:\DATN\dataframe\train_file\97.txt,"Chắc chắn từ thuở chân ướt chân ráo mới vào nghề, gần như 100% chúng ta bắt đầu với SQL và relational database."
10085,E:\DATN\dataframe\train_file\97.txt,"Trong relational database, data được tổ chức dưới dạng table bao gồm column (field) và row."
10086,E:\DATN\dataframe\train_file\97.txt,Chúng ta cần biết rõ data schema để tiến hành tạo column cho phù hợp.
10087,E:\DATN\dataframe\train_file\97.txt,"Ví dụ với table Product chứa thông tin của các sản phẩm bao gồm một vài column cơ bản như id, product_name, price, description."
10088,E:\DATN\dataframe\train_file\97.txt,"Khi có một sản phẩm mới thì thêm một record vào table Product với các thông tin id, name, price, description."
10089,E:\DATN\dataframe\train_file\97.txt,Nếu sản phẩm mới không có thông tin description cũng chẳng phải vấn đề gì lớn lắm.
10090,E:\DATN\dataframe\train_file\97.txt,"Nhưng nếu sản phẩm mới có thêm một vài extra data như tags, manufatured date... thì đúng là khó rồi."
10091,E:\DATN\dataframe\train_file\97.txt,"Thực ra cũng không khó lắm, chỉ cần tạo thêm column mới."
10092,E:\DATN\dataframe\train_file\97.txt,"Ok, vậy nếu tiếp tục có 1 sản phẩm khác lại thêm vài extra data khác thì sao, và cứ liên tục như vậy... thì đúng là.. khó vẫn hoàn khó."
10093,E:\DATN\dataframe\train_file\97.txt,"Ngoài ra, các sản phẩm không có extra data thì giá trị của các column đó sẽ là null, là empty."
10094,E:\DATN\dataframe\train_file\97.txt,Đại khái trông sẽ như này:
10095,E:\DATN\dataframe\train_file\97.txt,"Như vậy với relational database, ta cần xác định rõ cấu trúc của data được lưu vào database hay nói cách khác là define clearly data schema và nó cũng là điều cực kì quan trọng."
10096,E:\DATN\dataframe\train_file\97.txt,Vì toàn bộ các record (row) trong table đều phải tuân thủ theo các column đã được define và chỉ có thể thực hiện thao tác với data theo dạng đó (table/row/column).
10097,E:\DATN\dataframe\train_file\97.txt,Dù product có extra field hay không thì cũng đều cần đưa về một format để insert vào table.
10098,E:\DATN\dataframe\train_file\97.txt,"Nếu có giá trị thì lưu giá trị, nếu không có thì lưu null, chẳng thể bỏ đi được."
10099,E:\DATN\dataframe\train_file\97.txt,1.3) Relation
10100,E:\DATN\dataframe\train_file\97.txt,Một điều quan trọng khác trong thế giới relational database là không chỉ thao tác với một table mà có thể với nhiều table khác và những table này cũng có thể có relation (quan hệ).
10101,E:\DATN\dataframe\train_file\97.txt,"Ví dụ có 3 tables User, Order và Product đại diện cho 3 thứ quan hệ với nhau: khách hàng, đơn hàng và sản phẩm."
10102,E:\DATN\dataframe\train_file\97.txt,User: lưu thông tin khách hàng.
10103,E:\DATN\dataframe\train_file\97.txt,Product: lưu thông tin về sản phẩm.
10104,E:\DATN\dataframe\train_file\97.txt,Order: lưu thông tin đơn hàng mà khách hàng đã đặt.
10105,E:\DATN\dataframe\train_file\97.txt,"Một user có thể có nhiều order, và một product có thể thuộc nhiều order khác nhau."
10106,E:\DATN\dataframe\train_file\97.txt,"Trực tiếp tạo nên sự liên quan giữa user, product và order."
10107,E:\DATN\dataframe\train_file\97.txt,Từ đó chúng ta có thể tạo một kết nối từ hai thứ tưởng chừng không liên quan nhưng lại rất lan quyên đến nhau là user và product.
10108,E:\DATN\dataframe\train_file\97.txt,Trông thế này:
10109,E:\DATN\dataframe\train_file\97.txt,1.4) Types of relation
10110,E:\DATN\dataframe\train_file\97.txt,"Phần này chắc chắn đã quá quen thuộc, không cần trình bày dài dòng."
10111,E:\DATN\dataframe\train_file\97.txt,Tuy nhiên mình vẫn muống đưa vào vì nó chính là điểm mạnh của SQL và relational database.
10112,E:\DATN\dataframe\train_file\97.txt,Có 3 loại relation cơ bản là:
10113,E:\DATN\dataframe\train_file\97.txt,One to One.
10114,E:\DATN\dataframe\train_file\97.txt,One to Many.
10115,E:\DATN\dataframe\train_file\97.txt,Many to Many.
10116,E:\DATN\dataframe\train_file\97.txt,1.4.1) One to One
10117,E:\DATN\dataframe\train_file\97.txt,"Ví dụ có 2 table là UserInfo: lưu thông tin chung như tên, tuổi, giới tính... và UserContact: lưu thông tin liên lạc."
10118,E:\DATN\dataframe\train_file\97.txt,Một user chỉ có một record ở table UserInfo và related đến một record ở table UserContact thông qua contact_id.
10119,E:\DATN\dataframe\train_file\97.txt,Có thể một số bạn sẽ đặt câu hỏi sao không gộp chung thành một table cho đơn giản mà phải tách làm 2 table và quan hệ One to One làm gì cho phức tạp?
10120,E:\DATN\dataframe\train_file\97.txt,Có 2 lí do chính cho việc này:
10121,E:\DATN\dataframe\train_file\97.txt,"Khách quan: tăng tốc độ thao tác (insert/delete/update/select) với data, tất nhiên nó là rất nhỏ và chỉ phát huy tác dụng khi table có số lượng record cực lớn."
10122,E:\DATN\dataframe\train_file\97.txt,Nhưng vì sao lại tăng tốc độ?
10123,E:\DATN\dataframe\train_file\97.txt,Chúng ta cần hiểu cơ chế database lưu trữ data và cách thức data được lấy lên từ disk thế nào (có thể tìm hiểu kĩ hơn ở  của mình nhé).
10124,E:\DATN\dataframe\train_file\97.txt,Chủ quan: làm cho database trông clear hơn và phục vụ đúng mục đích hơn.
10125,E:\DATN\dataframe\train_file\97.txt,"Nếu gộp cả 2 table vào thì có tới 20 columns chẳng hạn, nhưng nếu tách ra 3 - 4 table phục vụ cho từng mục đích khác nhau thì số lượng columns chỉ còn 5 - 6."
10126,E:\DATN\dataframe\train_file\97.txt,"Ví dụ có những lúc chỉ cần thông tin liên lạc để gửi mail thì select từ table UserContact, hoặc hiển thị profile thì chỉ cần UserInfo."
10127,E:\DATN\dataframe\train_file\97.txt,1.4.2) One to Many
10128,E:\DATN\dataframe\train_file\97.txt,Một ngày đẹp trời user muốn thêm địa chỉ và số điện thoại mới nhưng không muốn bỏ địa chỉ cũ.
10129,E:\DATN\dataframe\train_file\97.txt,Sử dụng 2 table như trên thì đúng là.. hơi khoai.
10130,E:\DATN\dataframe\train_file\97.txt,Nếu bạn là tín đồ của Shopee thì sẽ thấy khi order chúng ta có thể chọn địa chỉ giao hàng trong một danh sách các địa chỉ từ trước đó hoặc được tạo mới.
10131,E:\DATN\dataframe\train_file\97.txt,Mà chẳng cần là tín đồ Shopee cũng biết khi design system là phải nghĩ đến điều này.
10132,E:\DATN\dataframe\train_file\97.txt,Có nghĩa là một user hoàn toàn có thể có một hoặc nhiều địa chỉ khác nhau.
10133,E:\DATN\dataframe\train_file\97.txt,"Đó là ví dụ của One to Many relation, trông nó dư lày:"
10134,E:\DATN\dataframe\train_file\97.txt,1.4.3) Many to Many
10135,E:\DATN\dataframe\train_file\97.txt,"Cuối cùng là Many to Many relation, rất phổ biến trong đời sống thực."
10136,E:\DATN\dataframe\train_file\97.txt,"Ví dụ một đơn hàng có thể có nhiều sản phẩm, và cùng mã sản phẩm đó cũng có thể nằm trong nhiều đơn hàng khác nhau."
10137,E:\DATN\dataframe\train_file\97.txt,Vậy thể hiện nó trên database với table như thế nào?
10138,E:\DATN\dataframe\train_file\97.txt,Nếu chỉ có 2 table là Order và Product thì có 2 cách như sau:
10139,E:\DATN\dataframe\train_file\97.txt,Mỗi table sẽ có thêm reference đến table kia thông qua id.
10140,E:\DATN\dataframe\train_file\97.txt,Nếu có 3 orders và 3 products thì cần tổng cộng tới 9 records ở mỗi table (bao gồm cả duplicate data) để thể hiện quan hệ này...
10141,E:\DATN\dataframe\train_file\97.txt,Mỗi table có thêm một column để lưu list các reference_id đến table kia...
10142,E:\DATN\dataframe\train_file\97.txt,Cả 2 cách trên đều stupid nên các engineer đi trước có cách khác là tạo một table trung gian lưu quan hệ của order và product.
10143,E:\DATN\dataframe\train_file\97.txt,Trông nó như này:
10144,E:\DATN\dataframe\train_file\97.txt,Thêm một bảng nhưng so với 2 cách trên thì.. perfect hơn nhiều.
10145,E:\DATN\dataframe\train_file\97.txt,"Không duplicate data, mỗi table chỉ có đúng 3 orders và 3 products, relation lúc này chuyển sang table trung gian là OrderProduct."
10146,E:\DATN\dataframe\train_file\97.txt,1.5) Finalize
10147,E:\DATN\dataframe\train_file\97.txt,"Chốt lại, SQL được sử dụng để tương tác với data của relation database và có 2 tính chất cực kì quan trọng:"
10148,E:\DATN\dataframe\train_file\97.txt,Strict schema: data được lưu trữ tại các table có tính chất cố định và cần được define từ trước.
10149,E:\DATN\dataframe\train_file\97.txt,Relational data: data được lưu trữ phân tán trên nhiều table khác nhau và kết nối với nhau thông qua relation và SQL là thứ dùng để tương tác với relation đó (JOIN).
10150,E:\DATN\dataframe\train_file\97.txt,"Càng nhiều data phân tán trên nhiều table khác nhau thì SQL query càng dài, nhưng nó chính là điểm mạnh của SQL."
10151,E:\DATN\dataframe\train_file\97.txt,2) NoSQL
10152,E:\DATN\dataframe\train_file\97.txt,"SQL thì học nhiều nghe nhiều lắm rồi, còn NoSQL thì sao?"
10153,E:\DATN\dataframe\train_file\97.txt,"Thực ra nó cũng không phải quá là mới mẻ, nhưng nó vẫn là mới so với những người chưa nghe, chưa làm hoặc chưa thành thục về chúng."
10154,E:\DATN\dataframe\train_file\97.txt,2.1) NoSQL là gì?
10155,E:\DATN\dataframe\train_file\97.txt,"Cái tên nói lên tất cả, No trong NoSQL có thể hiểu theo 2 cách sau:"
10156,E:\DATN\dataframe\train_file\97.txt,Không sử dụng SQL.
10157,E:\DATN\dataframe\train_file\97.txt,No relation.
10158,E:\DATN\dataframe\train_file\97.txt,"Như vậy NoSQL nói đến những loại non-relational database lưu trữ data KHÔNG theo dạng table - column - row, data KHÔNG thể hiện quan hệ với nhau, và cũng KHÔNG sử dụng SQL để tương tác với data."
10159,E:\DATN\dataframe\train_file\97.txt,Vậy nếu muốn tương tác với data trong non-relational database thì làm cách nào?
10160,E:\DATN\dataframe\train_file\97.txt,Mỗi database khác nhau sẽ có những cách thức khác nhau để làm điều này.
10161,E:\DATN\dataframe\train_file\97.txt,"Ví dụ với Elasticsearch là các REST APIs, Redis là các command line..."
10162,E:\DATN\dataframe\train_file\97.txt,"Trong thế giới NoSQL - non-relational database, tính đến thời điểm hiện tại có 4 mô hình lưu trữ data là:"
10163,E:\DATN\dataframe\train_file\97.txt,"Document database: , ..."
10164,E:\DATN\dataframe\train_file\97.txt,"Key - value store: , , ..."
10165,E:\DATN\dataframe\train_file\97.txt,"Wide column: , , ..."
10166,E:\DATN\dataframe\train_file\97.txt,"Graph database: , , ..."
10167,E:\DATN\dataframe\train_file\97.txt,"Nếu đi sâu vào từng model thì dài quá, mình sẽ đề cập trong bài viết khác."
10168,E:\DATN\dataframe\train_file\97.txt,"Về cơ bản cả 4 loại đều có những phần chung về cơ chế lưu trữ và tổ chức data để phân biệt với relation database, do vậy mình sẽ chọn một loại phổ biến và tiêu biểu nhất là MongoDB để lấy ví dụ về NoSQL."
10169,E:\DATN\dataframe\train_file\97.txt,2.2) MongoDB tổ chức data thế nào?
10170,E:\DATN\dataframe\train_file\97.txt,"Với SQL, ta có database Shop bao gồm các table User, Product, Order với mỗi table bao gồm các row (record) có nhiều column đại diện cho thông tin của một loại data."
10171,E:\DATN\dataframe\train_file\97.txt,"Sang đến NoSQL sẽ không còn khái niệm table, column, record nữa mà thay vào đó cụ thể với MongoDB là collection, document, key, value."
10172,E:\DATN\dataframe\train_file\97.txt,Trông nó sẽ như này:
10173,E:\DATN\dataframe\train_file\97.txt,"Dễ dàng nhận thấy collection tương đương với table, document tương đương với record (row), JSON key tương đương với column trong mối tương quan giữa SQL và NoSQL."
10174,E:\DATN\dataframe\train_file\97.txt,Ngoài ra một điều đặc biệt khác là document tổ chức data dưới dạng JSON và KHÔNG cần tuân theo một schema cố định.
10175,E:\DATN\dataframe\train_file\97.txt,"Điều đó nghĩa là có thể có nhiều documents khác schema, khác structure, khác field trong cùng một collection."
10176,E:\DATN\dataframe\train_file\97.txt,Như vậy có thể hiểu rằng trong cùng collection User hoàn toàn có thể có document của Order.
10177,E:\DATN\dataframe\train_file\97.txt,Nhưng không ai làm như thế cả!
10178,E:\DATN\dataframe\train_file\97.txt,Việc các document khác schema là trong trường hợp có các extra field như ví dụ trên với SQL thì việc tổ chức data sẽ gọn nhẹ hơn nhiều.
10179,E:\DATN\dataframe\train_file\97.txt,Trông nó như này:
10180,E:\DATN\dataframe\train_file\97.txt,"Mặc dù nó giúp tiết kiệm không gian và làm cho data structure linh động hơn, không cần phải sửa schema khi bỗng dưng có một document đặc biệt có vài extra field (vì làm gì có schema mà sửa), nhưng chính nó cũng là nhược điểm, vì không có schema nên khó khăn trong việc dự đoán format của data."
10181,E:\DATN\dataframe\train_file\97.txt,Nhưng nếu chọn NoSQL ngay từ đầu thì không cần quan tâm lắm đến vấn đề này vì nó đã có ưu điểm quá to là super flexible data structure.
10182,E:\DATN\dataframe\train_file\97.txt,"Ví dụ khi build software sử dụng SQL chạy rất ổn định, mượt mà."
10183,E:\DATN\dataframe\train_file\97.txt,"Nhưng đến một lúc nào đó muốn hiển thị nhiều thông tin hơn, hay cụ thể là muốn lưu trữ và query nhiều data hơn cho một vài user trong User table, nếu sử dụng SQL thì chỉ có nước thêm column, sửa entity."
10184,E:\DATN\dataframe\train_file\97.txt,Như vậy toàn bộ user trong User table đều được thêm column.
10185,E:\DATN\dataframe\train_file\97.txt,Nhưng nếu sử dụng NoSQL thì... tuyệt vời rồi.
10186,E:\DATN\dataframe\train_file\97.txt,"User nào cần specific field nào thì cứ thêm thôi, những user khác không bị ảnh hưởng."
10187,E:\DATN\dataframe\train_file\97.txt,2.3) Relation
10188,E:\DATN\dataframe\train_file\97.txt,"Chúng ta thường nghe và hiểu NoSQL hay no-relational database nghĩa là nói về việc các collections (Document database) không có mối quan hệ nào với nhau (phi quan hệ), ngược lại với SQL."
10189,E:\DATN\dataframe\train_file\97.txt,Vậy nếu mối quan hệ User - Order - Product như ví dụ trên với SQL thì thể hiện trong NoSQL như thế nào vì trong thực tế cả 3 vẫn có mối liên quan đến nhau?
10190,E:\DATN\dataframe\train_file\97.txt,"Trên lí thuyết, ta vẫn có thể set up relation giữa các document giống như SQL bằng cách thêm foreign key."
10191,E:\DATN\dataframe\train_file\97.txt,Nhưng vấn đề là không thể sử dụng SQL để join và query data được nên việc tạo FK như vậy làm sai lệch đi bản chất của NoSQL là no-relation.
10192,E:\DATN\dataframe\train_file\97.txt,Idea để giải quyết vấn đề này của NoSQL là gom nhóm các data có liên quan với nhau vào cùng một chỗ và chấp nhận việc duplicate.
10193,E:\DATN\dataframe\train_file\97.txt,"Ví dụ muốn hiển thị order cùng với một vài thông tin cơ bản của user và product, lúc này collection Order không chỉ chứa thông tin về order mà còn chứa thêm các thông tin cần thiết của user (id, name, email) và product (id, price)."
10194,E:\DATN\dataframe\train_file\97.txt,Trông như này:
10195,E:\DATN\dataframe\train_file\97.txt,"Như vậy vẫn collection User, Product với các thông tin chi tiết, nhưng chúng ta không cần query relation đó vì nó đã được duplicate những field cần thiết sang collection Order."
10196,E:\DATN\dataframe\train_file\97.txt,"Và đây chính là idea của NoSQL, càng ít các quan hệ thì tốc độ và hiệu quả query càng nhanh (không cần join)."
10197,E:\DATN\dataframe\train_file\97.txt,"No silver bullet, chẳng có gì là hoàn hảo, và cũng chính ưu điểm trên là nhược điểm của NoSQL, phải chấp nhận data bị duplicate ở nhiều nơi."
10198,E:\DATN\dataframe\train_file\97.txt,Update product data ở Product cũng kéo theo việc update product ở Order.
10199,E:\DATN\dataframe\train_file\97.txt,"Nhưng nếu việc update hiếm khi xảy ra, và là read heavy (read nhiều hơn write) thì nó vẫn là một điều tuyệt vời ông mặt zời."
10200,E:\DATN\dataframe\train_file\97.txt,"Một lưu ý nữa không phải là hoàn toàn không có relation, sẽ có những trường hợp vẫn cần relation nhưng cần hạn chế nhất có thể (no relation or less relation as possible)."
10201,E:\DATN\dataframe\train_file\97.txt,3) SQL vs NoSQL
10202,E:\DATN\dataframe\train_file\97.txt,"Cuối cùng là so sánh giữa SQL và NoSQL để... hiểu điểm mạnh, điểm yếu của từng loại mà áp dụng cho phù hợp."
10203,E:\DATN\dataframe\train_file\97.txt,Trên thực tế với những super big application / business đều áp dụng cả 2 loại SQL và NoSQL cho những data khác nhau với mục đích khác nhau.
10204,E:\DATN\dataframe\train_file\97.txt,Đừng so sánh để dìm hàng mà hãy so sánh để biết cách phát huy ưu điểm và hạn chế nhược điểm.
10205,E:\DATN\dataframe\train_file\97.txt,Không chỉ trong lĩnh vực này mà còn thực tế ngoài đời sống nữa nhé các tài năng trẻ.
10206,E:\DATN\dataframe\train_file\97.txt,3.1) Data schema
10207,E:\DATN\dataframe\train_file\97.txt,"Đầu tiên là về data schema, không cần bàn luận nhiều nữa vì 2 phần trên nói hết cả rồi."
10208,E:\DATN\dataframe\train_file\97.txt,"Với SQL, cấu trúc của table, column sẽ được define trước và phụ thuộc vào schema."
10209,E:\DATN\dataframe\train_file\97.txt,"Ưu điểm là chúng ta biết trước được data format, đồng thời nhược điểm là data không flexible."
10210,E:\DATN\dataframe\train_file\97.txt,Khó để flexible thôi chứ không phải không thể.
10211,E:\DATN\dataframe\train_file\97.txt,Bằng cách áp dụng EAV model chúng ta có thể dễ dàng biến Relational database strict schema sang dynamic & flexible data struct và cái giá phải trả đó là tốc độ query và sự tường minh trong design.
10212,E:\DATN\dataframe\train_file\97.txt,"Lại thuật ngữ mới, EAV model là gì?"
10213,E:\DATN\dataframe\train_file\97.txt,Chờ bài sau nhé hoặc bạn có thể tìm đọc thêm về nó.
10214,E:\DATN\dataframe\train_file\97.txt,"Ngược lại, nhược điểm và ưu điểm với data schema của SQL chính là ưu điểm và nhược điểm của NoSQL."
10215,E:\DATN\dataframe\train_file\97.txt,"NoSQL là schema-less, không tuân thủ theo một chuẩn data nào nên nó rất linh động trong việc mở rộng các record."
10216,E:\DATN\dataframe\train_file\97.txt,3.2) Relation and data structure
10217,E:\DATN\dataframe\train_file\97.txt,"Tiếp theo, relation là một ưu điểm rất mạnh của relational database vì nó sinh ra với mục đích đó."
10218,E:\DATN\dataframe\train_file\97.txt,Data trước khi lưu trữ sẽ được chuẩn hoá (normalize) và chia vào nhiều table khác nhau.
10219,E:\DATN\dataframe\train_file\97.txt,Các data relation đến nhau thông qua FK.
10220,E:\DATN\dataframe\train_file\97.txt,Việc update data chỉ cần diễn ra ở một table và các table còn lại không cần thay đổi gì cả.
10221,E:\DATN\dataframe\train_file\97.txt,"Với NoSQL và non-relational database, relation là thứ vô cùng xa xỉ, gần như không có hoặc nếu có thì là rất rất ít."
10222,E:\DATN\dataframe\train_file\97.txt,"Do đó, sử dụng NoSQL phải chấp nhận duplicate data và khi update data có thể phải thực hiện ở nhiều collections nhưng đổi lại là tốc độ read data nhanh hơn so với relational database vì không có join."
10223,E:\DATN\dataframe\train_file\97.txt,3.3) Scaling
10224,E:\DATN\dataframe\train_file\97.txt,"Để nói về scaling và replicate data chắc phải dành riêng một bài khác mới đủ, mình sẽ trình bày ngắn gọn nhất để chúng ta nắm được mấu chốt phần này."
10225,E:\DATN\dataframe\train_file\97.txt,Có 2 loại scaling là vertical scaling (scale theo chiều dọc) và horizontal scaling (scale theo chiều ngang).
10226,E:\DATN\dataframe\train_file\97.txt,"Ví dụ thế này, gia đình A có 3 nhân khẩu, ở căn biệt thự 300m2 cũng gọi là rộng rãi vch rồi."
10227,E:\DATN\dataframe\train_file\97.txt,"Thế rồi thời gian thấm thoát thôi qua, gia đình A tăng số lượng người từ 3 lên 5, lên 10, lên 20, lên 50 rồi đến cả trăm người."
10228,E:\DATN\dataframe\train_file\97.txt,Thế là một căn biệt thự không đủ.
10229,E:\DATN\dataframe\train_file\97.txt,Bây giờ có 2 phương án thế này:
10230,E:\DATN\dataframe\train_file\97.txt,Một là xây thêm tầng: nhưng xây bao nhiêu cho đủ.
10231,E:\DATN\dataframe\train_file\97.txt,"Mà xây thêm thì cũng chỉ có giới hạn, cùng lắm như toà Lanmark 81 là kinh lắm rồi."
10232,E:\DATN\dataframe\train_file\97.txt,Đây là ví dụ của vertical scaling.
10233,E:\DATN\dataframe\train_file\97.txt,"Với software, điều này tương tự với việc vẫn là con server đó nhưng ta cải thiện sức mạnh bằng cách tăng RAM, tăng CPU, chuyển từ HDD sang SSD."
10234,E:\DATN\dataframe\train_file\97.txt,"Hai là mua thêm nhà: trên lí thuyết đất đai có giới hạn, nhưng chỉ sợ thiếu tiền thôi chứ không sợ thiếu đất."
10235,E:\DATN\dataframe\train_file\97.txt,"Nếu không lo về tài chính thì cách này có vẻ ổn hơn cách đầu, gần như không giới hạn."
10236,E:\DATN\dataframe\train_file\97.txt,Và đây là ví dụ của horizontal scaling: phân tán dữ liệu trên nhiều server khác nhau thay vì chỉ dùng một server.
10237,E:\DATN\dataframe\train_file\97.txt,Vậy thì nó có liên quan gì đến SQL và NoSQL?
10238,E:\DATN\dataframe\train_file\97.txt,Ta cần hiểu rõ hơn về tính chất đặc thù của từng loại.
10239,E:\DATN\dataframe\train_file\97.txt,"Kim chỉ nam của relational database là relation, nhờ đó mới có thể sử dụng SQL để query data."
10240,E:\DATN\dataframe\train_file\97.txt,"Như vậy, nếu data được phân tán trên nhiều server khác nhau thì việc join data gần như bất khả thi hoặc cần những kĩ thuật phức tạp mới có thể làm được."
10241,E:\DATN\dataframe\train_file\97.txt,Vậy nên SQL và relational database chỉ phù hợp với vertical scaling.
10242,E:\DATN\dataframe\train_file\97.txt,Với NoSQL và non-relational database thì việc horizontal scaling trở nên dễ dàng hơn vì nó đã loại bỏ relation.
10243,E:\DATN\dataframe\train_file\97.txt,Mỗi record trong NoSQL đã có đủ thông tin cho chính nó và không cần join nên việc phân tán data (documents) ra nhiều server không gặp bất lợi gì.
10244,E:\DATN\dataframe\train_file\97.txt,Ngoài ra hoàn toàn có thể phân tán cả các records thuộc cùng một document ra nhiều nơi khác nhau (partition/sharding).
10245,E:\DATN\dataframe\train_file\97.txt,Vì vậy NoSQL scale đơn giản hơn rất nhiều cả vertical scale và horizontal scale.
10246,E:\DATN\dataframe\train_file\97.txt,Vẫn là câu nói quen thuộc chẳng có gì hoàn hảo 100%.
10247,E:\DATN\dataframe\train_file\97.txt,Nếu NoSQL distributed data ra nhiều server khác nhau thì lúc query data biết data nằm ở server nào để query?
10248,E:\DATN\dataframe\train_file\97.txt,"Ngoài ra, trong trường hợp tăng số lượng server thì data có được re-balance giữa các server không?"
10249,E:\DATN\dataframe\train_file\97.txt,Hoặc toàn bộ query chỉ tập trung vào một vài server thì xử lí thế nào?
10250,E:\DATN\dataframe\train_file\97.txt,"Vô vàn những câu hỏi hóc búa hiện lên, nhưng bài dài lắm rồi, để dành cho bài viết sau nhé."
10251,E:\DATN\dataframe\train_file\97.txt,Tạm thời ta chỉ cần hiểu rằng việc horizontal scale với NoSQL đơn giản hơn SQL nhiều.
10252,E:\DATN\dataframe\train_file\97.txt,3.4) Query speed
10253,E:\DATN\dataframe\train_file\97.txt,Phần mà ai cũng quan tâm đó là tốc độ query data.
10254,E:\DATN\dataframe\train_file\97.txt,Rất khó để nói rằng SQL hay NoSQL query nhanh hơn.
10255,E:\DATN\dataframe\train_file\97.txt,Phải phụ thuộc vào từng hoàn cảnh và lượng data cũng như data structure ta mới có thể trả lời rõ ràng được.
10256,E:\DATN\dataframe\train_file\97.txt,Nếu fetch data phức tạp với nhiều relation và có hàng nghìn queries 1 lúc thì SQL có tốc độ không tốt bằng NoSQL.
10257,E:\DATN\dataframe\train_file\97.txt,Nhưng nếu data được update thường xuyên và write > read thì việc sử dụng NoSQL chưa chắc đã cho tốc độ tốt hơn so với SQL.
10258,E:\DATN\dataframe\train_file\97.txt,"Cuối cùng, theo mình nghĩ việc quyết định lựa chọn SQL hay NoSQL hay cả 2 sẽ phụ thuộc vào 3 yếu tố sau:"
10259,E:\DATN\dataframe\train_file\97.txt,Business của dự án.
10260,E:\DATN\dataframe\train_file\97.txt,Dung lượng dữ liệu.
10261,E:\DATN\dataframe\train_file\97.txt,Kĩ năng của team.
10262,E:\DATN\dataframe\train_file\97.txt,Còn rất rất nhiều yếu tố khác và đã có vô vàn các bài viết về nó rồi nên mình không đề cập ở đây.
10263,E:\DATN\dataframe\train_file\97.txt,"Chốt lại, SQL cũng được mà NoSQL cũng được, điều quan trọng là bạn cần nắm rõ, hiểu kĩ và có thể xử lí mọi vấn đề liên quan đến nó là ok."
10264,E:\DATN\dataframe\train_file\97.txt,After credit
10265,E:\DATN\dataframe\train_file\97.txt,"Tên MongoDB bắt nguồn từ humongous nghĩa là to lớn, khổng lồ với ý nghĩa nó có thể chứa được một lượng rất rất lớn data."
10266,E:\DATN\dataframe\train_file\97.txt,"Cho những ai chưa biết ngoài SQL, NoSQL còn có một loại khác là NewSQL."
10267,E:\DATN\dataframe\train_file\97.txt,Và nó cũng đã xuất hiện cách đây 7-8 năm về trước rồi.
10268,E:\DATN\dataframe\train_file\97.txt,Cụ thể nó có khác gì so với SQL và NoSQL thì hẹn gặp trong bài viết khác nhé.
10269,E:\DATN\dataframe\train_file\98.txt,Đôi dòng về Pseudo Labeling trong Machine Learning
10270,E:\DATN\dataframe\train_file\98.txt,"Nhân một ngày đang hì hục với cái đồ án môn học mà chưa biết xử lý thế nào khi muốn cải tiến kết quả với dataset nhỏ, lại được ngồi nghe Seminar của anh Leader, mình có cảm hứng để viết bài viết này chia sẻ kiến thức cho chính bản thân cũng như mọi người về việc sử dụng pseudo labeling trong các bài toán Machine Learning."
10271,E:\DATN\dataframe\train_file\98.txt,Có thể nói việc sử dụng Pseudo Label có vai trò rất to lớn trong các vấn đề về small dataset.
10272,E:\DATN\dataframe\train_file\98.txt,"Hãy tưởng tượng bạn có một bài toán mà có cả dữ liệu có nhãn và không có nhãn, thì việc sử dụng pseudo label là một giải pháp tương đối ổn áp."
10273,E:\DATN\dataframe\train_file\98.txt,"Chúng ta bắt gặp ứng dụng của Pseudo labeling trong các app như Google photos khi nó nhận dạng các khuôn mặt trong ảnh, và tạo ra một tên gợi ý dựa trên những dữ liệu đã lưu trước đó."
10274,E:\DATN\dataframe\train_file\98.txt,Chúng ta cùng điểm qua một vài nội dung chính liên quan đến Pseudo Labeling nào!
10275,E:\DATN\dataframe\train_file\98.txt,Semi-Supervised Learning
10276,E:\DATN\dataframe\train_file\98.txt,"Chắc hẳn chúng ta đã quá quen thuộc với 2 cái tên Supervised Learning và Unsupervised Learning, phân biệt dễ nhất giữa chúng là dữ liệu bài toán có nhãn và không có nhãn."
10277,E:\DATN\dataframe\train_file\98.txt,Vậy Semi-Supervised Learning là gì?
10278,E:\DATN\dataframe\train_file\98.txt,Trước hết để mình dẫn dắt một chút.
10279,E:\DATN\dataframe\train_file\98.txt,"Yoshua Bengio's đã từng trả lời cho câu hỏi của Quora:""Why is Unsupervised Learning important?"
10280,E:\DATN\dataframe\train_file\98.txt,"Yoshua Bengio's trả lời nôm na như sau: Với học có giám sát, chúng ta dạy cho máy tính ""học"" như con người bằng các dữ liệu có nhãn."
10281,E:\DATN\dataframe\train_file\98.txt,Tuy nhiên đây không phải cách học có của con người.
10282,E:\DATN\dataframe\train_file\98.txt,"Ừ thì nhờ ngôn ngữ chúng ta có được các cái tên minh họa cho các sự vật hiện tượng, nhưng phần lớn những gì chúng ta quan sát ban đầu đều không được gán nhãn, ít nhất là lúc đầu."
10283,E:\DATN\dataframe\train_file\98.txt,"Việc đánh nhãn dữ liệu là vô cùng tốn kém và mất thời gian, đơn giản việc ứng dụng AI trong sinh học (tinh sinh học), để có được dữ liệu có nhãn cho các bài toán chuẩn đoán, yêu cầu phải là những người bác sĩ có chuyên môn."
10284,E:\DATN\dataframe\train_file\98.txt,Vậy giải pháp ở đây là gì?
10285,E:\DATN\dataframe\train_file\98.txt,Hiển nhiên là một cách sao cho:
10286,E:\DATN\dataframe\train_file\98.txt,Thuật toán Machine Learning hoạt động mà không cần nhãn dữ liệu (Unsupervised Learning).
10287,E:\DATN\dataframe\train_file\98.txt,Tự động gán nhãn dữ liệu hoặc sử dụng số lượng lớn dữ liệu không nhãn kết hợp số lượng nhỏ dữ liệu có nhãn (Chính là Semi-Supervised Learning).
10288,E:\DATN\dataframe\train_file\98.txt,Các bài toán khi chúng ta có một lượng lớn dữ liệu X nhưng chỉ một phần trong chúng được gán nhãn được gọi là Semi-Supervised Learning.
10289,E:\DATN\dataframe\train_file\98.txt,Những bài toán thuộc nhóm này nằm giữa hai nhóm Supervised và Unsupervised .
10290,E:\DATN\dataframe\train_file\98.txt,Dữ liệu không nhãn có ích gì?
10291,E:\DATN\dataframe\train_file\98.txt,Dữ liệu có nhãn tương đối đắt và khó lấy hơn rất nhiều so với dữ liệu không có nhãn.
10292,E:\DATN\dataframe\train_file\98.txt,Dữ liệu không có nhãn cải thiện độ chắc chắn của mô hình bằng ranh giới quyết định chính xác hơn.
10293,E:\DATN\dataframe\train_file\98.txt,Pseudo Labeling là gì?
10294,E:\DATN\dataframe\train_file\98.txt,"Để hiểu qua Pseudo Labeling là gì, mời bạn đọc xem qua hình vẽ dưới đây"
10295,E:\DATN\dataframe\train_file\98.txt,"Pseudo labeling hiểu đơn giản là bạn dùng một mô hình sau khi huấn luyện với dữ liệu có nhãn để dự đoán “nhãn giả” cho các dữ liệu không nhãn, sau đó sử dụng dữ liệu có nhãn ban đầu với dữ liệu có nhãn giả vừa tạo để huấn luyện lại mô hình."
10296,E:\DATN\dataframe\train_file\98.txt,"Bổ sung một chút là khi tạo các nhãn giả, lọc ra những dự đoán có độ tin cậy cao (ví dụ như xác suất đáng tin cậy, cao hơn 1 ngưỡng (threshold) nào đó) Pseudo Labeling là một phương pháp hiệu quả giúp cải thiện độ chính xác của bài toán phân loại, đặc biệt là trong trường hợp ít dữ liệu."
10297,E:\DATN\dataframe\train_file\98.txt,"là một idea tác giả đã sử dụng pseudo-labeling để chiến thắng trong cuộc thi ""Santander's Customer Transaction competition""."
10298,E:\DATN\dataframe\train_file\98.txt,"Bạn đọc có thể tham khảo thêm source code về Pseudo Labeling ví dụ , được implement bằng pytorch bởi tác giả Anirudh Shenoy"
10299,E:\DATN\dataframe\train_file\98.txt,Một số lưu ý khi dùng Pseudo Labeling
10300,E:\DATN\dataframe\train_file\98.txt,"Không nên trộn lẫn dữ liệu có nhãn với dữ liệu nhãn giả, nên tách biệt dữ liệu nhãn thật và nhãn giả để ta có 2 hàm loss, với trọng số hàm loss đối với dữ liệu nhãn giả thấp hơn để làm giảm phần nào ảnh hưởng của dữ liệu nhãn giả."
10301,E:\DATN\dataframe\train_file\98.txt,Loss_per_batch = labeled_los_batch + weight * pseudolabel_loss_batch
10302,E:\DATN\dataframe\train_file\98.txt,"Bạn cũng có thể trộn lẫn 2 loại dữ liệu này để xem kết quả thế nào, sau cùng chúng ta sẽ đánh giá mô hình dự trên tập test"
10303,E:\DATN\dataframe\train_file\98.txt,Tóm lại
10304,E:\DATN\dataframe\train_file\98.txt,"Theo cá nhân mình thấy thì đay là một kỹ thuật tương đối đơn giản mà hiệu quả trong 1 số trường hợp lại tương đối cao, đặhc biệt trong các bài toán phân loại mà dữ liệu thì ít (phân loại 2,3 nhãn thì đẹp)."
10305,E:\DATN\dataframe\train_file\98.txt,"Cá nhân mình cũng đang thử trong đồ án môn học thử xem, có gì mình sẽ cập nhật kết quả cũng như nội dung đồ án trong các bài viết sau nhé."
10306,E:\DATN\dataframe\train_file\98.txt,Cảm ơn mọi người đã đọc đến những dòng cuối cùng này.
10307,E:\DATN\dataframe\train_file\98.txt,Cho mình một upvote và một vài comment để mình có động lực chia sẻ thêm nhé ^^
10308,E:\DATN\dataframe\train_file\99.txt,Viết Bot xem thời tiết trên Telegram bằng Java và Spring Boot
10309,E:\DATN\dataframe\train_file\99.txt,"Telegram là ứng dụng nhắn tin tập trung vào tốc độ và bảo mật, nó siêu nhanh, đơn giản và miễn phí."
10310,E:\DATN\dataframe\train_file\99.txt,"Bạn có thể sử dụng Telegram cùng lúc trên nhiều thiết bị, tin nhắn được đồng bộ đồng thời trên tất cả các thiết bị: điện thoại, máy tính bảng hay máy tính."
10311,E:\DATN\dataframe\train_file\99.txt,"Với Telegram, bạn có thể gửi tin nhắn, hình ảnh, video, file (bất kỳ loại nào từ doc, zip đến mp3...) cũng như tạo group lên tới 200.000 người hoặc tạo kênh để phát sóng nội dung đến số lượng khán giả không bị giới hạn."
10312,E:\DATN\dataframe\train_file\99.txt,"Bạn có thể gửi tin nhắn cho các số điện thoại có trong danh bạ, tìm người dùng theo username của họ."
10313,E:\DATN\dataframe\train_file\99.txt,"Telegram giống như sự kết hợp giữa SMS và email, có thể giải quyết tất cả những nhu cầu nhắn tin cá nhân hoặc công việc của bạn."
10314,E:\DATN\dataframe\train_file\99.txt,"Ngoài tất cả những tính năng trên, Telegram còn hỗ trợ các cuộc gọi thoại được mã hóa đầu cuối."
10315,E:\DATN\dataframe\train_file\99.txt,Bot Telegram là gì?
10316,E:\DATN\dataframe\train_file\99.txt,Bot Telegram là giống như một robot có sẵn trong ứng dụng nhằm giúp người dùng tạo lập và quản lý các bot.
10317,E:\DATN\dataframe\train_file\99.txt,Nếu bạn lần đầu biết đến Bot API Telegram thì hãy truy cập vào trang web này để biết thêm thông tin.
10318,E:\DATN\dataframe\train_file\99.txt,"Người dùng có thể điều khiển các bot để nhận thông báo và tin tức; tạo các công cụ tùy chỉnh; trải nghiệm trò chơi; tích hợp với các dịch vụ như Gmail Bot, GIF Bot, Wiki Bot,… Đặc biệt là sử dụng Bot Father để thực hiện tạo New Bot."
10319,E:\DATN\dataframe\train_file\99.txt,Việc cài đặt Bot không khó như nhiều người suy nghĩ.
10320,E:\DATN\dataframe\train_file\99.txt,Bạn có thể dễ dàng thực hiện việc này ngay cả khi bạn sử dụng điện thoại hay máy tính.
10321,E:\DATN\dataframe\train_file\99.txt,Hướng dẫn tạo Bot Telegram
10322,E:\DATN\dataframe\train_file\99.txt,"Sau khi đăng nhập với tai khoản Telegram, chúng ta truy cập đến đường dẫn ."
10323,E:\DATN\dataframe\train_file\99.txt,"Click vào button Start, màn hình sẽ hiển thị một list các command để có thể giao tiếp"
10324,E:\DATN\dataframe\train_file\99.txt,"Trong đoạn văn bản đó, bạn hãy nhấn /newbot – create a new bot."
10325,E:\DATN\dataframe\train_file\99.txt,"Tiếp theo, bạn nhập tên cho newbot của bạn tùy ý thích."
10326,E:\DATN\dataframe\train_file\99.txt,Nhấn Enter
10327,E:\DATN\dataframe\train_file\99.txt,"Tiếp theo, Botfather sẽ yêu cầu bạn nhập tên người dùng cho bot của bạn."
10328,E:\DATN\dataframe\train_file\99.txt,Botfather sẽ thông báo trên màn hình bạn đã tạo thành công new bot bao gồm đường link dẫn đến bot mới và mã HTTP API Telegram.
10329,E:\DATN\dataframe\train_file\99.txt,Xây dựng Bot xem thời tiết bằng Java và Spring Boot
10330,E:\DATN\dataframe\train_file\99.txt,Khởi tạo ứng dụng Spring Boot
10331,E:\DATN\dataframe\train_file\99.txt,Đầu tiên chúng ta cần khởi tạo ứng dụng Spring Boot mới tại đây:
10332,E:\DATN\dataframe\train_file\99.txt,Mục Project: chọn Gradle Project
10333,E:\DATN\dataframe\train_file\99.txt,Mục Language: chọn Java
10334,E:\DATN\dataframe\train_file\99.txt,"Mục Group: có thể nhập tuỳ ý, ở đây mình để mặc định là com.example"
10335,E:\DATN\dataframe\train_file\99.txt,"Mục Artifact: có thể nhập tuỳ ý, mình sẽ nhập là weatherbot"
10336,E:\DATN\dataframe\train_file\99.txt,Mục Name: đây là tên của ứng dụng.
10337,E:\DATN\dataframe\train_file\99.txt,Nhập weatherbot
10338,E:\DATN\dataframe\train_file\99.txt,"Mục Description: mô tả cho ứng dụng, có thể nhập tuỳ ý"
10339,E:\DATN\dataframe\train_file\99.txt,"Mục Package name: để mặc định là com.example.weatherbot, các bạn có thể thay đổi nếu muốn"
10340,E:\DATN\dataframe\train_file\99.txt,Mục Packaging: chọn Jar
10341,E:\DATN\dataframe\train_file\99.txt,Mục Java: 11.
10342,E:\DATN\dataframe\train_file\99.txt,Chung ta chọn Java 11 thay vì java 8 để có thể sử dụng HTTP Client API sẵn có trong JDK 11
10343,E:\DATN\dataframe\train_file\99.txt,Phần Dependencies: Chúng ta chọn thêm thư viện Lombok
10344,E:\DATN\dataframe\train_file\99.txt,"Sau đó nhấn Generate, projects sẽ được tải về máy."
10345,E:\DATN\dataframe\train_file\99.txt,Cấu hình cho Bot
10346,E:\DATN\dataframe\train_file\99.txt,Các thư viện sử dụng để xây dựng Bot:
10347,E:\DATN\dataframe\train_file\99.txt,TelegramBots: Thư viện java để tạo Telegram Bot.
10348,E:\DATN\dataframe\train_file\99.txt,Link github:
10349,E:\DATN\dataframe\train_file\99.txt,Simple Telegram Command Bot Spring Boot Starter: Project do mình tự xây dựng hỗ trợ tự động cấu hình nhanh ứng dụng Spring Boot điều khiển Bot Telegram tự động trả lời tin nhắn khi nhận được lệnh từ người dùng.
10350,E:\DATN\dataframe\train_file\99.txt,Link github:
10351,E:\DATN\dataframe\train_file\99.txt,Thêm dependencies vào file build.gradle:
10352,E:\DATN\dataframe\train_file\99.txt,	maven { url 'https://jitpack.io' }
10353,E:\DATN\dataframe\train_file\99.txt,	implementation 'org.telegram:telegrambots:6.1.0'
10354,E:\DATN\dataframe\train_file\99.txt,	implementation 'com.github.ndanhkhoi:simple-telegram-command-bot-spring-boot-starter:2022.10.05'
10355,E:\DATN\dataframe\train_file\99.txt,"Thêm cấu hình bot: tiến hành đổi tên file application.properties thành application.yml, sau đó thêm vào đoạn cấu hình sau:"
10356,E:\DATN\dataframe\train_file\99.txt,    username: {username}
10357,E:\DATN\dataframe\train_file\99.txt,    token: {token}
10358,E:\DATN\dataframe\train_file\99.txt,Trong đó:
10359,E:\DATN\dataframe\train_file\99.txt,{username}: là username của bot chúng ta đã khai báo ở trên với Bot's Father
10360,E:\DATN\dataframe\train_file\99.txt,{token}: là mã HTTP API Telegram mà Bot's Father đã sinh ra ở bước trên
10361,E:\DATN\dataframe\train_file\99.txt,{package}: là tên package chứa các class xử lý việc trả lời tin nhắn của Bot.
10362,E:\DATN\dataframe\train_file\99.txt,Ở đây chúng ta điền packge name đã khai báo lúc khởi tạo ứng dụng: com.example.weatherbot
10363,E:\DATN\dataframe\train_file\99.txt,"Tới bước này thì Bot của chúng ta đã có thể xử lý 1 số lệnh mặc định có sẵn như: /start, /help"
10364,E:\DATN\dataframe\train_file\99.txt,"Tiến hành chạy thử ứng dụng: mở terminal, chạy lệnh sau:"
10365,E:\DATN\dataframe\train_file\99.txt,./gradlew bootRun # hoặc gradlew bootRun nếu chạy trên CMD
10366,E:\DATN\dataframe\train_file\99.txt,Ứng dụng sau khi khởi chạy thành công
10367,E:\DATN\dataframe\train_file\99.txt,"Test thử Bot, mở Telegram, truy cập vào link Bot do Bot's Father sinh ra và nhấn thử các lệnh /start và /cmd:"
10368,E:\DATN\dataframe\train_file\99.txt,Viết hàm xử lý Bot trả lời tự động khi nhận được lệnh xem thời tiết
10369,E:\DATN\dataframe\train_file\99.txt,"Trong package com.example.weatherbot, tiến hành tạo 1 class mới với tên WeatherRoute"
10370,E:\DATN\dataframe\train_file\99.txt,public class WeatherRoute {
10371,E:\DATN\dataframe\train_file\99.txt,Trong đó:
10372,E:\DATN\dataframe\train_file\99.txt,: là annotation của Lombok hỗ trợ ghi log trong ứng dụng
10373,E:\DATN\dataframe\train_file\99.txt,": là annotation của Simple Telegram Command Bot Spring Boot Starter, đánh dấu đây là class chứa các hàm xử lý khi Bot nhận nhận được tin nhắn"
10374,E:\DATN\dataframe\train_file\99.txt,Thông tin thời tiết chúng ta sẽ tiến hành lấy từ  - một trang web open source cho phép lấy thông tin thời tiết hiện tại ở các địa điểm khác nhau.
10375,E:\DATN\dataframe\train_file\99.txt,Chi tiết trên
10376,E:\DATN\dataframe\train_file\99.txt,Do cần lấy thông tin thời tiết từ API nên chúng ta sẽ tiến hành khai báo 1 HTTP Client để sử dụng
10377,E:\DATN\dataframe\train_file\99.txt,   private static final HttpClient httpClient = HttpClient.newBuilder()
10378,E:\DATN\dataframe\train_file\99.txt,Sau đó tiền hành viết hàm xử lệnh cho Bot
10379,E:\DATN\dataframe\train_file\99.txt,"   @CommandDescription(""Xem thời tiết"")"
10380,E:\DATN\dataframe\train_file\99.txt,"    @CommandMapping(value = ""/weather"", parseMode = MessageParseMode.HTML, allowAllUserAccess = true)"
10381,E:\DATN\dataframe\train_file\99.txt,"    public String getCurrentWeather(Update update, @CommandBody(description = ""Tên thành phố"") String cityName) {"
10382,E:\DATN\dataframe\train_file\99.txt,        if (cityName != null && !cityName.isBlank()) {
10383,E:\DATN\dataframe\train_file\99.txt,"                String urlString = ""https://vi.wttr.in/"" + URLEncoder.encode(cityName, StandardCharsets.UTF_8) + ""?m?T?tqp0"";"
10384,E:\DATN\dataframe\train_file\99.txt,                HttpRequest request = HttpRequest.newBuilder()
10385,E:\DATN\dataframe\train_file\99.txt,"                HttpResponse<String> response = httpClient.send(request, HttpResponse.BodyHandlers.ofString());"
10386,E:\DATN\dataframe\train_file\99.txt,                String body = response.body();
10387,E:\DATN\dataframe\train_file\99.txt,"                String result = body.substring(body.indexOf(""<pre>"") + 5, body.indexOf(""</pre>""));"
10388,E:\DATN\dataframe\train_file\99.txt,"                return TelegramMessageUtils.wrapByTag(result, TelegramTextStyled.CODE);"
10389,E:\DATN\dataframe\train_file\99.txt,            catch (Exception ex) {
10390,E:\DATN\dataframe\train_file\99.txt,"                log.error(""Có lỗi xảy ra"", ex);"
10391,E:\DATN\dataframe\train_file\99.txt,"                return ""Có lỗi xảy ra"";"
10392,E:\DATN\dataframe\train_file\99.txt,"            return ""Vui lòng nhập tên thành phố !"
10393,E:\DATN\dataframe\train_file\99.txt,Các annotations của Simple Telegram Command Bot Spring Boot Starter sử dụng trong đoạn code này:
10394,E:\DATN\dataframe\train_file\99.txt,: mô tả cho lệnh
10395,E:\DATN\dataframe\train_file\99.txt,: đánh dấu phương thức này là phương thức xử lý khi Bot nhận được lệnh nào đó.
10396,E:\DATN\dataframe\train_file\99.txt,"Thuộc tính value = ""/weather"" cho biết phương thức này sẽ xử lý lệnh /weather, parseMode = MessageParseMode.HTML đánh dấu tin nhắn phản hồi sẽ được gửi dạng HTML, allowAllUserAccess = true cho phép lệnh này có thể được gọi bởi tất cả các user"
10397,E:\DATN\dataframe\train_file\99.txt,: Đánh dấu param này sẽ lưu giá trị của đối số truyền cho lệnh
10398,E:\DATN\dataframe\train_file\99.txt,Kết quả trả về của hàm sẽ là nội dung tin nhắn được phản hồi cho người dùng.
10399,E:\DATN\dataframe\train_file\99.txt,Nội dung class WeatherRoute sau khi hoàn thiện:
10400,E:\DATN\dataframe\train_file\99.txt,public class WeatherRoute {
10401,E:\DATN\dataframe\train_file\99.txt,    private static final HttpClient httpClient = HttpClient.newBuilder()
10402,E:\DATN\dataframe\train_file\99.txt,"    @CommandDescription(""Xem thời tiết"")"
10403,E:\DATN\dataframe\train_file\99.txt,"    @CommandMapping(value = ""/weather"", useHtml = true, allowAllUserAccess = true)"
10404,E:\DATN\dataframe\train_file\99.txt,"    public String getCurrentWeather(Update update, @CommandBody(description = ""Tên thành phố"") String cityName) {"
10405,E:\DATN\dataframe\train_file\99.txt,        if (cityName != null && !cityName.isBlank()) {
10406,E:\DATN\dataframe\train_file\99.txt,"                String urlString = ""https://vi.wttr.in/"" + URLEncoder.encode(cityName, StandardCharsets.UTF_8) + ""?m?T?tqp0"";"
10407,E:\DATN\dataframe\train_file\99.txt,                HttpRequest request = HttpRequest.newBuilder()
10408,E:\DATN\dataframe\train_file\99.txt,"                HttpResponse<String> response = httpClient.send(request, HttpResponse.BodyHandlers.ofString());"
10409,E:\DATN\dataframe\train_file\99.txt,                String body = response.body();
10410,E:\DATN\dataframe\train_file\99.txt,"                String result = body.substring(body.indexOf(""<pre>"") + 5, body.indexOf(""</pre>""));"
10411,E:\DATN\dataframe\train_file\99.txt,"                return TelegramMessageUtils.wrapByTag(result, TelegramTextStyled.CODE);"
10412,E:\DATN\dataframe\train_file\99.txt,            catch (Exception ex) {
10413,E:\DATN\dataframe\train_file\99.txt,"                log.error(""Có lỗi xảy ra"", ex);"
10414,E:\DATN\dataframe\train_file\99.txt,"                return ""Có lỗi xảy ra"";"
10415,E:\DATN\dataframe\train_file\99.txt,"            return ""Vui lòng nhập tên thành phố !"
10416,E:\DATN\dataframe\train_file\99.txt,Tiến hành chạy lại ứng dụng:
10417,E:\DATN\dataframe\train_file\99.txt,./gradlew bootRun # hoặc gradlew bootRun nếu chạy trên CMD
10418,E:\DATN\dataframe\train_file\99.txt,Test thử Bot:
10419,E:\DATN\dataframe\train_file\99.txt,Truy cập vào bot và chat lệnh sau:
10420,E:\DATN\dataframe\train_file\99.txt,/weather Cần Thơ
10421,E:\DATN\dataframe\train_file\99.txt,Kết quả như sau:
10422,E:\DATN\dataframe\train_file\99.txt,Như vậy là chúng ta đã tạo xong Bot Chat Telegram đơn giản cho phép xem thông tin thời tiết hiện tại theo địa điểm.
10423,E:\DATN\dataframe\train_file\99.txt,Các bạn có thể phát triển thêm cấc chức năng khác cho Bot bằng cách thêm các hàm  để xử lý các lệnh khác.
10424,E:\DATN\dataframe\train_file\99.txt,"Ngoài ra  còn cung cấp các tuỳ chọn khác như gửi file, gửi voice chat, phân quyền user gọi lệnh, .... Mình sẽ viết cụ thể hơn vào các bài sau."
10425,E:\DATN\dataframe\train_file\99.txt,Cảm ơn các bạn đã theo dõi.
10426,E:\DATN\dataframe\train_file\99.txt,See you next time!
10427,E:\DATN\dataframe\train_file\99.txt,Các nguồn tham khảo:
